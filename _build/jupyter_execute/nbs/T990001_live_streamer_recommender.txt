import pandas as pd
import numpy as np
from datetime import datetime

import seaborn as sns
import matplotlib.pyplot as plt
%matplotlib inline

import plotly.express as px

import random

from sklearn.model_selection import train_test_split as train_test_split_sk
from sklearn.cluster import KMeans

!pip install scikit-surprise
from surprise.model_selection.search import GridSearchCV
from surprise import Reader,Dataset, accuracy,SVD, SVDpp, SlopeOne, NMF, NormalPredictor, KNNBaseline, KNNBasic, KNNWithMeans, KNNWithZScore, BaselineOnly, CoClustering
from surprise.model_selection import cross_validate, train_test_split

!pip install optuna
import optuna

!pip install implicit
import implicit

import scipy.sparse as sparse


#Individual Channel streams information dataset
df_channel = pd.read_csv('/content/drive/MyDrive/kumu_data/kumu_channel_db.csv')

#Watchlog for both gameshow and livestreams of the users dataset
df_gameshow = pd.read_csv('/content/drive/MyDrive/kumu_data/kumu_gameshow_watchlog_db.csv')
df_ls1 = pd.read_csv('/content/drive/MyDrive/kumu_data/kumu_livestream_watchlog_db_p1.csv')
df_ls2 = pd.read_csv('/content/drive/MyDrive/kumu_data/kumu_livestream_watchlog_db_p2.csv')

#Relationship dataset between users and streamers
df_rel = pd.read_csv('/content/drive/MyDrive/kumu_data/kumu_reco_dataset.csv')


#Concatenating the two separated livestream watchlog because of the separation due to file size contraints
df_livestream = pd.concat([df_ls1,df_ls2],axis=0)
df_livestream = df_livestream.rename(columns={'viewer_id':'user_id'})

#Concatenating the livestream watchlog and gameshow watchlog
df_all = pd.concat([df_livestream,df_gameshow],axis=0)

#Summing up those entries with the same User_id and channel_ID
df_all = df_all.groupby(['user_id','channel_id']).agg({'duration':sum}).reset_index()


df_all.head(5)

df_channel.head(5)

df_channel['live_day'] = df_channel['live_start_time'].apply(lambda x: pd.to_datetime(x,format='%Y-%m-%d %H:%M:%S %Z').strftime('%A'))

#joining the channel df to get the details of every channel_id
df = pd.merge(df_all,df_channel,how='left',on='channel_id')
df = df.rename(columns={'duration_x':'user_duration','duration_y':'total_stream_duration'})

df.head()

plt.figure(figsize=(16,9))
sns.set_style('darkgrid')
sns.kdeplot(df['user_duration'], shade=True, color='r')
plt.title('Distribution Plot of the Watch Durations of the Users')
plt.xlabel('user_watch_duration (s)')

df['user_duration'].describe()

#Skewness and kurtosis of the watch durations
print('Skewness: %f' % df['user_duration'].skew())
print('Kurtosis: %f' % df['user_duration'].kurtosis())

df_day = df.groupby(['live_day']).agg({'user_id': lambda x: x.nunique(),'streamer_id': lambda y: y.nunique(),'user_duration':sum}).reset_index()
df_day = df_day.rename(columns={'user_id':'total_unique_viewers','streamer_id':'total_unique_streamers','user_duration':'total_watch_duration'})

df_day

g, axes = plt.subplots(1,3, figsize=(20,8))
sns.set_style('dark')
sns.barplot(x='live_day', y='total_unique_viewers', order=['Monday','Tuesday','Wednesday','Thursday','Friday','Saturday','Sunday'],data=df_day,ax=axes[0])
label1 = axes[0].set_xticklabels(axes[0].get_xticklabels(),rotation=45)

sns.barplot(x='live_day', y='total_unique_streamers', order=['Monday','Tuesday','Wednesday','Thursday','Friday','Saturday','Sunday'],data=df_day,ax=axes[1])
label2 = axes[1].set_xticklabels(axes[1].get_xticklabels(),rotation=45)
sns.barplot(x='live_day', y='total_watch_duration', order=['Monday','Tuesday','Wednesday','Thursday','Friday','Saturday','Sunday'],data=df_day,ax=axes[2])
label3 = axes[2].set_xticklabels(axes[2].get_xticklabels(),rotation=45)


plt.figure(figsize=(10,6))
sns.set_style('darkgrid')
sns.scatterplot(x='like_count',y='comment_count',data=df_channel,hue='live_day')

df_channel['engagement_count']=df_channel['like_count']+df_channel['comment_count']

days = ['Monday','Tuesday','Wednesday','Thursday','Friday','Saturday','Sunday']
g, axes = plt.subplots(1,2, figsize=(16,14))
sns.set_style('darkgrid')
sns.boxplot(x='live_day',y='engagement_count',data=df_channel,order=days,ax=axes[0])
sns.boxplot(x='live_day',y='diamonds',data=df_channel,order=days,ax=axes[1])

g, axes = plt.subplots(1,3, figsize=(20,8))
sns.set_style('darkgrid')
sns.scatterplot(x='duration',y='engagement_count',data=df_channel,hue='live_day',ax=axes[0])
sns.scatterplot(x='duration',y='diamonds',data=df_channel,hue='live_day',ax=axes[1])
sns.scatterplot(x='engagement_count',y='diamonds',data=df_channel,hue='live_day',ax=axes[2])

g, axes = plt.subplots(1,2, figsize=(20,8))
sns.set_style('darkgrid')
sns.scatterplot(x='total_viewer',y='engagement_count',data=df_channel,hue='live_day',ax=axes[0])
sns.scatterplot(x='total_viewer',y='diamonds',data=df_channel,hue='live_day',ax=axes[1])

plt.figure(figsize=(12,8))
sns.heatmap(df_channel[['duration','diamonds','total_viewer','engagement_count']].corr(), cmap='viridis', annot=True)

df_rel.head(5)

df_rel.drop('engagement',axis=1,inplace=True)

g, axes = plt.subplots(1,3, figsize=(20,8))
sns.set_style('darkgrid')
sns.scatterplot(x='view_count',y='comment_count',data=df_rel,ax=axes[0])
sns.scatterplot(x='view_count',y='coin_count',data=df_rel,ax=axes[1])
sns.scatterplot(x='comment_count',y='coin_count',data=df_rel,ax=axes[2])

plt.figure(figsize=(12,8))
sns.heatmap(df_rel.corr(), cmap='viridis', annot=True)

df_users = pd.DataFrame(df['user_id'].value_counts()).reset_index()
df_users.columns = ['user_id','times_watched']
ax = plt.figure(figsize=(16,8))
sns.set_style('darkgrid')
total = df_users['user_id'].nunique()
ax = sns.countplot(x='times_watched',data=df_users[df_users['times_watched']<=30])
tot_pct = 0
for p in ax.patches:
    height = p.get_height()
    ax.text(p.get_x()+p.get_width()/2.,
            height + 1,
            '{:1.2f}%'.format(height*100/total),
            ha="center")
    tot_pct+= height*100/total
tit = ax.set_title('Distribution of Times Watched per User (Clipped at 50)')
    

df_streamers = pd.DataFrame(df['streamer_id'].value_counts()).reset_index()
df_streamers.columns = ['streamer_id','times_streamed']
ax = plt.figure(figsize=(16,8))
sns.set_style('darkgrid')
total = df_streamers['streamer_id'].nunique()
ax = sns.countplot(x='times_streamed',data=df_streamers[df_streamers['times_streamed']<=30])
tot_pct = 0
for p in ax.patches:
    height = p.get_height()
    ax.text(p.get_x()+p.get_width()/2.,
            height + 1,
            '{:1.2f}%'.format(height*100/total),
            ha="center")
    tot_pct+= height*100/total
tit = ax.set_title('Distribution of Times Streamed per Streamer (Clipped at 30)')
    

df['pct_watched'] = df['user_duration']*100/df['total_stream_duration']
ranges = [0,10,20,30,40,50,60,70,80,90,100]
labels=['0-10','11-20','21-30',
        '31-40','41-50','51-60','61-70','71-80','81-90','91-100']
df['pct_watched_bin'] = pd.cut(df.pct_watched, ranges,labels=labels)

ax = plt.figure(figsize=(16,8))
sns.set_style('darkgrid')
total = len(df)
ax = sns.countplot(x='pct_watched_bin',data=df)
for p in ax.patches:
    height = p.get_height()
    ax.text(p.get_x()+p.get_width()/2.,
            height + 1,
            '{:1.2f}%'.format(height*100/total),
            ha="center")
tit = ax.set_title('Percent buckets of the % of their watch time duration to the total stream duration')

df_cf = df.groupby(['user_id','streamer_id']).agg({'user_duration':np.mean}).reset_index()

df_cf['scaled_user_duration'] = np.log(df_cf['user_duration'])
df_cf.head(5)

g = sns.distplot(df_cf['scaled_user_duration'])
tit = g.set_title('Distribution Plot for the Scaled Watch Duration for each User')

#Sampling the dataset for the initial model algorithm selection
sampled_df = df_cf.sample(n=100000)
reader = Reader(rating_scale=(0,df_cf['scaled_user_duration'].max()))
data = Dataset.load_from_df(sampled_df[['user_id','streamer_id','scaled_user_duration']], reader)
raw_duration = data.raw_ratings

#Shuffling the data
random.shuffle(raw_duration)

#Manually splitting train and test set after shuffling the data
# Train = 80% of the data, Test = 20% of the data
threshold = int(.8 * len(raw_duration))
train_raw_duration = raw_duration[:threshold]
test_raw_duration = raw_duration[threshold:]

data.raw_ratings = train_raw_duration # data is now the train set

benchmark = []

#We will use SVD, SVDpp, NMF, and KNNWithMeans as our model choices
for algorithm in [SVD(), SVDpp(), NMF(), KNNWithMeans()]:
    # Perform cross validation
    results = cross_validate(algorithm, data, measures=['RMSE'], cv=5, verbose=False,n_jobs=1)
    
    # Get results & append algorithm name
    tmp = pd.DataFrame.from_dict(results).mean(axis=0)
    tmp = tmp.append(pd.Series([str(algorithm).split(' ')[0].split('.')[-1]], index=['Algorithm']))
    benchmark.append(tmp)
    
results = pd.DataFrame(benchmark).set_index('Algorithm').sort_values('test_rmse') 

results

algo = SVD()
trainset = data.build_full_trainset()
algo.fit(trainset)
testset = data.construct_testset(test_raw_duration)
predictions = algo.test(testset)
accuracy.rmse(predictions)

data = Dataset.load_from_df(df_cf[['user_id','streamer_id','scaled_user_duration']], reader)
raw_duration = data.raw_ratings

# shuffle ratings if you want
random.shuffle(raw_duration)

# Train = 80% of the data, Test = 20% of the data
threshold = int(.8 * len(raw_duration))
train_raw_duration = raw_duration[:threshold]
test_raw_duration = raw_duration[threshold:]

data.raw_rating = train_raw_duration
trainset = data.build_full_trainset()

import optuna

def objective(trial):
    n_factors = trial.suggest_int('n_factors', 70,300,10)
    n_epochs = trial.suggest_int('n_epochs', 6,16,2)
    reg_all = trial.suggest_uniform('reg_all',0.001,0.05)
    lr_all = trial.suggest_uniform('lr_all',0.00005,0.01)
    svd = SVD(n_factors=n_factors,n_epochs=n_epochs,reg_all=reg_all,lr_all=lr_all)

    return cross_validate(svd, data, measures=['RMSE'], cv=3, verbose=False,n_jobs=1)['test_rmse'].mean()

study = optuna.create_study(direction='minimize')
study.optimize(objective, n_trials=100)

study.best_params

study.best_value

params = {'lr_all': 0.001427237312606455,
 'n_epochs': 14,
 'n_factors': 70,
 'reg_all': 0.028138308089573162}
 
algo = SVD(n_factors = params['n_factors'],n_epochs=params['n_epochs'],reg_all=params['reg_all'],lr_all=params['lr_all'])

algo.fit(trainset)
testset = data.construct_testset(test_raw_duration)

testset = data.construct_testset(test_raw_duration)
predictions = algo.test(testset)
accuracy.rmse(predictions)


def get_real_rmse(preds):
  err2 = []
  for i in range(len(preds)):
    err = (np.exp(preds[i][2])-np.exp(preds[i][3]))**2
    err2.append(err)
  return (np.sqrt(np.mean(err2)))

get_real_rmse(predictions)

def get_est_duration(uid,iid):
  log_est = algo.predict(uid,iid)[3]
  est_dur = np.exp(log_est)
  return est_dur

get_est_duration('ffff2b91-308d-4ac8-8bad-c255f9bbd187','56c17686-ad3e-4ba8-a21a-402720862f14')

def recommend_streamer(uid,only_new=True,num_reco=10):
  if uid not in df_cf['user_id'].unique():
    df = df_cf.groupby(['streamer_id']).agg({'user_duration':sum}).reset_index().sort_values(['user_duration'],ascending=False).iloc[0:num_reco].reset_index(drop=True)
    df.columns = ['streamer_id','total_duration_from_other_users']
  else:
    if only_new:
      watched = df_cf[df_cf['user_id']==uid]['streamer_id'].values
      all_streamers = df_cf['streamer_id'].unique()
      streamers = [i for i in all_streamers if i not in watched]
    else:
      streamers = df_cf['streamer_id'].unique()
    df = pd.DataFrame(streamers,columns=['streamer_id'])
    df['est_duration'] = df['streamer_id'].apply(lambda x: np.exp(algo.predict(uid,x)[3]))
    df = df.sort_values(['est_duration'],ascending=False).iloc[0:num_reco,:].reset_index(drop=True)
  return df


recommend_streamer('unknown-user-id')

recommend_streamer('00000a8a-b9de-44de-88d4-4adc741eb7d8')

#Preparing the Sparse Matrix that will be fitted to the ALS

sparse_streamer_user = sparse.csr_matrix((df_cf['user_duration'].astype(float), 
                                          (df_cf['streamer_id'].astype('category').cat.codes, df_cf['user_id'].astype('category').cat.codes)))
sparse_user_streamer = sparse.csr_matrix((df_cf['user_duration'].astype(float), 
                                          (df_cf['user_id'].astype('category').cat.codes, df_cf['streamer_id'].astype('category').cat.codes)))

users_dict = dict(zip(df_cf.user_id.astype('category'), df_cf.user_id.astype('category').cat.codes))
streamers_dict = dict(zip( df_cf.streamer_id.astype('category').cat.codes, df_cf.streamer_id.astype('category')))

# initialize a model
model = implicit.als.AlternatingLeastSquares(factors=50)

# train the model on a sparse matrix of item/user/confidence weights
model.fit(sparse_streamer_user)

def recommend_streamers(uid,user_streamers):
    recommendations = model.recommend(users_dict[uid],user_streamers,filter_already_liked_items=False)
    iid = []
    scores = []
    for i in recommendations:
        iid.append(streamers_dict[i[0]])
        scores.append(i[1])
    return pd.DataFrame(zip(iid,scores),columns=['streamer_id','score'])

df_cf[df_cf['user_id']=='ffffe69c-b408-44e4-b611-def853fd19f6'][['streamer_id','user_duration']].sort_values('user_duration',ascending=False)

recommend_streamers('ffffe69c-b408-44e4-b611-def853fd19f6',user_streamers)

def make_train(ratings, pct_test = 0.2):
    '''
    This function will take in the original user-item matrix and "mask" a percentage of the original ratings where a
    user-item interaction has taken place for use as a test set. The test set will contain all of the original ratings, 
    while the training set replaces the specified percentage of them with a zero in the original ratings matrix. 
    
    parameters: 
    
    ratings - the original ratings matrix from which you want to generate a train/test set. Test is just a complete
    copy of the original set. This is in the form of a sparse csr_matrix. 
    
    pct_test - The percentage of user-item interactions where an interaction took place that you want to mask in the 
    training set for later comparison to the test set, which contains all of the original ratings. 
    
    returns:
    
    training_set - The altered version of the original data with a certain percentage of the user-item pairs 
    that originally had interaction set back to zero.
    
    test_set - A copy of the original ratings matrix, unaltered, so it can be used to see how the rank order 
    compares with the actual interactions.
    
    user_inds - From the randomly selected user-item indices, which user rows were altered in the training data.
    This will be necessary later when evaluating the performance via AUC.
    '''
    test_set = ratings.copy() # Make a copy of the original set to be the test set. 
    test_set[test_set != 0] = 1 # Store the test set as a binary preference matrix
    training_set = ratings.copy() # Make a copy of the original data we can alter as our training set. 
    nonzero_inds = training_set.nonzero() # Find the indices in the ratings data where an interaction exists
    nonzero_pairs = list(zip(nonzero_inds[0], nonzero_inds[1])) # Zip these pairs together of user,item index into list
    random.seed(0) # Set the random seed to zero for reproducibility
    num_samples = int(np.ceil(pct_test*len(nonzero_pairs))) # Round the number of samples needed to the nearest integer
    samples = random.sample(nonzero_pairs, num_samples) # Sample a random number of user-item pairs without replacement
    user_inds = [index[0] for index in samples] # Get the user row indices
    item_inds = [index[1] for index in samples] # Get the item column indices
    training_set[user_inds, item_inds] = 0 # Assign all of the randomly chosen user-item pairs to zero
    training_set.eliminate_zeros() # Get rid of zeros in sparse array storage after update to save space
    return training_set, test_set, list(set(user_inds)) # Output the unique list of user rows that were altered  

train, test, users_altered = make_train(sparse_user_streamer, pct_test = 0.2)

from sklearn import metrics
def auc_score(predictions, test):
    '''
    This simple function will output the area under the curve using sklearn's metrics. 
    
    parameters:
    
    - predictions: your prediction output
    
    - test: the actual target result you are comparing to
    
    returns:
    
    - AUC (area under the Receiver Operating Characterisic curve)
    '''
    fpr, tpr, thresholds = metrics.roc_curve(test, predictions)
    return metrics.auc(fpr, tpr)   

def calc_mean_auc(training_set, altered_users, predictions, test_set):
    '''
    This function will calculate the mean AUC by user for any user that had their user-item matrix altered. 
    
    parameters:
    
    training_set - The training set resulting from make_train, where a certain percentage of the original
    user/item interactions are reset to zero to hide them from the model 
    
    predictions - The matrix of your predicted ratings for each user/item pair as output from the implicit MF.
    These should be stored in a list, with user vectors as item zero and item vectors as item one. 
    
    altered_users - The indices of the users where at least one user/item pair was altered from make_train function
    
    test_set - The test set constucted earlier from make_train function
    
    
    
    returns:
    
    The mean AUC (area under the Receiver Operator Characteristic curve) of the test set only on user-item interactions
    there were originally zero to test ranking ability in addition to the most popular items as a benchmark.
    '''
    
    
    store_auc = [] # An empty list to store the AUC for each user that had an item removed from the training set
    popularity_auc = [] # To store popular AUC scores
    pop_items = np.array(test_set.sum(axis = 0)).reshape(-1) # Get sum of item iteractions to find most popular
    item_vecs = predictions[1]
    for i,user in enumerate(altered_users):
        # Iterate through each user that had an item altered
        training_row = training_set[user,:].toarray().reshape(-1) # Get the training set row
        zero_inds = np.where(training_row == 0) # Find where the interaction had not yet occurred
        # Get the predicted values based on our user/item vectors
        user_vec = predictions[0][user,:]
        pred = user_vec.dot(item_vecs).toarray()[0,zero_inds].reshape(-1)
        # Get only the items that were originally zero
        # Select all ratings from the MF prediction for this user that originally had no iteraction
        actual = test_set[user,:].toarray()[0,zero_inds].reshape(-1) 
        # Select the binarized yes/no interaction pairs from the original full data
        # that align with the same pairs in training 
        pop = pop_items[zero_inds] # Get the item popularity for our chosen items
        store_auc.append(auc_score(pred, actual)) # Calculate AUC for the given user and store
        popularity_auc.append(auc_score(pop, actual)) # Calculate AUC using most popular and score
    # End users iteration
    score = float('%.3f'%np.mean(store_auc)), float('%.3f'%np.mean(popularity_auc))
    score = pd.DataFrame(score).T
    score.columns = ['recommender_AUC_score','popularity_AUC_score']
    
    return score  

alpha = 40

user_vecs, item_vecs = implicit.alternating_least_squares((train*alpha).astype('double'), 
                                                          factors=20, 
                                                          regularization = 0.1, 
                                                         iterations = 50)

calc_mean_auc(train, users_altered, 
              [sparse.csr_matrix(user_vecs), sparse.csr_matrix(item_vecs.T)], test)


df_viewer = df_rel.groupby(['viewer_id']).agg({'view_count':sum,'comment_count':sum,'coin_count':sum}).reset_index()
df_viewer.columns = ['viewer_id','total_streams_viewed','total_comments_given','total_coins_given']
df_streamer = df_rel.groupby(['streamer_id']).agg({'view_count':sum,'comment_count':sum,'coin_count':sum}).reset_index()
df_streamer.columns = ['streamer_id','total_streams','total_comments_received','total_coins_received']

df_viewer

from sklearn.cluster import KMeans

def elbow_method(df):
  #Using Streams viewed/streamed, coin given/received, and comments given/received as the clustering factors...
  xcluster3d = df.values
  wcss = []
  for i in range(1,15):
      km = KMeans(n_clusters = i, init = 'k-means++', max_iter = 500, n_init = 20, random_state = 42)
      km.fit(xcluster3d)
      wcss.append(km.inertia_)
  plt.figure(figsize=(12,8))
  sns.set_style('darkgrid')
  g = sns.lineplot(x=range(1,15),y=wcss,color='r')
  g.set_title('Elbow Method')
  g.set_xlabel("Clusters")
  g.set_ylabel("WCSS")


elbow_method(df_viewer[['total_streams_viewed','total_comments_given','total_coins_given']])

elbow_method(df_streamer[['total_streams','total_comments_received','total_coins_received']])

#Applying the optimal clusters to the kmeans
km3d_viewer = KMeans(n_clusters = 4, init = 'k-means++', max_iter = 500, n_init = 20, random_state = 42)
km3d_streamer = KMeans(n_clusters = 4, init = 'k-means++', max_iter = 500, n_init = 20, random_state = 42)
kcluster3d_viewer = km3d_viewer.fit_predict(df_viewer[['total_streams_viewed','total_comments_given','total_coins_given']])
kcluster3d_streamer = km3d_streamer.fit_predict(df_streamer[['total_streams','total_comments_received','total_coins_received']])
df_viewer['cluster']=kcluster3d_viewer
df_viewer['cluster'] = df_viewer['cluster'].apply(lambda x: 'Cluster '+str(x+1))
df_streamer['cluster']=kcluster3d_streamer
df_streamer['cluster'] = df_streamer['cluster'].apply(lambda x: 'Cluster '+str(x+1))

fig = px.scatter_3d(df_streamer, x='total_streams', y='total_comments_received', z='total_coins_received',
              color='cluster')
fig.show()

import plotly.express as px
fig = px.scatter_3d(df_viewer, x='total_streams_viewed', y='total_comments_given', z='total_coins_given',
              color='cluster')
fig.show()
