{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/sparsh-ai/reco-book/blob/stage/nbs/T677598_Jaccard_Cosine_SVD_DeepWalk_ML100K.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QB8Kjuy1ApsF"
   },
   "source": [
    "# Recommender System with DeepWalk Graph Embeddings\n",
    "\n",
    "**Description:** A tutorial on building a movie recommender system that will learn user-item representation using graph embedding and comparing performance with other methods like matrix factorization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "duOegrbCH_Uj"
   },
   "source": [
    "## Data gathering and exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M10NbHleDF96"
   },
   "outputs": [],
   "source": [
    "!wget https://raw.githubusercontent.com/sparsh-ai/rec-data-public/master/ml-other/ml100k_ratings.csv\n",
    "!wget https://raw.githubusercontent.com/sparsh-ai/rec-data-public/master/ml-other/ml100k_movies.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dW3-0phsDrpc"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.sparse import coo_matrix, csr_matrix\n",
    "from scipy.sparse.linalg import svds, norm\n",
    "from scipy.spatial.distance import cosine\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import operator\n",
    "from collections import defaultdict\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FUzXL9-PpnYs"
   },
   "outputs": [],
   "source": [
    "def print_stats(df, uid=1):\n",
    "  print(df.shape)\n",
    "  print(df.movieId.nunique())\n",
    "  print(max(df.movieId))\n",
    "  if uid:\n",
    "    print(df.userId.nunique())\n",
    "    print(max(df.userId))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QsIUlasGEG1w"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964982703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964981247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964982224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "      <td>5.0</td>\n",
       "      <td>964983815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>5.0</td>\n",
       "      <td>964982931</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating  timestamp\n",
       "0       1        1     4.0  964982703\n",
       "1       1        3     4.0  964981247\n",
       "2       1        6     4.0  964982224\n",
       "3       1       47     5.0  964983815\n",
       "4       1       50     5.0  964982931"
      ]
     },
     "execution_count": 238,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating_df = pd.read_csv('ml100k_ratings.csv', sep=',', header=0)\n",
    "rating_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZODEGVn1F08H"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100836, 4)\n",
      "9724\n",
      "193609\n",
      "610\n",
      "610\n"
     ]
    }
   ],
   "source": [
    "print_stats(rating_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KKxem0FVF_SG"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieId</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Jumanji (1995)</td>\n",
       "      <td>Adventure|Children|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Grumpier Old Men (1995)</td>\n",
       "      <td>Comedy|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Waiting to Exhale (1995)</td>\n",
       "      <td>Comedy|Drama|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Father of the Bride Part II (1995)</td>\n",
       "      <td>Comedy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   movieId  ...                                       genres\n",
       "0        1  ...  Adventure|Animation|Children|Comedy|Fantasy\n",
       "1        2  ...                   Adventure|Children|Fantasy\n",
       "2        3  ...                               Comedy|Romance\n",
       "3        4  ...                         Comedy|Drama|Romance\n",
       "4        5  ...                                       Comedy\n",
       "\n",
       "[5 rows x 3 columns]"
      ]
     },
     "execution_count": 240,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_df = pd.read_csv('ml100k_movies.csv', sep=',', header=0)\n",
    "movie_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZmTFFculp52P"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9742, 3)\n",
      "9742\n",
      "193609\n"
     ]
    }
   ],
   "source": [
    "print_stats(movie_df, uid=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XWnDNTepIDmT"
   },
   "source": [
    "## Neighborhood method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pr1CHpAT-0wZ"
   },
   "source": [
    "### Jaccard Similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LPqcRWFCIrrf"
   },
   "source": [
    "If we ignore the ratings that the users have given to the movies, and consider the movies that the users have watched, we get a set of movies/users for every user/movie. Think of this formulation as a bipartite graph of users and movies where there is an edge between a user and a movie if a user has watched the movie, the edges have all same weights.\n",
    "\n",
    "Create a dictionary of movies as keys and values as users that have rated them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B3NvTMTsGgIW"
   },
   "outputs": [],
   "source": [
    "movie_sets = dict((movie, set(users)) for movie, users in rating_df.groupby('movieId')['userId'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dyUS2QlFJSc_"
   },
   "source": [
    "Since we have a set of users to characterize each movie, to compute the similarity of two movies, we use Jaccard Index which, for two sets, is the ratio of number of elements in the intersection and number of elements in the union.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mtga_4oHJSAI"
   },
   "outputs": [],
   "source": [
    "def jaccard(movie1, movie2, movie_sets):\n",
    "    a = movie_sets[movie1]\n",
    "    b = movie_sets[movie2]\n",
    "    intersection = float(len(a.intersection(b)))\n",
    "    return intersection / (len(a) + len(b) - intersection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_rXFwdZLJXWN"
   },
   "source": [
    "Let's explore similarity between some movies, qualitatively. We use the movies dataframe to get the names of the movies via their Ids."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E_1TCARUK2Ci"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'Star Wars: Episode IV - A New Hope (1977)'"
      ]
     },
     "execution_count": 244,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_df[movie_df.movieId == 260].title.values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q-9x2b28JZkT"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jaccard distance between 'StarWars:EpisodeIV-ANewHope(1977)' and 'StarWars:EpisodeV-TheEmpireStrikesBack(1980)' is 0.70\n",
      "Jaccard distance between 'StarWars:EpisodeIV-ANewHope(1977)' and 'StarWars:EpisodeVI-ReturnoftheJedi(1983)' is 0.64\n",
      "Jaccard distance between 'StarWars:EpisodeIV-ANewHope(1977)' and 'ToyStory(1995)' is 0.40\n"
     ]
    }
   ],
   "source": [
    "title = movie_df[movie_df.movieId == 260].title.values[0]\n",
    "title = ''.join(title.split())\n",
    "\n",
    "print(\"Jaccard distance between '%s' and '%s' is %.2f\"%(\n",
    "    title, \n",
    "     ''.join(movie_df[movie_df.movieId == 1196].title.values[0].split()), \n",
    "    jaccard(260, 1196, movie_sets)))\n",
    "\n",
    "print(\"Jaccard distance between '%s' and '%s' is %.2f\"%(\n",
    "    title, \n",
    "    ''.join(movie_df[movie_df.movieId == 1210].title.values[0].split()),\n",
    "    jaccard(260, 1210, movie_sets)))\n",
    "\n",
    "print(\"Jaccard distance between '%s' and '%s' is %.2f\"%(\n",
    "    title, \n",
    "    ''.join(movie_df[movie_df.movieId == 1].title.values[0].split()),\n",
    "    jaccard(260, 1, movie_sets)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "igqVmGzvNLoc"
   },
   "source": [
    "The movie Star Wars IV has higher similarity score with other Star Wars as compared to Toy Story.\n",
    "\n",
    "Using the Jaccard Index, we can retrieve top-k similar movies to a given movie. This provides a way to recommend movies of a user which are similar to the movies that the user has watched."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wRx6FxiuJf7G"
   },
   "outputs": [],
   "source": [
    "import operator \n",
    "\n",
    "def get_similar_movies_jaccard(movieid, movie_sets, top_n=5):\n",
    "    movie = movie_df[movie_df.movieId == movieid].title.values[0]\n",
    "    jaccard_dict = {x: jaccard(x, movieid, movie_sets) for x in movie_sets}\n",
    "    ranked_movies = sorted(jaccard_dict.items(), key=operator.itemgetter(1), reverse=True)[:top_n]\n",
    "    sim_movies = [movie_df[movie_df.movieId == id[0]].title.values[0] for id in ranked_movies]\n",
    "    return {'movie': movie, 'sim_movies': sim_movies}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ogn6T_5aNVbo"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'movie': 'Star Wars: Episode IV - A New Hope (1977)',\n",
       " 'sim_movies': ['Star Wars: Episode IV - A New Hope (1977)',\n",
       "  'Star Wars: Episode V - The Empire Strikes Back (1980)',\n",
       "  'Star Wars: Episode VI - Return of the Jedi (1983)',\n",
       "  'Raiders of the Lost Ark (Indiana Jones and the Raiders of the Lost Ark) (1981)',\n",
       "  'Matrix, The (1999)']}"
      ]
     },
     "execution_count": 248,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_similar_movies_jaccard(260, movie_sets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fPNAPxqlNWx-"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'movie': 'Toy Story (1995)',\n",
       " 'sim_movies': ['Toy Story (1995)',\n",
       "  'Independence Day (a.k.a. ID4) (1996)',\n",
       "  'Jurassic Park (1993)',\n",
       "  'Star Wars: Episode IV - A New Hope (1977)',\n",
       "  'Forrest Gump (1994)']}"
      ]
     },
     "execution_count": 249,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_similar_movies_jaccard(1, movie_sets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PDCLeFgJNnxN"
   },
   "source": [
    "### Cosine similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jBZTwurfNmWq"
   },
   "source": [
    "Rather than the set based similarity like Jaccard, we can define every movie as a sparse vector of dimension equal to the number of users and the vector entry corresponding to each user is given by the rating that the user has for the movie or zero if no rating exists (i.e. the user hasn't seen/rated the movie)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TjNjq4YeNarR"
   },
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import cosine\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kGcfDDr9O2OF"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "610"
      ]
     },
     "execution_count": 251,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_users = rating_df.userId.nunique()\n",
    "num_users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lzyItagFO5PI"
   },
   "outputs": [],
   "source": [
    "movie_sparse_vecs = []\n",
    "movies = []\n",
    "for movie, group in rating_df.groupby('movieId'):\n",
    "    vec = [0] * num_users\n",
    "    for x in group[['userId', 'rating']].values:\n",
    "        vec[int(x[0]) - 1] = x[1]\n",
    "    movie_sparse_vecs.append(vec)\n",
    "    movies.append(movie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C7NgHmrZPDxU"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9724, 610)\n"
     ]
    }
   ],
   "source": [
    "movie_sparse_vecs = np.array(movie_sparse_vecs)\n",
    "print(movie_sparse_vecs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Hd9m0ZIpPdmV"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8324073552233735\n"
     ]
    }
   ],
   "source": [
    "print(1.0 - cosine(movie_sparse_vecs[224], movie_sparse_vecs[897]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZP4K4AIxPD8T"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "224"
      ]
     },
     "execution_count": 255,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie2id = {x:i for i,x in enumerate(movies)}\n",
    "movie2id[260]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zIMlL-AUPGol"
   },
   "outputs": [],
   "source": [
    "def get_similar_movies_nbd_cosine(movieid, movie_vecs, top_n=5):\n",
    "    movie = movie_df[movie_df.movieId == movieid].title.values[0]\n",
    "    movie_idx = movie2id[movieid]\n",
    "    query = movie_vecs[movie_idx].reshape(1,-1)\n",
    "    ranking = cosine_similarity(movie_vecs,query)\n",
    "    top_ids = np.argsort(ranking, axis=0)\n",
    "    top_ids = top_ids[::-1][:top_n]\n",
    "    top_movie_ids = [movies[j[0]] for j in top_ids]\n",
    "    sim_movies = [movie_df[movie_df.movieId == id].title.values[0] for id in top_movie_ids]\n",
    "    return {'movie': movie, 'sim_movies': sim_movies}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oat5HmtoPJdW"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'movie': 'Toy Story (1995)',\n",
       " 'sim_movies': ['Toy Story (1995)',\n",
       "  'Toy Story 2 (1999)',\n",
       "  'Jurassic Park (1993)',\n",
       "  'Independence Day (a.k.a. ID4) (1996)',\n",
       "  'Star Wars: Episode IV - A New Hope (1977)']}"
      ]
     },
     "execution_count": 257,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movieid = 1\n",
    "movie_data = movie_sparse_vecs\n",
    "get_similar_movies_nbd_cosine(movieid, movie_data, top_n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eMz9kFZrQKUv"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'movie': 'Star Wars: Episode IV - A New Hope (1977)',\n",
       " 'sim_movies': ['Star Wars: Episode IV - A New Hope (1977)',\n",
       "  'Star Wars: Episode V - The Empire Strikes Back (1980)',\n",
       "  'Star Wars: Episode VI - Return of the Jedi (1983)',\n",
       "  'Raiders of the Lost Ark (Indiana Jones and the Raiders of the Lost Ark) (1981)',\n",
       "  'Matrix, The (1999)']}"
      ]
     },
     "execution_count": 258,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movieid = 260\n",
    "movie_data = movie_sparse_vecs\n",
    "get_similar_movies_nbd_cosine(movieid, movie_data, top_n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pw86BbsJ_gF7"
   },
   "source": [
    "## Factorization method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NeaTEXE4Q6Yz"
   },
   "source": [
    "### Singular Value Decomposition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7EqGRvLcQ_5Z"
   },
   "source": [
    "A very popular technique for recommendation systems is via matrix factorization. The idea is to reduce the dimensionality of the data before calculating similar movies/users. We factorize the user-item matrix to obtain the user factors and item factors which are the low-dimensional embeddings such that 'similar' user/items are mapped to 'nearby' points.\n",
    "\n",
    "This kind of analysis can generate matches that are impossible to find with the techniques discussed above as the latent factors can capture attributes which are hard for raw data to deciper e.g. a latent factor can correspond to the degree to which a movie is female oriented or degree to which there is a slow development of the charcters.\n",
    "\n",
    "Moreover, the user and the movies are embedded to the same space, which provides a direct way to compute user-movie similarity.\n",
    "\n",
    "We will use Singular Value Decomposition (SVD) for factorizing the matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wqmWohqGsqss"
   },
   "outputs": [],
   "source": [
    "le_movie = LabelEncoder()\n",
    "movie_df = movie_df[movie_df.movieId.isin(rating_df.movieId.unique())]\n",
    "rating_df.loc[:, 'movieId'] = le_movie.fit_transform(rating_df.loc[:, 'movieId'])\n",
    "rating_df.loc[:, 'movieId']+=1\n",
    "movie_df.loc[:, 'movieId'] = le_movie.transform(movie_df.loc[:, 'movieId'])\n",
    "movie_df.loc[:, 'movieId']+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yBA0Ha2MQKf2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9724, 610)"
      ]
     },
     "execution_count": 260,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings_mat = np.ndarray(\n",
    "    shape=(np.max(rating_df.movieId.values), np.max(rating_df.userId.values)),\n",
    "    dtype=np.uint8)\n",
    "ratings_mat[rating_df.movieId.values-1, rating_df.userId.values-1] = rating_df.rating.values\n",
    "ratings_mat.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sFDqtsgQRFkD"
   },
   "source": [
    "Normalize the rating matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pdCoya1BRDvC"
   },
   "outputs": [],
   "source": [
    "normalised_mat = ratings_mat - np.asarray([(np.mean(ratings_mat, 1))]).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_z-9rYIKRP8W"
   },
   "source": [
    "The number of the latent-factors is chosen to be 50 i.e. top-50 singular values of the SVD are considered. The choice of the number of latent factors is a hyperparameter of the model, and requires a more sophisticated analysis to tune. We provide no reason for the choice of 50."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "01TPkUiTROKT"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(610, 50) (50, 9724)\n"
     ]
    }
   ],
   "source": [
    "n_factors = 50\n",
    "\n",
    "A = normalised_mat.T / np.sqrt(ratings_mat.shape[0] - 1)\n",
    "U, S, V = svds(A, n_factors)\n",
    "\n",
    "print(U.shape, V.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ICeVcjCARW-U"
   },
   "outputs": [],
   "source": [
    "movie_factors = V.T\n",
    "user_factors = U"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gbBy8vcOSBsR"
   },
   "source": [
    "Instead of representing each movie as a sparse vector of the ratings of all 360,000 possible users for it, after factorizing the matrix each movie will be represented by a 50 dimensional dense vector.\n",
    "\n",
    "Define a routine to get top-n movies similar to a given movie.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pE51HtPzRZ--"
   },
   "outputs": [],
   "source": [
    "def get_similar_movies_matrix_factorization(data, movieid, top_n=10):\n",
    "    index = movieid - 1 # Movie id starts from 1\n",
    "    movie = movie_df[movie_df.movieId == movieid].title.values[0]\n",
    "    movie_row = data[index].reshape(1,-1)\n",
    "    similarity = cosine_similarity(movie_row, data)\n",
    "    sort_indexes = np.argsort(-similarity)[0]\n",
    "    return {'movie': movie, 'sim_movies': [movie_df[movie_df.movieId == id].title.values[0] for id in sort_indexes[:top_n] + 1]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E8nbbpG0SJ50"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'movie': 'Priest (1994)',\n",
       " 'sim_movies': ['Priest (1994)',\n",
       "  'Heidi Fleiss: Hollywood Madam (1995)',\n",
       "  'Reds (1981)',\n",
       "  'I Went Down (1997)',\n",
       "  'Metroland (1997)',\n",
       "  'Love Serenade (1996)',\n",
       "  'Cold Fever (Á köldum klaka) (1995)',\n",
       "  'Suture (1993)',\n",
       "  'Whole Wide World, The (1996)',\n",
       "  'Walking and Talking (1996)']}"
      ]
     },
     "execution_count": 265,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_id = 260\n",
    "get_similar_movies_matrix_factorization(movie_factors, movie_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6PHHeIzhSMlr"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'movie': 'Toy Story (1995)',\n",
       " 'sim_movies': ['Toy Story (1995)',\n",
       "  'Back to the Future (1985)',\n",
       "  \"Bug's Life, A (1998)\",\n",
       "  'Babe (1995)',\n",
       "  'Star Wars: Episode IV - A New Hope (1977)',\n",
       "  'Who Framed Roger Rabbit? (1988)',\n",
       "  'Mrs. Doubtfire (1993)',\n",
       "  'When Harry Met Sally... (1989)',\n",
       "  '101 Dalmatians (One Hundred and One Dalmatians) (1961)',\n",
       "  'Home Alone (1990)']}"
      ]
     },
     "execution_count": 266,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_id = 1\n",
    "get_similar_movies_matrix_factorization(movie_factors, movie_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2qepoNrhYqyH"
   },
   "source": [
    "Since the user and movies are in the same space, we can also compute movies similar to a user. A recommendation model can be defined as showing movies similar to the given user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fX8r-mcHSM0a"
   },
   "outputs": [],
   "source": [
    "def get_recommendations_matrix_factorization(userid, user_factors, movie_factors, top_n=10):\n",
    "    user_vec = user_factors[userid - 1].reshape(1,-1)\n",
    "    similarity = cosine_similarity(user_vec, movie_factors)\n",
    "    sort_indexes = np.argsort(-similarity)[0]\n",
    "    return [movie_df[movie_df.movieId == id].title.values[0] for id in sort_indexes[:top_n] + 1]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "swDNKl96Ytnq"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Jungle2Jungle (a.k.a. Jungle 2 Jungle) (1997)',\n",
       " \"Pete's Dragon (2016)\",\n",
       " 'Cellular (2004)',\n",
       " 'Replacement Killers, The (1998)',\n",
       " 'Rough Night (2017)',\n",
       " 'Star Wars: Episode III - Revenge of the Sith (2005)',\n",
       " 'Gentlemen Prefer Blondes (1953)',\n",
       " 'Spanglish (2004)',\n",
       " 'Sorry to Bother You (2018)',\n",
       " 'Planet of the Apes (2001)']"
      ]
     },
     "execution_count": 268,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_recos = get_recommendations_matrix_factorization(1, user_factors, movie_factors)\n",
    "top_recos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZlkzVgEKdcIO"
   },
   "source": [
    "## Graph Embedding method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qnS4CWLgdeEn"
   },
   "source": [
    "Create a user-movie graph with edge weights as the ratings. We will use DeepWalk to embed every node of the graph to a low-dimensional space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4ZAhnm2DYt0r"
   },
   "outputs": [],
   "source": [
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j0NI-HZUdg4g"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>44</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating\n",
       "0       1        1     4.0\n",
       "1       1        3     4.0\n",
       "2       1        6     4.0\n",
       "3       1       44     5.0\n",
       "4       1       47     5.0"
      ]
     },
     "execution_count": 270,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_item_edgelist = rating_df[['userId', 'movieId', 'rating']]\n",
    "user_item_edgelist.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SdNE_KWgdjI5"
   },
   "outputs": [],
   "source": [
    "user2dict = dict()\n",
    "movie2dict = dict()\n",
    "cnt = 0\n",
    "for x in user_item_edgelist.values:\n",
    "    usr = (x[0], 'user')\n",
    "    movie = (x[1], 'movie')\n",
    "    if usr in user2dict:\n",
    "        pass\n",
    "    else:\n",
    "        user2dict[usr] = cnt\n",
    "        cnt += 1\n",
    "    if movie in movie2dict:\n",
    "        pass\n",
    "    else:\n",
    "        movie2dict[movie] = cnt\n",
    "        cnt += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HfRpowdsdqmc"
   },
   "source": [
    "Create a user-movie weighted graph using python library networkx."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1GTDXkn3dmXj"
   },
   "outputs": [],
   "source": [
    "user_movie_graph = nx.Graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K_qtHynPdsDw"
   },
   "outputs": [],
   "source": [
    "for x in user_item_edgelist.values:\n",
    "    usr = (x[0], 'user')\n",
    "    movie = (x[1], 'movie')\n",
    "    user_movie_graph.add_node(user2dict[usr])\n",
    "    user_movie_graph.add_node(movie2dict[movie])\n",
    "    user_movie_graph.add_edge(user2dict[usr], movie2dict[movie], weight=float(x[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jIpTzjObduIZ"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100836"
      ]
     },
     "execution_count": 274,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_movie_graph.number_of_edges()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c-SQK75OdxfF"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10334"
      ]
     },
     "execution_count": 275,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_movie_graph.number_of_nodes()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L_LANA0gd1n7"
   },
   "source": [
    "### DeepWalk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "edZM0sM7d3Ta"
   },
   "source": [
    "We will use the implementation of DeepWalk provided in node2vec which is a bit different from original DeepWalk e.g. it uses negative sampling whereas the original DeepWalk paper used hierarchical sampling for the skip-gram model.\n",
    "\n",
    "To create embeddings from the context and non-context pairs, we are using Gensim python library. One can easily use Google word2vec or Facebook fasttext for this task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8OQN6lhyd-2o"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import networkx as nx\n",
    "import random\n",
    "\n",
    "\n",
    "class Graph():\n",
    "\tdef __init__(self, nx_G, is_directed, p, q):\n",
    "\t\tself.G = nx_G\n",
    "\t\tself.is_directed = is_directed\n",
    "\t\tself.p = p\n",
    "\t\tself.q = q\n",
    "\n",
    "\tdef node2vec_walk(self, walk_length, start_node):\n",
    "\t\t'''\n",
    "\t\tSimulate a random walk starting from start node.\n",
    "\t\t'''\n",
    "\t\tG = self.G\n",
    "\t\talias_nodes = self.alias_nodes\n",
    "\t\talias_edges = self.alias_edges\n",
    "\n",
    "\t\twalk = [start_node]\n",
    "\n",
    "\t\twhile len(walk) < walk_length:\n",
    "\t\t\tcur = walk[-1]\n",
    "\t\t\tcur_nbrs = sorted(G.neighbors(cur))\n",
    "\t\t\tif len(cur_nbrs) > 0:\n",
    "\t\t\t\tif len(walk) == 1:\n",
    "\t\t\t\t\twalk.append(cur_nbrs[alias_draw(alias_nodes[cur][0], alias_nodes[cur][1])])\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\tprev = walk[-2]\n",
    "\t\t\t\t\tnext = cur_nbrs[alias_draw(alias_edges[(prev, cur)][0], \n",
    "\t\t\t\t\t\talias_edges[(prev, cur)][1])]\n",
    "\t\t\t\t\twalk.append(next)\n",
    "\t\t\telse:\n",
    "\t\t\t\tbreak\n",
    "\n",
    "\t\treturn walk\n",
    "\n",
    "\tdef simulate_walks(self, num_walks, walk_length):\n",
    "\t\t'''\n",
    "\t\tRepeatedly simulate random walks from each node.\n",
    "\t\t'''\n",
    "\t\tG = self.G\n",
    "\t\twalks = []\n",
    "\t\tnodes = list(G.nodes())\n",
    "\t\tprint('Walk iteration:')\n",
    "\t\tfor walk_iter in range(num_walks):\n",
    "\t\t\tprint(str(walk_iter+1), '/', str(num_walks))\n",
    "\t\t\trandom.shuffle(nodes)\n",
    "\t\t\tfor node in nodes:\n",
    "\t\t\t\twalks.append(self.node2vec_walk(walk_length=walk_length, start_node=node))\n",
    "\n",
    "\t\treturn walks\n",
    "\n",
    "\tdef get_alias_edge(self, src, dst):\n",
    "\t\t'''\n",
    "\t\tGet the alias edge setup lists for a given edge.\n",
    "\t\t'''\n",
    "\t\tG = self.G\n",
    "\t\tp = self.p\n",
    "\t\tq = self.q\n",
    "\n",
    "\t\tunnormalized_probs = []\n",
    "\t\tfor dst_nbr in sorted(G.neighbors(dst)):\n",
    "\t\t\tif dst_nbr == src:\n",
    "\t\t\t\tunnormalized_probs.append(G[dst][dst_nbr]['weight']/p)\n",
    "\t\t\telif G.has_edge(dst_nbr, src):\n",
    "\t\t\t\tunnormalized_probs.append(G[dst][dst_nbr]['weight'])\n",
    "\t\t\telse:\n",
    "\t\t\t\tunnormalized_probs.append(G[dst][dst_nbr]['weight']/q)\n",
    "\t\tnorm_const = sum(unnormalized_probs)\n",
    "\t\ttry:\n",
    "\t\t\tnormalized_probs =  [float(u_prob)/norm_const for u_prob in unnormalized_probs]\n",
    "\t\texcept:\n",
    "\t\t\tnormalized_probs =  [0.0 for u_prob in unnormalized_probs]\n",
    "\n",
    "\t\treturn alias_setup(normalized_probs)\n",
    "\n",
    "\tdef preprocess_transition_probs(self):\n",
    "\t\t'''\n",
    "\t\tPreprocessing of transition probabilities for guiding the random walks.\n",
    "\t\t'''\n",
    "\t\tG = self.G\n",
    "\t\tis_directed = self.is_directed\n",
    "\n",
    "\t\talias_nodes = {}\n",
    "\t\tfor node in G.nodes():\n",
    "\t\t\tunnormalized_probs = [G[node][nbr]['weight'] for nbr in sorted(G.neighbors(node))]\n",
    "\t\t\tnorm_const = sum(unnormalized_probs)\n",
    "\t\t\ttry:\n",
    "\t\t\t\tnormalized_probs =  [float(u_prob)/norm_const for u_prob in unnormalized_probs]\n",
    "\t\t\texcept:\n",
    "\t\t\t\tprint(node)\n",
    "\t\t\t\tnormalized_probs =  [0.0 for u_prob in unnormalized_probs]\n",
    "\t\t\talias_nodes[node] = alias_setup(normalized_probs)\n",
    "\n",
    "\t\talias_edges = {}\n",
    "\t\ttriads = {}\n",
    "\n",
    "\t\tif is_directed:\n",
    "\t\t\tfor edge in G.edges():\n",
    "\t\t\t\talias_edges[edge] = self.get_alias_edge(edge[0], edge[1])\n",
    "\t\telse:\n",
    "\t\t\tfor edge in G.edges():\n",
    "\t\t\t\talias_edges[edge] = self.get_alias_edge(edge[0], edge[1])\n",
    "\t\t\t\talias_edges[(edge[1], edge[0])] = self.get_alias_edge(edge[1], edge[0])\n",
    "\n",
    "\t\tself.alias_nodes = alias_nodes\n",
    "\t\tself.alias_edges = alias_edges\n",
    "\n",
    "\t\treturn\n",
    "\n",
    "\n",
    "def alias_setup(probs):\n",
    "\t'''\n",
    "\tCompute utility lists for non-uniform sampling from discrete distributions.\n",
    "\tRefer to https://hips.seas.harvard.edu/blog/2013/03/03/the-alias-method-efficient-sampling-with-many-discrete-outcomes/\n",
    "\tfor details\n",
    "\t'''\n",
    "\tK = len(probs)\n",
    "\tq = np.zeros(K)\n",
    "\tJ = np.zeros(K, dtype=np.int)\n",
    "\n",
    "\tsmaller = []\n",
    "\tlarger = []\n",
    "\tfor kk, prob in enumerate(probs):\n",
    "\t    q[kk] = K*prob\n",
    "\t    if q[kk] < 1.0:\n",
    "\t        smaller.append(kk)\n",
    "\t    else:\n",
    "\t        larger.append(kk)\n",
    "\n",
    "\twhile len(smaller) > 0 and len(larger) > 0:\n",
    "\t    small = smaller.pop()\n",
    "\t    large = larger.pop()\n",
    "\n",
    "\t    J[small] = large\n",
    "\t    q[large] = q[large] + q[small] - 1.0\n",
    "\t    if q[large] < 1.0:\n",
    "\t        smaller.append(large)\n",
    "\t    else:\n",
    "\t        larger.append(large)\n",
    "\n",
    "\treturn J, q\n",
    "\n",
    "def alias_draw(J, q):\n",
    "\t'''\n",
    "\tDraw sample from a non-uniform discrete distribution using alias sampling.\n",
    "\t'''\n",
    "\tK = len(J)\n",
    "\n",
    "\tkk = int(np.floor(np.random.rand()*K))\n",
    "\tif np.random.rand() < q[kk]:\n",
    "\t    return kk\n",
    "\telse:\n",
    "\t    return J[kk]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ra1o_1uqdzEg"
   },
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3CDjicONeANx"
   },
   "outputs": [],
   "source": [
    "G = Graph(user_movie_graph, is_directed=False, p=1, q=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p991cjb0eErl"
   },
   "source": [
    "p,q = 1 for DeeWalk as the random walks are completely unbiased. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dmLtb2DoeF6o"
   },
   "outputs": [],
   "source": [
    "# Compute the transition probabilities based on the edge weights. \n",
    "G.preprocess_transition_probs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B0hqZsFPeVAO"
   },
   "source": [
    "Compute the random walks.\n",
    "- 10 walks for every node.\n",
    "- Each walk of length 80."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vzo8PeLxeJMa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Walk iteration:\n",
      "1 / 10\n",
      "2 / 10\n",
      "3 / 10\n",
      "4 / 10\n",
      "5 / 10\n",
      "6 / 10\n",
      "7 / 10\n",
      "8 / 10\n",
      "9 / 10\n",
      "10 / 10\n"
     ]
    }
   ],
   "source": [
    "walks = G.simulate_walks(num_walks=10, walk_length=80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F0khP0gceZKV"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "103340"
      ]
     },
     "execution_count": 281,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(walks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dbQKm1Ffec7G"
   },
   "outputs": [],
   "source": [
    "walks[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P5Si6PgmegPx"
   },
   "source": [
    "Learn Embeddings via Gensim, which creates context/non-context pairs and then Skip-gram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A5-9EBUreeFl"
   },
   "outputs": [],
   "source": [
    "def learn_embeddings(walks):\n",
    "    '''\n",
    "    Learn embeddings by optimizing the Skipgram objective using SGD.\n",
    "    Uses Gensim Word2Vec.\n",
    "    '''\n",
    "    walks = [list(map(str, walk)) for walk in walks]\n",
    "    model = Word2Vec(walks, size=50, window=10, min_count=0, sg=1, workers=8, iter=1)\n",
    "    return model.wv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gEIgJI3MeiKT"
   },
   "outputs": [],
   "source": [
    "node_embeddings = learn_embeddings(walks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bbWgRE-kekUr"
   },
   "source": [
    "The output of gensim is a specific type of key-value pair with keys as the string-ed node ids and the values are numpy array of embeddings, each of shape (50,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uAWzWP-RejW_"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2.1159494e-02, -4.3432057e-01,  6.9623584e-01,  4.8146245e-01,\n",
       "        9.6677847e-02, -3.1050149e-02,  1.9733864e-01,  7.9867625e-01,\n",
       "       -6.6979128e-01,  6.5312237e-01,  3.1304079e-01, -1.3411559e-01,\n",
       "       -1.5454048e-01, -2.7333325e-01,  1.4711864e-01,  2.2469629e-01,\n",
       "       -4.3890166e-01,  2.9871342e-01, -6.9798152e-03, -1.7996507e-02,\n",
       "       -6.7855030e-02, -4.3489739e-01,  1.5584855e-01,  7.7486165e-02,\n",
       "        3.7617716e-01,  2.8012756e-01, -8.3905622e-02, -3.5362533e-01,\n",
       "        2.2293477e-01, -1.4108117e-01,  1.6970167e-01, -6.3179672e-01,\n",
       "        1.5170584e-02,  6.1733756e-02, -1.2013953e-01, -2.3064958e-01,\n",
       "        2.4610328e-02,  5.0556450e-04,  2.1398006e-01, -1.0361964e-01,\n",
       "        4.8838145e-01, -3.6318046e-01, -3.1330651e-01,  8.6576389e-03,\n",
       "        1.9654050e-02, -4.6078888e-01,  2.7895319e-01, -1.7853497e-04,\n",
       "       -1.7593203e-01,  2.8144377e-01], dtype=float32)"
      ]
     },
     "execution_count": 285,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node_embeddings['0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KN4lwEGuem7m"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.42126354575157166"
      ]
     },
     "execution_count": 286,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie1 = str(movie2dict[(260, 'movie')])\n",
    "movie2 = str(movie2dict[(1196, 'movie')])\n",
    "1.0 - cosine(node_embeddings[movie1], node_embeddings[movie2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vDkdWW0detgT"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.29301050305366516"
      ]
     },
     "execution_count": 287,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie3 = str(movie2dict[(1210, 'movie')])\n",
    "1.0 - cosine(node_embeddings[movie1], node_embeddings[movie3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tME-F_Lhevgj"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5913276672363281"
      ]
     },
     "execution_count": 288,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie4 = str(movie2dict[(1, 'movie')])\n",
    "1.0 - cosine(node_embeddings[movie1], node_embeddings[movie4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_ZHQE0POeyK1"
   },
   "source": [
    "Since we worked with integer ids for nodes, let's create reverse mapping dictionaries that map integer user/movie to their actual ids."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G7vm86hqewvT"
   },
   "outputs": [],
   "source": [
    "reverse_movie2dict = {k:v for v,k in movie2dict.items()}\n",
    "reverse_user2dict = {k:v for v,k in user2dict.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "airO9UdDez0A"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10334, 50)"
      ]
     },
     "execution_count": 290,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node_vecs = [node_embeddings[str(i)] for i in range(cnt)]\n",
    "node_vecs = np.array(node_vecs)\n",
    "node_vecs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fGx5MRh4e27c"
   },
   "source": [
    "Movies similar to a given movie as an evaluation of the system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sdGDZOlfe1hy"
   },
   "outputs": [],
   "source": [
    "def get_similar_movies_graph_embeddings(movieid, movie_embed, top_n=10):\n",
    "    movie_idx = movie2dict[movieid]\n",
    "    query = movie_embed[movie_idx].reshape(1,-1)\n",
    "    ranking = cosine_similarity(query, movie_embed)\n",
    "    top_ids = np.argsort(-ranking)[0]\n",
    "    top_movie_ids = [reverse_movie2dict[j] for j in top_ids if j in reverse_movie2dict][:top_n]\n",
    "    sim_movies = [movie_df[movie_df.movieId == id[0]].title.values[0] for id in top_movie_ids]\n",
    "    return sim_movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Xe735WY7e4g9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Priest (1994)',\n",
       " 'Heidi Fleiss: Hollywood Madam (1995)',\n",
       " 'My Crazy Life (Mi vida loca) (1993)',\n",
       " 'Before the Rain (Pred dozhdot) (1994)',\n",
       " 'Boys of St. Vincent, The (1992)',\n",
       " 'Last Dance (1996)',\n",
       " 'Awfully Big Adventure, An (1995)',\n",
       " 'Queen Margot (Reine Margot, La) (1994)',\n",
       " \"Widows' Peak (1994)\",\n",
       " 'What Happened Was... (1994)']"
      ]
     },
     "execution_count": 292,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_similar_movies_graph_embeddings((260, 'movie'), node_vecs)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bwSSBvVre6uL"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Awfully Big Adventure, An (1995)',\n",
       " 'What Happened Was... (1994)',\n",
       " 'Song of the Little Road (Pather Panchali) (1955)',\n",
       " 'Death and the Maiden (1994)',\n",
       " 'Heidi Fleiss: Hollywood Madam (1995)',\n",
       " 'My Crazy Life (Mi vida loca) (1993)',\n",
       " 'Love & Human Remains (1993)',\n",
       " \"It's My Party (1996)\",\n",
       " 'Perez Family, The (1995)',\n",
       " 'Bitter Moon (1992)']"
      ]
     },
     "execution_count": 294,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_similar_movies_graph_embeddings((122, 'movie'), node_vecs)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8-IOyAdifFDD"
   },
   "source": [
    "We can also define the recommendation model based on the cosine similarity i.e the movies are ranked for a given user in terms of the cosine similarities of their corresponding embeddings with the embedding of the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HaVE4TJ-e8Af"
   },
   "outputs": [],
   "source": [
    "def get_recommended_movies_graph_embeddings(userid, node_embed, top_n=10):\n",
    "    user_idx = user2dict[userid]\n",
    "    query = node_embed[user_idx].reshape(1,-1)\n",
    "    ranking = cosine_similarity(query, node_embed)\n",
    "    top_ids = np.argsort(-ranking)[0]\n",
    "    top_movie_ids = [reverse_movie2dict[j] for j in top_ids if j in reverse_movie2dict][:top_n]\n",
    "    reco_movies = [movie_df[movie_df.movieId == id[0]].title.values[0] for id in top_movie_ids]\n",
    "    return reco_movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A4yH0XtwfH87"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Best Men (1997)',\n",
       " 'Newton Boys, The (1998)',\n",
       " 'Howard the Duck (1986)',\n",
       " \"Gulliver's Travels (1939)\",\n",
       " 'Shaft (1971)',\n",
       " 'Teenage Mutant Ninja Turtles III (1993)',\n",
       " 'Welcome to Woop-Woop (1997)',\n",
       " 'Song of the South (1946)',\n",
       " 'Three Caballeros, The (1945)',\n",
       " 'Lord of the Rings, The (1978)']"
      ]
     },
     "execution_count": 296,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_recommended_movies_graph_embeddings((1, 'user'), node_vecs, top_n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DE84gK9lfd3q"
   },
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qec-Xatvffbp"
   },
   "source": [
    "As another evalution, let's compare the generated recommendation for a user to the movies tnat the user has actually rated highly. We will get top 10 recommendations for a user, ranked by the cosine similarity, and compute how many of these movies comes from the set of the movies that the user has rated >= 4.5. This tantamounts to Precision@10 metric. For comparison, we will also compute the Precision for the recommendations produced by the matrix factorization model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hc_g0J9HfJKW"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\"Gulliver's Travels (1939)\",\n",
       " 'Lord of the Rings, The (1978)',\n",
       " 'Newton Boys, The (1998)',\n",
       " 'Shaft (1971)',\n",
       " 'Three Caballeros, The (1945)'}"
      ]
     },
     "execution_count": 303,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = 1\n",
    "recos = set(get_recommended_movies_graph_embeddings((idx, 'user'), node_vecs, top_n=10))\n",
    "true_pos = set([movie_df[movie_df.movieId == id].title.values[0] for id in rating_df[(rating_df['userId'] == idx) & (rating_df['rating'] >= 4.5)].movieId.values])\n",
    "recos.intersection(true_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fNqGo7yTfms_"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 302,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mf_recos = set(get_recommendations_matrix_factorization(idx, user_factors, movie_factors))\n",
    "mf_recos.intersection(true_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8IZqMiUi4uJH"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Dark Knight, The (2008)',\n",
       " 'Inglourious Basterds (2009)',\n",
       " 'The Jinx: The Life and Deaths of Robert Durst (2015)',\n",
       " 'Warrior (2011)',\n",
       " 'Wolf of Wall Street, The (2013)'}"
      ]
     },
     "execution_count": 306,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = 2\n",
    "recos = set(get_recommended_movies_graph_embeddings((idx, 'user'), node_vecs, top_n=10))\n",
    "true_pos = set([movie_df[movie_df.movieId == id].title.values[0] for id in rating_df[(rating_df['userId'] == idx) & (rating_df['rating'] >= 4.5)].movieId.values])\n",
    "recos.intersection(true_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bUdrrf394uD4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 307,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mf_recos = set(get_recommendations_matrix_factorization(idx, user_factors, movie_factors))\n",
    "mf_recos.intersection(true_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4D_XSEcG4t_o"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Alien Contamination (1980)',\n",
       " 'Android (1982)',\n",
       " 'Clonus Horror, The (1979)',\n",
       " 'Death Race 2000 (1975)',\n",
       " 'Galaxy of Terror (Quest) (1981)',\n",
       " 'Hangar 18 (1980)',\n",
       " 'Looker (1981)',\n",
       " 'Master of the Flying Guillotine (Du bi quan wang da po xue di zi) (1975)',\n",
       " 'Saturn 3 (1980)',\n",
       " 'The Lair of the White Worm (1988)'}"
      ]
     },
     "execution_count": 308,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = 3\n",
    "recos = set(get_recommended_movies_graph_embeddings((idx, 'user'), node_vecs, top_n=10))\n",
    "true_pos = set([movie_df[movie_df.movieId == id].title.values[0] for id in rating_df[(rating_df['userId'] == idx) & (rating_df['rating'] >= 4.5)].movieId.values])\n",
    "recos.intersection(true_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "58DgvlWs4t7j"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 309,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mf_recos = set(get_recommendations_matrix_factorization(idx, user_factors, movie_factors))\n",
    "mf_recos.intersection(true_pos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YOZmA9_YfxWt"
   },
   "source": [
    "## Enriched network with additional information : Genres"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DBYwBf61f0jA"
   },
   "source": [
    "Genres of the movies can be used as additional signal for better recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rfnzO7XJfrV4"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieId</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Adventure|Children|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Comedy|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Comedy|Drama|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Comedy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   movieId                                       genres\n",
       "0        1  Adventure|Animation|Children|Comedy|Fantasy\n",
       "1        2                   Adventure|Children|Fantasy\n",
       "2        3                               Comedy|Romance\n",
       "3        4                         Comedy|Drama|Romance\n",
       "4        5                                       Comedy"
      ]
     },
     "execution_count": 311,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_genre_edgelist = movie_df[['movieId', 'genres']]\n",
    "movie_genre_edgelist.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PWv1JOfXf3GP"
   },
   "outputs": [],
   "source": [
    "genre2int = dict()\n",
    "for x in movie_genre_edgelist.values:\n",
    "    genres = x[1].split('|')\n",
    "    for genre in genres:\n",
    "        if genre in genre2int:\n",
    "            pass\n",
    "        else:\n",
    "            genre2int[genre] = cnt\n",
    "            cnt += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C0K12ahgf4sE"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'(no genres listed)': 10353,\n",
       " 'Action': 10341,\n",
       " 'Adventure': 10334,\n",
       " 'Animation': 10335,\n",
       " 'Children': 10336,\n",
       " 'Comedy': 10337,\n",
       " 'Crime': 10342,\n",
       " 'Documentary': 10349,\n",
       " 'Drama': 10340,\n",
       " 'Fantasy': 10338,\n",
       " 'Film-Noir': 10352,\n",
       " 'Horror': 10344,\n",
       " 'IMAX': 10350,\n",
       " 'Musical': 10348,\n",
       " 'Mystery': 10345,\n",
       " 'Romance': 10339,\n",
       " 'Sci-Fi': 10346,\n",
       " 'Thriller': 10343,\n",
       " 'War': 10347,\n",
       " 'Western': 10351}"
      ]
     },
     "execution_count": 313,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genre2int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-VN3ns7Lf6wG"
   },
   "outputs": [],
   "source": [
    "#hide\n",
    "movie_genre_graph = nx.Graph()\n",
    "for x in movie_genre_edgelist.values:\n",
    "    movie = (x[0], 'movie')\n",
    "    genres = x[1].split('|')\n",
    "    if movie in movie2dict:\n",
    "        for genre in genres:\n",
    "            if genre in genre2int:\n",
    "                movie_genre_graph.add_node(movie2dict[movie])\n",
    "                movie_genre_graph.add_node(genre2int[genre])\n",
    "                movie_genre_graph.add_edge(movie2dict[movie], genre2int[genre], weight=1.0)\n",
    "            else:\n",
    "                pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZJfxRpg_gOw7"
   },
   "source": [
    "Combine the user-movie and movie-genre graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UzNYrmFbgPLx"
   },
   "outputs": [],
   "source": [
    "user_movie_genre_graph =  nx.Graph()\n",
    "user_movie_genre_graph.add_weighted_edges_from([(x,y,user_movie_graph[x][y]['weight']) for x,y in user_movie_graph.edges()])\n",
    "user_movie_genre_graph.add_weighted_edges_from([(x,y,movie_genre_graph[x][y]['weight']) for x,y in movie_genre_graph.edges()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JQ_8398FgTKV"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "122882"
      ]
     },
     "execution_count": 316,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_movie_genre_graph.number_of_edges()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4SmKuNBFgVG2"
   },
   "outputs": [],
   "source": [
    "G_enriched = Graph(user_movie_genre_graph, is_directed=False, p=1, q=1)\n",
    "G_enriched.preprocess_transition_probs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j8S99KDqgmYZ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Walk iteration:\n",
      "1 / 10\n",
      "2 / 10\n",
      "3 / 10\n",
      "4 / 10\n",
      "5 / 10\n",
      "6 / 10\n",
      "7 / 10\n",
      "8 / 10\n",
      "9 / 10\n",
      "10 / 10\n"
     ]
    }
   ],
   "source": [
    "walks_enriched = G_enriched.simulate_walks(num_walks=10, walk_length=80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BwL6dSROgqBt"
   },
   "outputs": [],
   "source": [
    "node_embeddings_enriched = learn_embeddings(walks_enriched)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OTI0WB7pgr8o"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10354, 50)"
      ]
     },
     "execution_count": 320,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node_vecs_enriched = [node_embeddings_enriched[str(i)] for i in range(cnt)]\n",
    "node_vecs_enriched = np.array(node_vecs_enriched)\n",
    "node_vecs_enriched.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x88M_qXGgtdJ"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Priest (1994)',\n",
       " 'Mrs. Parker and the Vicious Circle (1994)',\n",
       " 'Last Dance (1996)',\n",
       " 'Tom & Viv (1994)',\n",
       " 'Georgia (1995)',\n",
       " 'My Crazy Life (Mi vida loca) (1993)',\n",
       " 'Before the Rain (Pred dozhdot) (1994)',\n",
       " 'Haunted World of Edward D. Wood Jr., The (1996)',\n",
       " 'To Live (Huozhe) (1994)',\n",
       " 'Vanya on 42nd Street (1994)']"
      ]
     },
     "execution_count": 321,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_similar_movies_graph_embeddings((260, 'movie'), node_vecs_enriched)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kp6b2ab-gukp"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Priest (1994)',\n",
       " 'Heidi Fleiss: Hollywood Madam (1995)',\n",
       " 'My Crazy Life (Mi vida loca) (1993)',\n",
       " 'Before the Rain (Pred dozhdot) (1994)',\n",
       " 'Boys of St. Vincent, The (1992)',\n",
       " 'Last Dance (1996)',\n",
       " 'Awfully Big Adventure, An (1995)',\n",
       " 'Queen Margot (Reine Margot, La) (1994)',\n",
       " \"Widows' Peak (1994)\",\n",
       " 'What Happened Was... (1994)']"
      ]
     },
     "execution_count": 322,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_similar_movies_graph_embeddings((260, 'movie'), node_vecs)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JyM9nEvGgu2Y"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "5\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "idx = 1\n",
    "true_pos = set([movie_df[movie_df.movieId == id].title.values[0] for id in rating_df[(rating_df['userId'] == idx) & (rating_df['rating'] >= 4.5)].movieId.values])\n",
    "\n",
    "mf_recos = set(get_recommendations_matrix_factorization(idx, user_factors, movie_factors))\n",
    "print(len(mf_recos.intersection(true_pos)))\n",
    "\n",
    "ge_recos = set(get_recommended_movies_graph_embeddings((idx, 'user'), node_vecs, top_n=10))\n",
    "print(len(ge_recos.intersection(true_pos)))\n",
    "\n",
    "ge_enriched_reso = set(get_recommended_movies_graph_embeddings((idx, 'user'), node_vecs_enriched, top_n=10))\n",
    "print(len(ge_enriched_reso.intersection(true_pos)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7uHvvdK2g3zq"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "2\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "idx = 8\n",
    "true_pos = set([movie_df[movie_df.movieId == id].title.values[0] for id in rating_df[(rating_df['userId'] == idx) & (rating_df['rating'] >= 4.5)].movieId.values])\n",
    "\n",
    "mf_recos = set(get_recommendations_matrix_factorization(idx, user_factors, movie_factors))\n",
    "print(len(mf_recos.intersection(true_pos)))\n",
    "\n",
    "ge_recos = set(get_recommended_movies_graph_embeddings((idx, 'user'), node_vecs, top_n=10))\n",
    "print(len(ge_recos.intersection(true_pos)))\n",
    "\n",
    "ge_enriched_reso = set(get_recommended_movies_graph_embeddings((idx, 'user'), node_vecs_enriched, top_n=10))\n",
    "print(len(ge_enriched_reso.intersection(true_pos)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gmqv_SAl-dcf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "idx = 20\n",
    "true_pos = set([movie_df[movie_df.movieId == id].title.values[0] for id in rating_df[(rating_df['userId'] == idx) & (rating_df['rating'] >= 4.5)].movieId.values])\n",
    "\n",
    "mf_recos = set(get_recommendations_matrix_factorization(idx, user_factors, movie_factors))\n",
    "print(len(mf_recos.intersection(true_pos)))\n",
    "\n",
    "ge_recos = set(get_recommended_movies_graph_embeddings((idx, 'user'), node_vecs, top_n=10))\n",
    "print(len(ge_recos.intersection(true_pos)))\n",
    "\n",
    "ge_enriched_reso = set(get_recommended_movies_graph_embeddings((idx, 'user'), node_vecs_enriched, top_n=10))\n",
    "print(len(ge_enriched_reso.intersection(true_pos)))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "T677598_Jaccard_Cosine_SVD_DeepWalk_ML100K.ipynb",
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}