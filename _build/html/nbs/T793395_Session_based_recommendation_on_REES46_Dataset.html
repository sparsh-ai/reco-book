
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>End-to-end Session-based recommendation on REES46 Dataset &#8212; Reco Book</title>
    
  <link href="../_static/css/theme.css" rel="stylesheet" />
  <link href="../_static/css/index.c5995385ac14fb8791e8eb36b4908be2.css" rel="stylesheet" />

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../_static/sphinx-book-theme.css?digest=c3fdc42140077d1ad13ad2f1588a4309" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../_static/js/index.1c5a1a01449ed65a7b51.js">

    <script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/togglebutton.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../_static/sphinx-book-theme.12a9622fbb08dcb3a2a40b2c02b83a57.js"></script>
    <script async="async" src="https://unpkg.com/thebe@0.5.1/lib/index.js"></script>
    <script >
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="DeepWalk from scratch referencing Karateclub library" href="T382881_DeepWalk_Karateclub.html" />
    <link rel="prev" title="Transformers4Rec XLNet on Synthetic data" href="T382183_Transformers4Rec_XLNet_on_Synthetic_data.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../index.html">
      
      
      
      <h1 class="site-logo" id="site-title">Reco Book</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../index.html">
   Tutorials in Jupyter notebook format
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  User Stories
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1 current active has-children">
  <a class="reference internal" href="US780867_Transformer_based_Recommenders.html">
   Transformer-based Recommenders
  </a>
  <input checked="" class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="current">
   <li class="toctree-l2">
    <a class="reference internal" href="T034923_BERT4Rec_on_ML1M_in_PyTorch.html">
     BERT4Rec on ML-1M in PyTorch
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="T595874_BERT4Rec_on_ML25M_in_PyTorch_Lightning.html">
     BERT4Rec on ML-25M
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="T088416_BST_Implementation_in_MXNet.html">
     BST Implementation in MXNet
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="T602245_BST_implementation_in_PyTorch.html">
     BST implementation in PyTorch
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="T007665_BST_on_ML1M_in_Keras.html">
     A Transformer-based recommendation system
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="T881207_BST_PTLightning_ML1M.html">
     Rating prediction using the Behavior Sequence Transformer (BST) model on ML-1M dataset in PyTorch Lightning
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="T025247_BST_using_Deepctr_library.html">
     BST using Deepctr library
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="T757997_SASRec_PyTorch.html">
     SASRec implementation with PyTorch Library
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="T225287_SASRec_PaddlePaddle.html">
     SASRec implementation with Paddle Library
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="T701627_SR_SAN_Session_based_Model.html">
     SR-SAN Session-based Recommender
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="T975104_SSEPT_ML1M_Tensorflow1x.html">
     SSE-PT Personalized Transformer Recommender on ML-1M in Tensorflow 1.x
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="T472955_GCSAN_Session_based_Model.html">
     GCSAN Session-based Recommender
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="T970274_Transformers4Rec_Session_based_Recommender_on_Yoochoose.html">
     End-to-end session-based recommendation with Transformers4Rec
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="T382183_Transformers4Rec_XLNet_on_Synthetic_data.html">
     Transformers4Rec XLNet on Synthetic data
    </a>
   </li>
   <li class="toctree-l2 current active">
    <a class="current reference internal" href="#">
     End-to-end Session-based recommendation on REES46 Dataset
    </a>
   </li>
  </ul>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Prototypes
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="T382881_DeepWalk_Karateclub.html">
   DeepWalk from scratch referencing Karateclub library
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T384270_DeepWalk_pure_python.html">
   DeepWalk in pure python
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T677598_Jaccard_Cosine_SVD_DeepWalk_ML100K.html">
   Recommender System with DeepWalk Graph Embeddings
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T815556_Node2vec_Karateclub.html">
   Node2vec from scratch referencing Karateclub library
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T894941_Node2vec_MovieLens_Keras.html">
   Graph representation learning with node2vec
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T611050_Node2vec_PyG.html">
   Node2vec from scratch in PyTorch Geometric
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T186367_Node2vec_library.html">
   Node2vec from scratch referencing node2vec library
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T331379_bayesian_personalized_ranking.html">
   BPR from scratch
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T081831_Data_Poisoning_Attacks_on_Factorization_Based_Collaborative_Filtering.html">
   Data Poisoning Attacks on Factorization-Based Collaborative Filtering
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T102448_Adversarial_Learning_for_Recommendation.html">
   Adversarial Training (Regularization) on a Recommender System
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T865035_Simulating_Data_Poisoning_Attacks_against_Twitter_Recommender.html">
   Load and process dataset
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T711285_Data_Poisoning_Attack_using_LFM_and_ItemAE_on_Synthetic_Dataset.html">
   Injection attack using LFM and ItemAE model trained on Toy dataset
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T355514_Black_box_Attack_on_Sequential_Recs.html">
   Black-box Attack on Sequential Recs
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T873451_Statistics_fundamentals.html">
   Statictics Fundamentals
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T890478_Batch_Learning_from_Bandit_Feedback_%28BLBF%29.html">
   Imports
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T257798_Off_Policy_Learning_in_Two_stage_Recommender_Systems.html">
   Off-Policy Learning in Two-stage Recommender Systems
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T471827_Adaptive_Estimator_Selection_for_Off_Policy_Evaluation.html">
   Adaptive Estimator Selection for Off-Policy Evaluation
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T902666_Evaluating_the_Robustness_of_Off_Policy_Evaluation.html">
   Evaluating the Robustness of Off-Policy Evaluation
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T705904_Evaluation_of_Multiple_Off_Policy_Estimators_on_Synthetic_Dataset.html">
   Evaluation of Multiple Off-Policy Estimators on Synthetic Dataset
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T874693_Evaluating_Standard_Off_Policy_Estimators_with_Small_Sample_Open_Bandit_Dataset.html">
   Evaluating Standard Off-Policy Estimators with Small Sample Open-Bandit Dataset
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T792262_Optimal_Off_Policy_Evaluation_from_Multiple_Logging_Policies.html">
   Optimal Off-Policy Evaluation from Multiple Logging Policies
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T167249_Offline_Policy_Evaluation_with_VW_Command_Line.html">
   Offline Policy Evaluation with VW Command Line
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T966055_OBP_Library_Workshop_Tutorials.html">
   OBP Library Workshop Tutorials
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T632722_PyTorch_Fundamentals_Part_1.html">
   PyTorch Fundamentals Part 1
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T472467_PyTorch_Fundamentals_Part_2.html">
   PyTorch Fundamentals Part 2
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T206654_PyTorch_Fundamentals_Part_3.html">
   PyTorch Fundamentals Part 3
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T536348_Attention_Mechanisms.html">
   Imports
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T500796_Agricultural_Satellite_Image_Segmentation.html">
   Agricultural Satellite Image Segmentation
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T611432_Image_Analysis_with_Tensorflow.html">
   Image Analysis with Tensorflow
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T925716_MongoDB_to_CSV_Conversion.html">
   MongoDB to CSV conversion
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T396469_PDF_to_Word_Cloud_via_Email.html">
   PDF to WordCloud via Email
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T030890_Job_Scraping_and_Clustering.html">
   Job scraping and clustering
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T897054_Scene_Text_Recognition.html">
   Scene Text Recognition
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T034809_Large_scale_Document_Retrieval_with_Elastic_Search.html">
   Large-scale Document Retrieval with ElasticSearch
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T467251_vowpal_wabbit_contextual_recommender.html">
   Simulating a news personalization scenario using Contextual Bandits
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T686684_similar_product_recommender.html">
   Similar Product Recommender system using Deep Learning for an online e-commerce store
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T132203_Retail_Product_Recommendations_using_Word2vec.html">
   Retail Product Recommendations using word2vec
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T501828_Recommender_Implicit_Negative_Feedback.html">
   Retail Product Recommendation with Negative Implicit Feedback
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T315965_Sequence_Aware_Recommenders_Music.html">
   Sequence Aware Recommender Systems
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T051777_image_similarity_recommendations.html">
   Similar Product Recommendations
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T990172_recobook_diversity_aware_book_recommender.html">
   Diversity Aware Book Recommender
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T488549_Goodreads_Diversity_Aware_Book_Recommender.html">
   Diversity Aware Book Recommender
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T023535_Kafka_MongoDB_Real_time_Streaming.html">
   Kafka MongoDB Real-time Streaming
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T622304_Session_based_Recommender_Using_Word2vec.html">
   Session-based recommendation using word2vec
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T416854_bandit_based_recommender_using_thompson_sampling_app.html">
   Bandit-based Online Learning using Thompson Sampling
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T198578_Booking_dot_com_Trip_Recommendation.html">
   Booking.com Trip Recommendation
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T519734_Vowpal_Wabbit_Contextual_Bandit.html">
   Vowpal Wabbit Contextual Bandit
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T871537_Recommendation_Systems_using_Olist_Dataset.html">
   Recommendation systems using Olist dataset
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T057885_Offline_Replayer_Evaluation.html">
   Offline Replayer Evaluation
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T915054_method_for_effective_online_testing.html">
   Methods for effective online testing
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T513987_Recsys_2020_Feature_Engineering_Tutorial.html">
   Recsys’20 Feature Engineering Tutorial
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T227901_amazon_personalize_batch_job.html">
   Amazon Personalize Batch Job
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T022961_Amazon_Personalize_Workshop.html">
   Amazon Personalize Workshop
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T424437_Collaborative_Filtering_on_ML_latest_small.html">
   Collaborative Filtering on ML-latest-small
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T539160_Building_and_Deploying_ASOS_Fashion_Recommender.html">
   Building and deploying ASOS fashion recommender
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T757697_Simple_Similarity_based_Recommender.html">
   Simple Similarity based Recommmendations
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T051594_Analytics_Zoo.html">
   Analytics Zoo
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T313645_A_B_Testing.html">
   A/B Testing
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T475711_PinSage_Graph_based_Recommender.html">
   PinSage Graph-based Recommender
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T516490_Graph_Embeddings.html">
   Learn Embeddings using Graph Networks
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T822164_movielens_milvus_redis_efficient_retrieval.html">
   Recommender with Redis and Milvus
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T845186_Anime_Recommender.html">
   RekoNet Anime Recommender
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T855843_kafka_spark_streaming_colab.html">
   Kafka and Spark Streaming in Colab
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T460437_Building_Models_From_Scratch.html">
   Building Models from scratch
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T855971_Conet_Model_for_Movie_Recommender.html">
   CoNet model
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T996996_content_based_and_collaborative_movielens.html">
   Movie Recommendation with Content-Based and Collaborative Filtering
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T239418_Simple_Movie_Recommenders.html">
   Simple Movie Recommenders
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T138337_Simple_Movie_Recommender.html">
   Simple movie recommender in implicit, explicit, and cold-start settings
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T935440_The_importance_of_Rating_Normalization.html">
   The importance of Rating Normalization
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T612622_cornac_examples.html">
   Cornac Examples
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T561435_Flower_Classification.html">
   Flower classification
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T680910_Trivago_Session_based_Recommender.html">
   Trivago Session-based Recommender
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T990000_ads_selection_using_bandits.html">
   Best Ads detection using bandit methods
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T990000_book_crossing_surprise_svd_nmf.html">
   Book-Crossing Recommendation System
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T990000_book_recommender_kubeflow.html">
   Books recommendations with Kubeflow Pipelines on Scaleway Kapsule
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T990000_build_a_kubeflow_pipeline.html">
   Build a Kubeflow Pipeline
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T990000_causal_inference.html">
   Causal Inference
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T990000_concept_embedding_nlp.html">
   Exploring Word Embeddings
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T990000_concept_neural_net.html">
   Neural Network
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T990000_concept_nlp_basics.html">
   Natural Language Processing 101
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T990000_concept_transformer_lm.html">
   TransformerLM Quick Start and Guide
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T990000_content_based_music_recommender_lyricsfreak.html">
   Content-based method for song recommendation
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T990000_evaluation_metrics_basics.html">
   Recommender System Evaluations
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T990000_implicit_synthetic.html">
   Comparing Implicit Models on Synthetic Data
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T990000_movie_recommender_tensorflow.html">
   Recommendation Systems with TensorFlow
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T990000_movie_recommender_tensorflow_sagemaker.html">
   Movie recommender using Tensorflow in Sagemaker
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T990000_movielens_eda_modeling.html">
   Movielens EDA and Modeling
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T990000_read_data_from_cassandra_into_pandas.html">
   Read Cassandra Data Snapshot as DataFrame
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T990000_rl_in_action.html">
   Reinforcement Learning fundamentals in action
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T990000_rnn_cnn_basics.html">
   Processing sequences using RNNs and CNNs
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T990000_tf_serving_in_action.html">
   TF Serving in action
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T990000_training_indexing_movie_recommender.html">
   Training and indexing movie recommender
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T207114_EduRec_MOOCCube_Course_Recommender.html">
   EduRec MOOCCube Course Recommender
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T273184_Multi_Task_Learning.html">
   Multi-task Learning
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T661108_Book_Recommender_API.html">
   Book Recommender API
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T912764_Simple_Movie_Recommender_App.html">
   Simple Movie Recommender App
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T964554_Career_Village_Questions_Recommendation.html">
   CareerVillage Questions Recommendation
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T990001_amazon_women_apparel_tfidf_word2vec.html">
   Amazon Product Recommender
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T990001_anime_recommender_graph_network.html">
   Anime Recommender with Bi-partite Graph Network
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T990001_concept_self_attention.html">
   Self-Attention
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T990001_course_recommender_svd_flask.html">
   Course Recommender with SVD based similarity
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T990001_data_mining_similarity_measures.html">
   Concept - Data Mining Similarity Measures
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T990001_jaccard_recommender.html">
   Jaccard Similarity based Recommender
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T990001_live_streamer_recommender.html">
   Live Streamer Recommender with Implicit feedback
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T990001_songs_embedding_skipgram_recommender.html">
   Song Embeddings - Skipgram Recommender
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T990001_toy_example_car_recommender_knn.html">
   Toy example - Car Recommender using KNN method
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T990001_wikirecs_recommender.html">
   WikiRecs
  </a>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../_sources/nbs/T793395_Session_based_recommendation_on_REES46_Dataset.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
        title="Fullscreen mode"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        <a class="binder-button" href="https://mybinder.org/v2/gh/sparsh-ai/reco-book/main?urlpath=tree/nbs/T793395_Session_based_recommendation_on_REES46_Dataset.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Launch Binder" data-toggle="tooltip"
                data-placement="left"><img class="binder-button-logo"
                    src="../_static/images/logo_binder.svg"
                    alt="Interact on binder">Binder</button></a>
        
        
        
        
    </div>
</div>

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show">
            
            <div class="tocsection onthispage pt-5 pb-3">
                <i class="fas fa-list"></i> Contents
            </div>
            <nav id="bd-toc-nav" aria-label="Page">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#learning-objectives">
   Learning Objectives
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#import-the-required-libraries">
   Import the required libraries
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#read-and-process-e-commerce-data">
   Read and Process E-Commerce data
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#read-data-via-cudf-from-csv">
   Read Data via cuDF from CSV
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#convert-timestamp-from-datetime">
   Convert timestamp from datetime
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#categorify-user-session-column">
   Categorify
   <code class="docutils literal notranslate">
    <span class="pre">
     user_session
    </span>
   </code>
   column
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#removing-consecutive-repeated-user-item-interactions">
   Removing consecutive repeated (user, item) interactions
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#include-the-item-first-time-seen-feature-for-recency-calculation">
   Include the item first time seen feature (for recency calculation)
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#etl-with-nvtabular">
   ETL with NVTabular
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#read-the-input-parquet-file">
   Read the Input Parquet file
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#initialize-nvtabular-workflow">
   Initialize NVTabular Workflow
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#categorical-features-encoding">
     Categorical Features Encoding
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#extract-temporal-features">
     Extract Temporal Features
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#normalize-continuous-features">
     Normalize Continuous Features
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#grouping-interactions-into-sessions">
     Grouping interactions into sessions
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#exporting-data">
   Exporting data
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#session-based-recommendation-with-transformers4rec">
   Session-based recommendation with Transformers4Rec
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#training-an-rnn-based-session-based-recommendation-model">
   Training an RNN-based Session-based Recommendation Model
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#instantiates-schema-object-from-a-schema-file">
     Instantiates Schema object from a
     <code class="docutils literal notranslate">
      <span class="pre">
       schema
      </span>
     </code>
     file.
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#defining-the-input-block-tabularsequencefeatures">
     Defining the input block:
     <code class="docutils literal notranslate">
      <span class="pre">
       TabularSequenceFeatures
      </span>
     </code>
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#connecting-the-blocks-with-sequentialblock">
     Connecting the blocks with
     <code class="docutils literal notranslate">
      <span class="pre">
       SequentialBlock
      </span>
     </code>
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#item-prediction-head-and-tying-embeddings">
     Item Prediction head and tying embeddings
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#define-a-dataloader-function-from-schema">
     Define a Dataloader function from schema
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#daily-fine-tuning-training-over-a-time-window">
     Daily Fine-Tuning: Training over a time window
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#set-training-arguments">
     Set training arguments
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#instantiate-the-trainer">
     Instantiate the Trainer
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#model-finetuning-and-incremental-evaluation">
     Model finetuning and incremental evaluation
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#metrics">
     Metrics
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#restart-the-kernel-to-free-our-gpu-memory">
     Restart the kernel to free our GPU memory
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#training-a-transformer-based-session-based-recommendation-model">
   Training a Transformer-based Session-based Recommendation Model
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#what-s-transformers">
     What’s Transformers?
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#xlnet">
     XLNet
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#train-xlnet-for-next-item-prediction">
     Train XLNET for Next Item Prediction
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#define-input-block">
     Define Input block
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#train-xlnet-with-side-information-for-next-item-prediction">
     Train XLNET with Side Information for Next Item Prediction
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#training-and-evaluation">
     Training and Evaluation
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#exporting-the-preprocessing-workflow-and-model-for-deployment-to-triton-server">
   Exporting the preprocessing workflow and model for deployment to Triton server
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#triton-for-recommender-systems">
   Triton for Recommender Systems
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#pull-and-start-inference-docker-container">
   Pull and start Inference docker container
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#deploy-pytorch-and-nvtabular-model-to-triton-inference-server">
   Deploy PyTorch and NVTabular Model to Triton Inference Server
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#review-exported-files">
   Review exported files
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#loading-model">
   Loading Model
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#sent-requests-for-predictions">
   Sent Requests for Predictions
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#visualise-top-k-predictions">
   Visualise top-k predictions
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#unload-models-and-shut-down-the-kernel">
   Unload models and shut down the kernel
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#references">
   References
  </a>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <p><a href="https://colab.research.google.com/github/sparsh-ai/reco-book/blob/stage/nbs/T793395_Session_based_recommendation_on_REES46_Dataset.ipynb" target="_parent"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/></a></p>
<div class="section" id="end-to-end-session-based-recommendation-on-rees46-dataset">
<h1>End-to-end Session-based recommendation on REES46 Dataset<a class="headerlink" href="#end-to-end-session-based-recommendation-on-rees46-dataset" title="Permalink to this headline">¶</a></h1>
<p>Session-based recommendation, a sub-area of sequential recommendation, has been an important task in online services like e-commerce and news portals. Session-based recommenders provide relevant and personalized recommendations even when prior user history is not available or their tastes change over time. They recently gained popularity due to their ability to capture short-term or contextual user preferences towards items.</p>
<div class="section" id="learning-objectives">
<h2>Learning Objectives<a class="headerlink" href="#learning-objectives" title="Permalink to this headline">¶</a></h2>
<p>In this tutorial, we will learn:</p>
<ul class="simple">
<li><p>the main concepts and algorithms for session-based recommendation</p></li>
<li><p>implementation of preprocessing and feature engineering techniques for session-based recommendation model on GPU with NVTabular</p></li>
<li><p>how to build, train and evaluate a session-based recommendation model based on RNN and Transformer architectures with Transformers4Rec library</p></li>
<li><p>how to deploy a trained model to the Triton Inference Server</p></li>
<li><p>Preprocessing with cuDF and NVTabular</p></li>
<li><p>Feature engineering with NVTabular</p></li>
<li><p>Introduction to Transformers4Rec</p></li>
<li><p>Introduction to session-based recommendation</p></li>
<li><p>Accelerated dataloaders for PyTorch</p></li>
<li><p>Traning and evaluating an RNN-based session based recommendation model for next item prediction task</p></li>
<li><p>Traning and evaluating Transformer architecture based session-based recommendation model next item prediction task</p></li>
<li><p>Using side information (additional features) to improve the accuracy of a model</p></li>
<li><p>Deploying to inference with Triton</p></li>
</ul>
</div>
<div class="section" id="import-the-required-libraries">
<h2>Import the required libraries<a class="headerlink" href="#import-the-required-libraries" title="Permalink to this headline">¶</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span> 
<span class="kn">import</span> <span class="nn">gc</span>
<span class="kn">import</span> <span class="nn">shutil</span>
<span class="kn">import</span> <span class="nn">glob</span>

<span class="kn">import</span> <span class="nn">cudf</span>
<span class="kn">import</span> <span class="nn">cupy</span> <span class="k">as</span> <span class="nn">cp</span>
<span class="kn">import</span> <span class="nn">nvtabular</span> <span class="k">as</span> <span class="nn">nvt</span>
<span class="kn">from</span> <span class="nn">nvtabular</span> <span class="kn">import</span> <span class="n">ColumnSelector</span>

<span class="kn">import</span> <span class="nn">transformers4rec.torch</span> <span class="k">as</span> <span class="nn">tr</span>
<span class="kn">from</span> <span class="nn">transformers4rec.torch.ranking_metric</span> <span class="kn">import</span> <span class="n">NDCGAt</span><span class="p">,</span> <span class="n">RecallAt</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="read-and-process-e-commerce-data">
<h2>Read and Process E-Commerce data<a class="headerlink" href="#read-and-process-e-commerce-data" title="Permalink to this headline">¶</a></h2>
<p>In this section, we are going to use a subset of a publicly available <a class="reference external" href="https://www.kaggle.com/mkechinov/ecommerce-behavior-data-from-multi-category-store">eCommerce dataset</a>. The full dataset contains 7 months data (from October 2019 to April 2020) from a large multi-category online store. Each row in the file represents an event. All events are related to products and users. Each event is like many-to-many relation between products and users.
Data collected by Open CDP project and the source of the dataset is <a class="reference external" href="https://rees46.com/">REES46 Marketing Platform</a>.</p>
<p>We use only <code class="docutils literal notranslate"><span class="pre">2019-Oct.csv</span></code> file for training our models, so you can visit this site and download the csv file: <a class="reference external" href="https://www.kaggle.com/mkechinov/ecommerce-behavior-data-from-multi-category-store">https://www.kaggle.com/mkechinov/ecommerce-behavior-data-from-multi-category-store</a>.</p>
</div>
<div class="section" id="read-data-via-cudf-from-csv">
<h2>Read Data via cuDF from CSV<a class="headerlink" href="#read-data-via-cudf-from-csv" title="Permalink to this headline">¶</a></h2>
<p>At this point we expect that you have already downloaded the <code class="docutils literal notranslate"><span class="pre">2019-Oct.csv</span></code> dataset and stored it in the <code class="docutils literal notranslate"><span class="pre">INPUT_DATA_DIR</span></code> as defined below. It is worth mentioning that the raw dataset is ~ 6 GB, therefore a single GPU with 16 GB or less memory might run out of memory.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># define some information about where to get our data</span>
<span class="n">INPUT_DATA_DIR</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;INPUT_DATA_DIR&quot;</span><span class="p">,</span> <span class="s2">&quot;/workspace/data/&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">%%</span><span class="n">time</span>
<span class="n">raw_df</span> <span class="o">=</span> <span class="n">cudf</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">INPUT_DATA_DIR</span><span class="p">,</span> <span class="s1">&#39;2019-Oct.csv&#39;</span><span class="p">))</span> 
<span class="n">raw_df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>CPU times: user 3.2 s, sys: 1.5 s, total: 4.69 s
Wall time: 5.32 s
</pre></div>
</div>
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>event_time</th>
      <th>event_type</th>
      <th>product_id</th>
      <th>category_id</th>
      <th>category_code</th>
      <th>brand</th>
      <th>price</th>
      <th>user_id</th>
      <th>user_session</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>2019-10-01 00:00:00 UTC</td>
      <td>view</td>
      <td>44600062</td>
      <td>2103807459595387724</td>
      <td>&lt;NA&gt;</td>
      <td>shiseido</td>
      <td>35.79</td>
      <td>541312140</td>
      <td>72d76fde-8bb3-4e00-8c23-a032dfed738c</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2019-10-01 00:00:00 UTC</td>
      <td>view</td>
      <td>3900821</td>
      <td>2053013552326770905</td>
      <td>appliances.environment.water_heater</td>
      <td>aqua</td>
      <td>33.20</td>
      <td>554748717</td>
      <td>9333dfbd-b87a-4708-9857-6336556b0fcc</td>
    </tr>
    <tr>
      <th>2</th>
      <td>2019-10-01 00:00:01 UTC</td>
      <td>view</td>
      <td>17200506</td>
      <td>2053013559792632471</td>
      <td>furniture.living_room.sofa</td>
      <td>&lt;NA&gt;</td>
      <td>543.10</td>
      <td>519107250</td>
      <td>566511c2-e2e3-422b-b695-cf8e6e792ca8</td>
    </tr>
    <tr>
      <th>3</th>
      <td>2019-10-01 00:00:01 UTC</td>
      <td>view</td>
      <td>1307067</td>
      <td>2053013558920217191</td>
      <td>computers.notebook</td>
      <td>lenovo</td>
      <td>251.74</td>
      <td>550050854</td>
      <td>7c90fc70-0e80-4590-96f3-13c02c18c713</td>
    </tr>
    <tr>
      <th>4</th>
      <td>2019-10-01 00:00:04 UTC</td>
      <td>view</td>
      <td>1004237</td>
      <td>2053013555631882655</td>
      <td>electronics.smartphone</td>
      <td>apple</td>
      <td>1081.98</td>
      <td>535871217</td>
      <td>c6bd7419-2748-4c56-95b4-8cec9ff8b80d</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">raw_df</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(42448764, 9)
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="convert-timestamp-from-datetime">
<h2>Convert timestamp from datetime<a class="headerlink" href="#convert-timestamp-from-datetime" title="Permalink to this headline">¶</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">raw_df</span><span class="p">[</span><span class="s1">&#39;event_time_dt&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">raw_df</span><span class="p">[</span><span class="s1">&#39;event_time&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s1">&#39;datetime64[s]&#39;</span><span class="p">)</span>
<span class="n">raw_df</span><span class="p">[</span><span class="s1">&#39;event_time_ts&#39;</span><span class="p">]</span><span class="o">=</span> <span class="n">raw_df</span><span class="p">[</span><span class="s1">&#39;event_time_dt&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s1">&#39;int&#39;</span><span class="p">)</span>
<span class="n">raw_df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>event_time</th>
      <th>event_type</th>
      <th>product_id</th>
      <th>category_id</th>
      <th>category_code</th>
      <th>brand</th>
      <th>price</th>
      <th>user_id</th>
      <th>user_session</th>
      <th>event_time_dt</th>
      <th>event_time_ts</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>2019-10-01 00:00:00 UTC</td>
      <td>view</td>
      <td>44600062</td>
      <td>2103807459595387724</td>
      <td>&lt;NA&gt;</td>
      <td>shiseido</td>
      <td>35.79</td>
      <td>541312140</td>
      <td>72d76fde-8bb3-4e00-8c23-a032dfed738c</td>
      <td>2019-10-01 00:00:00</td>
      <td>1569888000</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2019-10-01 00:00:00 UTC</td>
      <td>view</td>
      <td>3900821</td>
      <td>2053013552326770905</td>
      <td>appliances.environment.water_heater</td>
      <td>aqua</td>
      <td>33.20</td>
      <td>554748717</td>
      <td>9333dfbd-b87a-4708-9857-6336556b0fcc</td>
      <td>2019-10-01 00:00:00</td>
      <td>1569888000</td>
    </tr>
    <tr>
      <th>2</th>
      <td>2019-10-01 00:00:01 UTC</td>
      <td>view</td>
      <td>17200506</td>
      <td>2053013559792632471</td>
      <td>furniture.living_room.sofa</td>
      <td>&lt;NA&gt;</td>
      <td>543.10</td>
      <td>519107250</td>
      <td>566511c2-e2e3-422b-b695-cf8e6e792ca8</td>
      <td>2019-10-01 00:00:01</td>
      <td>1569888001</td>
    </tr>
    <tr>
      <th>3</th>
      <td>2019-10-01 00:00:01 UTC</td>
      <td>view</td>
      <td>1307067</td>
      <td>2053013558920217191</td>
      <td>computers.notebook</td>
      <td>lenovo</td>
      <td>251.74</td>
      <td>550050854</td>
      <td>7c90fc70-0e80-4590-96f3-13c02c18c713</td>
      <td>2019-10-01 00:00:01</td>
      <td>1569888001</td>
    </tr>
    <tr>
      <th>4</th>
      <td>2019-10-01 00:00:04 UTC</td>
      <td>view</td>
      <td>1004237</td>
      <td>2053013555631882655</td>
      <td>electronics.smartphone</td>
      <td>apple</td>
      <td>1081.98</td>
      <td>535871217</td>
      <td>c6bd7419-2748-4c56-95b4-8cec9ff8b80d</td>
      <td>2019-10-01 00:00:04</td>
      <td>1569888004</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># check out the columns with nulls</span>
<span class="n">raw_df</span><span class="o">.</span><span class="n">isnull</span><span class="p">()</span><span class="o">.</span><span class="n">any</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>event_time       False
event_type       False
product_id       False
category_id      False
category_code     True
brand             True
price            False
user_id          False
user_session      True
event_time_dt    False
event_time_ts    False
dtype: bool
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Remove rows where `user_session` is null.</span>
<span class="n">raw_df</span> <span class="o">=</span> <span class="n">raw_df</span><span class="p">[</span><span class="n">raw_df</span><span class="p">[</span><span class="s1">&#39;user_session&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">isnull</span><span class="p">()</span><span class="o">==</span><span class="kc">False</span><span class="p">]</span>
<span class="nb">len</span><span class="p">(</span><span class="n">raw_df</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>42448762
</pre></div>
</div>
</div>
</div>
<p>We no longer need <code class="docutils literal notranslate"><span class="pre">event_time</span></code> column.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">raw_df</span> <span class="o">=</span> <span class="n">raw_df</span><span class="o">.</span><span class="n">drop</span><span class="p">([</span><span class="s1">&#39;event_time&#39;</span><span class="p">],</span>  <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="categorify-user-session-column">
<h2>Categorify <code class="docutils literal notranslate"><span class="pre">user_session</span></code> column<a class="headerlink" href="#categorify-user-session-column" title="Permalink to this headline">¶</a></h2>
<p>Although <code class="docutils literal notranslate"><span class="pre">user_session</span></code> is not used as an input feature for the model, it is useful to convert those raw long string to int values to avoid potential failures when grouping interactions by <code class="docutils literal notranslate"><span class="pre">user_session</span></code> in the next section.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">cols</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">raw_df</span><span class="o">.</span><span class="n">columns</span><span class="p">)</span>
<span class="n">cols</span><span class="o">.</span><span class="n">remove</span><span class="p">(</span><span class="s1">&#39;user_session&#39;</span><span class="p">)</span>
<span class="n">cols</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[&#39;event_type&#39;,
 &#39;product_id&#39;,
 &#39;category_id&#39;,
 &#39;category_code&#39;,
 &#39;brand&#39;,
 &#39;price&#39;,
 &#39;user_id&#39;,
 &#39;event_time_dt&#39;,
 &#39;event_time_ts&#39;]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># load data </span>
<span class="n">df_event</span> <span class="o">=</span> <span class="n">nvt</span><span class="o">.</span><span class="n">Dataset</span><span class="p">(</span><span class="n">raw_df</span><span class="p">)</span> 

<span class="c1"># categorify user_session </span>
<span class="n">cat_feats</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;user_session&#39;</span><span class="p">]</span> <span class="o">&gt;&gt;</span> <span class="n">nvt</span><span class="o">.</span><span class="n">ops</span><span class="o">.</span><span class="n">Categorify</span><span class="p">()</span>

<span class="n">workflow</span> <span class="o">=</span> <span class="n">nvt</span><span class="o">.</span><span class="n">Workflow</span><span class="p">(</span><span class="n">cols</span> <span class="o">+</span> <span class="n">cat_feats</span><span class="p">)</span>
<span class="n">workflow</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">df_event</span><span class="p">)</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">workflow</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">df_event</span><span class="p">)</span><span class="o">.</span><span class="n">to_ddf</span><span class="p">()</span><span class="o">.</span><span class="n">compute</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>user_session</th>
      <th>event_type</th>
      <th>product_id</th>
      <th>category_id</th>
      <th>category_code</th>
      <th>brand</th>
      <th>price</th>
      <th>user_id</th>
      <th>event_time_dt</th>
      <th>event_time_ts</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>5126085</td>
      <td>view</td>
      <td>44600062</td>
      <td>2103807459595387724</td>
      <td>&lt;NA&gt;</td>
      <td>shiseido</td>
      <td>35.79</td>
      <td>541312140</td>
      <td>2019-10-01 00:00:00</td>
      <td>1569888000</td>
    </tr>
    <tr>
      <th>1</th>
      <td>7854470</td>
      <td>view</td>
      <td>3900821</td>
      <td>2053013552326770905</td>
      <td>appliances.environment.water_heater</td>
      <td>aqua</td>
      <td>33.20</td>
      <td>554748717</td>
      <td>2019-10-01 00:00:00</td>
      <td>1569888000</td>
    </tr>
    <tr>
      <th>2</th>
      <td>730655</td>
      <td>view</td>
      <td>17200506</td>
      <td>2053013559792632471</td>
      <td>furniture.living_room.sofa</td>
      <td>&lt;NA&gt;</td>
      <td>543.10</td>
      <td>519107250</td>
      <td>2019-10-01 00:00:01</td>
      <td>1569888001</td>
    </tr>
    <tr>
      <th>3</th>
      <td>1637332</td>
      <td>view</td>
      <td>1307067</td>
      <td>2053013558920217191</td>
      <td>computers.notebook</td>
      <td>lenovo</td>
      <td>251.74</td>
      <td>550050854</td>
      <td>2019-10-01 00:00:01</td>
      <td>1569888001</td>
    </tr>
    <tr>
      <th>4</th>
      <td>4202155</td>
      <td>view</td>
      <td>1004237</td>
      <td>2053013555631882655</td>
      <td>electronics.smartphone</td>
      <td>apple</td>
      <td>1081.98</td>
      <td>535871217</td>
      <td>2019-10-01 00:00:04</td>
      <td>1569888004</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">raw_df</span> <span class="o">=</span> <span class="kc">None</span>
<span class="k">del</span><span class="p">(</span><span class="n">raw_df</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">gc</span><span class="o">.</span><span class="n">collect</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>145
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="removing-consecutive-repeated-user-item-interactions">
<h2>Removing consecutive repeated (user, item) interactions<a class="headerlink" href="#removing-consecutive-repeated-user-item-interactions" title="Permalink to this headline">¶</a></h2>
<p>We keep repeated interactions on the same items, removing only consecutive interactions, because it might be due to browser tab refreshes or different interaction types (e.g. click, add-to-card, purchase)</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">%%</span><span class="n">time</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">sort_values</span><span class="p">([</span><span class="s1">&#39;user_session&#39;</span><span class="p">,</span> <span class="s1">&#39;event_time_ts&#39;</span><span class="p">])</span><span class="o">.</span><span class="n">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Count with in-session repeated interactions: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">df</span><span class="p">)))</span>
<span class="c1"># Sorts the dataframe by session and timestamp, to remove consecutive repetitions</span>
<span class="n">df</span><span class="p">[</span><span class="s1">&#39;product_id_past&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;product_id&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">shift</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">fillna</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="n">df</span><span class="p">[</span><span class="s1">&#39;session_id_past&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;user_session&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">shift</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">fillna</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="c1">#Keeping only no consecutive repeated in session interactions</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="o">~</span><span class="p">((</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;user_session&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;session_id_past&#39;</span><span class="p">])</span> <span class="o">&amp;</span> \
             <span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;product_id&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;product_id_past&#39;</span><span class="p">]))]</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Count after removed in-session repeated interactions: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">df</span><span class="p">)))</span>
<span class="k">del</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;product_id_past&#39;</span><span class="p">])</span>
<span class="k">del</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;session_id_past&#39;</span><span class="p">])</span>

<span class="n">gc</span><span class="o">.</span><span class="n">collect</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Count with in-session repeated interactions: 42448762
Count after removed in-session repeated interactions: 30733301
CPU times: user 789 ms, sys: 120 ms, total: 909 ms
Wall time: 1.16 s
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="include-the-item-first-time-seen-feature-for-recency-calculation">
<h2>Include the item first time seen feature (for recency calculation)<a class="headerlink" href="#include-the-item-first-time-seen-feature-for-recency-calculation" title="Permalink to this headline">¶</a></h2>
<p>We create <code class="docutils literal notranslate"><span class="pre">prod_first_event_time_ts</span></code> column which indicates the timestamp that an item was seen first time.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">item_first_interaction_df</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="s1">&#39;product_id&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">agg</span><span class="p">({</span><span class="s1">&#39;event_time_ts&#39;</span><span class="p">:</span> <span class="s1">&#39;min&#39;</span><span class="p">})</span> \
            <span class="o">.</span><span class="n">reset_index</span><span class="p">()</span><span class="o">.</span><span class="n">rename</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;event_time_ts&#39;</span><span class="p">:</span> <span class="s1">&#39;prod_first_event_time_ts&#39;</span><span class="p">})</span>
<span class="n">item_first_interaction_df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
<span class="n">gc</span><span class="o">.</span><span class="n">collect</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">merge</span><span class="p">(</span><span class="n">item_first_interaction_df</span><span class="p">,</span> <span class="n">on</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;product_id&#39;</span><span class="p">],</span> <span class="n">how</span><span class="o">=</span><span class="s1">&#39;left&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>user_session</th>
      <th>event_type</th>
      <th>product_id</th>
      <th>category_id</th>
      <th>category_code</th>
      <th>brand</th>
      <th>price</th>
      <th>user_id</th>
      <th>event_time_dt</th>
      <th>event_time_ts</th>
      <th>prod_first_event_time_ts</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>94</td>
      <td>view</td>
      <td>26202560</td>
      <td>2053013563693335403</td>
      <td>&lt;NA&gt;</td>
      <td>&lt;NA&gt;</td>
      <td>388.49</td>
      <td>512892706</td>
      <td>2019-10-15 17:21:59</td>
      <td>1571160119</td>
      <td>1569925682</td>
    </tr>
    <tr>
      <th>1</th>
      <td>94</td>
      <td>view</td>
      <td>26203994</td>
      <td>2053013563693335403</td>
      <td>&lt;NA&gt;</td>
      <td>&lt;NA&gt;</td>
      <td>157.79</td>
      <td>512892706</td>
      <td>2019-10-15 17:22:17</td>
      <td>1571160137</td>
      <td>1569941460</td>
    </tr>
    <tr>
      <th>2</th>
      <td>94</td>
      <td>view</td>
      <td>26204036</td>
      <td>2053013563693335403</td>
      <td>&lt;NA&gt;</td>
      <td>sokolov</td>
      <td>471.70</td>
      <td>512892706</td>
      <td>2019-10-15 17:22:29</td>
      <td>1571160149</td>
      <td>1569897265</td>
    </tr>
    <tr>
      <th>3</th>
      <td>94</td>
      <td>view</td>
      <td>26203994</td>
      <td>2053013563693335403</td>
      <td>&lt;NA&gt;</td>
      <td>&lt;NA&gt;</td>
      <td>157.79</td>
      <td>512892706</td>
      <td>2019-10-15 17:22:58</td>
      <td>1571160178</td>
      <td>1569941460</td>
    </tr>
    <tr>
      <th>4</th>
      <td>94</td>
      <td>view</td>
      <td>26203727</td>
      <td>2053013563693335403</td>
      <td>&lt;NA&gt;</td>
      <td>lucente</td>
      <td>317.38</td>
      <td>512892706</td>
      <td>2019-10-15 17:23:19</td>
      <td>1571160199</td>
      <td>1569901056</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">del</span><span class="p">(</span><span class="n">item_first_interaction_df</span><span class="p">)</span>
<span class="n">item_first_interaction_df</span><span class="o">=</span><span class="kc">None</span>
<span class="n">gc</span><span class="o">.</span><span class="n">collect</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0
</pre></div>
</div>
</div>
</div>
<p>In this tutorial, we only use one week of data from Oct 2019 dataset.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># check the min date</span>
<span class="n">df</span><span class="p">[</span><span class="s1">&#39;event_time_dt&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">min</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>numpy.datetime64(&#39;2019-10-01T00:00:00&#39;)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Filters only the first week of the data.</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;event_time_dt&#39;</span><span class="p">]</span> <span class="o">&lt;</span> <span class="n">np</span><span class="o">.</span><span class="n">datetime64</span><span class="p">(</span><span class="s1">&#39;2019-10-08&#39;</span><span class="p">)]</span><span class="o">.</span><span class="n">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>We verify that we only have the first week of Oct-2019 dataset.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;event_time_dt&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">max</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>numpy.datetime64(&#39;2019-10-07T23:59:59&#39;)
</pre></div>
</div>
</div>
</div>
<p>We drop <code class="docutils literal notranslate"><span class="pre">event_time_dt</span></code> column as it will not be used anymore.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">drop</span><span class="p">([</span><span class="s1">&#39;event_time_dt&#39;</span><span class="p">],</span>  <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>user_session</th>
      <th>event_type</th>
      <th>product_id</th>
      <th>category_id</th>
      <th>category_code</th>
      <th>brand</th>
      <th>price</th>
      <th>user_id</th>
      <th>event_time_ts</th>
      <th>prod_first_event_time_ts</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>43</td>
      <td>view</td>
      <td>5300797</td>
      <td>2053013563173241677</td>
      <td>&lt;NA&gt;</td>
      <td>panasonic</td>
      <td>39.90</td>
      <td>513903572</td>
      <td>1570460611</td>
      <td>1569948287</td>
    </tr>
    <tr>
      <th>1</th>
      <td>43</td>
      <td>view</td>
      <td>5300798</td>
      <td>2053013563173241677</td>
      <td>&lt;NA&gt;</td>
      <td>panasonic</td>
      <td>32.18</td>
      <td>513903572</td>
      <td>1570460616</td>
      <td>1569934097</td>
    </tr>
    <tr>
      <th>2</th>
      <td>43</td>
      <td>view</td>
      <td>5300284</td>
      <td>2053013563173241677</td>
      <td>&lt;NA&gt;</td>
      <td>rowenta</td>
      <td>30.86</td>
      <td>513903572</td>
      <td>1570460621</td>
      <td>1569927253</td>
    </tr>
    <tr>
      <th>3</th>
      <td>43</td>
      <td>view</td>
      <td>5300382</td>
      <td>2053013563173241677</td>
      <td>&lt;NA&gt;</td>
      <td>remington</td>
      <td>28.22</td>
      <td>513903572</td>
      <td>1570460636</td>
      <td>1570026747</td>
    </tr>
    <tr>
      <th>4</th>
      <td>43</td>
      <td>view</td>
      <td>5300366</td>
      <td>2053013563173241677</td>
      <td>&lt;NA&gt;</td>
      <td>polaris</td>
      <td>26.46</td>
      <td>513903572</td>
      <td>1570460650</td>
      <td>1570097085</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>Save the data as a single parquet file to be used in the ETL section.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># save df as parquet files on disk</span>
<span class="n">df</span><span class="o">.</span><span class="n">to_parquet</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">INPUT_DATA_DIR</span><span class="p">,</span> <span class="s1">&#39;Oct-2019.parquet&#39;</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="etl-with-nvtabular">
<h2>ETL with NVTabular<a class="headerlink" href="#etl-with-nvtabular" title="Permalink to this headline">¶</a></h2>
<p>In this section, we will create a preprocessing and feature engineering pipeline with <a class="reference external" href="https://github.com/rapidsai/cudf">Rapids cuDF</a> and <a class="reference external" href="https://github.com/NVIDIA/NVTabular">Merlin NVTabular</a> libraries to prepare our dataset for session-based recommendation model training.</p>
<p>NVTabular is a feature engineering and preprocessing library for tabular data that is designed to easily manipulate terabyte scale datasets and train deep learning (DL) based recommender systems. It provides high-level abstraction to simplify code and accelerates computation on the GPU using the RAPIDS Dask-cuDF library, and is designed to be interoperable with both PyTorch and TensorFlow using dataloaders that have been developed as extensions of native framework code.</p>
<p>Our main goal is to create sequential features. In order to do that, we are going to perform the following:</p>
<ul class="simple">
<li><p>Categorify categorical features with <code class="docutils literal notranslate"><span class="pre">Categorify()</span></code> op</p></li>
<li><p>Create temporal features with a <code class="docutils literal notranslate"><span class="pre">user-defined</span> <span class="pre">custom</span></code> op and <code class="docutils literal notranslate"><span class="pre">Lambda</span></code> op</p></li>
<li><p>Transform continuous features using <code class="docutils literal notranslate"><span class="pre">Log</span></code> and <code class="docutils literal notranslate"><span class="pre">Normalize</span></code> ops</p></li>
<li><p>Group all these features together at the session level sorting the interactions by time with <code class="docutils literal notranslate"><span class="pre">Groupby</span></code></p></li>
<li><p>Finally export the preprocessed datasets to parquet files by hive-partitioning.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># define data path about where to get our data</span>
<span class="n">INPUT_DATA_DIR</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;INPUT_DATA_DIR&quot;</span><span class="p">,</span> <span class="s2">&quot;/workspace/data/&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="read-the-input-parquet-file">
<h2>Read the Input Parquet file<a class="headerlink" href="#read-the-input-parquet-file" title="Permalink to this headline">¶</a></h2>
<p>We already performed certain preprocessing steps on the first month (Oct-2019) of the raw dataset : <br></p>
<ul class="simple">
<li><p>we created <code class="docutils literal notranslate"><span class="pre">event_time_ts</span></code> column from <code class="docutils literal notranslate"><span class="pre">event_time</span></code> column which shows the time when event happened at (in UTC).</p></li>
<li><p>we created <code class="docutils literal notranslate"><span class="pre">prod_first_event_time_ts</span></code> column which indicates the timestamp that an item was seen first time.</p></li>
<li><p>we removed the rows where the <code class="docutils literal notranslate"><span class="pre">user_session</span></code> is Null. As a result, 2 rows were removed.</p></li>
<li><p>we categorified the <code class="docutils literal notranslate"><span class="pre">user_session</span></code> column, so that it now has only integer values.</p></li>
<li><p>we removed consequetively repeated (user, item) interactions. For example, an original session with <code class="docutils literal notranslate"><span class="pre">[1,</span> <span class="pre">2,</span> <span class="pre">4,</span> <span class="pre">1,</span> <span class="pre">2,</span> <span class="pre">2,</span> <span class="pre">3,</span> <span class="pre">3,</span> <span class="pre">3]</span></code> product interactions has become <code class="docutils literal notranslate"><span class="pre">[1,</span> <span class="pre">2,</span> <span class="pre">4,</span> <span class="pre">1,</span> <span class="pre">2,</span> <span class="pre">3]</span></code> after removing the repeated interactions on the same item within the same session.</p></li>
</ul>
<p>Even though the original dataset contains 7 months data files, we are going to use the first seven days of the <code class="docutils literal notranslate"><span class="pre">Oct-2019.csv</span></code> ecommerce dataset. We use cuDF to read the parquet file.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">%%</span><span class="n">time</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">cudf</span><span class="o">.</span><span class="n">read_parquet</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">INPUT_DATA_DIR</span><span class="p">,</span> <span class="s1">&#39;Oct-2019.parquet&#39;</span><span class="p">))</span>  
<span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>CPU times: user 665 ms, sys: 330 ms, total: 995 ms
Wall time: 999 ms
</pre></div>
</div>
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>user_session</th>
      <th>event_type</th>
      <th>product_id</th>
      <th>category_id</th>
      <th>category_code</th>
      <th>brand</th>
      <th>price</th>
      <th>user_id</th>
      <th>event_time_ts</th>
      <th>prod_first_event_time_ts</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>43</td>
      <td>view</td>
      <td>5300797</td>
      <td>2053013563173241677</td>
      <td>&lt;NA&gt;</td>
      <td>panasonic</td>
      <td>39.90</td>
      <td>513903572</td>
      <td>1570460611</td>
      <td>1569948287</td>
    </tr>
    <tr>
      <th>1</th>
      <td>43</td>
      <td>view</td>
      <td>5300798</td>
      <td>2053013563173241677</td>
      <td>&lt;NA&gt;</td>
      <td>panasonic</td>
      <td>32.18</td>
      <td>513903572</td>
      <td>1570460616</td>
      <td>1569934097</td>
    </tr>
    <tr>
      <th>2</th>
      <td>43</td>
      <td>view</td>
      <td>5300284</td>
      <td>2053013563173241677</td>
      <td>&lt;NA&gt;</td>
      <td>rowenta</td>
      <td>30.86</td>
      <td>513903572</td>
      <td>1570460621</td>
      <td>1569927253</td>
    </tr>
    <tr>
      <th>3</th>
      <td>43</td>
      <td>view</td>
      <td>5300382</td>
      <td>2053013563173241677</td>
      <td>&lt;NA&gt;</td>
      <td>remington</td>
      <td>28.22</td>
      <td>513903572</td>
      <td>1570460636</td>
      <td>1570026747</td>
    </tr>
    <tr>
      <th>4</th>
      <td>43</td>
      <td>view</td>
      <td>5300366</td>
      <td>2053013563173241677</td>
      <td>&lt;NA&gt;</td>
      <td>polaris</td>
      <td>26.46</td>
      <td>513903572</td>
      <td>1570460650</td>
      <td>1570097085</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">df</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(6390928, 10)
</pre></div>
</div>
</div>
</div>
<p>Let’s check if there is any column with nulls.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">df</span><span class="o">.</span><span class="n">isnull</span><span class="p">()</span><span class="o">.</span><span class="n">any</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>user_session                False
event_type                  False
product_id                  False
category_id                 False
category_code                True
brand                        True
price                       False
user_id                     False
event_time_ts               False
prod_first_event_time_ts    False
dtype: bool
</pre></div>
</div>
</div>
</div>
<p>We see that <code class="docutils literal notranslate"><span class="pre">'category_code'</span></code> and <code class="docutils literal notranslate"><span class="pre">'brand'</span></code> columns have null values, and in the following cell we are going to fill these nulls with via categorify op, and then all categorical columns will be encoded to continuous integers. Note that we add <code class="docutils literal notranslate"><span class="pre">start_index=1</span></code> in the <code class="docutils literal notranslate"><span class="pre">Categorify</span> <span class="pre">op</span></code> for the categorical columns, the reason for that we want the encoded null values to start from <code class="docutils literal notranslate"><span class="pre">1</span></code> instead of <code class="docutils literal notranslate"><span class="pre">0</span></code> because we reserve <code class="docutils literal notranslate"><span class="pre">0</span></code> for padding the sequence features.</p>
</div>
<div class="section" id="initialize-nvtabular-workflow">
<h2>Initialize NVTabular Workflow<a class="headerlink" href="#initialize-nvtabular-workflow" title="Permalink to this headline">¶</a></h2>
<div class="section" id="categorical-features-encoding">
<h3>Categorical Features Encoding<a class="headerlink" href="#categorical-features-encoding" title="Permalink to this headline">¶</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># categorify features </span>
<span class="n">cat_feats</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;user_session&#39;</span><span class="p">,</span> <span class="s1">&#39;category_code&#39;</span><span class="p">,</span> <span class="s1">&#39;brand&#39;</span><span class="p">,</span> <span class="s1">&#39;user_id&#39;</span><span class="p">,</span> <span class="s1">&#39;product_id&#39;</span><span class="p">,</span> <span class="s1">&#39;category_id&#39;</span><span class="p">,</span> <span class="s1">&#39;event_type&#39;</span><span class="p">]</span> <span class="o">&gt;&gt;</span> <span class="n">nvt</span><span class="o">.</span><span class="n">ops</span><span class="o">.</span><span class="n">Categorify</span><span class="p">(</span><span class="n">start_index</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="extract-temporal-features">
<h3>Extract Temporal Features<a class="headerlink" href="#extract-temporal-features" title="Permalink to this headline">¶</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># create time features</span>
<span class="n">session_ts</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;event_time_ts&#39;</span><span class="p">]</span>

<span class="n">session_time</span> <span class="o">=</span> <span class="p">(</span>
    <span class="n">session_ts</span> <span class="o">&gt;&gt;</span> 
    <span class="n">nvt</span><span class="o">.</span><span class="n">ops</span><span class="o">.</span><span class="n">LambdaOp</span><span class="p">(</span><span class="k">lambda</span> <span class="n">col</span><span class="p">:</span> <span class="n">cudf</span><span class="o">.</span><span class="n">to_datetime</span><span class="p">(</span><span class="n">col</span><span class="p">,</span> <span class="n">unit</span><span class="o">=</span><span class="s1">&#39;s&#39;</span><span class="p">))</span> <span class="o">&gt;&gt;</span> 
    <span class="n">nvt</span><span class="o">.</span><span class="n">ops</span><span class="o">.</span><span class="n">Rename</span><span class="p">(</span><span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;event_time_dt&#39;</span><span class="p">)</span>
<span class="p">)</span>

<span class="n">sessiontime_weekday</span> <span class="o">=</span> <span class="p">(</span>
    <span class="n">session_time</span> <span class="o">&gt;&gt;</span> 
    <span class="n">nvt</span><span class="o">.</span><span class="n">ops</span><span class="o">.</span><span class="n">LambdaOp</span><span class="p">(</span><span class="k">lambda</span> <span class="n">col</span><span class="p">:</span> <span class="n">col</span><span class="o">.</span><span class="n">dt</span><span class="o">.</span><span class="n">weekday</span><span class="p">)</span> <span class="o">&gt;&gt;</span> 
    <span class="n">nvt</span><span class="o">.</span><span class="n">ops</span><span class="o">.</span><span class="n">Rename</span><span class="p">(</span><span class="n">name</span> <span class="o">=</span><span class="s1">&#39;et_dayofweek&#39;</span><span class="p">)</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Now let’s create cycling features from the <code class="docutils literal notranslate"><span class="pre">sessiontime_weekday</span></code> column. We would like to use the temporal features (hour, day of week, month, etc.) that have inherently cyclical characteristic. We represent the day of week as a cycling feature (sine and cosine), so that it can be represented in a continuous space. That way, the difference between the representation of two different days is the same, in other words, with cyclical features we can convey closeness between data. You can read more about it <a class="reference external" href="https://ianlondon.github.io/blog/encoding-cyclical-features-24hour-time/">here</a>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">get_cycled_feature_value_sin</span><span class="p">(</span><span class="n">col</span><span class="p">,</span> <span class="n">max_value</span><span class="p">):</span>
    <span class="n">value_scaled</span> <span class="o">=</span> <span class="p">(</span><span class="n">col</span> <span class="o">+</span> <span class="mf">0.000001</span><span class="p">)</span> <span class="o">/</span> <span class="n">max_value</span>
    <span class="n">value_sin</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="mi">2</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">pi</span><span class="o">*</span><span class="n">value_scaled</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">value_sin</span>

<span class="k">def</span> <span class="nf">get_cycled_feature_value_cos</span><span class="p">(</span><span class="n">col</span><span class="p">,</span> <span class="n">max_value</span><span class="p">):</span>
    <span class="n">value_scaled</span> <span class="o">=</span> <span class="p">(</span><span class="n">col</span> <span class="o">+</span> <span class="mf">0.000001</span><span class="p">)</span> <span class="o">/</span> <span class="n">max_value</span>
    <span class="n">value_cos</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">cos</span><span class="p">(</span><span class="mi">2</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">pi</span><span class="o">*</span><span class="n">value_scaled</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">value_cos</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">weekday_sin</span> <span class="o">=</span> <span class="n">sessiontime_weekday</span> <span class="o">&gt;&gt;</span> <span class="p">(</span><span class="k">lambda</span> <span class="n">col</span><span class="p">:</span> <span class="n">get_cycled_feature_value_sin</span><span class="p">(</span><span class="n">col</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="mi">7</span><span class="p">))</span> <span class="o">&gt;&gt;</span> <span class="n">nvt</span><span class="o">.</span><span class="n">ops</span><span class="o">.</span><span class="n">Rename</span><span class="p">(</span><span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;et_dayofweek_sin&#39;</span><span class="p">)</span>
<span class="n">weekday_cos</span><span class="o">=</span> <span class="n">sessiontime_weekday</span> <span class="o">&gt;&gt;</span> <span class="p">(</span><span class="k">lambda</span> <span class="n">col</span><span class="p">:</span> <span class="n">get_cycled_feature_value_cos</span><span class="p">(</span><span class="n">col</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="mi">7</span><span class="p">))</span> <span class="o">&gt;&gt;</span> <span class="n">nvt</span><span class="o">.</span><span class="n">ops</span><span class="o">.</span><span class="n">Rename</span><span class="p">(</span><span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;et_dayofweek_cos&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p><strong>Add Product Recency feature</strong></p>
<ul class="simple">
<li><p>Let’s define a custom op to calculate product recency in days</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">nvtabular.ops</span> <span class="kn">import</span> <span class="n">Operator</span>

<span class="k">class</span> <span class="nc">ItemRecency</span><span class="p">(</span><span class="n">Operator</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">transform</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">columns</span><span class="p">,</span> <span class="n">gdf</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">column</span> <span class="ow">in</span> <span class="n">columns</span><span class="o">.</span><span class="n">names</span><span class="p">:</span>
            <span class="n">col</span> <span class="o">=</span> <span class="n">gdf</span><span class="p">[</span><span class="n">column</span><span class="p">]</span>
            <span class="n">item_first_timestamp</span> <span class="o">=</span> <span class="n">gdf</span><span class="p">[</span><span class="s1">&#39;prod_first_event_time_ts&#39;</span><span class="p">]</span>
            <span class="n">delta_days</span> <span class="o">=</span> <span class="p">(</span><span class="n">col</span> <span class="o">-</span> <span class="n">item_first_timestamp</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="mi">60</span><span class="o">*</span><span class="mi">60</span><span class="o">*</span><span class="mi">24</span><span class="p">)</span>
            <span class="n">gdf</span><span class="p">[</span><span class="n">column</span> <span class="o">+</span> <span class="s2">&quot;_age_days&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">delta_days</span> <span class="o">*</span> <span class="p">(</span><span class="n">delta_days</span> <span class="o">&gt;=</span><span class="mi">0</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">gdf</span>
            
    <span class="k">def</span> <span class="nf">output_column_names</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">columns</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">ColumnSelector</span><span class="p">([</span><span class="n">column</span> <span class="o">+</span> <span class="s2">&quot;_age_days&quot;</span> <span class="k">for</span> <span class="n">column</span> <span class="ow">in</span> <span class="n">columns</span><span class="o">.</span><span class="n">names</span><span class="p">])</span>

    <span class="k">def</span> <span class="nf">dependencies</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="p">[</span><span class="s2">&quot;prod_first_event_time_ts&quot;</span><span class="p">]</span>
    
    
<span class="n">recency_features</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;event_time_ts&#39;</span><span class="p">]</span> <span class="o">&gt;&gt;</span> <span class="n">ItemRecency</span><span class="p">()</span> 
<span class="n">recency_features_norm</span> <span class="o">=</span> <span class="n">recency_features</span> <span class="o">&gt;&gt;</span> <span class="n">nvt</span><span class="o">.</span><span class="n">ops</span><span class="o">.</span><span class="n">LogOp</span><span class="p">()</span> <span class="o">&gt;&gt;</span> <span class="n">nvt</span><span class="o">.</span><span class="n">ops</span><span class="o">.</span><span class="n">Normalize</span><span class="p">()</span> <span class="o">&gt;&gt;</span> <span class="n">nvt</span><span class="o">.</span><span class="n">ops</span><span class="o">.</span><span class="n">Rename</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s1">&#39;product_recency_days_log_norm&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">time_features</span> <span class="o">=</span> <span class="p">(</span>
    <span class="n">session_time</span> <span class="o">+</span>
    <span class="n">sessiontime_weekday</span> <span class="o">+</span>
    <span class="n">weekday_sin</span> <span class="o">+</span>
    <span class="n">weekday_cos</span> <span class="o">+</span>
    <span class="n">recency_features_norm</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="normalize-continuous-features">
<h3>Normalize Continuous Features<a class="headerlink" href="#normalize-continuous-features" title="Permalink to this headline">¶</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Smoothing price long-tailed distribution and applying standardization</span>
<span class="n">price_log</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;price&#39;</span><span class="p">]</span> <span class="o">&gt;&gt;</span> <span class="n">nvt</span><span class="o">.</span><span class="n">ops</span><span class="o">.</span><span class="n">LogOp</span><span class="p">()</span> <span class="o">&gt;&gt;</span> <span class="n">nvt</span><span class="o">.</span><span class="n">ops</span><span class="o">.</span><span class="n">Normalize</span><span class="p">()</span> <span class="o">&gt;&gt;</span> <span class="n">nvt</span><span class="o">.</span><span class="n">ops</span><span class="o">.</span><span class="n">Rename</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s1">&#39;price_log_norm&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Relative price to the average price for the category_id</span>
<span class="k">def</span> <span class="nf">relative_price_to_avg_categ</span><span class="p">(</span><span class="n">col</span><span class="p">,</span> <span class="n">gdf</span><span class="p">):</span>
    <span class="n">epsilon</span> <span class="o">=</span> <span class="mf">1e-5</span>
    <span class="n">col</span> <span class="o">=</span> <span class="p">((</span><span class="n">gdf</span><span class="p">[</span><span class="s1">&#39;price&#39;</span><span class="p">]</span> <span class="o">-</span> <span class="n">col</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">col</span> <span class="o">+</span> <span class="n">epsilon</span><span class="p">))</span> <span class="o">*</span> <span class="p">(</span><span class="n">col</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">col</span>
    
<span class="n">avg_category_id_pr</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;category_id&#39;</span><span class="p">]</span> <span class="o">&gt;&gt;</span> <span class="n">nvt</span><span class="o">.</span><span class="n">ops</span><span class="o">.</span><span class="n">JoinGroupby</span><span class="p">(</span><span class="n">cont_cols</span> <span class="o">=</span><span class="p">[</span><span class="s1">&#39;price&#39;</span><span class="p">],</span> <span class="n">stats</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;mean&quot;</span><span class="p">])</span> <span class="o">&gt;&gt;</span> <span class="n">nvt</span><span class="o">.</span><span class="n">ops</span><span class="o">.</span><span class="n">Rename</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s1">&#39;avg_category_id_price&#39;</span><span class="p">)</span>
<span class="n">relative_price_to_avg_category</span> <span class="o">=</span> <span class="n">avg_category_id_pr</span> <span class="o">&gt;&gt;</span> <span class="n">nvt</span><span class="o">.</span><span class="n">ops</span><span class="o">.</span><span class="n">LambdaOp</span><span class="p">(</span><span class="n">relative_price_to_avg_categ</span><span class="p">,</span> <span class="n">dependency</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;price&#39;</span><span class="p">])</span> <span class="o">&gt;&gt;</span> <span class="n">nvt</span><span class="o">.</span><span class="n">ops</span><span class="o">.</span><span class="n">Rename</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s2">&quot;relative_price_to_avg_categ_id&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="grouping-interactions-into-sessions">
<h3>Grouping interactions into sessions<a class="headerlink" href="#grouping-interactions-into-sessions" title="Permalink to this headline">¶</a></h3>
<p><strong>Aggregate by session id and creates the sequential features</strong></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">groupby_feats</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;event_time_ts&#39;</span><span class="p">,</span> <span class="s1">&#39;user_session&#39;</span><span class="p">]</span> <span class="o">+</span> <span class="n">cat_feats</span> <span class="o">+</span> <span class="n">time_features</span> <span class="o">+</span> <span class="n">price_log</span> <span class="o">+</span> <span class="n">relative_price_to_avg_category</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Define Groupby Workflow</span>
<span class="n">groupby_features</span> <span class="o">=</span> <span class="n">groupby_feats</span> <span class="o">&gt;&gt;</span> <span class="n">nvt</span><span class="o">.</span><span class="n">ops</span><span class="o">.</span><span class="n">Groupby</span><span class="p">(</span>
    <span class="n">groupby_cols</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;user_session&quot;</span><span class="p">],</span> 
    <span class="n">sort_cols</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;event_time_ts&quot;</span><span class="p">],</span>
    <span class="n">aggs</span><span class="o">=</span><span class="p">{</span>
        <span class="s1">&#39;user_id&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;first&#39;</span><span class="p">],</span>
        <span class="s1">&#39;product_id&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;list&quot;</span><span class="p">,</span> <span class="s2">&quot;count&quot;</span><span class="p">],</span>
        <span class="s1">&#39;category_code&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;list&quot;</span><span class="p">],</span>  
        <span class="s1">&#39;event_type&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;list&quot;</span><span class="p">],</span> 
        <span class="s1">&#39;brand&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;list&quot;</span><span class="p">],</span> 
        <span class="s1">&#39;category_id&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;list&quot;</span><span class="p">],</span> 
        <span class="s1">&#39;event_time_ts&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;first&quot;</span><span class="p">],</span>
        <span class="s1">&#39;event_time_dt&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;first&quot;</span><span class="p">],</span>
        <span class="s1">&#39;et_dayofweek_sin&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;list&quot;</span><span class="p">],</span>
        <span class="s1">&#39;et_dayofweek_cos&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;list&quot;</span><span class="p">],</span>
        <span class="s1">&#39;price_log_norm&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;list&quot;</span><span class="p">],</span>
        <span class="s1">&#39;relative_price_to_avg_categ_id&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;list&quot;</span><span class="p">],</span>
        <span class="s1">&#39;product_recency_days_log_norm&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;list&quot;</span><span class="p">]</span>
        <span class="p">},</span>
    <span class="n">name_sep</span><span class="o">=</span><span class="s2">&quot;-&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>Select columns which are list</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">groupby_features_list</span> <span class="o">=</span> <span class="n">groupby_features</span><span class="p">[</span><span class="s1">&#39;product_id-list&#39;</span><span class="p">,</span>
        <span class="s1">&#39;category_code-list&#39;</span><span class="p">,</span>  
        <span class="s1">&#39;event_type-list&#39;</span><span class="p">,</span> 
        <span class="s1">&#39;brand-list&#39;</span><span class="p">,</span> 
        <span class="s1">&#39;category_id-list&#39;</span><span class="p">,</span> 
        <span class="s1">&#39;et_dayofweek_sin-list&#39;</span><span class="p">,</span>
        <span class="s1">&#39;et_dayofweek_cos-list&#39;</span><span class="p">,</span>
        <span class="s1">&#39;price_log_norm-list&#39;</span><span class="p">,</span>
        <span class="s1">&#39;relative_price_to_avg_categ_id-list&#39;</span><span class="p">,</span>
        <span class="s1">&#39;product_recency_days_log_norm-list&#39;</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">SESSIONS_MAX_LENGTH</span> <span class="o">=</span> <span class="mi">20</span> 
<span class="n">MINIMUM_SESSION_LENGTH</span> <span class="o">=</span> <span class="mi">2</span>
</pre></div>
</div>
</div>
</div>
<p>We truncate the sequence features in length according to sessions_max_length param, which is set as 20 in our example.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">groupby_features_trim</span> <span class="o">=</span> <span class="n">groupby_features_list</span> <span class="o">&gt;&gt;</span> <span class="n">nvt</span><span class="o">.</span><span class="n">ops</span><span class="o">.</span><span class="n">ListSlice</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="n">SESSIONS_MAX_LENGTH</span><span class="p">)</span> <span class="o">&gt;&gt;</span> <span class="n">nvt</span><span class="o">.</span><span class="n">ops</span><span class="o">.</span><span class="n">Rename</span><span class="p">(</span><span class="n">postfix</span> <span class="o">=</span> <span class="s1">&#39;_seq&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>Create a <code class="docutils literal notranslate"><span class="pre">day_index</span></code> column in order to partition sessions by day when saving the parquet files.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># calculate session day index based on &#39;timestamp-first&#39; column</span>
<span class="n">day_index</span> <span class="o">=</span> <span class="p">((</span><span class="n">groupby_features</span><span class="p">[</span><span class="s1">&#39;event_time_dt-first&#39;</span><span class="p">])</span>  <span class="o">&gt;&gt;</span> 
    <span class="n">nvt</span><span class="o">.</span><span class="n">ops</span><span class="o">.</span><span class="n">LambdaOp</span><span class="p">(</span><span class="k">lambda</span> <span class="n">col</span><span class="p">:</span> <span class="p">(</span><span class="n">col</span> <span class="o">-</span> <span class="n">col</span><span class="o">.</span><span class="n">min</span><span class="p">())</span><span class="o">.</span><span class="n">dt</span><span class="o">.</span><span class="n">days</span> <span class="o">+</span><span class="mi">1</span><span class="p">)</span> <span class="o">&gt;&gt;</span> 
    <span class="n">nvt</span><span class="o">.</span><span class="n">ops</span><span class="o">.</span><span class="n">Rename</span><span class="p">(</span><span class="n">f</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">col</span><span class="p">:</span> <span class="s2">&quot;day_index&quot;</span><span class="p">)</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>Select certain columns to be used in model training</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">selected_features</span> <span class="o">=</span> <span class="n">groupby_features</span><span class="p">[</span><span class="s1">&#39;user_session&#39;</span><span class="p">,</span> <span class="s1">&#39;product_id-count&#39;</span><span class="p">]</span> <span class="o">+</span> <span class="n">groupby_features_trim</span> <span class="o">+</span> <span class="n">day_index</span>
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>Filter out the session that have less than 2 interactions.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">filtered_sessions</span> <span class="o">=</span> <span class="n">selected_features</span> <span class="o">&gt;&gt;</span> <span class="n">nvt</span><span class="o">.</span><span class="n">ops</span><span class="o">.</span><span class="n">Filter</span><span class="p">(</span><span class="n">f</span><span class="o">=</span><span class="k">lambda</span> <span class="n">df</span><span class="p">:</span> <span class="n">df</span><span class="p">[</span><span class="s2">&quot;product_id-count&quot;</span><span class="p">]</span> <span class="o">&gt;=</span> <span class="n">MINIMUM_SESSION_LENGTH</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># avoid numba warnings</span>
<span class="kn">from</span> <span class="nn">numba</span> <span class="kn">import</span> <span class="n">config</span>
<span class="n">config</span><span class="o">.</span><span class="n">CUDA_LOW_OCCUPANCY_WARNINGS</span> <span class="o">=</span> <span class="mi">0</span>
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>Initialize the NVTabular dataset object and workflow graph.</p></li>
</ul>
<p>NVTabular’s preprocessing and feature engineering workflows are directed graphs of operators. When we initialize a Workflow with our pipeline, workflow organizes the input and output columns.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">dataset</span> <span class="o">=</span> <span class="n">nvt</span><span class="o">.</span><span class="n">Dataset</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>

<span class="n">workflow</span> <span class="o">=</span> <span class="n">nvt</span><span class="o">.</span><span class="n">Workflow</span><span class="p">(</span><span class="n">filtered_sessions</span><span class="p">)</span>
<span class="n">workflow</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
<span class="n">sessions_gdf</span> <span class="o">=</span> <span class="n">workflow</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span><span class="o">.</span><span class="n">to_ddf</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p>Above, we created an NVTabular Dataset object using our input dataset. Then, we calculate statistics for this workflow on the input dataset, i.e. on our training set, using the <code class="docutils literal notranslate"><span class="pre">workflow.fit()</span></code> method so that our Workflow can use these stats to transform any given input.</p>
<p>Let’s print the head of our preprocessed dataset. You can notice that now each example (row) is a session and the sequential features with respect to user interactions were converted to lists with matching length.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">sessions_gdf</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>user_session</th>
      <th>product_id-count</th>
      <th>product_id-list_seq</th>
      <th>category_code-list_seq</th>
      <th>event_type-list_seq</th>
      <th>brand-list_seq</th>
      <th>category_id-list_seq</th>
      <th>et_dayofweek_sin-list_seq</th>
      <th>et_dayofweek_cos-list_seq</th>
      <th>price_log_norm-list_seq</th>
      <th>relative_price_to_avg_categ_id-list_seq</th>
      <th>product_recency_days_log_norm-list_seq</th>
      <th>day_index</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>2</td>
      <td>779</td>
      <td>[19064, 52057, 13290, 11446, 15835, 879, 633, ...</td>
      <td>[1, 1, 1, 1, 1, 12, 12, 12, 12, 12, 12, 12, 12...</td>
      <td>[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...</td>
      <td>[171, 120, 231, 392, 562, 20, 9, 20, 295, 143,...</td>
      <td>[3, 3, 3, 3, 3, 17, 17, 17, 17, 17, 17, 17, 17...</td>
      <td>[0.9749277, 0.9749277, 0.9749277, 0.9749277, 0...</td>
      <td>[-0.22252177, -0.22252177, -0.22252177, -0.222...</td>
      <td>[-0.6063043, -0.5922227, -0.58657265, -0.95319...</td>
      <td>[0.03519271796785072, 0.05391070768135458, 0.0...</td>
      <td>[-2.2660856, -2.2660856, -2.2657654, -2.266085...</td>
      <td>1</td>
    </tr>
    <tr>
      <th>1</th>
      <td>3</td>
      <td>316</td>
      <td>[252, 2801, 5399, 1074, 252, 355, 327, 319, 34...</td>
      <td>[1, 17, 17, 15, 1, 1, 17, 31, 17, 17, 17, 17, ...</td>
      <td>[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...</td>
      <td>[1, 1, 1, 1, 1, 50, 1, 1, 36, 1, 1, 36, 50, 1,...</td>
      <td>[234, 36, 36, 30, 234, 52, 36, 48, 36, 36, 36,...</td>
      <td>[0.43388295, 0.43388295, 0.43388295, 0.4338829...</td>
      <td>[-0.90096927, -0.90096927, -0.90096927, -0.900...</td>
      <td>[0.76379955, 0.40693888, 0.2585879, 0.01305802...</td>
      <td>[0.0006990395296891112, -0.04875344158592035, ...</td>
      <td>[-0.8581507, -0.9379308, -1.0066843, -0.936325...</td>
      <td>2</td>
    </tr>
    <tr>
      <th>2</th>
      <td>4</td>
      <td>277</td>
      <td>[765, 353, 1360, 1965, 2204, 3129, 726, 861, 9...</td>
      <td>[12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 1...</td>
      <td>[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...</td>
      <td>[448, 114, 1, 20, 20, 72, 114, 143, 20, 141, 7...</td>
      <td>[17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 1...</td>
      <td>[0.43388295, 0.43388295, 0.43388295, 0.4338829...</td>
      <td>[-0.90096927, -0.90096927, -0.90096927, -0.900...</td>
      <td>[-1.7807854, -0.5645747, -0.04535069, -0.43499...</td>
      <td>[-0.832720989925482, -0.19123240368025274, 0.5...</td>
      <td>[-0.7992506, -0.78641737, -0.8228414, -0.79577...</td>
      <td>2</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">workflow</span><span class="o">.</span><span class="n">output_schema</span><span class="o">.</span><span class="n">column_names</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[&#39;user_session&#39;,
 &#39;product_id-count&#39;,
 &#39;product_id-list_seq&#39;,
 &#39;category_code-list_seq&#39;,
 &#39;event_type-list_seq&#39;,
 &#39;brand-list_seq&#39;,
 &#39;category_id-list_seq&#39;,
 &#39;et_dayofweek_sin-list_seq&#39;,
 &#39;et_dayofweek_cos-list_seq&#39;,
 &#39;price_log_norm-list_seq&#39;,
 &#39;relative_price_to_avg_categ_id-list_seq&#39;,
 &#39;product_recency_days_log_norm-list_seq&#39;,
 &#39;day_index&#39;]
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>Save NVTabular workflow to load at the inference step.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">workflow_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">INPUT_DATA_DIR</span><span class="p">,</span> <span class="s1">&#39;workflow_etl&#39;</span><span class="p">)</span>
<span class="n">workflow</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">workflow_path</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="section" id="exporting-data">
<h2>Exporting data<a class="headerlink" href="#exporting-data" title="Permalink to this headline">¶</a></h2>
<p>We export dataset to parquet partioned by the session <code class="docutils literal notranslate"><span class="pre">day_index</span></code> column.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span># define partition column
PARTITION_COL = &#39;day_index&#39;

# define output_folder to store the partitioned parquet files
OUTPUT_FOLDER = os.environ.get(&quot;OUTPUT_FOLDER&quot;, INPUT_DATA_DIR + &quot;sessions_by_day&quot;)
!mkdir -p $OUTPUT_FOLDER
</pre></div>
</div>
</div>
</div>
<p>In this section we are going to create a folder structure as shown below. As we explained above, this is just to structure parquet files so that it would be easier to do incremental training and evaluation.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">/</span><span class="n">sessions_by_day</span><span class="o">/</span>
<span class="o">|--</span> <span class="mi">1</span>
<span class="o">|</span>   <span class="o">|--</span> <span class="n">train</span><span class="o">.</span><span class="n">parquet</span>
<span class="o">|</span>   <span class="o">|--</span> <span class="n">valid</span><span class="o">.</span><span class="n">parquet</span>
<span class="o">|</span>   <span class="o">|--</span> <span class="n">test</span><span class="o">.</span><span class="n">parquet</span>

<span class="o">|--</span> <span class="mi">2</span>
<span class="o">|</span>   <span class="o">|--</span> <span class="n">train</span><span class="o">.</span><span class="n">parquet</span>
<span class="o">|</span>   <span class="o">|--</span> <span class="n">valid</span><span class="o">.</span><span class="n">parquet</span>
<span class="o">|</span>   <span class="o">|--</span> <span class="n">test</span><span class="o">.</span><span class="n">parquet</span>
</pre></div>
</div>
<p><code class="docutils literal notranslate"><span class="pre">gpu_preprocessing</span></code> function converts the process df to a Dataset object and write out hive-partitioned data to disk.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">transformers4rec.data.preprocessing</span> <span class="kn">import</span> <span class="n">save_time_based_splits</span>
<span class="n">save_time_based_splits</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">nvt</span><span class="o">.</span><span class="n">Dataset</span><span class="p">(</span><span class="n">sessions_gdf</span><span class="p">),</span>
                       <span class="n">output_dir</span><span class="o">=</span> <span class="n">OUTPUT_FOLDER</span><span class="p">,</span>
                       <span class="n">partition_col</span><span class="o">=</span><span class="n">PARTITION_COL</span><span class="p">,</span>
                       <span class="n">timestamp_col</span><span class="o">=</span><span class="s1">&#39;user_session&#39;</span><span class="p">,</span> 
                      <span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Creating time-based splits: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:02&lt;00:00,  2.63it/s]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span># check out the OUTPUT_FOLDER
!ls $OUTPUT_FOLDER
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>1  2  3  4  5  6  7
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Copyright 2021 NVIDIA Corporation. All Rights Reserved.</span>
<span class="c1">#</span>
<span class="c1"># Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);</span>
<span class="c1"># you may not use this file except in compliance with the License.</span>
<span class="c1"># You may obtain a copy of the License at</span>
<span class="c1">#</span>
<span class="c1">#     http://www.apache.org/licenses/LICENSE-2.0</span>
<span class="c1">#</span>
<span class="c1"># Unless required by applicable law or agreed to in writing, software</span>
<span class="c1"># distributed under the License is distributed on an &quot;AS IS&quot; BASIS,</span>
<span class="c1"># WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span>
<span class="c1"># See the License for the specific language governing permissions and</span>
<span class="c1"># limitations under the License.</span>
<span class="c1"># ==============================================================================</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="session-based-recommendation-with-transformers4rec">
<h2>Session-based recommendation with Transformers4Rec<a class="headerlink" href="#session-based-recommendation-with-transformers4rec" title="Permalink to this headline">¶</a></h2>
<p>In the previous section we went through our ETL pipeline with NVTabular library, and created sequential features to be used for training a session-based recommendation model. In this section we will learn:</p>
<ul class="simple">
<li><p>Accelerating data loading of parquet files multiple features on PyTorch using NVTabular library</p></li>
<li><p>Training and evaluating an RNN-based (GRU) session-based recommendation model</p></li>
<li><p>Training and evaluating a Transformer architecture (XLNET) for session-based recommendation model</p></li>
<li><p>Integrate side information (additional features) into transformer architectures in order to improve recommendation accuracy</p></li>
</ul>
<p>Session-based recommendation, a sub-area of sequential recommendation, has been an important task in online services like e-commerce and news portals, where most users either browse anonymously or may have very distinct interests for different sessions. Session-Based Recommender Systems (SBRS) have
been proposed to model the sequence of interactions within the current user session, where a session is a short sequence of user interactions typically bounded by user inactivity. They have recently gained popularity due to their ability to capture short-term and contextual user preferences towards items.</p>
<p>Many methods have been proposed to leverage the sequence of interactions that occur during a session, including session-based k-NN algorithms like V-SkNN [1] and neural approaches like GRU4Rec [2]. In addition,  state of the art NLP approaches have inspired RecSys practitioners and researchers to leverage the self-attention mechanism and the Transformer-based architectures for sequential [3] and session-based recommendation [4].</p>
<p>In this tutorial, we introduce the <a class="reference external" href="https://github.com/NVIDIA-Merlin/Transformers4Rec">Transformers4Rec</a> open-source library for sequential and session-based recommendation task.</p>
<p>With Transformers4Rec we import from the HF Transformers NLP library the transformer architectures and their configuration classes.</p>
<p>In addition, Transformers4Rec provides additional blocks necessary for recommendation, e.g., input features normalization and aggregation, and heads for recommendation and sequence classification/prediction. We also extend their Trainer class to allow for the evaluation with RecSys metrics.</p>
<p>Here are some of the most important modules:</p>
<ul class="simple">
<li><p><a class="reference external" href="https://nvidia-merlin.github.io/Transformers4Rec/main/api/transformers4rec.torch.html#transformers4rec.torch.TabularSequenceFeatures">TabularSequenceFeatures</a> is the input block for sequential features. Based on a <code class="docutils literal notranslate"><span class="pre">Schema</span></code> and options set by the user, it dynamically creates all the necessary layers (e.g. embedding layers) to encode, normalize, and aggregate categorical and continuous features. It also allows to set the <code class="docutils literal notranslate"><span class="pre">masking</span></code> training approach (e.g. Causal LM, Masked LM).</p></li>
<li><p><a class="reference external" href="https://nvidia-merlin.github.io/Transformers4Rec/main/api/transformers4rec.torch.html#transformers4rec.torch.TransformerBlock">TransformerBlock</a> class is the bridge that adapts HuggingFace Transformers for session-based and sequential-based recommendation models.</p></li>
<li><p><a class="reference external" href="https://nvidia-merlin.github.io/Transformers4Rec/main/api/transformers4rec.torch.html#transformers4rec.torch.SequentialBlock">SequentialBlock</a> allows the definition of a model body as as sequence of layer (similarly to <a class="reference external" href="https://pytorch.org/docs/stable/generated/torch.nn.Sequential.html">torch.nn.sequential</a>). It is designed to define our model as a sequence of layers and automatically setting the input shape of a layer from the output shape of the previous one.</p></li>
<li><p><a class="reference external" href="https://nvidia-merlin.github.io/Transformers4Rec/main/api/transformers4rec.torch.html#transformers4rec.torch.Head">Head</a> class defines the head of a model.</p></li>
<li><p><a class="reference external" href="https://nvidia-merlin.github.io/Transformers4Rec/main/api/transformers4rec.torch.html#transformers4rec.torch.NextItemPredictionTask">NextItemPredictionTask</a> is the class to support next item prediction task, combining a model body with a head.</p></li>
<li><p><a class="reference external" href="https://nvidia-merlin.github.io/Transformers4Rec/main/api/transformers4rec.torch.html#transformers4rec.torch.Trainer">Trainer</a> extends the <code class="docutils literal notranslate"><span class="pre">Trainer</span></code> class from HF transformers and manages the model training and evaluation.</p></li>
</ul>
<p>You can check the <a class="reference external" href="https://nvidia-merlin.github.io/Transformers4Rec/main/index.html">full documentation</a> of Transformers4Rec if needed.</p>
<p>In the following Figure, we present a reference architecture that we are going to build with Transformers4Rec PyTorch API in this section. We are going to start using only <code class="docutils literal notranslate"><span class="pre">product-id</span></code> as input feature, but as you can notice in the figure, we can add additional categorical and numerical features later to improve recommendation accuracy.</p>
<img src='https://s3.us-west-2.amazonaws.com/secure.notion-static.com/360a24b7-5d3f-41bc-bafc-e6f7a50b8a90/Untitled.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAT73L2G45O3KS52Y5%2F20211011%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20211011T112731Z&X-Amz-Expires=86400&X-Amz-Signature=2127778c75a954ad2b20a01cbb06aa9774a935b18af8875d784d0250dc999f93&X-Amz-SignedHeaders=host&response-content-disposition=filename%20%3D%22Untitled.png%22'>
<p><center>Figure 1. Transformers4Rec meta-architecture.</center></p></div>
<div class="section" id="training-an-rnn-based-session-based-recommendation-model">
<h2>Training an RNN-based Session-based Recommendation Model<a class="headerlink" href="#training-an-rnn-based-session-based-recommendation-model" title="Permalink to this headline">¶</a></h2>
<p>In this section, we use a type of Recurrent Neural Networks (RNN) - the Gated Recurrent Unit (GRU)[5] - to do next-item prediction using a sequence of events (e.g., click, view, or purchase) per user in a given session. There is obviously some sequential patterns that we want to capture to provide more relevant recommendations. In our case, the input of the GRU layer is a representation of the user interaction, the internal GRU hidden state encodes a representation of the session based on past interactions and the outputs are the next-item predictions. Basically, for each item in a given session, we generate the output as the predicted preference of the items, i.e. the likelihood of being the next.</p>
<p>Figure 2 illustrates the logic of predicting next item in a given session. First, the product ids are embedded and fed as a sequence to a GRU layer, which outputs a representation than can be used to predict the next item. For the sake of simplicity, we treat the recommendation as a multi-class classification problem and use cross-entropy loss. In our first example, we use a GRU block instead of <code class="docutils literal notranslate"><span class="pre">Transformer</span> <span class="pre">block</span></code> (shown in the Figure 1).</p>
<p><center><img src='https://s3.us-west-2.amazonaws.com/secure.notion-static.com/72275c7e-3e6c-4399-adb0-406c1bd36863/Untitled.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAT73L2G45O3KS52Y5%2F20211011%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20211011T112939Z&X-Amz-Expires=86400&X-Amz-Signature=19668197b543d096cd1b1e9ed1579dfca46c9329d70edd4b4b937902209ef0e4&X-Amz-SignedHeaders=host&response-content-disposition=filename%20%3D%22Untitled.png%22'><br>Figure 2. Next item prediction with RNN.</center></p><div class="section" id="instantiates-schema-object-from-a-schema-file">
<h3>Instantiates Schema object from a <code class="docutils literal notranslate"><span class="pre">schema</span></code> file.<a class="headerlink" href="#instantiates-schema-object-from-a-schema-file" title="Permalink to this headline">¶</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">merlin_standard_lib</span> <span class="kn">import</span> <span class="n">Schema</span>
<span class="c1"># Define schema object to pass it to the TabularSequenceFeatures class</span>
<span class="n">SCHEMA_PATH</span> <span class="o">=</span> <span class="s1">&#39;schema_tutorial.pb&#39;</span>
<span class="n">schema</span> <span class="o">=</span> <span class="n">Schema</span><span class="p">()</span><span class="o">.</span><span class="n">from_proto_text</span><span class="p">(</span><span class="n">SCHEMA_PATH</span><span class="p">)</span>
<span class="n">schema</span> <span class="o">=</span> <span class="n">schema</span><span class="o">.</span><span class="n">select_by_name</span><span class="p">([</span><span class="s1">&#39;product_id-list_seq&#39;</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
<p>Transformers4Rec library relies on <code class="docutils literal notranslate"><span class="pre">Schema</span></code> object in <code class="docutils literal notranslate"><span class="pre">TabularSequenceFeatures</span></code> that takes the input features as input and create all the necessary layers to process and aggregate them. As you can see below, the <code class="docutils literal notranslate"><span class="pre">schema.pb</span></code> is a protobuf text file contains features metadata, including statistics about features such as cardinality, min and max values and also tags based on their characteristics and dtypes (e.g., <code class="docutils literal notranslate"><span class="pre">categorical</span></code>, <code class="docutils literal notranslate"><span class="pre">continuous</span></code>, <code class="docutils literal notranslate"><span class="pre">list</span></code>, <code class="docutils literal notranslate"><span class="pre">item_id</span></code>). We can tag our target column and even add the prediction task such as <code class="docutils literal notranslate"><span class="pre">binary</span></code>, <code class="docutils literal notranslate"><span class="pre">regression</span></code> or <code class="docutils literal notranslate"><span class="pre">multiclass</span></code> as tags for the target column in the <code class="docutils literal notranslate"><span class="pre">schema.pb</span></code> file. The <code class="docutils literal notranslate"><span class="pre">Schema</span></code> provides a standard representation for metadata that is useful when training machine learning or deep learning models.</p>
<p>The metadata information loaded from <code class="docutils literal notranslate"><span class="pre">Schema</span></code> and their tags are used to automatically set the parameters of Transformers4rec models. Certain Transformers4rec modules have a <code class="docutils literal notranslate"><span class="pre">from_schema()</span></code> method to instantiate their parameters and layers from protobuf text file respectively.</p>
<p>Although in this tutorial we are defining the <code class="docutils literal notranslate"><span class="pre">Schema</span></code> manually, the next NVTabular release is going to generate the schema with appropriate types and tags automatically from the preprocessing workflow, allowing the user to set additional feaure tags if needed.</p>
<p>Let’s inspect the first lines of <code class="docutils literal notranslate"><span class="pre">schema.pb</span></code></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>!head -30 $SCHEMA_PATH
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>feature {
  name: &quot;user_session&quot;
  type: INT
  int_domain {
    name: &quot;user_session&quot;
    min: 1
    max: 1877365
    is_categorical: false
  }
  annotation {
    tag: &quot;groupby_col&quot;
  }
}
feature {
  name: &quot;category_id-list_seq&quot;
  value_count {
    min: 2
    max: 20
  }
  type: INT
  int_domain {
    name: &quot;category_id-list_seq&quot;
    min: 1
    max: 566
    is_categorical: true
  }
  annotation {
    tag: &quot;list&quot;
    tag: &quot;categorical&quot;
    tag: &quot;item&quot;
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="defining-the-input-block-tabularsequencefeatures">
<h3>Defining the input block: <code class="docutils literal notranslate"><span class="pre">TabularSequenceFeatures</span></code><a class="headerlink" href="#defining-the-input-block-tabularsequencefeatures" title="Permalink to this headline">¶</a></h3>
<p>We define our input block using <code class="docutils literal notranslate"><span class="pre">TabularSequenceFeatures</span></code> class. The <code class="docutils literal notranslate"><span class="pre">from_schema()</span></code> method directly parses the schema and accepts sequential and non-sequential features. Based on the <code class="docutils literal notranslate"><span class="pre">Schema</span></code> and some user-defined options, the categorical features are represented by embeddings and numerical features can be represented as continuous scalars or by a technique named Soft One-Hot embeddings (more info in our <a class="reference external" href="https://github.com/NVIDIA-Merlin/publications/blob/main/2021_acm_recsys_transformers4rec/Appendices/Appendix_A-Techniques_used_in_Transformers4Rec_Meta-Architecture.md">paper’s online appendix</a>).</p>
<p>The embedding features can optionally be normalized (<code class="docutils literal notranslate"><span class="pre">layer_norm=True</span></code>). Data augmentation methods like “Stochastic Swap Noise” (<code class="docutils literal notranslate"><span class="pre">pre=&quot;stochastic-swap-noise&quot;</span></code>) and <code class="docutils literal notranslate"><span class="pre">aggregation</span></code> opptions (like <code class="docutils literal notranslate"><span class="pre">concat</span></code> and <code class="docutils literal notranslate"><span class="pre">elementwise-sum</span></code>) are also available. The continuous features can also be combined and projected by MLP layers by setting <code class="docutils literal notranslate"><span class="pre">continuous_projection=[dim]</span></code>. Finally, the <code class="docutils literal notranslate"><span class="pre">max_sequence_length</span></code> argument defines the maximum sequence length of our sequential input.</p>
<p>Another important argument is the <code class="docutils literal notranslate"><span class="pre">masking</span></code> method, which sets the training approach. See Section 3.2.2 for details on this.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">sequence_length</span> <span class="o">=</span> <span class="mi">20</span>
<span class="n">inputs</span> <span class="o">=</span> <span class="n">tr</span><span class="o">.</span><span class="n">TabularSequenceFeatures</span><span class="o">.</span><span class="n">from_schema</span><span class="p">(</span>
        <span class="n">schema</span><span class="p">,</span>
        <span class="n">max_sequence_length</span><span class="o">=</span> <span class="n">sequence_length</span><span class="p">,</span>
        <span class="n">masking</span> <span class="o">=</span> <span class="s1">&#39;causal&#39;</span><span class="p">,</span>
    <span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="connecting-the-blocks-with-sequentialblock">
<h3>Connecting the blocks with <code class="docutils literal notranslate"><span class="pre">SequentialBlock</span></code><a class="headerlink" href="#connecting-the-blocks-with-sequentialblock" title="Permalink to this headline">¶</a></h3>
<p>The <code class="docutils literal notranslate"><span class="pre">SequentialBlock</span></code> creates a pipeline by connecting the building blocks in a serial way, so that the input shape of one block is inferred from the output of the previus block. In this example, the <code class="docutils literal notranslate"><span class="pre">TabularSequenceFeatures</span></code> object is followed by an MLP projection layer, which feeds data to a GRU block.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">d_model</span> <span class="o">=</span> <span class="mi">128</span>
<span class="n">body</span> <span class="o">=</span> <span class="n">tr</span><span class="o">.</span><span class="n">SequentialBlock</span><span class="p">(</span>
        <span class="n">inputs</span><span class="p">,</span>
        <span class="n">tr</span><span class="o">.</span><span class="n">MLPBlock</span><span class="p">([</span><span class="n">d_model</span><span class="p">]),</span>
        <span class="n">tr</span><span class="o">.</span><span class="n">Block</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">GRU</span><span class="p">(</span><span class="n">input_size</span><span class="o">=</span><span class="n">d_model</span><span class="p">,</span> <span class="n">hidden_size</span><span class="o">=</span><span class="n">d_model</span><span class="p">,</span> <span class="n">num_layers</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span> <span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="n">d_model</span><span class="p">])</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="item-prediction-head-and-tying-embeddings">
<h3>Item Prediction head and tying embeddings<a class="headerlink" href="#item-prediction-head-and-tying-embeddings" title="Permalink to this headline">¶</a></h3>
<p>In our experiments published in our <a class="reference external" href="https://github.com/NVIDIA-Merlin/publications/blob/main/2021_acm_recsys_transformers4rec/recsys21_transformers4rec_paper.pdf">ACM RecSys’21 paper</a> [8], we used the next item prediction head, which projects the output of the RNN/Transformer block to the items space, followed by a softmax layer to produce the relevance scores over all items. For the output layer we provide the <code class="docutils literal notranslate"><span class="pre">Tying</span> <span class="pre">Embeddings</span></code> technique (<code class="docutils literal notranslate"><span class="pre">weight_tying</span></code>). It was proposed originally by the NLP community to tie the weights of the input (item id) embedding matrix with the output projection layer, showed to be a very effective technique in extensive experimentation for competitions and empirical analysis (for more details see our <a class="reference external" href="https://github.com/NVIDIA-Merlin/publications/blob/main/2021_acm_recsys_transformers4rec/recsys21_transformers4rec_paper.pdf">paper</a> and its online <a class="reference external" href="https://github.com/NVIDIA-Merlin/publications/blob/main/2021_acm_recsys_transformers4rec/Appendices/Appendix_A-Techniques_used_in_Transformers4Rec_Meta-Architecture.md">appendix</a>). In practice, such technique helps the network to learn faster item embeddings even for rare items, reduces the number of parameters for large item cardinalities and enables Approximate Nearest Neighbours (ANN) search on inference, as the predictions can be obtained by a dot product between the model output and the item embeddings.</p>
<p>Next, we link the transformer-body to the inputs and the prediction tasks to get the final PyTorch <code class="docutils literal notranslate"><span class="pre">Model</span></code> class.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">head</span> <span class="o">=</span> <span class="n">tr</span><span class="o">.</span><span class="n">Head</span><span class="p">(</span>
    <span class="n">body</span><span class="p">,</span>
    <span class="n">tr</span><span class="o">.</span><span class="n">NextItemPredictionTask</span><span class="p">(</span><span class="n">weight_tying</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">hf_format</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> 
                              <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="n">NDCGAt</span><span class="p">(</span><span class="n">top_ks</span><span class="o">=</span><span class="p">[</span><span class="mi">10</span><span class="p">,</span> <span class="mi">20</span><span class="p">],</span> <span class="n">labels_onehot</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>  
                                       <span class="n">RecallAt</span><span class="p">(</span><span class="n">top_ks</span><span class="o">=</span><span class="p">[</span><span class="mi">10</span><span class="p">,</span> <span class="mi">20</span><span class="p">],</span> <span class="n">labels_onehot</span><span class="o">=</span><span class="kc">True</span><span class="p">)]),</span>
<span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">tr</span><span class="o">.</span><span class="n">Model</span><span class="p">(</span><span class="n">head</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Projecting inputs of NextItemPredictionTask to&#39;64&#39; As weight tying requires the input dimension &#39;128&#39; to be equal to the item-id embedding dimension &#39;64&#39;
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="define-a-dataloader-function-from-schema">
<h3>Define a Dataloader function from schema<a class="headerlink" href="#define-a-dataloader-function-from-schema" title="Permalink to this headline">¶</a></h3>
<p>We use optimized NVTabular PyTorch Dataloader which has the following benefits:</p>
<ul class="simple">
<li><p>removing bottlenecks from dataloading by processing large chunks of data at a time instead iterating by row</p></li>
<li><p>processing datasets that don’t fit within the GPU or CPU memory by streaming from the disk</p></li>
<li><p>reading data directly into the GPU memory and removing CPU-GPU communication</p></li>
<li><p>preparing batch asynchronously into the GPU to avoid CPU-GPU communication</p></li>
<li><p>supporting commonly used formats such as parquet</p></li>
<li><p>having native support to sparse sequential features</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># import NVTabular dependencies</span>
<span class="kn">from</span> <span class="nn">transformers4rec.torch.utils.data_utils</span> <span class="kn">import</span> <span class="n">NVTabularDataLoader</span>

<span class="n">x_cat_names</span><span class="p">,</span> <span class="n">x_cont_names</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;product_id-list_seq&#39;</span><span class="p">],</span> <span class="p">[]</span>

<span class="c1"># dictionary representing max sequence length for column</span>
<span class="n">sparse_features_max</span> <span class="o">=</span> <span class="p">{</span>
    <span class="n">fname</span><span class="p">:</span> <span class="n">sequence_length</span>
    <span class="k">for</span> <span class="n">fname</span> <span class="ow">in</span> <span class="n">x_cat_names</span> <span class="o">+</span> <span class="n">x_cont_names</span>
<span class="p">}</span>

<span class="c1"># Define a `get_dataloader` function to call in the training loop</span>
<span class="k">def</span> <span class="nf">get_dataloader</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">):</span>

    <span class="k">return</span> <span class="n">NVTabularDataLoader</span><span class="o">.</span><span class="n">from_schema</span><span class="p">(</span>
        <span class="n">schema</span><span class="p">,</span>
        <span class="n">path</span><span class="p">,</span> 
        <span class="n">batch_size</span><span class="p">,</span>
        <span class="n">max_sequence_length</span><span class="o">=</span><span class="n">sequence_length</span><span class="p">,</span>
        <span class="n">sparse_names</span><span class="o">=</span><span class="n">x_cat_names</span> <span class="o">+</span> <span class="n">x_cont_names</span><span class="p">,</span>
        <span class="n">sparse_max</span><span class="o">=</span><span class="n">sparse_features_max</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="daily-fine-tuning-training-over-a-time-window">
<h3>Daily Fine-Tuning: Training over a time window<a class="headerlink" href="#daily-fine-tuning-training-over-a-time-window" title="Permalink to this headline">¶</a></h3>
<p>Now that the model is defined, we are going to launch training. For that, Transfromers4rec extends the HF Transformers <code class="docutils literal notranslate"><span class="pre">Trainer</span></code> class to adapt the evaluation loop for session-based recommendation task and the calculation of ranking metrics.
The original HF <code class="docutils literal notranslate"><span class="pre">Trainer.train()</span></code> method is not overloaded, meaning that we leverage the efficient training implementation from HF transformers library, which manages for example half-precision (FP16) training.</p>
</div>
<div class="section" id="set-training-arguments">
<h3>Set training arguments<a class="headerlink" href="#set-training-arguments" title="Permalink to this headline">¶</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">transformers4rec.config.trainer</span> <span class="kn">import</span> <span class="n">T4RecTrainingArguments</span>
<span class="kn">from</span> <span class="nn">transformers4rec.torch</span> <span class="kn">import</span> <span class="n">Trainer</span>

<span class="c1">#Set arguments for training </span>
<span class="n">train_args</span> <span class="o">=</span> <span class="n">T4RecTrainingArguments</span><span class="p">(</span><span class="n">local_rank</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> 
                                    <span class="n">dataloader_drop_last</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
                                    <span class="n">report_to</span> <span class="o">=</span> <span class="p">[],</span>   <span class="c1">#set empy list to avoig logging metrics to Weights&amp;Biases</span>
                                    <span class="n">gradient_accumulation_steps</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
                                    <span class="n">per_device_train_batch_size</span> <span class="o">=</span> <span class="mi">256</span><span class="p">,</span> 
                                    <span class="n">per_device_eval_batch_size</span> <span class="o">=</span> <span class="mi">32</span><span class="p">,</span>
                                    <span class="n">output_dir</span> <span class="o">=</span> <span class="s2">&quot;./tmp&quot;</span><span class="p">,</span> 
                                    <span class="n">max_sequence_length</span><span class="o">=</span><span class="n">sequence_length</span><span class="p">,</span>
                                    <span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.00071</span><span class="p">,</span>
                                    <span class="n">num_train_epochs</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>
                                    <span class="n">logging_steps</span><span class="o">=</span><span class="mi">200</span><span class="p">,</span>
                                   <span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="instantiate-the-trainer">
<h3>Instantiate the Trainer<a class="headerlink" href="#instantiate-the-trainer" title="Permalink to this headline">¶</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Instantiate the T4Rec Trainer, which manages training and evaluation</span>
<span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span>
    <span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span>
    <span class="n">args</span><span class="o">=</span><span class="n">train_args</span><span class="p">,</span>
    <span class="n">schema</span><span class="o">=</span><span class="n">schema</span><span class="p">,</span>
    <span class="n">compute_metrics</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Define the output folder of the processed parquet files</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">OUTPUT_DIR</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;OUTPUT_DIR&quot;</span><span class="p">,</span> <span class="s2">&quot;/workspace/data/sessions_by_day&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="model-finetuning-and-incremental-evaluation">
<h3>Model finetuning and incremental evaluation<a class="headerlink" href="#model-finetuning-and-incremental-evaluation" title="Permalink to this headline">¶</a></h3>
<p>Training models incrementally, e.g. fine-tuning pre-trained models with new data over time is a common practice in industry to scale to the large streaming data been generated every data. Furthermore, it is common to evaluate recommendation models on data that came after the one used to train the models, for a more realistic evaluation.</p>
<p>Here, we use a loop that to conduct a time-based finetuning, by iteratively training and evaluating using a sliding time window as follows: At each iteration, we use training data of a specific time index <i>t</i> to train the model then we evaluate on the validation data of next index <i>t + 1</i>. We set the start time to 1 and end time to 4.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">%%</span><span class="n">time</span>
<span class="n">start_time_window_index</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">final_time_window_index</span> <span class="o">=</span> <span class="mi">4</span>
<span class="k">for</span> <span class="n">time_index</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">start_time_window_index</span><span class="p">,</span> <span class="n">final_time_window_index</span><span class="p">):</span>
    <span class="c1"># Set data </span>
    <span class="n">time_index_train</span> <span class="o">=</span> <span class="n">time_index</span>
    <span class="n">time_index_eval</span> <span class="o">=</span> <span class="n">time_index</span> <span class="o">+</span> <span class="mi">1</span>
    <span class="n">train_paths</span> <span class="o">=</span> <span class="n">glob</span><span class="o">.</span><span class="n">glob</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">OUTPUT_DIR</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">time_index_train</span><span class="si">}</span><span class="s2">/train.parquet&quot;</span><span class="p">))</span>
    <span class="n">eval_paths</span> <span class="o">=</span> <span class="n">glob</span><span class="o">.</span><span class="n">glob</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">OUTPUT_DIR</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">time_index_eval</span><span class="si">}</span><span class="s2">/valid.parquet&quot;</span><span class="p">))</span>
    
    <span class="c1"># Initialize dataloaders</span>
    <span class="n">trainer</span><span class="o">.</span><span class="n">train_dataloader</span> <span class="o">=</span> <span class="n">get_dataloader</span><span class="p">(</span><span class="n">train_paths</span><span class="p">,</span> <span class="n">train_args</span><span class="o">.</span><span class="n">per_device_train_batch_size</span><span class="p">)</span>
    <span class="n">trainer</span><span class="o">.</span><span class="n">eval_dataloader</span> <span class="o">=</span> <span class="n">get_dataloader</span><span class="p">(</span><span class="n">eval_paths</span><span class="p">,</span> <span class="n">train_args</span><span class="o">.</span><span class="n">per_device_eval_batch_size</span><span class="p">)</span>
    
    <span class="c1"># Train on day related to time_index </span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;*&#39;</span><span class="o">*</span><span class="mi">20</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Launch training for day </span><span class="si">%s</span><span class="s2"> are:&quot;</span> <span class="o">%</span><span class="n">time_index</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;*&#39;</span><span class="o">*</span><span class="mi">20</span> <span class="o">+</span> <span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>
    <span class="n">trainer</span><span class="o">.</span><span class="n">reset_lr_scheduler</span><span class="p">()</span>
    <span class="n">trainer</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
    <span class="n">trainer</span><span class="o">.</span><span class="n">state</span><span class="o">.</span><span class="n">global_step</span> <span class="o">+=</span><span class="mi">1</span>
    
    <span class="c1"># Evaluate on the following day</span>
    <span class="n">train_metrics</span> <span class="o">=</span> <span class="n">trainer</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">metric_key_prefix</span><span class="o">=</span><span class="s1">&#39;eval&#39;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;*&#39;</span><span class="o">*</span><span class="mi">20</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Eval results for day </span><span class="si">%s</span><span class="s2"> are:</span><span class="se">\t</span><span class="s2">&quot;</span> <span class="o">%</span><span class="n">time_index_eval</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span> <span class="o">+</span> <span class="s1">&#39;*&#39;</span><span class="o">*</span><span class="mi">20</span> <span class="o">+</span> <span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">train_metrics</span><span class="o">.</span><span class="n">keys</span><span class="p">()):</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot; </span><span class="si">%s</span><span class="s2"> = </span><span class="si">%s</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="nb">str</span><span class="p">(</span><span class="n">train_metrics</span><span class="p">[</span><span class="n">key</span><span class="p">])))</span> 
    <span class="n">trainer</span><span class="o">.</span><span class="n">wipe_memory</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>***** Running training *****
  Num examples = 112128
  Num Epochs = 3
  Instantaneous batch size per device = 256
  Total train batch size (w. parallel, distributed &amp; accumulation) = 256
  Gradient Accumulation steps = 1
  Total optimization steps = 1314
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>********************
Launch training for day 1 are:
********************
</pre></div>
</div>
<div class="output text_html">
    <div>

      <progress value='1314' max='1314' style='width:300px; height:20px; vertical-align: middle;'></progress>
      [1314/1314 00:51, Epoch 3/3]
    </div>
    <table border="1" class="dataframe">
  <thead>
    <tr style="text-align: left;">
      <th>Step</th>
      <th>Training Loss</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>200</td>
      <td>9.975300</td>
    </tr>
    <tr>
      <td>400</td>
      <td>9.218200</td>
    </tr>
    <tr>
      <td>600</td>
      <td>8.972500</td>
    </tr>
    <tr>
      <td>800</td>
      <td>8.898600</td>
    </tr>
    <tr>
      <td>1000</td>
      <td>8.804800</td>
    </tr>
    <tr>
      <td>1200</td>
      <td>8.801400</td>
    </tr>
  </tbody>
</table><p></div><div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Saving model checkpoint to ./tmp/checkpoint-500
Trainer.model is not a `PreTrainedModel`, only saving its state dict.
Saving model checkpoint to ./tmp/checkpoint-1000
Trainer.model is not a `PreTrainedModel`, only saving its state dict.


Training completed. Do not forget to share your model on huggingface.co/models =)
</pre></div>
</div>
<div class="output text_html">
<div>

  <progress value='1285' max='415' style='width:300px; height:20px; vertical-align: middle;'></progress>
  [415/415 01:55]
</div>
</div><div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>********************
Eval results for day 2 are:	

********************

 epoch = 3.0
 eval/loss = 8.881314277648926
 eval/next-item/ndcg_at_10 = 0.036112383008003235
 eval/next-item/ndcg_at_20 = 0.04597809165716171
 eval/next-item/recall_at_10 = 0.06884850561618805
 eval/next-item/recall_at_20 = 0.10798582434654236
 eval_runtime = 6.3241
 eval_samples_per_second = 2099.891
 eval_steps_per_second = 65.622
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>***** Running training *****
  Num examples = 106240
  Num Epochs = 3
  Instantaneous batch size per device = 256
  Total train batch size (w. parallel, distributed &amp; accumulation) = 256
  Gradient Accumulation steps = 1
  Total optimization steps = 1245
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>********************
Launch training for day 2 are:
********************
</pre></div>
</div>
<div class="output text_html">
    <div>

      <progress value='1245' max='1245' style='width:300px; height:20px; vertical-align: middle;'></progress>
      [1245/1245 00:48, Epoch 3/3]
    </div>
    <table border="1" class="dataframe">
  <thead>
    <tr style="text-align: left;">
      <th>Step</th>
      <th>Training Loss</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>200</td>
      <td>8.992400</td>
    </tr>
    <tr>
      <td>400</td>
      <td>8.859700</td>
    </tr>
    <tr>
      <td>600</td>
      <td>8.636400</td>
    </tr>
    <tr>
      <td>800</td>
      <td>8.524400</td>
    </tr>
    <tr>
      <td>1000</td>
      <td>8.396200</td>
    </tr>
    <tr>
      <td>1200</td>
      <td>8.369100</td>
    </tr>
  </tbody>
</table><p></div><div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Saving model checkpoint to ./tmp/checkpoint-500
Trainer.model is not a `PreTrainedModel`, only saving its state dict.
Saving model checkpoint to ./tmp/checkpoint-1000
Trainer.model is not a `PreTrainedModel`, only saving its state dict.


Training completed. Do not forget to share your model on huggingface.co/models =)
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>********************
Eval results for day 3 are:	

********************

 epoch = 3.0
 eval/loss = 8.505434036254883
 eval/next-item/ndcg_at_10 = 0.05683322995901108
 eval/next-item/ndcg_at_20 = 0.0703873336315155
 eval/next-item/recall_at_10 = 0.10895449668169022
 eval/next-item/recall_at_20 = 0.16269777715206146
 eval_runtime = 5.949
 eval_samples_per_second = 2065.548
 eval_steps_per_second = 64.548
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>***** Running training *****
  Num examples = 97792
  Num Epochs = 3
  Instantaneous batch size per device = 256
  Total train batch size (w. parallel, distributed &amp; accumulation) = 256
  Gradient Accumulation steps = 1
  Total optimization steps = 1146
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>********************
Launch training for day 3 are:
********************
</pre></div>
</div>
<div class="output text_html">
    <div>

      <progress value='1146' max='1146' style='width:300px; height:20px; vertical-align: middle;'></progress>
      [1146/1146 00:45, Epoch 3/3]
    </div>
    <table border="1" class="dataframe">
  <thead>
    <tr style="text-align: left;">
      <th>Step</th>
      <th>Training Loss</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>200</td>
      <td>8.581200</td>
    </tr>
    <tr>
      <td>400</td>
      <td>8.463000</td>
    </tr>
    <tr>
      <td>600</td>
      <td>8.274700</td>
    </tr>
    <tr>
      <td>800</td>
      <td>8.186600</td>
    </tr>
    <tr>
      <td>1000</td>
      <td>8.055800</td>
    </tr>
  </tbody>
</table><p></div><div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Saving model checkpoint to ./tmp/checkpoint-500
Trainer.model is not a `PreTrainedModel`, only saving its state dict.
Saving model checkpoint to ./tmp/checkpoint-1000
Trainer.model is not a `PreTrainedModel`, only saving its state dict.


Training completed. Do not forget to share your model on huggingface.co/models =)
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>********************
Eval results for day 4 are:	

********************

 epoch = 3.0
 eval/loss = 8.123461723327637
 eval/next-item/ndcg_at_10 = 0.07151895016431808
 eval/next-item/ndcg_at_20 = 0.08768121898174286
 eval/next-item/recall_at_10 = 0.1361762434244156
 eval/next-item/recall_at_20 = 0.20020613074302673
 eval_runtime = 7.5055
 eval_samples_per_second = 2072.086
 eval_steps_per_second = 64.753
CPU times: user 2min 18s, sys: 30.2 s, total: 2min 49s
Wall time: 2min 48s
</pre></div>
</div>
</div>
</div>
<p>Let’s write out model evaluation accuracy results to a text file to compare model at the end</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s2">&quot;results.txt&quot;</span><span class="p">,</span> <span class="s1">&#39;w&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span> 
    <span class="n">f</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="s1">&#39;GRU accuracy results:&#39;</span><span class="p">)</span>
    <span class="n">f</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span>  <span class="n">model</span><span class="o">.</span><span class="n">compute_metrics</span><span class="p">()</span><span class="o">.</span><span class="n">items</span><span class="p">():</span> 
        <span class="n">f</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="s1">&#39;</span><span class="si">%s</span><span class="s1">:</span><span class="si">%s</span><span class="se">\n</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="n">value</span><span class="o">.</span><span class="n">item</span><span class="p">()))</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="metrics">
<h3>Metrics<a class="headerlink" href="#metrics" title="Permalink to this headline">¶</a></h3>
<p>We have extended the HuggingFace transformers Trainer class (PyTorch only) to support evaluation of RecSys metrics. The following information
retrieval metrics are used to compute the Top-20 accuracy of recommendation lists containing all items: <br></p>
<ul class="simple">
<li><p><strong>Normalized Discounted Cumulative Gain (NDCG&#64;20):</strong> NDCG accounts for rank of the relevant item in the recommendation list and is a more fine-grained metric than HR, which only verifies whether the relevant item is among the top-k items.</p></li>
<li><p><strong>Hit Rate (HR&#64;20)</strong>: Also known as <code class="docutils literal notranslate"><span class="pre">Recall&#64;n</span></code> when there is only one relevant item in the recommendation list. HR just verifies whether the relevant item is among the top-n items.</p></li>
</ul>
</div>
<div class="section" id="restart-the-kernel-to-free-our-gpu-memory">
<h3>Restart the kernel to free our GPU memory<a class="headerlink" href="#restart-the-kernel-to-free-our-gpu-memory" title="Permalink to this headline">¶</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">IPython</span>
<span class="n">app</span> <span class="o">=</span> <span class="n">IPython</span><span class="o">.</span><span class="n">Application</span><span class="o">.</span><span class="n">instance</span><span class="p">()</span>
<span class="n">app</span><span class="o">.</span><span class="n">kernel</span><span class="o">.</span><span class="n">do_shutdown</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>{&#39;status&#39;: &#39;ok&#39;, &#39;restart&#39;: True}
</pre></div>
</div>
</div>
</div>
<p>At this stage if the kernel does not restart automatically, we expect you to manually restart the kernel to free GPU memory so that you can move on to the next session-based model training with a SOTA deep learning Transformer-based model, <a class="reference external" href="https://arxiv.org/pdf/1906.08237.pdf">XLNet</a>.</p>
</div>
</div>
<div class="section" id="training-a-transformer-based-session-based-recommendation-model">
<h2>Training a Transformer-based Session-based Recommendation Model<a class="headerlink" href="#training-a-transformer-based-session-based-recommendation-model" title="Permalink to this headline">¶</a></h2>
<div class="section" id="what-s-transformers">
<h3>What’s Transformers?<a class="headerlink" href="#what-s-transformers" title="Permalink to this headline">¶</a></h3>
<p>The Transformer is a competitive alternative to the models using Recurrent Neural Networks (RNNs) for a range of sequence modeling tasks. The Transformer architecture [6] was introduced as a novel architecture in NLP domain that aims to solve sequence-to-sequence tasks relying entirely on self-attention mechanism to compute representations of its input and output. Hence, the Transformer overperforms RNNs with their three mechanisms:</p>
<ul class="simple">
<li><p>Non-sequential: Transformers network is parallelized where as RNN computations are inherently sequential. That resulted in significant speed-up in the training time.</p></li>
<li><p>Self-attention mechanisms: Transformers rely entirely on self-attention mechanisms that directly model relationships between all item-ids in a sequence.</p></li>
<li><p>Positional encodings: A representation of the location or “position” of items in a sequence which is used to give the order context to the model architecture.</p></li>
</ul>
<p><center><img src='https://s3.us-west-2.amazonaws.com/secure.notion-static.com/5a89728b-f767-43f9-a04b-249ac5148c2a/Untitled.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAT73L2G45O3KS52Y5%2F20211011%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20211011T113310Z&X-Amz-Expires=86400&X-Amz-Signature=ae0e7ad7c947f6e916c5e809d2779079c81ebd16d9dc2eca17604c5fcca04d02&X-Amz-SignedHeaders=host&response-content-disposition=filename%20%3D%22Untitled.png%22'><br>Figure 3. Transformer vs vanilla RNN.</center></p><p>Figure 4 illustrates the differences of Transformer (self-attention based) and a vanilla RNN architecture. As we see, RNN cannot be parallelized because it uses sequential processing over time (notice the sequential path from previous cells to the current one). On the other hand, the Transformer is a more powerful architecture because the self-attention mechanism is capable of representing dependencies within the sequence of tokens, favors parallel processing and handle longer sequences.</p>
<p>As illustrated in the <a class="reference external" href="https://arxiv.org/pdf/1706.03762.pdf">Attention is All You Need</a> paper, the original transformer model is made up of an encoder and decoder where each is a stack we can call a transformer block. In Transformers4Rec architectures we use the encoder block of transformer architecture.</p>
<p><center><img src='https://s3.us-west-2.amazonaws.com/secure.notion-static.com/f0b9e980-ad4e-452b-8936-68fbac8fccd7/Untitled.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAT73L2G45O3KS52Y5%2F20211011%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20211011T113407Z&X-Amz-Expires=86400&X-Amz-Signature=263317ed25284a919e276c6d552bc032ab9100106730663b6d2d8dc5fcc77c95&X-Amz-SignedHeaders=host&response-content-disposition=filename%20%3D%22Untitled.png%22'><br>Figure 4. Encoder block of the Transformer Architecture.</center></p></div>
<div class="section" id="xlnet">
<h3>XLNet<a class="headerlink" href="#xlnet" title="Permalink to this headline">¶</a></h3>
<p>Here, we use XLNet [10] as the Transformer block in our architecture. It was originally proposed to be trained with the <em>Permutation Language Modeling (PLM)</em>  technique, that combines the advantages of autoregressive (Causal LM) and autoencoding (Masked LM). Although, we found out in our <a class="reference external" href="https://github.com/NVIDIA-Merlin/publications/blob/main/2021_acm_recsys_transformers4rec/recsys21_transformers4rec_paper.pdf">paper</a> [8] that the <em>Masked Language Model (MLM)</em> approach worked better than PLM for the small sequences in session-based recommendation, thus we use MLM for this example. MLM was introduced in <em>BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding</em> paper [8].</p>
<p>Figure 5 illustrates the causal language modeling (LM) and masked LM. In this example, we use in causal LM for RNN masked LM for XLNet. Causal LM is the task of predicting the token following a sequence of tokens, where the model only attends to the left context, i.e. models the probability of a token given the previous tokens in a sentence [7]. On the other hand, the MLM randomly masks some of the tokens from the input sequence, and the objective is to predict the original vocabulary id of the masked word based only on its bi-directional context. When we train with MLM, the Transformer layer is also allowed to use positions on the right (future information) during training. During inference, all past items are visible for the Transformer layer, which tries to predict the next item. It performs a type of data augmentation, by masking different positions of the sequences in each training epoch.</p>
<p><center><img src='https://s3.us-west-2.amazonaws.com/secure.notion-static.com/35f985e3-b874-4aba-9420-7ee6fa0b8e7e/Untitled.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAT73L2G45O3KS52Y5%2F20211011%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20211011T113457Z&X-Amz-Expires=86400&X-Amz-Signature=4e1a1639f829054317666ff74fc10dbff4411c150405bec184f5b3cbd2127977&X-Amz-SignedHeaders=host&response-content-disposition=filename%20%3D%22Untitled.png%22'><br>Figure 5. Causal and Masked Language Model masking methods.</center></p></div>
<div class="section" id="train-xlnet-for-next-item-prediction">
<h3>Train XLNET for Next Item Prediction<a class="headerlink" href="#train-xlnet-for-next-item-prediction" title="Permalink to this headline">¶</a></h3>
<p>Now we are going to define an architecture for next-item prediction using the XLNET architecture.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">glob</span>

<span class="kn">import</span> <span class="nn">torch</span> 
<span class="kn">import</span> <span class="nn">transformers4rec.torch</span> <span class="k">as</span> <span class="nn">tr</span>

<span class="kn">from</span> <span class="nn">transformers4rec.torch.ranking_metric</span> <span class="kn">import</span> <span class="n">NDCGAt</span><span class="p">,</span> <span class="n">RecallAt</span>
</pre></div>
</div>
</div>
</div>
<p>As we did above, we start with defining our schema object and selecting only the <code class="docutils literal notranslate"><span class="pre">product_id</span></code> feature for training.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">merlin_standard_lib</span> <span class="kn">import</span> <span class="n">Schema</span>

<span class="c1"># Define schema object to pass it to the TabularSequenceFeatures class</span>
<span class="n">SCHEMA_PATH</span> <span class="o">=</span> <span class="s1">&#39;schema_tutorial.pb&#39;</span>
<span class="n">schema</span> <span class="o">=</span> <span class="n">Schema</span><span class="p">()</span><span class="o">.</span><span class="n">from_proto_text</span><span class="p">(</span><span class="n">SCHEMA_PATH</span><span class="p">)</span>

<span class="c1"># Create a sub-schema only with the selected features</span>
<span class="n">schema</span> <span class="o">=</span> <span class="n">schema</span><span class="o">.</span><span class="n">select_by_name</span><span class="p">([</span><span class="s1">&#39;product_id-list_seq&#39;</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="define-input-block">
<h3>Define Input block<a class="headerlink" href="#define-input-block" title="Permalink to this headline">¶</a></h3>
<p>Here we instantiate <code class="docutils literal notranslate"><span class="pre">TabularSequenceFeatures</span></code> from the feature schema and set <code class="docutils literal notranslate"><span class="pre">masking=&quot;mlm&quot;</span></code> to use MLM as training method.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1">#Input </span>
<span class="n">sequence_length</span><span class="p">,</span> <span class="n">d_model</span> <span class="o">=</span> <span class="mi">20</span><span class="p">,</span> <span class="mi">192</span>
<span class="c1"># Define input module to process tabular input-features and to prepare masked inputs</span>
<span class="n">inputs</span><span class="o">=</span> <span class="n">tr</span><span class="o">.</span><span class="n">TabularSequenceFeatures</span><span class="o">.</span><span class="n">from_schema</span><span class="p">(</span>
    <span class="n">schema</span><span class="p">,</span>
    <span class="n">max_sequence_length</span><span class="o">=</span><span class="n">sequence_length</span><span class="p">,</span>
    <span class="n">d_output</span><span class="o">=</span><span class="n">d_model</span><span class="p">,</span>
    <span class="n">masking</span><span class="o">=</span><span class="s2">&quot;mlm&quot;</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>We have inherited the original <code class="docutils literal notranslate"><span class="pre">XLNetConfig</span></code> class of HF transformers with some default arguments in the <code class="docutils literal notranslate"><span class="pre">build()</span></code> method. Here we use it to instantiate an XLNET model according to the arguments (<code class="docutils literal notranslate"><span class="pre">d_model</span></code>, <code class="docutils literal notranslate"><span class="pre">n_head</span></code>, etc.), defining the model architecture.</p>
<p>The <code class="docutils literal notranslate"><span class="pre">TransformerBlock</span></code> class supports HF Transformers for session-based and sequential-based recommendation models. <code class="docutils literal notranslate"><span class="pre">NextItemPredictionTask</span></code> is the class to support next item prediction task, encapsulating the corresponding heads and loss.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Define XLNetConfig class and set default parameters for HF XLNet config  </span>
<span class="n">transformer_config</span> <span class="o">=</span> <span class="n">tr</span><span class="o">.</span><span class="n">XLNetConfig</span><span class="o">.</span><span class="n">build</span><span class="p">(</span>
    <span class="n">d_model</span><span class="o">=</span><span class="n">d_model</span><span class="p">,</span> <span class="n">n_head</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">n_layer</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">total_seq_length</span><span class="o">=</span><span class="n">sequence_length</span>
<span class="p">)</span>
<span class="c1"># Define the model block including: inputs, masking, projection and transformer block.</span>
<span class="n">body</span> <span class="o">=</span> <span class="n">tr</span><span class="o">.</span><span class="n">SequentialBlock</span><span class="p">(</span>
    <span class="n">inputs</span><span class="p">,</span> <span class="n">tr</span><span class="o">.</span><span class="n">MLPBlock</span><span class="p">([</span><span class="mi">192</span><span class="p">]),</span> <span class="n">tr</span><span class="o">.</span><span class="n">TransformerBlock</span><span class="p">(</span><span class="n">transformer_config</span><span class="p">,</span> <span class="n">masking</span><span class="o">=</span><span class="n">inputs</span><span class="o">.</span><span class="n">masking</span><span class="p">)</span>
<span class="p">)</span>

<span class="c1"># Define the head for to next item prediction task </span>
<span class="n">head</span> <span class="o">=</span> <span class="n">tr</span><span class="o">.</span><span class="n">Head</span><span class="p">(</span>
    <span class="n">body</span><span class="p">,</span>
    <span class="n">tr</span><span class="o">.</span><span class="n">NextItemPredictionTask</span><span class="p">(</span><span class="n">weight_tying</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">hf_format</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> 
                              <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="n">NDCGAt</span><span class="p">(</span><span class="n">top_ks</span><span class="o">=</span><span class="p">[</span><span class="mi">10</span><span class="p">,</span> <span class="mi">20</span><span class="p">],</span> <span class="n">labels_onehot</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>  
                                       <span class="n">RecallAt</span><span class="p">(</span><span class="n">top_ks</span><span class="o">=</span><span class="p">[</span><span class="mi">10</span><span class="p">,</span> <span class="mi">20</span><span class="p">],</span> <span class="n">labels_onehot</span><span class="o">=</span><span class="kc">True</span><span class="p">)]),</span>
<span class="p">)</span>

<span class="c1"># Get the end-to-end Model class </span>
<span class="n">model</span> <span class="o">=</span> <span class="n">tr</span><span class="o">.</span><span class="n">Model</span><span class="p">(</span><span class="n">head</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Projecting inputs of NextItemPredictionTask to&#39;64&#39; As weight tying requires the input dimension &#39;192&#39; to be equal to the item-id embedding dimension &#39;64&#39;
</pre></div>
</div>
</div>
</div>
<p><strong>Set training arguments</strong></p>
<p>Among the training arguments you can set the <code class="docutils literal notranslate"><span class="pre">data_loader_engine</span></code> to automatically instantiate the dataloader based on the schema, rather than instantiating the data loader manually like we did for the RNN example. The default value is <code class="docutils literal notranslate"><span class="pre">&quot;nvtabular&quot;</span></code> for optimized GPU-based data-loading. Optionally the PyarrowDataLoader (<code class="docutils literal notranslate"><span class="pre">&quot;pyarrow&quot;</span></code>) can also be used as a basic option, but it is slower and works only for small datasets, as the full data is loaded into CPU memory.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">transformers4rec.config.trainer</span> <span class="kn">import</span> <span class="n">T4RecTrainingArguments</span>
<span class="kn">from</span> <span class="nn">transformers4rec.torch</span> <span class="kn">import</span> <span class="n">Trainer</span>

<span class="c1">#Set arguments for training </span>
<span class="n">training_args</span> <span class="o">=</span> <span class="n">T4RecTrainingArguments</span><span class="p">(</span>
            <span class="n">output_dir</span><span class="o">=</span><span class="s2">&quot;./tmp&quot;</span><span class="p">,</span>
            <span class="n">max_sequence_length</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span>
            <span class="n">data_loader_engine</span><span class="o">=</span><span class="s1">&#39;nvtabular&#39;</span><span class="p">,</span>
            <span class="n">num_train_epochs</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> 
            <span class="n">dataloader_drop_last</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
            <span class="n">per_device_train_batch_size</span> <span class="o">=</span> <span class="mi">256</span><span class="p">,</span>
            <span class="n">per_device_eval_batch_size</span> <span class="o">=</span> <span class="mi">32</span><span class="p">,</span>
            <span class="n">gradient_accumulation_steps</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
            <span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.000666</span><span class="p">,</span>
            <span class="n">report_to</span> <span class="o">=</span> <span class="p">[],</span>
            <span class="n">logging_steps</span><span class="o">=</span><span class="mi">200</span><span class="p">,</span>
        <span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>PyTorch: setting up devices
</pre></div>
</div>
</div>
</div>
<p><strong>Instantiate the trainer</strong></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Instantiate the T4Rec Trainer, which manages training and evaluation</span>
<span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span>
    <span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span>
    <span class="n">args</span><span class="o">=</span><span class="n">training_args</span><span class="p">,</span>
    <span class="n">schema</span><span class="o">=</span><span class="n">schema</span><span class="p">,</span>
    <span class="n">compute_metrics</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Define the output folder of the processed parquet files</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">OUTPUT_DIR</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;OUTPUT_DIR&quot;</span><span class="p">,</span> <span class="s2">&quot;/workspace/data/sessions_by_day&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Now, we do time-based fine-tuning the model by iteratively training and evaluating using a sliding time window, like we did for the RNN example.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">%%</span><span class="n">time</span>
<span class="n">start_time_window_index</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">final_time_window_index</span> <span class="o">=</span> <span class="mi">4</span>
<span class="k">for</span> <span class="n">time_index</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">start_time_window_index</span><span class="p">,</span> <span class="n">final_time_window_index</span><span class="p">):</span>
    <span class="c1"># Set data </span>
    <span class="n">time_index_train</span> <span class="o">=</span> <span class="n">time_index</span>
    <span class="n">time_index_eval</span> <span class="o">=</span> <span class="n">time_index</span> <span class="o">+</span> <span class="mi">1</span>
    <span class="n">train_paths</span> <span class="o">=</span> <span class="n">glob</span><span class="o">.</span><span class="n">glob</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">OUTPUT_DIR</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">time_index_train</span><span class="si">}</span><span class="s2">/train.parquet&quot;</span><span class="p">))</span>
    <span class="n">eval_paths</span> <span class="o">=</span> <span class="n">glob</span><span class="o">.</span><span class="n">glob</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">OUTPUT_DIR</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">time_index_eval</span><span class="si">}</span><span class="s2">/valid.parquet&quot;</span><span class="p">))</span>
    <span class="c1"># Train on day related to time_index </span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;*&#39;</span><span class="o">*</span><span class="mi">20</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Launch training for day </span><span class="si">%s</span><span class="s2"> are:&quot;</span> <span class="o">%</span><span class="n">time_index</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;*&#39;</span><span class="o">*</span><span class="mi">20</span> <span class="o">+</span> <span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>
    <span class="n">trainer</span><span class="o">.</span><span class="n">train_dataset_or_path</span> <span class="o">=</span> <span class="n">train_paths</span>
    <span class="n">trainer</span><span class="o">.</span><span class="n">reset_lr_scheduler</span><span class="p">()</span>
    <span class="n">trainer</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
    <span class="n">trainer</span><span class="o">.</span><span class="n">state</span><span class="o">.</span><span class="n">global_step</span> <span class="o">+=</span><span class="mi">1</span>
    <span class="c1"># Evaluate on the following day</span>
    <span class="n">trainer</span><span class="o">.</span><span class="n">eval_dataset_or_path</span> <span class="o">=</span> <span class="n">eval_paths</span>
    <span class="n">train_metrics</span> <span class="o">=</span> <span class="n">trainer</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">metric_key_prefix</span><span class="o">=</span><span class="s1">&#39;eval&#39;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;*&#39;</span><span class="o">*</span><span class="mi">20</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Eval results for day </span><span class="si">%s</span><span class="s2"> are:</span><span class="se">\t</span><span class="s2">&quot;</span> <span class="o">%</span><span class="n">time_index_eval</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span> <span class="o">+</span> <span class="s1">&#39;*&#39;</span><span class="o">*</span><span class="mi">20</span> <span class="o">+</span> <span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">train_metrics</span><span class="o">.</span><span class="n">keys</span><span class="p">()):</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot; </span><span class="si">%s</span><span class="s2"> = </span><span class="si">%s</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="nb">str</span><span class="p">(</span><span class="n">train_metrics</span><span class="p">[</span><span class="n">key</span><span class="p">])))</span> 
    <span class="n">trainer</span><span class="o">.</span><span class="n">wipe_memory</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>***** Running training *****
  Num examples = 112128
  Num Epochs = 3
  Instantaneous batch size per device = 256
  Total train batch size (w. parallel, distributed &amp; accumulation) = 256
  Gradient Accumulation steps = 1
  Total optimization steps = 1314
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>********************
Launch training for day 1 are:
********************
</pre></div>
</div>
<div class="output text_html">
    <div>

      <progress value='1314' max='1314' style='width:300px; height:20px; vertical-align: middle;'></progress>
      [1314/1314 00:45, Epoch 3/3]
    </div>
    <table border="1" class="dataframe">
  <thead>
    <tr style="text-align: left;">
      <th>Step</th>
      <th>Training Loss</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>200</td>
      <td>9.927000</td>
    </tr>
    <tr>
      <td>400</td>
      <td>9.046400</td>
    </tr>
    <tr>
      <td>600</td>
      <td>8.779300</td>
    </tr>
    <tr>
      <td>800</td>
      <td>8.635800</td>
    </tr>
    <tr>
      <td>1000</td>
      <td>8.539400</td>
    </tr>
    <tr>
      <td>1200</td>
      <td>8.507000</td>
    </tr>
  </tbody>
</table><p></div><div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Saving model checkpoint to ./tmp/checkpoint-500
Trainer.model is not a `PreTrainedModel`, only saving its state dict.
Saving model checkpoint to ./tmp/checkpoint-1000
Trainer.model is not a `PreTrainedModel`, only saving its state dict.


Training completed. Do not forget to share your model on huggingface.co/models =)
</pre></div>
</div>
<div class="output text_html">
<div>

  <progress value='1285' max='415' style='width:300px; height:20px; vertical-align: middle;'></progress>
  [415/415 01:48]
</div>
</div><div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>********************
Eval results for day 2 are:	

********************

 epoch = 3.0
 eval/loss = 8.753535270690918
 eval/next-item/ndcg_at_10 = 0.049175068736076355
 eval/next-item/ndcg_at_20 = 0.06000332161784172
 eval/next-item/recall_at_10 = 0.09177286922931671
 eval/next-item/recall_at_20 = 0.1346806436777115
 eval_runtime = 7.0703
 eval_samples_per_second = 1878.271
 eval_steps_per_second = 58.696
********************
Launch training for day 2 are:
********************
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>***** Running training *****
  Num examples = 106240
  Num Epochs = 3
  Instantaneous batch size per device = 256
  Total train batch size (w. parallel, distributed &amp; accumulation) = 256
  Gradient Accumulation steps = 1
  Total optimization steps = 1245
</pre></div>
</div>
<div class="output text_html">
    <div>

      <progress value='1245' max='1245' style='width:300px; height:20px; vertical-align: middle;'></progress>
      [1245/1245 00:43, Epoch 3/3]
    </div>
    <table border="1" class="dataframe">
  <thead>
    <tr style="text-align: left;">
      <th>Step</th>
      <th>Training Loss</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>200</td>
      <td>8.635100</td>
    </tr>
    <tr>
      <td>400</td>
      <td>8.523100</td>
    </tr>
    <tr>
      <td>600</td>
      <td>8.375600</td>
    </tr>
    <tr>
      <td>800</td>
      <td>8.322400</td>
    </tr>
    <tr>
      <td>1000</td>
      <td>8.232100</td>
    </tr>
    <tr>
      <td>1200</td>
      <td>8.209900</td>
    </tr>
  </tbody>
</table><p></div><div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Saving model checkpoint to ./tmp/checkpoint-500
Trainer.model is not a `PreTrainedModel`, only saving its state dict.
Saving model checkpoint to ./tmp/checkpoint-1000
Trainer.model is not a `PreTrainedModel`, only saving its state dict.


Training completed. Do not forget to share your model on huggingface.co/models =)
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>********************
Eval results for day 3 are:	

********************

 epoch = 3.0
 eval/loss = 8.421579360961914
 eval/next-item/ndcg_at_10 = 0.061416078358888626
 eval/next-item/ndcg_at_20 = 0.07491344213485718
 eval/next-item/recall_at_10 = 0.11719132959842682
 eval/next-item/recall_at_20 = 0.17060838639736176
 eval_runtime = 7.0074
 eval_samples_per_second = 1753.564
 eval_steps_per_second = 54.799
********************
Launch training for day 3 are:
********************
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>***** Running training *****
  Num examples = 97792
  Num Epochs = 3
  Instantaneous batch size per device = 256
  Total train batch size (w. parallel, distributed &amp; accumulation) = 256
  Gradient Accumulation steps = 1
  Total optimization steps = 1146
</pre></div>
</div>
<div class="output text_html">
    <div>

      <progress value='1146' max='1146' style='width:300px; height:20px; vertical-align: middle;'></progress>
      [1146/1146 00:40, Epoch 3/3]
    </div>
    <table border="1" class="dataframe">
  <thead>
    <tr style="text-align: left;">
      <th>Step</th>
      <th>Training Loss</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>200</td>
      <td>8.312100</td>
    </tr>
    <tr>
      <td>400</td>
      <td>8.226900</td>
    </tr>
    <tr>
      <td>600</td>
      <td>8.095400</td>
    </tr>
    <tr>
      <td>800</td>
      <td>8.065600</td>
    </tr>
    <tr>
      <td>1000</td>
      <td>7.965600</td>
    </tr>
  </tbody>
</table><p></div><div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Saving model checkpoint to ./tmp/checkpoint-500
Trainer.model is not a `PreTrainedModel`, only saving its state dict.
Saving model checkpoint to ./tmp/checkpoint-1000
Trainer.model is not a `PreTrainedModel`, only saving its state dict.


Training completed. Do not forget to share your model on huggingface.co/models =)
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>********************
Eval results for day 4 are:	

********************

 epoch = 3.0
 eval/loss = 8.107558250427246
 eval/next-item/ndcg_at_10 = 0.07384572923183441
 eval/next-item/ndcg_at_20 = 0.08944202959537506
 eval/next-item/recall_at_10 = 0.13939706981182098
 eval/next-item/recall_at_20 = 0.20175212621688843
 eval_runtime = 8.9372
 eval_samples_per_second = 1740.144
 eval_steps_per_second = 54.38
CPU times: user 6min 57s, sys: 14.3 s, total: 7min 11s
Wall time: 2min 35s
</pre></div>
</div>
</div>
</div>
<p>Add eval accuracy metric results to the existing resuls.txt file.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s2">&quot;results.txt&quot;</span><span class="p">,</span> <span class="s1">&#39;a&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="n">f</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>
    <span class="n">f</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="s1">&#39;XLNet-MLM accuracy results:&#39;</span><span class="p">)</span>
    <span class="n">f</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span>  <span class="n">model</span><span class="o">.</span><span class="n">compute_metrics</span><span class="p">()</span><span class="o">.</span><span class="n">items</span><span class="p">():</span> 
        <span class="n">f</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="s1">&#39;</span><span class="si">%s</span><span class="s1">:</span><span class="si">%s</span><span class="se">\n</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="n">value</span><span class="o">.</span><span class="n">item</span><span class="p">()))</span>
</pre></div>
</div>
</div>
</div>
<p><strong>Restart the kernel to free our GPU memory</strong></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">IPython</span>
<span class="n">app</span> <span class="o">=</span> <span class="n">IPython</span><span class="o">.</span><span class="n">Application</span><span class="o">.</span><span class="n">instance</span><span class="p">()</span>
<span class="n">app</span><span class="o">.</span><span class="n">kernel</span><span class="o">.</span><span class="n">do_shutdown</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>{&#39;status&#39;: &#39;ok&#39;, &#39;restart&#39;: True}
</pre></div>
</div>
</div>
</div>
<p>At this stage if the kernel does not restart automatically, we expect you to manually restart the kernel to free GPU memory so that you can move on to the next session-based model training with XLNet using side information.</p>
</div>
<div class="section" id="train-xlnet-with-side-information-for-next-item-prediction">
<h3>Train XLNET with Side Information for Next Item Prediction<a class="headerlink" href="#train-xlnet-with-side-information-for-next-item-prediction" title="Permalink to this headline">¶</a></h3>
<p>It is a common practice in RecSys to leverage additional tabular features of item (product) metadata and user context, providing the model more
information for meaningful predictions. With that motivation, in this section, we will use additional features to train our XLNET architecture. We already checked our <code class="docutils literal notranslate"><span class="pre">schema.pb</span></code>, saw that it includes features and their tags. Now it is time to use these additional features that we created earlier.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">glob</span>
<span class="kn">import</span> <span class="nn">nvtabular</span> <span class="k">as</span> <span class="nn">nvt</span>

<span class="kn">import</span> <span class="nn">torch</span> 
<span class="kn">import</span> <span class="nn">transformers4rec.torch</span> <span class="k">as</span> <span class="nn">tr</span>

<span class="kn">from</span> <span class="nn">transformers4rec.torch.ranking_metric</span> <span class="kn">import</span> <span class="n">NDCGAt</span><span class="p">,</span> <span class="n">RecallAt</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Define categorical and continuous columns to fed to training model</span>
<span class="n">x_cat_names</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;product_id-list_seq&#39;</span><span class="p">,</span> <span class="s1">&#39;category_id-list_seq&#39;</span><span class="p">,</span> <span class="s1">&#39;brand-list_seq&#39;</span><span class="p">]</span>
<span class="n">x_cont_names</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;product_recency_days_log_norm-list_seq&#39;</span><span class="p">,</span> <span class="s1">&#39;et_dayofweek_sin-list_seq&#39;</span><span class="p">,</span> <span class="s1">&#39;et_dayofweek_cos-list_seq&#39;</span><span class="p">,</span> 
                <span class="s1">&#39;price_log_norm-list_seq&#39;</span><span class="p">,</span> <span class="s1">&#39;relative_price_to_avg_categ_id-list_seq&#39;</span><span class="p">]</span>

<span class="kn">from</span> <span class="nn">merlin_standard_lib</span> <span class="kn">import</span> <span class="n">Schema</span>

<span class="c1"># Define schema object to pass it to the TabularSequenceFeatures class</span>
<span class="n">SCHEMA_PATH</span> <span class="o">=</span><span class="s1">&#39;schema_tutorial.pb&#39;</span>
<span class="n">schema</span> <span class="o">=</span> <span class="n">Schema</span><span class="p">()</span><span class="o">.</span><span class="n">from_proto_text</span><span class="p">(</span><span class="n">SCHEMA_PATH</span><span class="p">)</span>
<span class="n">schema</span> <span class="o">=</span> <span class="n">schema</span><span class="o">.</span><span class="n">select_by_name</span><span class="p">(</span><span class="n">x_cat_names</span> <span class="o">+</span> <span class="n">x_cont_names</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Here we set <code class="docutils literal notranslate"><span class="pre">aggregation=&quot;concat&quot;</span></code>, so that all categorical and continuous features are concatenated to form an interaction representation.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Define input block</span>
<span class="n">sequence_length</span><span class="p">,</span> <span class="n">d_model</span> <span class="o">=</span> <span class="mi">20</span><span class="p">,</span> <span class="mi">192</span>
<span class="c1"># Define input module to process tabular input-features and to prepare masked inputs</span>
<span class="n">inputs</span><span class="o">=</span> <span class="n">tr</span><span class="o">.</span><span class="n">TabularSequenceFeatures</span><span class="o">.</span><span class="n">from_schema</span><span class="p">(</span>
    <span class="n">schema</span><span class="p">,</span>
    <span class="n">max_sequence_length</span><span class="o">=</span><span class="n">sequence_length</span><span class="p">,</span>
    <span class="n">aggregation</span><span class="o">=</span><span class="s2">&quot;concat&quot;</span><span class="p">,</span>
    <span class="n">d_output</span><span class="o">=</span><span class="n">d_model</span><span class="p">,</span>
    <span class="n">masking</span><span class="o">=</span><span class="s2">&quot;mlm&quot;</span><span class="p">,</span>
<span class="p">)</span>

<span class="c1"># Define XLNetConfig class and set default parameters for HF XLNet config  </span>
<span class="n">transformer_config</span> <span class="o">=</span> <span class="n">tr</span><span class="o">.</span><span class="n">XLNetConfig</span><span class="o">.</span><span class="n">build</span><span class="p">(</span>
    <span class="n">d_model</span><span class="o">=</span><span class="n">d_model</span><span class="p">,</span> <span class="n">n_head</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">n_layer</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">total_seq_length</span><span class="o">=</span><span class="n">sequence_length</span>
<span class="p">)</span>
<span class="c1"># Define the model block including: inputs, masking, projection and transformer block.</span>
<span class="n">body</span> <span class="o">=</span> <span class="n">tr</span><span class="o">.</span><span class="n">SequentialBlock</span><span class="p">(</span>
    <span class="n">inputs</span><span class="p">,</span> <span class="n">tr</span><span class="o">.</span><span class="n">MLPBlock</span><span class="p">([</span><span class="mi">192</span><span class="p">]),</span> <span class="n">tr</span><span class="o">.</span><span class="n">TransformerBlock</span><span class="p">(</span><span class="n">transformer_config</span><span class="p">,</span> <span class="n">masking</span><span class="o">=</span><span class="n">inputs</span><span class="o">.</span><span class="n">masking</span><span class="p">)</span>
<span class="p">)</span>

<span class="c1"># Define the head related to next item prediction task </span>
<span class="n">head</span> <span class="o">=</span> <span class="n">tr</span><span class="o">.</span><span class="n">Head</span><span class="p">(</span>
    <span class="n">body</span><span class="p">,</span>
    <span class="n">tr</span><span class="o">.</span><span class="n">NextItemPredictionTask</span><span class="p">(</span><span class="n">weight_tying</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">hf_format</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> 
                                     <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="n">NDCGAt</span><span class="p">(</span><span class="n">top_ks</span><span class="o">=</span><span class="p">[</span><span class="mi">10</span><span class="p">,</span> <span class="mi">20</span><span class="p">],</span> <span class="n">labels_onehot</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>  
                                              <span class="n">RecallAt</span><span class="p">(</span><span class="n">top_ks</span><span class="o">=</span><span class="p">[</span><span class="mi">10</span><span class="p">,</span> <span class="mi">20</span><span class="p">],</span> <span class="n">labels_onehot</span><span class="o">=</span><span class="kc">True</span><span class="p">)]),</span>
<span class="p">)</span>

<span class="c1"># Get the end-to-end Model class </span>
<span class="n">model</span> <span class="o">=</span> <span class="n">tr</span><span class="o">.</span><span class="n">Model</span><span class="p">(</span><span class="n">head</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Projecting inputs of NextItemPredictionTask to&#39;64&#39; As weight tying requires the input dimension &#39;192&#39; to be equal to the item-id embedding dimension &#39;64&#39;
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="training-and-evaluation">
<h3>Training and Evaluation<a class="headerlink" href="#training-and-evaluation" title="Permalink to this headline">¶</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">transformers4rec.config.trainer</span> <span class="kn">import</span> <span class="n">T4RecTrainingArguments</span>
<span class="kn">from</span> <span class="nn">transformers4rec.torch</span> <span class="kn">import</span> <span class="n">Trainer</span>

<span class="c1">#Set arguments for training </span>
<span class="n">training_args</span> <span class="o">=</span> <span class="n">T4RecTrainingArguments</span><span class="p">(</span>
            <span class="n">output_dir</span><span class="o">=</span><span class="s2">&quot;./tmp&quot;</span><span class="p">,</span>
            <span class="n">max_sequence_length</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span>
            <span class="n">data_loader_engine</span><span class="o">=</span><span class="s1">&#39;nvtabular&#39;</span><span class="p">,</span>
            <span class="n">num_train_epochs</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> 
            <span class="n">dataloader_drop_last</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
            <span class="n">per_device_train_batch_size</span> <span class="o">=</span> <span class="mi">256</span><span class="p">,</span>
            <span class="n">per_device_eval_batch_size</span> <span class="o">=</span> <span class="mi">32</span><span class="p">,</span>
            <span class="n">gradient_accumulation_steps</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
            <span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.000666</span><span class="p">,</span>
            <span class="n">report_to</span> <span class="o">=</span> <span class="p">[],</span>
            <span class="n">logging_steps</span><span class="o">=</span><span class="mi">200</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Instantiate the T4Rec Trainer, which manages training and evaluation</span>
<span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span>
    <span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span>
    <span class="n">args</span><span class="o">=</span><span class="n">training_args</span><span class="p">,</span>
    <span class="n">schema</span><span class="o">=</span><span class="n">schema</span><span class="p">,</span>
    <span class="n">compute_metrics</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Define the output folder of the processed parquet files</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">OUTPUT_DIR</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;OUTPUT_DIR&quot;</span><span class="p">,</span> <span class="s2">&quot;/workspace/data/sessions_by_day&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">%%</span><span class="n">time</span>
<span class="n">start_time_window_index</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">final_time_window_index</span> <span class="o">=</span> <span class="mi">4</span>
<span class="k">for</span> <span class="n">time_index</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">start_time_window_index</span><span class="p">,</span> <span class="n">final_time_window_index</span><span class="p">):</span>
    <span class="c1"># Set data </span>
    <span class="n">time_index_train</span> <span class="o">=</span> <span class="n">time_index</span>
    <span class="n">time_index_eval</span> <span class="o">=</span> <span class="n">time_index</span> <span class="o">+</span> <span class="mi">1</span>
    <span class="n">train_paths</span> <span class="o">=</span> <span class="n">glob</span><span class="o">.</span><span class="n">glob</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">OUTPUT_DIR</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">time_index_train</span><span class="si">}</span><span class="s2">/train.parquet&quot;</span><span class="p">))</span>
    <span class="n">eval_paths</span> <span class="o">=</span> <span class="n">glob</span><span class="o">.</span><span class="n">glob</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">OUTPUT_DIR</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">time_index_eval</span><span class="si">}</span><span class="s2">/valid.parquet&quot;</span><span class="p">))</span>
    <span class="c1"># Train on day related to time_index </span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;*&#39;</span><span class="o">*</span><span class="mi">20</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Launch training for day </span><span class="si">%s</span><span class="s2"> are:&quot;</span> <span class="o">%</span><span class="n">time_index</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;*&#39;</span><span class="o">*</span><span class="mi">20</span> <span class="o">+</span> <span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>
    <span class="n">trainer</span><span class="o">.</span><span class="n">train_dataset_or_path</span> <span class="o">=</span> <span class="n">train_paths</span>
    <span class="n">trainer</span><span class="o">.</span><span class="n">reset_lr_scheduler</span><span class="p">()</span>
    <span class="n">trainer</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
    <span class="n">trainer</span><span class="o">.</span><span class="n">state</span><span class="o">.</span><span class="n">global_step</span> <span class="o">+=</span><span class="mi">1</span>
    <span class="c1"># Evaluate on the following day</span>
    <span class="n">trainer</span><span class="o">.</span><span class="n">eval_dataset_or_path</span> <span class="o">=</span> <span class="n">eval_paths</span>
    <span class="n">train_metrics</span> <span class="o">=</span> <span class="n">trainer</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">metric_key_prefix</span><span class="o">=</span><span class="s1">&#39;eval&#39;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;*&#39;</span><span class="o">*</span><span class="mi">20</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Eval results for day </span><span class="si">%s</span><span class="s2"> are:</span><span class="se">\t</span><span class="s2">&quot;</span> <span class="o">%</span><span class="n">time_index_eval</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span> <span class="o">+</span> <span class="s1">&#39;*&#39;</span><span class="o">*</span><span class="mi">20</span> <span class="o">+</span> <span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">train_metrics</span><span class="o">.</span><span class="n">keys</span><span class="p">()):</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot; </span><span class="si">%s</span><span class="s2"> = </span><span class="si">%s</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="nb">str</span><span class="p">(</span><span class="n">train_metrics</span><span class="p">[</span><span class="n">key</span><span class="p">])))</span> 
    <span class="n">trainer</span><span class="o">.</span><span class="n">wipe_memory</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>********************
Launch training for day 1 are:
********************
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>***** Running training *****
  Num examples = 112128
  Num Epochs = 3
  Instantaneous batch size per device = 256
  Total train batch size (w. parallel, distributed &amp; accumulation) = 256
  Gradient Accumulation steps = 1
  Total optimization steps = 1314
</pre></div>
</div>
<div class="output text_html">
    <div>

      <progress value='1314' max='1314' style='width:300px; height:20px; vertical-align: middle;'></progress>
      [1314/1314 00:51, Epoch 3/3]
    </div>
    <table border="1" class="dataframe">
  <thead>
    <tr style="text-align: left;">
      <th>Step</th>
      <th>Training Loss</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>200</td>
      <td>9.836900</td>
    </tr>
    <tr>
      <td>400</td>
      <td>8.937700</td>
    </tr>
    <tr>
      <td>600</td>
      <td>8.665200</td>
    </tr>
    <tr>
      <td>800</td>
      <td>8.518700</td>
    </tr>
    <tr>
      <td>1000</td>
      <td>8.411900</td>
    </tr>
    <tr>
      <td>1200</td>
      <td>8.371200</td>
    </tr>
  </tbody>
</table><p></div><div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Saving model checkpoint to ./tmp/checkpoint-500
Trainer.model is not a `PreTrainedModel`, only saving its state dict.
Saving model checkpoint to ./tmp/checkpoint-1000
Trainer.model is not a `PreTrainedModel`, only saving its state dict.


Training completed. Do not forget to share your model on huggingface.co/models =)
</pre></div>
</div>
<div class="output text_html">
<div>

  <progress value='1285' max='415' style='width:300px; height:20px; vertical-align: middle;'></progress>
  [415/415 02:11]
</div>
</div><div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>********************
Eval results for day 2 are:	

********************

 epoch = 3.0
 eval/loss = 8.605655670166016
 eval/next-item/ndcg_at_10 = 0.0545700266957283
 eval/next-item/ndcg_at_20 = 0.06626961380243301
 eval/next-item/recall_at_10 = 0.10270718485116959
 eval/next-item/recall_at_20 = 0.14915919303894043
 eval_runtime = 9.5026
 eval_samples_per_second = 1397.507
 eval_steps_per_second = 43.672
********************
Launch training for day 2 are:
********************
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>***** Running training *****
  Num examples = 106240
  Num Epochs = 3
  Instantaneous batch size per device = 256
  Total train batch size (w. parallel, distributed &amp; accumulation) = 256
  Gradient Accumulation steps = 1
  Total optimization steps = 1245
</pre></div>
</div>
<div class="output text_html">
    <div>

      <progress value='1245' max='1245' style='width:300px; height:20px; vertical-align: middle;'></progress>
      [1245/1245 00:50, Epoch 3/3]
    </div>
    <table border="1" class="dataframe">
  <thead>
    <tr style="text-align: left;">
      <th>Step</th>
      <th>Training Loss</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>200</td>
      <td>8.466200</td>
    </tr>
    <tr>
      <td>400</td>
      <td>8.315800</td>
    </tr>
    <tr>
      <td>600</td>
      <td>8.120000</td>
    </tr>
    <tr>
      <td>800</td>
      <td>8.036200</td>
    </tr>
    <tr>
      <td>1000</td>
      <td>7.920700</td>
    </tr>
    <tr>
      <td>1200</td>
      <td>7.883900</td>
    </tr>
  </tbody>
</table><p></div><div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Saving model checkpoint to ./tmp/checkpoint-500
Trainer.model is not a `PreTrainedModel`, only saving its state dict.
Saving model checkpoint to ./tmp/checkpoint-1000
Trainer.model is not a `PreTrainedModel`, only saving its state dict.


Training completed. Do not forget to share your model on huggingface.co/models =)
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>********************
Eval results for day 3 are:	

********************

 epoch = 3.0
 eval/loss = 8.162181854248047
 eval/next-item/ndcg_at_10 = 0.0733010321855545
 eval/next-item/ndcg_at_20 = 0.08980806171894073
 eval/next-item/recall_at_10 = 0.13904747366905212
 eval/next-item/recall_at_20 = 0.20428968966007233
 eval_runtime = 9.1126
 eval_samples_per_second = 1348.468
 eval_steps_per_second = 42.14
********************
Launch training for day 3 are:
********************
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>***** Running training *****
  Num examples = 97792
  Num Epochs = 3
  Instantaneous batch size per device = 256
  Total train batch size (w. parallel, distributed &amp; accumulation) = 256
  Gradient Accumulation steps = 1
  Total optimization steps = 1146
</pre></div>
</div>
<div class="output text_html">
    <div>

      <progress value='1146' max='1146' style='width:300px; height:20px; vertical-align: middle;'></progress>
      [1146/1146 00:47, Epoch 3/3]
    </div>
    <table border="1" class="dataframe">
  <thead>
    <tr style="text-align: left;">
      <th>Step</th>
      <th>Training Loss</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>200</td>
      <td>8.016800</td>
    </tr>
    <tr>
      <td>400</td>
      <td>7.900500</td>
    </tr>
    <tr>
      <td>600</td>
      <td>7.740200</td>
    </tr>
    <tr>
      <td>800</td>
      <td>7.691500</td>
    </tr>
    <tr>
      <td>1000</td>
      <td>7.583600</td>
    </tr>
  </tbody>
</table><p></div><div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Saving model checkpoint to ./tmp/checkpoint-500
Trainer.model is not a `PreTrainedModel`, only saving its state dict.
Saving model checkpoint to ./tmp/checkpoint-1000
Trainer.model is not a `PreTrainedModel`, only saving its state dict.


Training completed. Do not forget to share your model on huggingface.co/models =)
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>********************
Eval results for day 4 are:	

********************

 epoch = 3.0
 eval/loss = 7.774728775024414
 eval/next-item/ndcg_at_10 = 0.09089759737253189
 eval/next-item/ndcg_at_20 = 0.10928591340780258
 eval/next-item/recall_at_10 = 0.16947951912879944
 eval/next-item/recall_at_20 = 0.24214120209217072
 eval_runtime = 11.8897
 eval_samples_per_second = 1308.02
 eval_steps_per_second = 40.876
CPU times: user 7min 29s, sys: 16.9 s, total: 7min 45s
Wall time: 3min 10s
</pre></div>
</div>
</div>
</div>
<p>Add XLNet-MLM with side information accuracy results to the <code class="docutils literal notranslate"><span class="pre">results.txt</span></code></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s2">&quot;results.txt&quot;</span><span class="p">,</span> <span class="s1">&#39;a&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="n">f</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>
    <span class="n">f</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="s1">&#39;XLNet-MLM with side information accuracy results:&#39;</span><span class="p">)</span>
    <span class="n">f</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span>  <span class="n">model</span><span class="o">.</span><span class="n">compute_metrics</span><span class="p">()</span><span class="o">.</span><span class="n">items</span><span class="p">():</span> 
        <span class="n">f</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="s1">&#39;</span><span class="si">%s</span><span class="s1"> </span><span class="si">%s</span><span class="se">\n</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="n">value</span><span class="o">.</span><span class="n">item</span><span class="p">()))</span>
</pre></div>
</div>
</div>
</div>
<p>After model training and evaluation is completed we can save our trained model in the next section.</p>
</div>
</div>
<div class="section" id="exporting-the-preprocessing-workflow-and-model-for-deployment-to-triton-server">
<h2>Exporting the preprocessing workflow and model for deployment to Triton server<a class="headerlink" href="#exporting-the-preprocessing-workflow-and-model-for-deployment-to-triton-server" title="Permalink to this headline">¶</a></h2>
<p>Load the preproc workflow that we saved in the ETL section.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">nvtabular</span> <span class="k">as</span> <span class="nn">nvt</span>

<span class="c1"># define data path about where to get our data</span>
<span class="n">INPUT_DATA_DIR</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;INPUT_DATA_DIR&quot;</span><span class="p">,</span> <span class="s2">&quot;/workspace/data/&quot;</span><span class="p">)</span>
<span class="n">workflow_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">INPUT_DATA_DIR</span><span class="p">,</span> <span class="s1">&#39;workflow_etl&#39;</span><span class="p">)</span>
<span class="n">workflow</span> <span class="o">=</span> <span class="n">nvt</span><span class="o">.</span><span class="n">Workflow</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">workflow_path</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># dictionary representing max sequence length for the sequential (list) columns</span>
<span class="n">sparse_features_max</span> <span class="o">=</span> <span class="p">{</span>
    <span class="n">fname</span><span class="p">:</span> <span class="n">sequence_length</span>
    <span class="k">for</span> <span class="n">fname</span> <span class="ow">in</span> <span class="n">x_cat_names</span> <span class="o">+</span> <span class="n">x_cont_names</span>
<span class="p">}</span>

<span class="n">sparse_features_max</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>{&#39;product_id-list_seq&#39;: 20,
 &#39;category_id-list_seq&#39;: 20,
 &#39;brand-list_seq&#39;: 20,
 &#39;product_recency_days_log_norm-list_seq&#39;: 20,
 &#39;et_dayofweek_sin-list_seq&#39;: 20,
 &#39;et_dayofweek_cos-list_seq&#39;: 20,
 &#39;price_log_norm-list_seq&#39;: 20,
 &#39;relative_price_to_avg_categ_id-list_seq&#39;: 20}
</pre></div>
</div>
</div>
</div>
<p>It is time to export the proc workflow and model in the format required by Triton Inference Server, by using the NVTabular’s <code class="docutils literal notranslate"><span class="pre">export_pytorch_ensemble()</span></code> function.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">nvtabular.inference.triton</span> <span class="kn">import</span> <span class="n">export_pytorch_ensemble</span>
<span class="n">export_pytorch_ensemble</span><span class="p">(</span>
    <span class="n">model</span><span class="p">,</span>
    <span class="n">workflow</span><span class="p">,</span>
    <span class="n">sparse_max</span><span class="o">=</span><span class="n">sparse_features_max</span><span class="p">,</span>
    <span class="n">name</span><span class="o">=</span> <span class="s2">&quot;t4r_pytorch&quot;</span><span class="p">,</span>
    <span class="n">model_path</span><span class="o">=</span> <span class="s2">&quot;/workspace/models&quot;</span><span class="p">,</span>
    <span class="n">label_columns</span> <span class="o">=</span><span class="p">[],</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Before we move on to the next section, let’s print out our results.txt file.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>!cat results.txt
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>GRU accuracy results:
next-item/ndcg_at_10:0.07151895016431808
next-item/ndcg_at_20:0.08768121898174286
next-item/recall_at_10:0.1361762434244156
next-item/recall_at_20:0.20020613074302673

XLNet-MLM accuracy results:
next-item/ndcg_at_10:0.07384572923183441
next-item/ndcg_at_20:0.08944202959537506
next-item/recall_at_10:0.13939706981182098
next-item/recall_at_20:0.20175212621688843

XLNet-MLM with side information accuracy results:
next-item/ndcg_at_10:0.08558817952871323
next-item/ndcg_at_20:0.10371016710996628
next-item/recall_at_10:0.1605256348848343
next-item/recall_at_20:0.2324143350124359
</pre></div>
</div>
</div>
</div>
<p>Let’s plot bar charts to visualize and compare the accuracy results using <code class="docutils literal notranslate"><span class="pre">visuals</span></code> util function.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">visuals</span> <span class="kn">import</span> <span class="n">create_bar_chart</span>
<span class="n">create_bar_chart</span><span class="p">(</span><span class="s1">&#39;results.txt&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/T793395_Session_based_recommendation_on_REES46_Dataset_204_0.png" src="../_images/T793395_Session_based_recommendation_on_REES46_Dataset_204_0.png" />
<img alt="../_images/T793395_Session_based_recommendation_on_REES46_Dataset_204_1.png" src="../_images/T793395_Session_based_recommendation_on_REES46_Dataset_204_1.png" />
</div>
</div>
</div>
<div class="section" id="triton-for-recommender-systems">
<h2>Triton for Recommender Systems<a class="headerlink" href="#triton-for-recommender-systems" title="Permalink to this headline">¶</a></h2>
<p>NVIDIA <a class="reference external" href="https://github.com/triton-inference-server/server">Triton Inference Server (TIS)</a> simplifies the deployment of AI models at scale in production. The Triton Inference Server allows us to deploy and serve our model for inference. It supports a number of different machine learning frameworks such as TensorFlow and PyTorch.</p>
<p>The last step of machine learning (ML)/deep learning (DL) pipeline is to deploy the ETL workflow and saved model to production. In the production setting, we want to transform the input data as done during training (ETL). We need to apply the same mean/std for continuous features and use the same categorical mapping to convert the categories to continuous integer before we use the DL model for a prediction. Therefore, we deploy the NVTabular workflow with the PyTorch model as an ensemble model to Triton Inference. The ensemble model guarantees that the same transformation is applied to the raw inputs.</p>
<img src='https://s3.us-west-2.amazonaws.com/secure.notion-static.com/55f95680-f556-45b4-93b3-a3f5eaf715f7/Untitled.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAT73L2G45O3KS52Y5%2F20211011%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20211011T114013Z&X-Amz-Expires=86400&X-Amz-Signature=3229c6eb93dda4a077bae72a876dcaa5da46602d1cdc28193ae42c540ff67944&X-Amz-SignedHeaders=host&response-content-disposition=filename%20%3D%22Untitled.png%22'><p><strong>Objectives:</strong></p>
<p>Learn how to deploy a model to Triton</p>
<ol class="simple">
<li><p>Deploy saved NVTabular and PyTorch models to Triton Inference Server</p></li>
<li><p>Sent requests for predictions</p></li>
</ol>
</div>
<div class="section" id="pull-and-start-inference-docker-container">
<h2>Pull and start Inference docker container<a class="headerlink" href="#pull-and-start-inference-docker-container" title="Permalink to this headline">¶</a></h2>
<p>At this point, before connecing to the Triton Server, we launch the inference docker container and then load the exported ensemble <code class="docutils literal notranslate"><span class="pre">t4r_pytorch</span></code> to the inference server. This is done with the scripts below:</p>
<p><strong>Launch the docker container:</strong></p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">docker</span> <span class="n">run</span> <span class="o">-</span><span class="n">it</span> <span class="o">--</span><span class="n">gpus</span> <span class="n">device</span><span class="o">=</span><span class="mi">0</span> <span class="o">-</span><span class="n">p</span> <span class="mi">8000</span><span class="p">:</span><span class="mi">8000</span> <span class="o">-</span><span class="n">p</span> <span class="mi">8001</span><span class="p">:</span><span class="mi">8001</span> <span class="o">-</span><span class="n">p</span> <span class="mi">8002</span><span class="p">:</span><span class="mi">8002</span> <span class="o">-</span><span class="n">v</span> <span class="o">&lt;</span><span class="n">path_to_saved_models</span><span class="o">&gt;</span><span class="p">:</span><span class="o">/</span><span class="n">workspace</span><span class="o">/</span><span class="n">models</span><span class="o">/</span> <span class="n">nvcr</span><span class="o">.</span><span class="n">io</span><span class="o">/</span><span class="n">nvidia</span><span class="o">/</span><span class="n">merlin</span><span class="o">/</span><span class="n">merlin</span><span class="o">-</span><span class="n">inference</span><span class="p">:</span><span class="mf">21.09</span>
</pre></div>
</div>
<p>This script will mount your local model-repository folder that includes your saved models from the previous cell to <code class="docutils literal notranslate"><span class="pre">/workspace/models</span></code> directory in the merlin-inference docker container.</p>
<p><strong>Start triton server</strong>
After you started the merlin-inference container, you can start triton server with the command below. You need to provide correct path of the models folder.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">tritonserver</span> <span class="o">--</span><span class="n">model</span><span class="o">-</span><span class="n">repository</span><span class="o">=&lt;</span><span class="n">path_to_models</span><span class="o">&gt;</span> <span class="o">--</span><span class="n">model</span><span class="o">-</span><span class="n">control</span><span class="o">-</span><span class="n">mode</span><span class="o">=</span><span class="n">explicit</span>
</pre></div>
</div>
<p>Note: The model-repository path for our example is <code class="docutils literal notranslate"><span class="pre">/workspace/models</span></code>. The models haven’t been loaded, yet. Below, we will request the Triton server to load the saved ensemble model.</p>
</div>
<div class="section" id="deploy-pytorch-and-nvtabular-model-to-triton-inference-server">
<h2>Deploy PyTorch and NVTabular Model to Triton Inference Server<a class="headerlink" href="#deploy-pytorch-and-nvtabular-model-to-triton-inference-server" title="Permalink to this headline">¶</a></h2>
<p>Our Triton server has already been launched and is ready to make requests. Remember we already exported the saved PyTorch model in the previous section, and generated the config files for Triton Inference Server.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Import dependencies</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">from</span> <span class="nn">time</span> <span class="kn">import</span> <span class="n">time</span>

<span class="kn">import</span> <span class="nn">argparse</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">sys</span>
<span class="kn">import</span> <span class="nn">cudf</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="review-exported-files">
<h2>Review exported files<a class="headerlink" href="#review-exported-files" title="Permalink to this headline">¶</a></h2>
<p>Triton expects a specific directory structure for our models as the following format:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">&lt;</span><span class="n">model</span><span class="o">-</span><span class="n">name</span><span class="o">&gt;/</span>
<span class="p">[</span><span class="n">config</span><span class="o">.</span><span class="n">pbtxt</span><span class="p">]</span>
<span class="o">&lt;</span><span class="n">version</span><span class="o">-</span><span class="n">name</span><span class="o">&gt;/</span>
  <span class="p">[</span><span class="n">model</span><span class="o">.</span><span class="n">savedmodel</span><span class="p">]</span><span class="o">/</span>
    <span class="o">&lt;</span><span class="n">pytorch_saved_model_files</span><span class="o">&gt;/</span>
      <span class="o">...</span>
</pre></div>
</div>
<p>Let’s check out our model repository layout. You can install tree library with <code class="docutils literal notranslate"><span class="pre">apt-get</span> <span class="pre">install</span> <span class="pre">tree</span></code>, and then run <code class="docutils literal notranslate"><span class="pre">!tree</span> <span class="pre">/workspace/models/</span></code> to print out the model repository layout as below:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>├── t4r_pytorch
│   ├── 1
│   └── config.pbtxt
├── t4r_pytorch_nvt
│   ├── 1
│   │   ├── model.py
│   │   ├── __pycache__
│   │   │   └── model.cpython-38.pyc
│   │   └── workflow
│   │       ├── categories
│   │       │   ├── cat_stats.category_id.parquet
│   │       │   ├── unique.brand.parquet
│   │       │   ├── unique.category_code.parquet
│   │       │   ├── unique.category_id.parquet
│   │       │   ├── unique.event_type.parquet
│   │       │   ├── unique.product_id.parquet
│   │       │   ├── unique.user_id.parquet
│   │       │   └── unique.user_session.parquet
│   │       ├── metadata.json
│   │       └── workflow.pkl
│   └── config.pbtxt
└── t4r_pytorch_pt
    ├── 1
    │   ├── model_info.json
    │   ├── model.pkl
    │   ├── model.pth
    │   ├── model.py
    │   └── __pycache__
    │       └── model.cpython-38.pyc
    └── config.pbtxt
</pre></div>
</div>
<p>Triton needs a <a class="reference external" href="https://github.com/triton-inference-server/server/blob/main/docs/model_configuration.md">config file</a> to understand how to interpret the model. Let’s look at the generated config file. It defines the input columns with datatype and dimensions and the output layer. Manually creating this config file can be complicated and NVTabular generates it with the <code class="docutils literal notranslate"><span class="pre">export_pytorch_ensemble()</span></code> function, which we used in the previous section.</p>
<p>The <a class="reference external" href="https://github.com/triton-inference-server/server/blob/main/docs/model_configuration.md">config file</a> needs the following information:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">name</span></code>: The name of our model. Must be the same name as the parent folder.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">platform</span></code>: The type of framework serving the model.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">input</span></code>: The input our model expects.</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">name</span></code>: Should correspond with the model input name.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">data_type</span></code>: Should correspond to the input’s data type.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">dims</span></code>: The dimensions of the <em>request</em> for the input. For models that support input and output tensors with variable-size dimensions, those dimensions can be listed as -1 in the input and output configuration.</p></li>
</ul>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">output</span></code>: The output parameters of our model.</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">name</span></code>: Should correspond with the model output name.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">data_type</span></code>: Should correspond to the output’s data type.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">dims</span></code>: The dimensions of the output.</p></li>
</ul>
</li>
</ul>
</div>
<div class="section" id="loading-model">
<h2>Loading Model<a class="headerlink" href="#loading-model" title="Permalink to this headline">¶</a></h2>
<p>Next, let’s build a client to connect to our server. The <code class="docutils literal notranslate"><span class="pre">InferenceServerClient</span></code> object is what we’ll be using to talk to Triton.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">tritonhttpclient</span>

<span class="k">try</span><span class="p">:</span>
    <span class="n">triton_client</span> <span class="o">=</span> <span class="n">tritonhttpclient</span><span class="o">.</span><span class="n">InferenceServerClient</span><span class="p">(</span><span class="n">url</span><span class="o">=</span><span class="s2">&quot;localhost:8000&quot;</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;client created.&quot;</span><span class="p">)</span>
<span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;channel creation failed: &quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">e</span><span class="p">))</span>
<span class="n">triton_client</span><span class="o">.</span><span class="n">is_server_live</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>client created.
GET /v2/health/live, headers None
&lt;HTTPSocketPoolResponse status=200 headers={&#39;content-length&#39;: &#39;0&#39;, &#39;content-type&#39;: &#39;text/plain&#39;}&gt;
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>True
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">triton_client</span><span class="o">.</span><span class="n">get_model_repository_index</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>POST /v2/repository/index, headers None

&lt;HTTPSocketPoolResponse status=200 headers={&#39;content-type&#39;: &#39;application/json&#39;, &#39;content-length&#39;: &#39;201&#39;}&gt;
bytearray(b&#39;[{&quot;name&quot;:&quot;t4r_pytorch&quot;,&quot;version&quot;:&quot;1&quot;,&quot;state&quot;:&quot;UNAVAILABLE&quot;,&quot;reason&quot;:&quot;unloaded&quot;},{&quot;name&quot;:&quot;t4r_pytorch_nvt&quot;,&quot;version&quot;:&quot;1&quot;,&quot;state&quot;:&quot;UNLOADING&quot;},{&quot;name&quot;:&quot;t4r_pytorch_pt&quot;,&quot;version&quot;:&quot;1&quot;,&quot;state&quot;:&quot;UNLOADING&quot;}]&#39;)
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[{&#39;name&#39;: &#39;t4r_pytorch&#39;,
  &#39;version&#39;: &#39;1&#39;,
  &#39;state&#39;: &#39;UNAVAILABLE&#39;,
  &#39;reason&#39;: &#39;unloaded&#39;},
 {&#39;name&#39;: &#39;t4r_pytorch_nvt&#39;, &#39;version&#39;: &#39;1&#39;, &#39;state&#39;: &#39;UNLOADING&#39;},
 {&#39;name&#39;: &#39;t4r_pytorch_pt&#39;, &#39;version&#39;: &#39;1&#39;, &#39;state&#39;: &#39;UNLOADING&#39;}]
</pre></div>
</div>
</div>
</div>
<p>We load the ensemble model</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">model_name</span> <span class="o">=</span> <span class="s2">&quot;t4r_pytorch&quot;</span>
<span class="n">triton_client</span><span class="o">.</span><span class="n">load_model</span><span class="p">(</span><span class="n">model_name</span><span class="o">=</span><span class="n">model_name</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>POST /v2/repository/models/t4r_pytorch/load, headers None

&lt;HTTPSocketPoolResponse status=200 headers={&#39;content-type&#39;: &#39;application/json&#39;, &#39;content-length&#39;: &#39;0&#39;}&gt;
Loaded model &#39;t4r_pytorch&#39;
</pre></div>
</div>
</div>
</div>
<p>If all models are loaded succesfully, you should be seeing successfully loaded status next to each model name on your terminal.</p>
</div>
<div class="section" id="sent-requests-for-predictions">
<h2>Sent Requests for Predictions<a class="headerlink" href="#sent-requests-for-predictions" title="Permalink to this headline">¶</a></h2>
<p>Load raw data for inference: We select the first 50 interactions and filter out sessions with less than 2 interactions. For this tutorial, just as an example we use the <code class="docutils literal notranslate"><span class="pre">Oct-2019</span></code> dataset that we used for model training.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">INPUT_DATA_DIR</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;INPUT_DATA_DIR&quot;</span><span class="p">,</span> <span class="s2">&quot;/workspace/data/&quot;</span><span class="p">)</span>
<span class="n">df</span><span class="o">=</span> <span class="n">cudf</span><span class="o">.</span><span class="n">read_parquet</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">INPUT_DATA_DIR</span><span class="p">,</span> <span class="s1">&#39;Oct-2019.parquet&#39;</span><span class="p">))</span>
<span class="n">df</span><span class="o">=</span><span class="n">df</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="s1">&#39;event_time_ts&#39;</span><span class="p">)</span>
<span class="n">batch</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:</span><span class="mi">50</span><span class="p">,:]</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">sessions_to_use</span> <span class="o">=</span> <span class="n">batch</span><span class="o">.</span><span class="n">user_session</span><span class="o">.</span><span class="n">value_counts</span><span class="p">()</span>
<span class="n">filtered_batch</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="n">batch</span><span class="o">.</span><span class="n">user_session</span><span class="o">.</span><span class="n">isin</span><span class="p">(</span><span class="n">sessions_to_use</span><span class="p">[</span><span class="n">sessions_to_use</span><span class="o">.</span><span class="n">values</span><span class="o">&gt;</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">index</span><span class="o">.</span><span class="n">values</span><span class="p">)]</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">filtered_batch</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>user_session</th>
      <th>event_type</th>
      <th>product_id</th>
      <th>category_id</th>
      <th>category_code</th>
      <th>brand</th>
      <th>price</th>
      <th>user_id</th>
      <th>event_time_ts</th>
      <th>prod_first_event_time_ts</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>3562914</th>
      <td>1637332</td>
      <td>view</td>
      <td>1307067</td>
      <td>2053013558920217191</td>
      <td>computers.notebook</td>
      <td>lenovo</td>
      <td>251.74</td>
      <td>550050854</td>
      <td>1569888001</td>
      <td>1569888001</td>
    </tr>
    <tr>
      <th>5173328</th>
      <td>4202155</td>
      <td>view</td>
      <td>1004237</td>
      <td>2053013555631882655</td>
      <td>electronics.smartphone</td>
      <td>apple</td>
      <td>1081.98</td>
      <td>535871217</td>
      <td>1569888004</td>
      <td>1569888004</td>
    </tr>
    <tr>
      <th>3741261</th>
      <td>1808164</td>
      <td>view</td>
      <td>1480613</td>
      <td>2053013561092866779</td>
      <td>computers.desktop</td>
      <td>pulser</td>
      <td>908.62</td>
      <td>512742880</td>
      <td>1569888005</td>
      <td>1569888005</td>
    </tr>
    <tr>
      <th>4996937</th>
      <td>3794756</td>
      <td>view</td>
      <td>31500053</td>
      <td>2053013558031024687</td>
      <td>&lt;NA&gt;</td>
      <td>luminarc</td>
      <td>41.16</td>
      <td>550978835</td>
      <td>1569888008</td>
      <td>1569888008</td>
    </tr>
    <tr>
      <th>5589259</th>
      <td>5470852</td>
      <td>view</td>
      <td>28719074</td>
      <td>2053013565480109009</td>
      <td>apparel.shoes.keds</td>
      <td>baden</td>
      <td>102.71</td>
      <td>520571932</td>
      <td>1569888010</td>
      <td>1569888010</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">nvtabular.inference.triton</span> <span class="k">as</span> <span class="nn">nvt_triton</span>
<span class="kn">import</span> <span class="nn">tritonclient.grpc</span> <span class="k">as</span> <span class="nn">grpcclient</span>

<span class="n">inputs</span> <span class="o">=</span> <span class="n">nvt_triton</span><span class="o">.</span><span class="n">convert_df_to_triton_input</span><span class="p">(</span><span class="n">filtered_batch</span><span class="o">.</span><span class="n">columns</span><span class="p">,</span> <span class="n">filtered_batch</span><span class="p">,</span> <span class="n">grpcclient</span><span class="o">.</span><span class="n">InferInput</span><span class="p">)</span>

<span class="n">output_names</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;output&quot;</span><span class="p">]</span>

<span class="n">outputs</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">col</span> <span class="ow">in</span> <span class="n">output_names</span><span class="p">:</span>
    <span class="n">outputs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">grpcclient</span><span class="o">.</span><span class="n">InferRequestedOutput</span><span class="p">(</span><span class="n">col</span><span class="p">))</span>
    
<span class="n">MODEL_NAME_NVT</span> <span class="o">=</span> <span class="s2">&quot;t4r_pytorch&quot;</span>

<span class="k">with</span> <span class="n">grpcclient</span><span class="o">.</span><span class="n">InferenceServerClient</span><span class="p">(</span><span class="s2">&quot;localhost:8001&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">client</span><span class="p">:</span>
    <span class="n">response</span> <span class="o">=</span> <span class="n">client</span><span class="o">.</span><span class="n">infer</span><span class="p">(</span><span class="n">MODEL_NAME_NVT</span><span class="p">,</span> <span class="n">inputs</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">col</span><span class="p">,</span> <span class="s1">&#39;:</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">response</span><span class="o">.</span><span class="n">as_numpy</span><span class="p">(</span><span class="n">col</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>output :
 [[-12.86381   -13.449438   -9.572359  ... -12.689846  -13.033402
  -13.294905 ]
 [-24.320768  -26.130745   -4.3342614 ... -24.07727   -25.470228
  -26.27378  ]
 [-22.867298  -24.897617   -6.6269407 ... -23.640343  -23.620872
  -24.977371 ]
 [-21.455946  -22.92965    -4.8912797 ... -21.020473  -22.514032
  -22.958193 ]
 [-24.569319  -26.149971   -4.223791  ... -24.316437  -25.649946
  -26.920403 ]
 [-14.218529  -14.833358   -8.438756  ... -14.013732  -14.700138
  -14.71361  ]]
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="visualise-top-k-predictions">
<h2>Visualise top-k predictions<a class="headerlink" href="#visualise-top-k-predictions" title="Permalink to this headline">¶</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">transformers4rec.torch.utils.examples_utils</span> <span class="kn">import</span> <span class="n">visualize_response</span>
<span class="n">visualize_response</span><span class="p">(</span><span class="n">filtered_batch</span><span class="p">,</span> <span class="n">response</span><span class="p">,</span> <span class="n">top_k</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">session_col</span><span class="o">=</span><span class="s1">&#39;user_session&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>- Top-5 predictions for session `1167651`: 1045 || 229 || 233 || 1085 || 10

- Top-5 predictions for session `1637332`: 11 || 7 || 4 || 2 || 3

- Top-5 predictions for session `1808164`: 162 || 142 || 226 || 80 || 200

- Top-5 predictions for session `3794756`: 3 || 2 || 26 || 364 || 10

- Top-5 predictions for session `4202155`: 2 || 57 || 36 || 38 || 10

- Top-5 predictions for session `5470852`: 1710 || 233 || 805 || 555 || 10
</pre></div>
</div>
</div>
</div>
<p>As you see we first got prediction results (logits) from the trained model head, and then by using a handy util function <code class="docutils literal notranslate"><span class="pre">visualize_response</span></code> we extracted top-k encoded item-ids from logits. Basically, we  generated recommended items for a given session.</p>
<p>This is the end of the tutorial. You successfully …</p>
<ol class="simple">
<li><p>performed feature engineering with NVTabular</p></li>
<li><p>trained transformer architecture based session-based recommendation models with Transformers4Rec</p></li>
<li><p>deployed a trained model to Triton Inference Server, sent request and got responses from the server.</p></li>
</ol>
</div>
<div class="section" id="unload-models-and-shut-down-the-kernel">
<h2>Unload models and shut down the kernel<a class="headerlink" href="#unload-models-and-shut-down-the-kernel" title="Permalink to this headline">¶</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">triton_client</span><span class="o">.</span><span class="n">unload_model</span><span class="p">(</span><span class="n">model_name</span><span class="o">=</span><span class="s2">&quot;t4r_pytorch&quot;</span><span class="p">)</span>
<span class="n">triton_client</span><span class="o">.</span><span class="n">unload_model</span><span class="p">(</span><span class="n">model_name</span><span class="o">=</span><span class="s2">&quot;t4r_pytorch_nvt&quot;</span><span class="p">)</span>
<span class="n">triton_client</span><span class="o">.</span><span class="n">unload_model</span><span class="p">(</span><span class="n">model_name</span><span class="o">=</span><span class="s2">&quot;t4r_pytorch_pt&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>POST /v2/repository/models/t4r_pytorch/unload, headers None
{&quot;parameters&quot;:{&quot;unload_dependents&quot;:false}}
&lt;HTTPSocketPoolResponse status=200 headers={&#39;content-type&#39;: &#39;application/json&#39;, &#39;content-length&#39;: &#39;0&#39;}&gt;
Loaded model &#39;t4r_pytorch&#39;
POST /v2/repository/models/t4r_pytorch_nvt/unload, headers None
{&quot;parameters&quot;:{&quot;unload_dependents&quot;:false}}
&lt;HTTPSocketPoolResponse status=200 headers={&#39;content-type&#39;: &#39;application/json&#39;, &#39;content-length&#39;: &#39;0&#39;}&gt;
Loaded model &#39;t4r_pytorch_nvt&#39;
POST /v2/repository/models/t4r_pytorch_pt/unload, headers None
{&quot;parameters&quot;:{&quot;unload_dependents&quot;:false}}
&lt;HTTPSocketPoolResponse status=200 headers={&#39;content-type&#39;: &#39;application/json&#39;, &#39;content-length&#39;: &#39;0&#39;}&gt;
Loaded model &#39;t4r_pytorch_pt&#39;
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="references">
<h2>References<a class="headerlink" href="#references" title="Permalink to this headline">¶</a></h2>
<p>[1] Malte Ludewig and Dietmar Jannach. 2018. Evaluation of session-based recommendation algorithms. User Modeling and User-Adapted Interaction 28, 4-5 (2018), 331–390.<br>
[2] Balázs Hidasi and Alexandros Karatzoglou. 2018. Recurrent neural networks with top-k gains for session-based recommendations. In Proceedings of the 27th ACMinternational conference on information and knowledge management. 843–852.<br>
[3] Fei Sun, Jun Liu, Jian Wu, Changhua Pei, Xiao Lin, Wenwu Ou, and Peng Jiang. 2019. BERT4Rec: Sequential recommendation with bidirectional encoder representations from transformer. In Proceedings of the 28th ACM international conference on information and knowledge management. 1441–1450.
[4] Shiming Sun, Yuanhe Tang, Zemei Dai, and Fu Zhou. 2019. Self-attention network for session-based recommendation with streaming data input. IEEE Access 7 (2019), 110499–110509.<br />
[5] Kyunghyun Cho, Bart Van Merriënboer, Caglar Gulcehre, Dzmitry Bahdanau, Fethi Bougares, Holger Schwenk, and Yoshua Bengio. 2014. Learning phrase representations using RNN encoder-decoder for statistical machine translation. arXiv preprint arXiv:1406.1078 (2014).<br />
[6] Vaswani, A., et al. (2017). Attention is all you need. In Advances in neural information processing systems (pp. 5998-6008).<br />
[7] Lample, Guillaume, and Alexis Conneau. “Cross-lingual language model pretraining.” arXiv preprint arXiv:1901.07291<br />
[8] Gabriel De Souza P. Moreira, et al. (2021). Transformers4Rec: Bridging the Gap between NLP and Sequential / Session-Based Recommendation. RecSys’21.<br />
[9] Understanding XLNet, BorealisAI. Online available: <a class="reference external" href="https://www.borealisai.com/en/blog/understanding-xlnet/">https://www.borealisai.com/en/blog/understanding-xlnet/</a><br />
[10] Yang, Zhilin, et al. “Xlnet: Generalized autoregressive pretraining for language understanding.” Advances in neural information processing systems 32 (2019).</p>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./nbs"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        
            



<div class='prev-next-bottom'>
    
    <div id="prev">
        <a class="left-prev" href="T382183_Transformers4Rec_XLNet_on_Synthetic_data.html" title="previous page">
            <i class="prevnext-label fas fa-angle-left"></i>
            <div class="prevnext-info">
                <p class="prevnext-label">previous</p>
                <p class="prevnext-title">Transformers4Rec XLNet on Synthetic data</p>
            </div>
        </a>
    </div>
     <div id="next">
        <a class="right-next" href="T382881_DeepWalk_Karateclub.html" title="next page">
            <div class="prevnext-info">
                <p class="prevnext-label">next</p>
                <p class="prevnext-title">DeepWalk from scratch referencing Karateclub library</p>
            </div>
            <i class="prevnext-label fas fa-angle-right"></i>
        </a>
     </div>

</div>
        
        </div>
    </div>
    <footer class="footer">
    <div class="container">
      <p>
        
          By Sparsh A.<br/>
        
            &copy; Copyright 2021.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>
  
  <script src="../_static/js/index.1c5a1a01449ed65a7b51.js"></script>

  
  </body>
</html>