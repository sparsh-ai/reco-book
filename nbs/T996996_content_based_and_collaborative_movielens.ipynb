{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    },
    "colab": {
      "name": "2021-06-27-content-based-and-collaborative-movielens.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "MCg0HdBdcw94"
      ],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YPdOfpO9c2_u"
      },
      "source": [
        "# Movie Recommendation with Content-Based and Collaborative Filtering\n",
        "> Applying content-based and collaborative filtering method on MovieLens dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_0ei3jeW5LIR"
      },
      "source": [
        "“*What movie should I watch this evening?*” \n",
        "\n",
        "Have you ever had to answer this question at least once when you came home from work? As for me — yes, and more than once. From Netflix to Hulu, the need to build robust movie recommendation systems is extremely important given the huge demand for personalized content of modern consumers.\n",
        "\n",
        "An example of recommendation system is such as this:\n",
        "* User A watches **Game of Thrones** and **Breaking Bad**.\n",
        "* User B does search on **Game of Thrones**, then the system suggests **Breaking Bad** from data collected about user A.\n",
        "\n",
        "Recommendation systems are used not only for movies, but on multiple other products and services like Amazon (Books, Items), Pandora/Spotify (Music), Google (News, Search), YouTube (Videos) etc.\n",
        "\n",
        "<img src='https://www.notion.so/image/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2F995cfc2f-58b8-42cd-978f-0e45c2dcbaec%2FUntitled.png?table=block&id=81a91944-d552-4cc9-8bb2-b69d878cf9a5&spaceId=63b72b1f-0e90-4ab8-a6df-a060a6545a56&width=2000&userId=21ec183f-f0be-4b6b-9b3e-6f0d4e5c5469&cache=v2'>\n",
        "\n",
        "Two most ubiquitous types of personalized recommendation systems are **Content-Based** and **Collaborative Filtering**. Collaborative filtering produces recommendations based on the knowledge of users’ attitude to items, that is it uses the “wisdom of the crowd” to recommend items. In contrast, content-based recommendation systems focus on the attributes of the items and give you recommendations based on the similarity between them.\n",
        "\n",
        "In this notebook, I will attempt at implementing these two systems to recommend movies and evaluate them to see which one performs better.\n",
        "\n",
        "After reading this post you will know:\n",
        "\n",
        "* About the MovieLens dataset problem for recommender system.\n",
        "* How to load and process the data.\n",
        "* How to do exploratory data analysis.\n",
        "* The 2 different types of recommendation engines.\n",
        "* How to develop a content-based recommendation model based on movie genres.\n",
        "* How to develop a collaborative filtering model based on user ratings.\n",
        "* Alternative approach to improve existing models.\n",
        "\n",
        "Let’s get started."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KVQYUMz7cw9Y"
      },
      "source": [
        "## The MovieLens Dataset\n",
        "One of the most common datasets that is available on the internet for building a Recommender System is the [MovieLens DataSet](https://grouplens.org/datasets/movielens/). This version of the dataset that I'm working with ([1M](https://grouplens.org/datasets/movielens/1m/)) contains 1,000,209 anonymous ratings of approximately 3,900 movies made by 6,040 MovieLens users who joined MovieLens in 2000.\n",
        "\n",
        "The data was collected by GroupLens researchers over various periods of time, depending on the size of the set. This 1M version was released on February 2003. Users were selected at random for inclusion. All users selected had rated at least 20 movies. Each user is represented by an id, and no other information is provided."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M4Zp8QvZ5WU5"
      },
      "source": [
        "<img src='https://www.notion.so/image/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2F23c3e15f-7344-4983-8ba5-2353b8358547%2FUntitled.png?table=block&id=afda3a6e-9e9a-4b3f-a1ac-57862620b0c2&spaceId=63b72b1f-0e90-4ab8-a6df-a060a6545a56&width=2000&userId=21ec183f-f0be-4b6b-9b3e-6f0d4e5c5469&cache=v2'>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "czhEjVXHeY01"
      },
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e2eign9dcw9b"
      },
      "source": [
        "## Data Preparation\n",
        "Let's load this data into Python. I will load the dataset with Pandas onto Dataframes **ratings**, **users**, and **movies**. Before that, I'll also pass in column names for each CSV and read them using pandas (the column names are available in the [Readme](https://github.com/khanhnamle1994/movielens/blob/master/README.md) file)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fK3YDkVVdXlH"
      },
      "source": [
        "!wget http://files.grouplens.org/datasets/movielens/ml-1m.zip\n",
        "!unzip ml-1m.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9mXUzB57ele0"
      },
      "source": [
        "### Convert .dat to .csv"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J5DN9lyXfb8L"
      },
      "source": [
        "# Define file directories\n",
        "MOVIELENS_DIR = 'ml-1m'\n",
        "USER_DATA_FILE = 'users.dat'\n",
        "MOVIE_DATA_FILE = 'movies.dat'\n",
        "RATING_DATA_FILE = 'ratings.dat'\n",
        "\n",
        "# Specify User's Age and Occupation Column\n",
        "AGES = { 1: \"Under 18\", 18: \"18-24\", 25: \"25-34\", 35: \"35-44\", 45: \"45-49\", 50: \"50-55\", 56: \"56+\" }\n",
        "OCCUPATIONS = { 0: \"other or not specified\", 1: \"academic/educator\", 2: \"artist\", 3: \"clerical/admin\",\n",
        "                4: \"college/grad student\", 5: \"customer service\", 6: \"doctor/health care\",\n",
        "                7: \"executive/managerial\", 8: \"farmer\", 9: \"homemaker\", 10: \"K-12 student\", 11: \"lawyer\",\n",
        "                12: \"programmer\", 13: \"retired\", 14: \"sales/marketing\", 15: \"scientist\", 16: \"self-employed\",\n",
        "                17: \"technician/engineer\", 18: \"tradesman/craftsman\", 19: \"unemployed\", 20: \"writer\" }\n",
        "\n",
        "# Define csv files to be saved into\n",
        "USERS_CSV_FILE = 'users.csv'\n",
        "MOVIES_CSV_FILE = 'movies.csv'\n",
        "RATINGS_CSV_FILE = 'ratings.csv'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yPreFnevfeDR",
        "outputId": "f22c6780-ff8c-4c78-ce31-58fc412585ee"
      },
      "source": [
        "# Read the Ratings File\n",
        "ratings = pd.read_csv(os.path.join(MOVIELENS_DIR, RATING_DATA_FILE), \n",
        "                    sep='::', \n",
        "                    engine='python', \n",
        "                    encoding='latin-1',\n",
        "                    names=['user_id', 'movie_id', 'rating', 'timestamp'])\n",
        "\n",
        "# Set max_userid to the maximum user_id in the ratings\n",
        "max_userid = ratings['user_id'].drop_duplicates().max()\n",
        "# Set max_movieid to the maximum movie_id in the ratings\n",
        "max_movieid = ratings['movie_id'].drop_duplicates().max()\n",
        "\n",
        "# Process ratings dataframe for Keras Deep Learning model\n",
        "# Add user_emb_id column whose values == user_id - 1\n",
        "ratings['user_emb_id'] = ratings['user_id'] - 1\n",
        "# Add movie_emb_id column whose values == movie_id - 1\n",
        "ratings['movie_emb_id'] = ratings['movie_id'] - 1\n",
        "\n",
        "print(len(ratings), 'ratings loaded')\n",
        "\n",
        "# Save into ratings.csv\n",
        "ratings.to_csv(RATINGS_CSV_FILE, \n",
        "               sep='\\t', \n",
        "               header=True, \n",
        "               encoding='latin-1', \n",
        "               columns=['user_id', 'movie_id', 'rating', 'timestamp', 'user_emb_id', 'movie_emb_id'])\n",
        "print('Saved to', RATINGS_CSV_FILE)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1000209 ratings loaded\n",
            "Saved to ratings.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e0Amjdajff1R",
        "outputId": "4f9b75ea-043b-486d-ed29-30d053af06c1"
      },
      "source": [
        "# Read the Users File\n",
        "users = pd.read_csv(os.path.join(MOVIELENS_DIR, USER_DATA_FILE), \n",
        "                    sep='::', \n",
        "                    engine='python', \n",
        "                    encoding='latin-1',\n",
        "                    names=['user_id', 'gender', 'age', 'occupation', 'zipcode'])\n",
        "users['age_desc'] = users['age'].apply(lambda x: AGES[x])\n",
        "users['occ_desc'] = users['occupation'].apply(lambda x: OCCUPATIONS[x])\n",
        "print(len(users), 'descriptions of', max_userid, 'users loaded.')\n",
        "\n",
        "# Save into users.csv\n",
        "users.to_csv(USERS_CSV_FILE, \n",
        "             sep='\\t', \n",
        "             header=True, \n",
        "             encoding='latin-1',\n",
        "             columns=['user_id', 'gender', 'age', 'occupation', 'zipcode', 'age_desc', 'occ_desc'])\n",
        "print('Saved to', USERS_CSV_FILE)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "6040 descriptions of 6040 users loaded.\n",
            "Saved to users.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cHosUFsoeegM",
        "outputId": "650594e9-bab4-4869-e1c2-c6c8780e96b8"
      },
      "source": [
        "# Read the Movies File\n",
        "movies = pd.read_csv(os.path.join(MOVIELENS_DIR, MOVIE_DATA_FILE), \n",
        "                    sep='::', \n",
        "                    engine='python', \n",
        "                    encoding='latin-1',\n",
        "                    names=['movie_id', 'title', 'genres'])\n",
        "print(len(movies), 'descriptions of', max_movieid, 'movies loaded.')\n",
        "\n",
        "# Save into movies.csv\n",
        "movies.to_csv(MOVIES_CSV_FILE, \n",
        "              sep='\\t', \n",
        "              header=True, \n",
        "              columns=['movie_id', 'title', 'genres'])\n",
        "print('Saved to', MOVIES_CSV_FILE)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3883 descriptions of 3952 movies loaded.\n",
            "Saved to movies.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2SUSJpsneiQO"
      },
      "source": [
        "### Data loading"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "t92ZpH8-cw9c"
      },
      "source": [
        "# Reading ratings file\n",
        "# Ignore the timestamp column\n",
        "ratings = pd.read_csv('ratings.csv', sep='\\t', encoding='latin-1', usecols=['user_id', 'movie_id', 'rating'])\n",
        "\n",
        "# Reading users file\n",
        "users = pd.read_csv('users.csv', sep='\\t', encoding='latin-1', usecols=['user_id', 'gender', 'zipcode', 'age_desc', 'occ_desc'])\n",
        "\n",
        "# Reading movies file\n",
        "movies = pd.read_csv('movies.csv', sep='\\t', encoding='latin-1', usecols=['movie_id', 'title', 'genres'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dW7jYx6Ncw9d"
      },
      "source": [
        "Now lets take a peak into the content of each file to understand them better.\n",
        "\n",
        "### Ratings Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DTmIPonQcw9d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "3eae3f15-73ce-4343-ee63-911888ac93a9"
      },
      "source": [
        "# Check the top 5 rows\n",
        "ratings.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_id</th>\n",
              "      <th>movie_id</th>\n",
              "      <th>rating</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1193</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>661</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>914</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>3408</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>2355</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   user_id  movie_id  rating\n",
              "0        1      1193       5\n",
              "1        1       661       3\n",
              "2        1       914       3\n",
              "3        1      3408       4\n",
              "4        1      2355       5"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DscPNwrPcw9e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc0efb66-7eed-4ad8-890f-00aff80a0721"
      },
      "source": [
        "# Check the file info\n",
        "ratings.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1000209 entries, 0 to 1000208\n",
            "Data columns (total 3 columns):\n",
            " #   Column    Non-Null Count    Dtype\n",
            "---  ------    --------------    -----\n",
            " 0   user_id   1000209 non-null  int64\n",
            " 1   movie_id  1000209 non-null  int64\n",
            " 2   rating    1000209 non-null  int64\n",
            "dtypes: int64(3)\n",
            "memory usage: 22.9 MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4783EUp-cw9f"
      },
      "source": [
        "This confirms that there are 1M ratings for different user and movie combinations.\n",
        "\n",
        "### Users Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l0dDQYrPcw9f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "c7bb371c-4639-400e-e737-54007b46a75c"
      },
      "source": [
        "# Check the top 5 rows\n",
        "users.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_id</th>\n",
              "      <th>gender</th>\n",
              "      <th>zipcode</th>\n",
              "      <th>age_desc</th>\n",
              "      <th>occ_desc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>F</td>\n",
              "      <td>48067</td>\n",
              "      <td>Under 18</td>\n",
              "      <td>K-12 student</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>M</td>\n",
              "      <td>70072</td>\n",
              "      <td>56+</td>\n",
              "      <td>self-employed</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>M</td>\n",
              "      <td>55117</td>\n",
              "      <td>25-34</td>\n",
              "      <td>scientist</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>M</td>\n",
              "      <td>02460</td>\n",
              "      <td>45-49</td>\n",
              "      <td>executive/managerial</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>M</td>\n",
              "      <td>55455</td>\n",
              "      <td>25-34</td>\n",
              "      <td>writer</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   user_id gender zipcode  age_desc              occ_desc\n",
              "0        1      F   48067  Under 18          K-12 student\n",
              "1        2      M   70072       56+         self-employed\n",
              "2        3      M   55117     25-34             scientist\n",
              "3        4      M   02460     45-49  executive/managerial\n",
              "4        5      M   55455     25-34                writer"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a0d6PMRIcw9f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c89f0e17-8f85-4201-d295-f5144d0ba576"
      },
      "source": [
        "# Check the file info\n",
        "users.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 6040 entries, 0 to 6039\n",
            "Data columns (total 5 columns):\n",
            " #   Column    Non-Null Count  Dtype \n",
            "---  ------    --------------  ----- \n",
            " 0   user_id   6040 non-null   int64 \n",
            " 1   gender    6040 non-null   object\n",
            " 2   zipcode   6040 non-null   object\n",
            " 3   age_desc  6040 non-null   object\n",
            " 4   occ_desc  6040 non-null   object\n",
            "dtypes: int64(1), object(4)\n",
            "memory usage: 236.1+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p01yaqEacw9g"
      },
      "source": [
        "This confirms that there are 6040 users and we have 5 features for each (unique user ID, gender, age, occupation and the zip code they are living in).\n",
        "\n",
        "### Movies Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MnMZ8EgZcw9g",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "43782783-8eb0-4693-9b57-56c2d35e4b09"
      },
      "source": [
        "# Check the top 5 rows\n",
        "movies.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>movie_id</th>\n",
              "      <th>title</th>\n",
              "      <th>genres</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>Toy Story (1995)</td>\n",
              "      <td>Animation|Children's|Comedy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>Jumanji (1995)</td>\n",
              "      <td>Adventure|Children's|Fantasy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>Grumpier Old Men (1995)</td>\n",
              "      <td>Comedy|Romance</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>Waiting to Exhale (1995)</td>\n",
              "      <td>Comedy|Drama</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>Father of the Bride Part II (1995)</td>\n",
              "      <td>Comedy</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   movie_id                               title                        genres\n",
              "0         1                    Toy Story (1995)   Animation|Children's|Comedy\n",
              "1         2                      Jumanji (1995)  Adventure|Children's|Fantasy\n",
              "2         3             Grumpier Old Men (1995)                Comedy|Romance\n",
              "3         4            Waiting to Exhale (1995)                  Comedy|Drama\n",
              "4         5  Father of the Bride Part II (1995)                        Comedy"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xxP20gv3cw9h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "67f98a30-071b-4805-9630-8721a5f61815"
      },
      "source": [
        "# Check the file info\n",
        "movies.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 3883 entries, 0 to 3882\n",
            "Data columns (total 3 columns):\n",
            " #   Column    Non-Null Count  Dtype \n",
            "---  ------    --------------  ----- \n",
            " 0   movie_id  3883 non-null   int64 \n",
            " 1   title     3883 non-null   object\n",
            " 2   genres    3883 non-null   object\n",
            "dtypes: int64(1), object(2)\n",
            "memory usage: 91.1+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YnoavPOycw9h"
      },
      "source": [
        "This dataset contains attributes of the 3883 movies. There are 3 columns including the movie ID, their titles, and their genres. Genres are pipe-separated and are selected from 18 genres (Action, Adventure, Animation, Children's, Comedy, Crime, Documentary, Drama, Fantasy, Film-Noir, Horror, Musical, Mystery, Romance, Sci-Fi, Thriller, War, Western)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T4sXMGorcw9h"
      },
      "source": [
        "## Data Exploration\n",
        "### Titles\n",
        "Are there certain words that feature more often in Movie Titles? I'll attempt to figure this out using a word-cloud visualization."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ynmUpt2acw9i"
      },
      "source": [
        "# Import new libraries\n",
        "%matplotlib inline\n",
        "import wordcloud\n",
        "from wordcloud import WordCloud, STOPWORDS\n",
        "\n",
        "# Create a wordcloud of the movie titles\n",
        "movies['title'] = movies['title'].fillna(\"\").astype('str')\n",
        "title_corpus = ' '.join(movies['title'])\n",
        "title_wordcloud = WordCloud(stopwords=STOPWORDS, background_color='black', height=2000, width=4000).generate(title_corpus)\n",
        "\n",
        "# Plot the wordcloud\n",
        "plt.figure(figsize=(16,8))\n",
        "plt.imshow(title_wordcloud)\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XNTj79i45cFK"
      },
      "source": [
        "<img src='https://www.notion.so/image/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2F3ea4e43d-d1f9-4113-a551-85de4694337b%2FUntitled.png?table=block&id=33274f6e-fbd1-40a5-a590-72ad57fe264b&spaceId=63b72b1f-0e90-4ab8-a6df-a060a6545a56&width=2000&userId=21ec183f-f0be-4b6b-9b3e-6f0d4e5c5469&cache=v2'>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xFa58FlCcw9i"
      },
      "source": [
        "Beautiful, isn't it? I can recognize that there are a lot of movie franchises in this dataset, as evidenced by words like *II* and *III*... In addition to that, *Day*, *Love*, *Life*, *Time*, *Night*, *Man*, *Dead*, *American* are among the most commonly occuring words.\n",
        "\n",
        "### Ratings\n",
        "Next I want to examine the **rating** further. Let's take a look at its summary statistics and distribution."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qgzDHHTZcw9j",
        "outputId": "27a5fe1c-6654-4126-835c-5f0f392900bd"
      },
      "source": [
        "# Get summary statistics of rating\n",
        "ratings['rating'].describe()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count    1.000209e+06\n",
              "mean     3.581564e+00\n",
              "std      1.117102e+00\n",
              "min      1.000000e+00\n",
              "25%      3.000000e+00\n",
              "50%      4.000000e+00\n",
              "75%      4.000000e+00\n",
              "max      5.000000e+00\n",
              "Name: rating, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S7kFLhLucw9k",
        "outputId": "da9e3946-d3a1-4f75-9803-7885f89a5775"
      },
      "source": [
        "# Import seaborn library\n",
        "import seaborn as sns\n",
        "sns.set_style('whitegrid')\n",
        "sns.set(font_scale=1.5)\n",
        "%matplotlib inline\n",
        "\n",
        "# Display distribution of rating\n",
        "sns.distplot(ratings['rating'].fillna(ratings['rating'].median()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x108ee97f0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x1051875c0>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AfIAqo0Qcw9l"
      },
      "source": [
        "It appears that users are quite generous in their ratings. The mean rating is 3.58 on a scale of 5. Half the movies have a rating of 4 and 5. I personally think that a 5-level rating skill wasn’t a good indicator as people could have different rating styles (i.e. person A could always use 4 for an average movie, whereas person B only gives 4 out for their favorites). Each user rated at least 20 movies, so I doubt the distribution could be caused just by chance variance in the quality of movies.\n",
        "\n",
        "Let's also take a look at a subset of 20 movies with the highest rating."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vLwpNQ8Acw9l",
        "outputId": "72b8e311-7337-451f-e1ea-a8b8fe6a0d5d"
      },
      "source": [
        "# Join all 3 files into one dataframe\n",
        "dataset = pd.merge(pd.merge(movies, ratings),users)\n",
        "# Display 20 movies with highest ratings\n",
        "dataset[['title','genres','rating']].sort_values('rating', ascending=False).head(20)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>genres</th>\n",
              "      <th>rating</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Toy Story (1995)</td>\n",
              "      <td>Animation|Children's|Comedy</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>489283</th>\n",
              "      <td>American Beauty (1999)</td>\n",
              "      <td>Comedy|Drama</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>489259</th>\n",
              "      <td>Election (1999)</td>\n",
              "      <td>Comedy</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>489257</th>\n",
              "      <td>Matrix, The (1999)</td>\n",
              "      <td>Action|Sci-Fi|Thriller</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>489256</th>\n",
              "      <td>Dead Ringers (1988)</td>\n",
              "      <td>Drama|Thriller</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>489237</th>\n",
              "      <td>Rushmore (1998)</td>\n",
              "      <td>Comedy</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>489236</th>\n",
              "      <td>Simple Plan, A (1998)</td>\n",
              "      <td>Crime|Thriller</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>489226</th>\n",
              "      <td>Hands on a Hard Body (1996)</td>\n",
              "      <td>Documentary</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>489224</th>\n",
              "      <td>Pleasantville (1998)</td>\n",
              "      <td>Comedy</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>489212</th>\n",
              "      <td>Say Anything... (1989)</td>\n",
              "      <td>Comedy|Drama|Romance</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>489207</th>\n",
              "      <td>Beetlejuice (1988)</td>\n",
              "      <td>Comedy|Fantasy</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>489190</th>\n",
              "      <td>Roger &amp; Me (1989)</td>\n",
              "      <td>Comedy|Documentary</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>489172</th>\n",
              "      <td>Buffalo 66 (1998)</td>\n",
              "      <td>Action|Comedy|Drama</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>489171</th>\n",
              "      <td>Out of Sight (1998)</td>\n",
              "      <td>Action|Crime|Romance</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>489170</th>\n",
              "      <td>I Went Down (1997)</td>\n",
              "      <td>Action|Comedy|Crime</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>489168</th>\n",
              "      <td>Opposite of Sex, The (1998)</td>\n",
              "      <td>Comedy|Drama</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>489157</th>\n",
              "      <td>Good Will Hunting (1997)</td>\n",
              "      <td>Drama</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>489152</th>\n",
              "      <td>Fast, Cheap &amp; Out of Control (1997)</td>\n",
              "      <td>Documentary</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>489149</th>\n",
              "      <td>L.A. Confidential (1997)</td>\n",
              "      <td>Crime|Film-Noir|Mystery|Thriller</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>489145</th>\n",
              "      <td>Contact (1997)</td>\n",
              "      <td>Drama|Sci-Fi</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                      title                            genres  \\\n",
              "0                          Toy Story (1995)       Animation|Children's|Comedy   \n",
              "489283               American Beauty (1999)                      Comedy|Drama   \n",
              "489259                      Election (1999)                            Comedy   \n",
              "489257                   Matrix, The (1999)            Action|Sci-Fi|Thriller   \n",
              "489256                  Dead Ringers (1988)                    Drama|Thriller   \n",
              "489237                      Rushmore (1998)                            Comedy   \n",
              "489236                Simple Plan, A (1998)                    Crime|Thriller   \n",
              "489226          Hands on a Hard Body (1996)                       Documentary   \n",
              "489224                 Pleasantville (1998)                            Comedy   \n",
              "489212               Say Anything... (1989)              Comedy|Drama|Romance   \n",
              "489207                   Beetlejuice (1988)                    Comedy|Fantasy   \n",
              "489190                    Roger & Me (1989)                Comedy|Documentary   \n",
              "489172                    Buffalo 66 (1998)               Action|Comedy|Drama   \n",
              "489171                  Out of Sight (1998)              Action|Crime|Romance   \n",
              "489170                   I Went Down (1997)               Action|Comedy|Crime   \n",
              "489168          Opposite of Sex, The (1998)                      Comedy|Drama   \n",
              "489157             Good Will Hunting (1997)                             Drama   \n",
              "489152  Fast, Cheap & Out of Control (1997)                       Documentary   \n",
              "489149             L.A. Confidential (1997)  Crime|Film-Noir|Mystery|Thriller   \n",
              "489145                       Contact (1997)                      Drama|Sci-Fi   \n",
              "\n",
              "        rating  \n",
              "0            5  \n",
              "489283       5  \n",
              "489259       5  \n",
              "489257       5  \n",
              "489256       5  \n",
              "489237       5  \n",
              "489236       5  \n",
              "489226       5  \n",
              "489224       5  \n",
              "489212       5  \n",
              "489207       5  \n",
              "489190       5  \n",
              "489172       5  \n",
              "489171       5  \n",
              "489170       5  \n",
              "489168       5  \n",
              "489157       5  \n",
              "489152       5  \n",
              "489149       5  \n",
              "489145       5  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uwHrlwO6cw9m"
      },
      "source": [
        "### Genres\n",
        "The genres variable will surely be important while building the recommendation engines since it describes the content of the film (i.e. Animation, Horror, Sci-Fi). A basic assumption is that films in the same genre should have similar contents. I'll attempt to see exactly which genres are the most popular."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "joxTWZXmcw9n",
        "outputId": "880aa820-5445-4ee9-dfcd-c0d3172e16fa"
      },
      "source": [
        "# Make a census of the genre keywords\n",
        "genre_labels = set()\n",
        "for s in movies['genres'].str.split('|').values:\n",
        "    genre_labels = genre_labels.union(set(s))\n",
        "\n",
        "# Function that counts the number of times each of the genre keywords appear\n",
        "def count_word(dataset, ref_col, census):\n",
        "    keyword_count = dict()\n",
        "    for s in census: \n",
        "        keyword_count[s] = 0\n",
        "    for census_keywords in dataset[ref_col].str.split('|'):        \n",
        "        if type(census_keywords) == float and pd.isnull(census_keywords): \n",
        "            continue        \n",
        "        for s in [s for s in census_keywords if s in census]: \n",
        "            if pd.notnull(s): \n",
        "                keyword_count[s] += 1\n",
        "    #______________________________________________________________________\n",
        "    # convert the dictionary in a list to sort the keywords by frequency\n",
        "    keyword_occurences = []\n",
        "    for k,v in keyword_count.items():\n",
        "        keyword_occurences.append([k,v])\n",
        "    keyword_occurences.sort(key = lambda x:x[1], reverse = True)\n",
        "    return keyword_occurences, keyword_count\n",
        "\n",
        "# Calling this function gives access to a list of genre keywords which are sorted by decreasing frequency\n",
        "keyword_occurences, dum = count_word(movies, 'genres', genre_labels)\n",
        "keyword_occurences[:5]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['Drama', 1603],\n",
              " ['Comedy', 1200],\n",
              " ['Action', 503],\n",
              " ['Thriller', 492],\n",
              " ['Romance', 471]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wFs3fb5Xcw9n"
      },
      "source": [
        "The top 5 genres are, in that respect order: Drama, Comedy, Action, Thriller, and Romance. I'll show this on a wordcloud too in order to make it more visually appealing."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BDg-nNhlcw9o"
      },
      "source": [
        "# Define the dictionary used to produce the genre wordcloud\n",
        "genres = dict()\n",
        "trunc_occurences = keyword_occurences[0:18]\n",
        "for s in trunc_occurences:\n",
        "    genres[s[0]] = s[1]\n",
        "\n",
        "# Create the wordcloud\n",
        "genre_wordcloud = WordCloud(width=1000,height=400, background_color='white')\n",
        "genre_wordcloud.generate_from_frequencies(genres)\n",
        "\n",
        "# Plot the wordcloud\n",
        "f, ax = plt.subplots(figsize=(16, 8))\n",
        "plt.imshow(genre_wordcloud, interpolation=\"bilinear\")\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U7zz3T3G5fgQ"
      },
      "source": [
        "<img src='https://www.notion.so/image/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2F3bc4fc2e-e5e9-4261-971b-455c186e1447%2FUntitled.png?table=block&id=c81e5161-3987-4064-9c24-a736195ce515&spaceId=63b72b1f-0e90-4ab8-a6df-a060a6545a56&width=2000&userId=21ec183f-f0be-4b6b-9b3e-6f0d4e5c5469&cache=v2'>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MMINypFrcw9o"
      },
      "source": [
        "## Types of Recommendation Engines\n",
        "\n",
        "### 1. Content-Based\n",
        "The Content-Based Recommender relies on the similarity of the items being recommended. The basic idea is that if you like an item, then you will also like a “similar” item. It generally works well when it's easy to determine the context/properties of each item.\n",
        "\n",
        "A content based recommender works with data that the user provides, either explicitly movie ratings for the MovieLens dataset. Based on that data, a user profile is generated, which is then used to make suggestions to the user. As the user provides more inputs or takes actions on the recommendations, the engine becomes more and more accurate.\n",
        "\n",
        "### 2. Collaborative Filtering\n",
        "The Collaborative Filtering Recommender is entirely based on the past behavior and not on the context. More specifically, it is based on the similarity in preferences, tastes and choices of two users. It analyses how similar the tastes of one user is to another and makes recommendations on the basis of that. \n",
        "\n",
        "For instance, if user A likes movies 1, 2, 3 and user B likes movies 2,3,4, then they have similar interests and A should like movie 4 and B should like movie 1. This makes it one of the most commonly used algorithm as it is not dependent on any additional information.\n",
        "\n",
        "In general, collaborative filtering is the workhorse of recommender engines. The algorithm has a very interesting property of being able to do feature learning on its own, which means that it can start to learn for itself what features to use. It can be divided into **Memory-Based Collaborative Filtering** and **Model-Based Collaborative filtering**. In this post, I'll only focus on the Memory-Based Collaborative Filtering technique.\n",
        "\n",
        "<img src='https://www.notion.so/image/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2F88b4039c-fe8c-4720-810d-b97784b459df%2FUntitled.png?table=block&id=773c2e47-1685-4f75-a9a3-e7b7cf63caa4&spaceId=63b72b1f-0e90-4ab8-a6df-a060a6545a56&width=2000&userId=21ec183f-f0be-4b6b-9b3e-6f0d4e5c5469&cache=v2'>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SGhotFlLcw9o"
      },
      "source": [
        "## Content-Based Recommendation Model\n",
        "### Theory\n",
        "The concepts of **Term Frequency (TF)** and **Inverse Document Frequency (IDF)** are used in information retrieval systems and also content based filtering mechanisms (such as a content based recommender). They are used to determine the relative importance of a document / article / news item / movie etc.\n",
        "\n",
        "TF is simply the frequency of a word in a document. IDF is the inverse of the document frequency among the whole corpus of documents. TF-IDF is used mainly because of two reasons: Suppose we search for “**the results of latest European Socccer games**” on Google. It is certain that “**the**” will occur more frequently than “**soccer games**” but the relative importance of **soccer games** is higher than the search query point of view. In such cases, TF-IDF weighting negates the effect of high frequency words in determining the importance of an item (document).\n",
        "\n",
        "Below is the equation to calculate the TF-IDF score:\n",
        "<img src='https://www.notion.so/image/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2Fe9b62bf0-cae6-4019-a4d2-cbbf5f22107d%2FUntitled.png?table=block&id=7de424d4-a2cf-4a60-840a-82fd97313b0d&spaceId=63b72b1f-0e90-4ab8-a6df-a060a6545a56&width=2000&userId=21ec183f-f0be-4b6b-9b3e-6f0d4e5c5469&cache=v2'>\n",
        "\n",
        "After calculating TF-IDF scores, how do we determine which items are closer to each other, rather closer to the user profile? This is accomplished using the **Vector Space Model** which computes the proximity based on the angle between the vectors. In this model, each item is stored as a vector of its attributes (which are also vectors) in an **n-dimensional space** and the angles between the vectors are calculated to **determine the similarity between the vectors**. Next, the user profile vectors are also created based on his actions on previous attributes of items and the similarity between an item and a user is also determined in a similar way.\n",
        "\n",
        "<img src='https://www.notion.so/image/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2F5cf1a0cf-474e-427c-849c-f059942f4b9e%2FUntitled.png?table=block&id=cf2dbbe9-34a8-42b3-8c78-7ab548b1d192&spaceId=63b72b1f-0e90-4ab8-a6df-a060a6545a56&width=2000&userId=21ec183f-f0be-4b6b-9b3e-6f0d4e5c5469&cache=v2'>\n",
        "\n",
        "Sentence 2 is more likely to be using Term 2 than using Term 1. Vice-versa for Sentence 1. The method of calculating this relative measure is calculated by taking the cosine of the angle between the sentences and the terms. The ultimate reason behind using cosine is that the **value of cosine will increase with decreasing value of the angle** between which signifies more similarity. The vectors are length normalized after which they become vectors of length 1 and then the cosine calculation is simply the sum-product of vectors.\n",
        "\n",
        "### Implementation\n",
        "With all that theory in mind, I am going to build a Content-Based Recommendation Engine that computes similarity between movies based on movie genres. It will suggest movies that are most similar to a particular movie based on its genre. To do so, I will make use of the file **movies.csv**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "CuclTziPcw9p"
      },
      "source": [
        "# Break up the big genre string into a string array\n",
        "movies['genres'] = movies['genres'].str.split('|')\n",
        "# Convert genres to string value\n",
        "movies['genres'] = movies['genres'].fillna(\"\").astype('str')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SwEYgNXbcw9q"
      },
      "source": [
        "I do not have a quantitative metric to judge our machine's performance so this will have to be done qualitatively. In order to do so, I'll use **TfidfVectorizer** function from **scikit-learn**, which transforms text to feature vectors that can be used as input to estimator."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CfuoOLmjcw9q",
        "outputId": "9682f094-99fd-4482-d5a4-47e2f4de2290"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "tf = TfidfVectorizer(analyzer='word',ngram_range=(1, 2),min_df=0, stop_words='english')\n",
        "tfidf_matrix = tf.fit_transform(movies['genres'])\n",
        "tfidf_matrix.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3883, 127)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NYw-6nVRcw9q"
      },
      "source": [
        "I will be using the **[Cosine Similarity](https://masongallo.github.io/machine/learning,/python/2016/07/29/cosine-similarity.html)** to calculate a numeric quantity that denotes the similarity between two movies. Since we have used the TF-IDF Vectorizer, calculating the Dot Product will directly give us the Cosine Similarity Score. Therefore, we will use sklearn's **linear_kernel** instead of cosine_similarities since it is much faster."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MRszy09Scw9r",
        "outputId": "6c7732d6-aca0-425f-e585-a2434b9680ad"
      },
      "source": [
        "from sklearn.metrics.pairwise import linear_kernel\n",
        "cosine_sim = linear_kernel(tfidf_matrix, tfidf_matrix)\n",
        "cosine_sim[:4, :4]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.        , 0.14193614, 0.09010857, 0.1056164 ],\n",
              "       [0.14193614, 1.        , 0.        , 0.        ],\n",
              "       [0.09010857, 0.        , 1.        , 0.1719888 ],\n",
              "       [0.1056164 , 0.        , 0.1719888 , 1.        ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4hNIZC_Gcw9r"
      },
      "source": [
        "I now have a pairwise cosine similarity matrix for all the movies in the dataset. The next step is to write a function that returns the 20 most similar movies based on the cosine similarity score."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "cG3XJIYhcw9s"
      },
      "source": [
        "# Build a 1-dimensional array with movie titles\n",
        "titles = movies['title']\n",
        "indices = pd.Series(movies.index, index=movies['title'])\n",
        "\n",
        "# Function that get movie recommendations based on the cosine similarity score of movie genres\n",
        "def genre_recommendations(title):\n",
        "    idx = indices[title]\n",
        "    sim_scores = list(enumerate(cosine_sim[idx]))\n",
        "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
        "    sim_scores = sim_scores[1:21]\n",
        "    movie_indices = [i[0] for i in sim_scores]\n",
        "    return titles.iloc[movie_indices]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-13svKoccw9t"
      },
      "source": [
        "Let's try and get the top recommendations for a few movies and see how good the recommendations are."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x0Bc5ML3cw9u",
        "outputId": "07be0a85-8a0d-493c-b689-9a08e1ca9258"
      },
      "source": [
        "genre_recommendations('Good Will Hunting (1997)').head(20)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "25                                        Othello (1995)\n",
              "26                                   Now and Then (1995)\n",
              "29     Shanghai Triad (Yao a yao yao dao waipo qiao) ...\n",
              "30                                Dangerous Minds (1995)\n",
              "35                               Dead Man Walking (1995)\n",
              "39                       Cry, the Beloved Country (1995)\n",
              "42                                    Restoration (1995)\n",
              "52                                       Lamerica (1994)\n",
              "54                                        Georgia (1995)\n",
              "56                          Home for the Holidays (1995)\n",
              "61                             Mr. Holland's Opus (1995)\n",
              "66                                       Two Bits (1995)\n",
              "77                            Crossing Guard, The (1995)\n",
              "79          White Balloon, The (Badkonake Sefid ) (1995)\n",
              "81                       Antonia's Line (Antonia) (1995)\n",
              "82       Once Upon a Time... When We Were Colored (1995)\n",
              "89                    Journey of August King, The (1995)\n",
              "92                                Beautiful Girls (1996)\n",
              "95                               Hate (Haine, La) (1995)\n",
              "112                             Margaret's Museum (1995)\n",
              "Name: title, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cbZQ-ZJpcw9v",
        "outputId": "37c5e177-8f18-4530-acc5-21bb0ba49f00"
      },
      "source": [
        "genre_recommendations('Toy Story (1995)').head(20)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1050               Aladdin and the King of Thieves (1996)\n",
              "2072                             American Tail, An (1986)\n",
              "2073           American Tail: Fievel Goes West, An (1991)\n",
              "2285                            Rugrats Movie, The (1998)\n",
              "2286                                 Bug's Life, A (1998)\n",
              "3045                                   Toy Story 2 (1999)\n",
              "3542                                Saludos Amigos (1943)\n",
              "3682                                   Chicken Run (2000)\n",
              "3685       Adventures of Rocky and Bullwinkle, The (2000)\n",
              "236                                 Goofy Movie, A (1995)\n",
              "12                                           Balto (1995)\n",
              "241                               Gumby: The Movie (1995)\n",
              "310                             Swan Princess, The (1994)\n",
              "592                                      Pinocchio (1940)\n",
              "612                                Aristocats, The (1970)\n",
              "700                               Oliver & Company (1988)\n",
              "876     Land Before Time III: The Time of the Great Gi...\n",
              "1010          Winnie the Pooh and the Blustery Day (1968)\n",
              "1012                       Sword in the Stone, The (1963)\n",
              "1020                        Fox and the Hound, The (1981)\n",
              "Name: title, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "io_zJZHccw9v",
        "outputId": "68118aa2-b5b4-4196-eddf-78ee8e1199f1"
      },
      "source": [
        "genre_recommendations('Saving Private Ryan (1998)').head(20)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "461            Heaven & Earth (1993)\n",
              "1204        Full Metal Jacket (1987)\n",
              "1214     Boat, The (Das Boot) (1981)\n",
              "1222                    Glory (1989)\n",
              "1545                G.I. Jane (1997)\n",
              "1959      Saving Private Ryan (1998)\n",
              "2358       Thin Red Line, The (1998)\n",
              "2993         Longest Day, The (1962)\n",
              "3559            Flying Tigers (1942)\n",
              "3574    Fighting Seabees, The (1944)\n",
              "3585    Guns of Navarone, The (1961)\n",
              "3684             Patriot, The (2000)\n",
              "40                Richard III (1995)\n",
              "153            Beyond Rangoon (1995)\n",
              "332         Walking Dead, The (1995)\n",
              "523          Schindler's List (1993)\n",
              "641        Courage Under Fire (1996)\n",
              "967          Nothing Personal (1995)\n",
              "979           Michael Collins (1996)\n",
              "1074                  Platoon (1986)\n",
              "Name: title, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TbP_HD8Gcw9w"
      },
      "source": [
        "As you can see, I have quite a decent list of recommendation for **Good Will Hunting** (Drama), **Toy Story** (Animation, Children's, Comedy), and **Saving Private Ryan** (Action, Thriller, War).\n",
        "\n",
        "Overall, here are the pros of using content-based recommendation:\n",
        "* No need for data on other users, thus no cold-start or sparsity problems.\n",
        "* Can recommend to users with unique tastes.\n",
        "* Can recommend new & unpopular items.\n",
        "* Can provide explanations for recommended items by listing content-features that caused an item to be recommended (in this case, movie genres)\n",
        "\n",
        "However, there are some cons of using this approach:\n",
        "* Finding the appropriate features is hard.\n",
        "* Does not recommend items outside a user's content profile.\n",
        "* Unable to exploit quality judgments of other users."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j-NiY14Wcw9w"
      },
      "source": [
        "## Collaborative Filtering Recommendation Model\n",
        "The content based engine suffers from some severe limitations. It is only capable of suggesting movies which are close to a certain movie. That is, it is not capable of capturing tastes and providing recommendations across genres.\n",
        "\n",
        "Also, the engine that we built is not really personal in that it doesn't capture the personal tastes and biases of a user. Anyone querying our engine for recommendations based on a movie will receive the same recommendations for that movie, regardless of who she/he is.\n",
        "\n",
        "Therefore, in this section, I will use Memory-Based Collaborative Filtering to make recommendations to movie users. The technique is based on the idea that users similar to a me can be used to predict how much I will like a particular product or service those users have used/experienced but I have not.\n",
        "\n",
        "### Theory\n",
        "There are 2 main types of memory-based collaborative filtering algorithms:\n",
        "1. **User-User Collaborative Filtering**: Here we find look alike users based on similarity and recommend movies which first user’s look-alike has chosen in past. This algorithm is very effective but takes a lot of time and resources. It requires to compute every user pair information which takes time. Therefore, for big base platforms, this algorithm is hard to implement without a very strong parallelizable system.\n",
        "2. **Item-Item Collaborative Filtering**: It is quite similar to previous algorithm, but instead of finding user's look-alike, we try finding movie's look-alike. Once we have movie's look-alike matrix, we can easily recommend alike movies to user who have rated any movie from the dataset. This algorithm is far less resource consuming than user-user collaborative filtering. Hence, for a new user, the algorithm takes far lesser time than user-user collaborate as we don’t need all similarity scores between users. And with fixed number of movies, movie-movie look alike matrix is fixed over time.\n",
        "\n",
        "<img src='https://www.notion.so/image/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2F91b1d105-5f8f-48d6-b0fe-a4fa349fbd64%2FUntitled.png?table=block&id=5f76137e-4670-41a4-abe5-69d8c9c859dd&spaceId=63b72b1f-0e90-4ab8-a6df-a060a6545a56&width=2000&userId=21ec183f-f0be-4b6b-9b3e-6f0d4e5c5469&cache=v2'>\n",
        "\n",
        "In either scenario, we builds a similarity matrix. For user-user collaborative filtering, the **user-similarity matrix** will consist of some distance metrics that measure the similarity between any two pairs of users. Likewise, the **item-similarity matrix** will measure the similarity between any two pairs of items.\n",
        "\n",
        "There are 3 distance similarity metrics that are usually used in collaborative filtering:\n",
        "1. **Jaccard Similarity**:\n",
        "    * Similarity is based on the number of users which have rated item A and B divided by the number of users who have rated either A or B\n",
        "    * It is typically used where we don’t have a numeric rating but just a boolean value like a product being bought or an add being clicked\n",
        "\n",
        "2. **Cosine Similarity**: (as in the Content-Based system)\n",
        "    * Similarity is the cosine of the angle between the 2 vectors of the item vectors of A and B\n",
        "    * Closer the vectors, smaller will be the angle and larger the cosine\n",
        "\n",
        "3. **Pearson Similarity**:\n",
        "    * Similarity is the pearson coefficient between the two vectors.\n",
        "\n",
        "For the purpose of diversity, I will use **Pearson Similarity** in this implementation.\n",
        "\n",
        "### Implementation\n",
        "I will use the file **ratings.csv** first as it contains User ID, Movie IDs and Ratings. These three elements are all I need for determining the similarity of the users based on their ratings for a particular movie.\n",
        "\n",
        "First I do some quick data processing:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "3Fj4PpGhcw9x"
      },
      "source": [
        "# Fill NaN values in user_id and movie_id column with 0\n",
        "ratings['user_id'] = ratings['user_id'].fillna(0)\n",
        "ratings['movie_id'] = ratings['movie_id'].fillna(0)\n",
        "\n",
        "# Replace NaN values in rating column with average of all values\n",
        "ratings['rating'] = ratings['rating'].fillna(ratings['rating'].mean())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "88mfDHRHcw9y"
      },
      "source": [
        "Due to the limited computing power in my laptop, I will build the recommender system using only a subset of the ratings. In particular, I will take a random sample of 20,000 ratings (2%) from the 1M ratings."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-nRZfdNWcw9y",
        "outputId": "345f265a-778b-4891-a3ee-28c0c3f9e1bf"
      },
      "source": [
        "# Randomly sample 1% of the ratings dataset\n",
        "small_data = ratings.sample(frac=0.02)\n",
        "# Check the sample info\n",
        "print(small_data.info())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 20004 entries, 562967 to 933367\n",
            "Data columns (total 3 columns):\n",
            "user_id     20004 non-null int64\n",
            "movie_id    20004 non-null int64\n",
            "rating      20004 non-null int64\n",
            "dtypes: int64(3)\n",
            "memory usage: 625.1 KB\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BMixcGMecw9z"
      },
      "source": [
        "Now I use the **scikit-learn library** to split the dataset into testing and training.  **Cross_validation.train_test_split** shuffles and splits the data into two datasets according to the percentage of test examples, which in this case is 0.2."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "idelK-b6cw9z",
        "outputId": "a2ffb6dd-8e03-44be-ffb0-2e52e8179408"
      },
      "source": [
        "from sklearn import cross_validation as cv\n",
        "train_data, test_data = cv.train_test_split(small_data, test_size=0.2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
            "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "te54OpyDcw90"
      },
      "source": [
        "Now I need to create a user-item matrix. Since I have splitted the data into testing and training, I need to create two matrices. The training matrix contains 80% of the ratings and the testing matrix contains 20% of the ratings."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tmxKkYNdcw90",
        "outputId": "5620b6a8-659e-4c45-a663-b95e4047b8dc"
      },
      "source": [
        "# Create two user-item matrices, one for training and another for testing\n",
        "train_data_matrix = train_data.as_matrix(columns = ['user_id', 'movie_id', 'rating'])\n",
        "test_data_matrix = test_data.as_matrix(columns = ['user_id', 'movie_id', 'rating'])\n",
        "\n",
        "# Check their shape\n",
        "print(train_data_matrix.shape)\n",
        "print(test_data_matrix.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(16003, 3)\n",
            "(4001, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-txo7ih6cw91"
      },
      "source": [
        "Now I use the **pairwise_distances** function from sklearn to calculate the [Pearson Correlation Coefficient](https://stackoverflow.com/questions/1838806/euclidean-distance-vs-pearson-correlation-vs-cosine-similarity). This method provides a safe way to take a distance matrix as input, while preserving compatibility with many other algorithms that take a vector array."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aM3D4tP-cw91",
        "outputId": "5cc00a7c-e351-40af-d56a-34e46d0fcbfd"
      },
      "source": [
        "from sklearn.metrics.pairwise import pairwise_distances\n",
        "\n",
        "# User Similarity Matrix\n",
        "user_correlation = 1 - pairwise_distances(train_data, metric='correlation')\n",
        "user_correlation[np.isnan(user_correlation)] = 0\n",
        "print(user_correlation[:4, :4])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1.         0.9762515  0.9303185  0.99137913]\n",
            " [0.9762515  1.         0.82877143 0.93945018]\n",
            " [0.9303185  0.82877143 1.         0.97035192]\n",
            " [0.99137913 0.93945018 0.97035192 1.        ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mBs6dXb3cw92",
        "outputId": "dc562a78-70d4-428c-af3b-c7acd51801ca"
      },
      "source": [
        "# Item Similarity Matrix\n",
        "item_correlation = 1 - pairwise_distances(train_data_matrix.T, metric='correlation')\n",
        "item_correlation[np.isnan(item_correlation)] = 0\n",
        "print(item_correlation[:4, :4])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 1.         -0.00586729  0.02494105]\n",
            " [-0.00586729  1.         -0.05788492]\n",
            " [ 0.02494105 -0.05788492  1.        ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ru6KEkJrcw93"
      },
      "source": [
        "With the similarity matrix in hand, I can now predict the ratings that were not included with the data. Using these predictions, I can then compare them with the test data to attempt to validate the quality of our recommender model.\n",
        "\n",
        "For the user-user CF case, I will look at the similarity between 2 users (A and B, for example) as weights that are multiplied by the ratings of a similar user B (corrected for the average rating of that user). I also need to normalize it so that the ratings stay between 1 and 5 and, as a final step, sum the average ratings for the user that I am trying to predict. The idea here is that some users may tend always to give high or low ratings to all movies. The relative difference in the ratings that these users give is more important than the absolute values. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "vI4vt-UQcw93"
      },
      "source": [
        "# Function to predict ratings\n",
        "def predict(ratings, similarity, type='user'):\n",
        "    if type == 'user':\n",
        "        mean_user_rating = ratings.mean(axis=1)\n",
        "        # Use np.newaxis so that mean_user_rating has same format as ratings\n",
        "        ratings_diff = (ratings - mean_user_rating[:, np.newaxis])\n",
        "        pred = mean_user_rating[:, np.newaxis] + similarity.dot(ratings_diff) / np.array([np.abs(similarity).sum(axis=1)]).T\n",
        "    elif type == 'item':\n",
        "        pred = ratings.dot(similarity) / np.array([np.abs(similarity).sum(axis=1)])\n",
        "    return pred"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MCg0HdBdcw94"
      },
      "source": [
        "### Evaluation\n",
        "There are many evaluation metrics but one of the most popular metric used to evaluate accuracy of predicted ratings is **Root Mean Squared Error (RMSE)**. I will use the **mean_square_error (MSE)** function from sklearn, where the RMSE is just the square root of MSE.\n",
        "\n",
        "$$\\mathit{RMSE} =\\sqrt{\\frac{1}{N} \\sum (x_i -\\hat{x_i})^2}$$\n",
        "\n",
        "I'll use the scikit-learn's **mean squared error** function as my validation metric. Comparing user- and item-based collaborative filtering, it looks like user-based collaborative filtering gives a better result."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "0HHVe1FScw94"
      },
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "from math import sqrt\n",
        "\n",
        "# Function to calculate RMSE\n",
        "def rmse(pred, actual):\n",
        "    # Ignore nonzero terms.\n",
        "    pred = pred[actual.nonzero()].flatten()\n",
        "    actual = actual[actual.nonzero()].flatten()\n",
        "    return sqrt(mean_squared_error(pred, actual))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oVAPzG3ncw95",
        "outputId": "22e154f5-1448-4c92-8869-a516fb72947a"
      },
      "source": [
        "# Predict ratings on the training data with both similarity score\n",
        "user_prediction = predict(train_data_matrix, user_correlation, type='user')\n",
        "item_prediction = predict(train_data_matrix, item_correlation, type='item')\n",
        "\n",
        "# RMSE on the test data\n",
        "print('User-based CF RMSE: ' + str(rmse(user_prediction, test_data_matrix)))\n",
        "print('Item-based CF RMSE: ' + str(rmse(item_prediction, test_data_matrix)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "User-based CF RMSE: 1447.6814769930884\n",
            "Item-based CF RMSE: 1678.7256599700413\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U8xSQtl8cw96",
        "outputId": "9c7deaad-ec30-4bb7-e2ba-ed32ba9d5b7a"
      },
      "source": [
        "# RMSE on the train data\n",
        "print('User-based CF RMSE: ' + str(rmse(user_prediction, train_data_matrix)))\n",
        "print('Item-based CF RMSE: ' + str(rmse(item_prediction, train_data_matrix)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "User-based CF RMSE: 699.9584792778463\n",
            "Item-based CF RMSE: 114.97271725933925\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RF1RJn7Jcw96"
      },
      "source": [
        "RMSE of training of model is a metric which measure how much the signal and the noise is explained by the model. I noticed that my RMSE is quite big. I suppose I might have overfitted the training data.\n",
        "\n",
        "Overall, Memory-based Collaborative Filtering is easy to implement and produce reasonable prediction quality. However, there are some drawback of this approach:\n",
        "\n",
        "* It doesn't address the well-known cold-start problem, that is when new user or new item enters the system. \n",
        "* It can't deal with sparse data, meaning it's hard to find users that have rated the same items.\n",
        "* It suffers when new users or items that don't have any ratings enter the system.\n",
        "* It tends to recommend popular items."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rlTtqWG6cw97"
      },
      "source": [
        "## Alternative Approach\n",
        "As I mentioned above, it looks like my Collaborative Filtering model suffers from overfitting problem as I only train it on a small sample dataset (2% of the actual 1M ratings). In order to deal with this, I need to apply dimensionality reduction techniques to capture more signals from the big dataset. Thus comes the use of **low-dimensional factor models (aka, Model-Based Collaborative Filtering)**. I won't be able to implement this approach in this notebook due to computing limit, however, I want to introduce it here to give you a general sense of its advantages.\n",
        "\n",
        "In this approach, CF models are developed using machine learning algorithms to predict user’s rating of unrated items. It has been shown that Model-based Collaborative Filtering has received greater exposure in industry research, mainly as an unsupervised learning method for latent variable decomposition and dimensionality reduction. An example is the competition to win the [Netflix Prize](https://en.wikipedia.org/wiki/Netflix_Prize), which used the best collaborative filtering algorithm to predict user ratings for films, based on previous ratings without any other information about the users or films.\n",
        "\n",
        "Matrix factorization is widely used for recommender systems where it can deal better with scalability and sparsity than Memory-based CF. The goal of MF is to learn the latent preferences of users and the latent attributes of items from known ratings (learn features that describe the characteristics of ratings) to then predict the unknown ratings through the dot product of the latent features of users and items. As per my understanding, the algorithms in this approach can further be broken down into 3 sub-types:\n",
        "\n",
        "* **Matrix Factorization (MF)**: The idea behind such models is that attitudes or preferences of a user can be determined by a small number of hidden latent factors. These factors are also called **Embeddings**, which represent different characteristics for users and items. Matrix factorization can be done by various methods including Support Vecot Decomposition (SVD), Probabilistic Matrix Factorization (PMF), and Non-Negative Matrix Factorization (NMF).\n",
        "\n",
        "* **Clustering based algorithm (KNN)**: The idea of clustering is same as that of memory-based recommendation systems. In memory-based algorithms, we use the similarities between users and/or items and use them as weights to predict a rating for a user and an item. The difference is that the similarities in this approach are calculated based on an unsupervised learning model, rather than Pearson correlation or cosine similarity.\n",
        "\n",
        "* **Neural Nets / Deep Learning**: The idea of using Neural Nets is similar to that of Model-Based Matrix Factorization. In matrix factorizaion, we decompose our original sparse matrix into product of 2 low rank orthogonal matrices. For neural net implementation, we don’t need them to be orthogonal, we want our model to learn the values of embedding matrix itself. The user latent features and movie latent features are looked up from the embedding matrices for specific movie-user combination. These are the input values for further linear and non-linear layers. We can pass this input to multiple relu, linear or sigmoid layers and learn the corresponding weights by any optimization algorithm (Adam, SGD, etc.).\n",
        "\n",
        "<img src='https://www.notion.so/image/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2F1237b743-6be0-49dd-9658-7ec7a0550452%2FUntitled.png?table=block&id=884fab53-922f-4d51-b30f-12afeb8f47ab&spaceId=63b72b1f-0e90-4ab8-a6df-a060a6545a56&width=2000&userId=21ec183f-f0be-4b6b-9b3e-6f0d4e5c5469&cache=v2'>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QXUyiEqLcw98"
      },
      "source": [
        "## Summary\n",
        "In this post, I introduced the Movie Lens dataset for building movie recommendation system.\n",
        "\n",
        "Specifically, I have developed recommendation models including:\n",
        "\n",
        "* How to load and review the data.\n",
        "* How to develop a content-based recommendation model based on movie genres.\n",
        "* How to develop a memory-based collaborative filtering model based on user ratings.\n",
        "* A glimpse at model-based collaborative filtering models as alternative options."
      ]
    }
  ]
}