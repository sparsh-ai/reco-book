{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"rec-tut-gml-06-sng-egonet-part-2-link-prediction.ipynb","provenance":[{"file_id":"1f05nHjML9TqPNTz_NWt_6VVUvYlPDGM6","timestamp":1628078002102},{"file_id":"18rsHbAXudxz_EspXEEFhfLLd-MT2jbhK","timestamp":1628066780292},{"file_id":"1sAKOySokSkK8dTp6GYjmIh3AjBOT1R0J","timestamp":1627993731574},{"file_id":"1FlR0Nt00zRzrjciEpl46j51IIomB0K_p","timestamp":1627989061002}],"collapsed_sections":[],"authorship_tag":"ABX9TyNM/KygfizW+jiXDxC8eGGH"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"YpmJoZkdZLce"},"source":["<font color='006A58'>**Social Network Graphs**</font>"]},{"cell_type":"markdown","metadata":{"id":"iCELO8ZtNZGF"},"source":["Social media represents, nowadays, one of the most interesting and rich sources of information. Every day, thousands of new connections arise, new users join communities, and billions of posts are shared. Graphs mathematically represent all those interactions, helping to make order of all such spontaneous and unstructured traffic.\n","\n","When dealing with social graphs, there are many interesting problems that can be addressed using machine learning. Under the correct settings, it is possible to extract useful insights from this huge amount of data, for improving your marketing strategy, identifying users with dangerous behaviors (for example, terrorist networks), and predicting the likelihood that a user will read your new post.\n","\n","Specifically, link prediction is one of the most interesting and important research topics in this field. Depending on what a connection in your social graph represents, by predicting future edges, you will be able to predict your next suggested friend, the next suggested movie, and which product you are likely to buy."]},{"cell_type":"markdown","metadata":{"id":"hRVQRO_eNcll"},"source":["> Tip: Link prediction task aims at forecasting the likelihood of a future connection between two nodes and it can be solved using several machine learning algorithms."]},{"cell_type":"code","metadata":{"id":"3drPlnSLW_Gr"},"source":["!wget http://snap.stanford.edu/data/facebook_combined.txt.gz\n","!wget http://snap.stanford.edu/data/facebook.tar.gz\n","!gzip -d facebook_combined.txt.gz\n","!tar -xf facebook.tar.gz"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qS8sGaksd6gd"},"source":["!pip install community\n","!pip install stellargraph\n","!pip install node2vec==0.3.3\n","!pip install git+https://github.com/palash1992/GEM.git"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_LI_9pKba8gX","executionInfo":{"status":"ok","timestamp":1628079472544,"user_tz":-330,"elapsed":1257,"user":{"displayName":"Sparsh Agarwal","photoUrl":"","userId":"13037694610922482904"}}},"source":["import os\n","import math\n","import glob\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","\n","from sklearn import metrics\n","from sklearn.model_selection import train_test_split\n","from sklearn.ensemble import RandomForestClassifier \n","\n","import community\n","from community import community_louvain\n","import networkx as nx\n","import networkx.algorithms.community as nx_comm\n","from node2vec import Node2Vec\n","from node2vec.edges import HadamardEmbedder \n","from stellargraph.data import EdgeSplitter\n","from stellargraph import StellarGraph\n","from stellargraph.mapper import GraphSAGELinkGenerator\n","from stellargraph.layer import GraphSAGE, link_classification\n","from tensorflow import keras\n","\n","%matplotlib inline\n","\n","default_edge_color = 'gray'\n","default_node_color = '#407cc9'\n","enhanced_node_color = '#f5b042'\n","enhanced_edge_color = '#cc2f04'"],"execution_count":12,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"LRnKXK4HBE9y"},"source":["Our goal is to predict the probability that the given 2 nodes are connected. It comes under the *Link Prediction* task. For this, we will first preprocess the data in the right format and then split it into train/test. Then, we will try 3 methods to train a binary classifier that will take 2 nodes as input and outputs the probability."]},{"cell_type":"markdown","metadata":{"id":"KSILTUN0BMMt"},"source":["## Preprocessing"]},{"cell_type":"markdown","metadata":{"id":"m5lPZSwXC7JR"},"source":["### Parse edge features"]},{"cell_type":"code","metadata":{"id":"WNUxlPEgDPNp","executionInfo":{"status":"ok","timestamp":1628079370558,"user_tz":-330,"elapsed":6,"user":{"displayName":"Sparsh Agarwal","photoUrl":"","userId":"13037694610922482904"}}},"source":["feat_file_name = \"feature_map.txt\"\n","feature_index = {}  #numeric index to name\n","inverted_feature_index = {} #name to numeric index\n","network = nx.Graph()"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"K5MVcVfeEvbj","executionInfo":{"status":"ok","timestamp":1628079372673,"user_tz":-330,"elapsed":1357,"user":{"displayName":"Sparsh Agarwal","photoUrl":"","userId":"13037694610922482904"}},"outputId":"cc4be015-b955-406d-ef5c-e8ff04acc0ae"},"source":["G = nx.read_edgelist(\"facebook_combined.txt\", create_using=nx.Graph(), nodetype=int)\n","print(nx.info(G))"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Name: \n","Type: Graph\n","Number of nodes: 4039\n","Number of edges: 88234\n","Average degree:  43.6910\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"7Fqfajd7EFP8","executionInfo":{"status":"ok","timestamp":1628079372674,"user_tz":-330,"elapsed":11,"user":{"displayName":"Sparsh Agarwal","photoUrl":"","userId":"13037694610922482904"}}},"source":["# let's first create a list of participant ids - we call it ego nodes in literature it seems\n","ego_nodes = set([int(name.split('.')[0]) for name in os.listdir(\"./facebook/\")])"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"OOc9IPnpDUhY","executionInfo":{"status":"ok","timestamp":1628079372676,"user_tz":-330,"elapsed":11,"user":{"displayName":"Sparsh Agarwal","photoUrl":"","userId":"13037694610922482904"}}},"source":["def parse_featname_line(line):\n","  \"\"\" used to parse each line of the files containing feature names \"\"\"\n","  line = line[(line.find(' '))+1:]  # chop first field\n","  split = line.split(';')\n","  name = ';'.join(split[:-1]) # feature name\n","  index = int(split[-1].split(\" \")[-1]) #feature index\n","  return index, name"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"v90kJqqpDI2w","executionInfo":{"status":"ok","timestamp":1628079372678,"user_tz":-330,"elapsed":12,"user":{"displayName":"Sparsh Agarwal","photoUrl":"","userId":"13037694610922482904"}}},"source":["def load_features():\n","  \"\"\" \n","  parse each ego-network and creates two dictionaries:\n","      - feature_index: maps numeric indices to names\n","      - inverted_feature_index: maps names to numeric indices\n","  \"\"\"\n","  feat_file_name = 'tmp.txt'\n","  # may need to build the index first\n","  if not os.path.exists(feat_file_name):\n","      feat_index = {}\n","      # build the index from data/*.featnames files\n","      featname_files = glob.iglob(\"facebook/*.featnames\")\n","      for featname_file_name in featname_files:\n","          featname_file = open(featname_file_name, 'r')\n","          for line in featname_file:\n","              # example line:\n","              # 0 birthday;anonymized feature 376\n","              index, name = parse_featname_line(line)\n","              feat_index[index] = name\n","          featname_file.close()\n","      keys = feat_index.keys()\n","      keys = sorted(keys)\n","      out = open(feat_file_name,'w')\n","      for key in keys:\n","          out.write(\"%d %s\\n\" % (key, feat_index[key]))\n","      out.close()\n","\n","  index_file = open(feat_file_name,'r')\n","  for line in index_file:\n","      split = line.strip().split(' ')\n","      key = int(split[0])\n","      val = split[1]\n","      feature_index[key] = val\n","  index_file.close()\n","\n","  for key in feature_index.keys():\n","      val = feature_index[key]\n","      inverted_feature_index[val] = key"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"dDen54DIFv8C","executionInfo":{"status":"ok","timestamp":1628079373549,"user_tz":-330,"elapsed":4,"user":{"displayName":"Sparsh Agarwal","photoUrl":"","userId":"13037694610922482904"}}},"source":["load_features()"],"execution_count":7,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"AwtLmoAdFSp2"},"source":["### Add parsed feature to the node"]},{"cell_type":"code","metadata":{"id":"7cZ_EB2JDM5D","executionInfo":{"status":"ok","timestamp":1628079376893,"user_tz":-330,"elapsed":7,"user":{"displayName":"Sparsh Agarwal","photoUrl":"","userId":"13037694610922482904"}}},"source":["def parse_nodes(network, ego_nodes):\n","  \"\"\"\n","  for each nodes in the network assign the corresponding features \n","  previously loaded using the load_features function\n","  \"\"\"\n","  # parse each node\n","  for node_id in ego_nodes:\n","      featname_file = open(f'facebook/{node_id}.featnames','r')\n","      feat_file     = open(f'facebook/{node_id}.feat','r')\n","      egofeat_file  = open(f'facebook/{node_id}.egofeat','r')\n","      edge_file     = open(f'facebook/{node_id}.edges','r')\n","\n","      ego_features = [int(x) for x in egofeat_file.readline().split(' ')]\n","\n","      # Add ego node features\n","      network.nodes[node_id]['features'] = np.zeros(len(feature_index))\n","      \n","      # parse ego node\n","      i = 0\n","      for line in featname_file:\n","          key, val = parse_featname_line(line)\n","          # Update feature value if necessary\n","          if ego_features[i] + 1 > network.nodes[node_id]['features'][key]:\n","              network.nodes[node_id]['features'][key] = ego_features[i] + 1\n","          i += 1\n","\n","      # parse neighboring nodes\n","      for line in feat_file:\n","          featname_file.seek(0)\n","          split = [int(x) for x in line.split(' ')]\n","          node_id = split[0]\n","          features = split[1:]\n","\n","          # Add node features\n","          network.nodes[node_id]['features'] = np.zeros(len(feature_index))\n","\n","          i = 0\n","          for line in featname_file:\n","              key, val = parse_featname_line(line)\n","              # Update feature value if necessary\n","              if features[i] + 1 > network.nodes[node_id]['features'][key]:\n","                  network.nodes[node_id]['features'][key] = features[i] + 1\n","              i += 1\n","          \n","      featname_file.close()\n","      feat_file.close()\n","      egofeat_file.close()\n","      edge_file.close()"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"qv-rF9vPEZ12","executionInfo":{"status":"ok","timestamp":1628079383045,"user_tz":-330,"elapsed":6157,"user":{"displayName":"Sparsh Agarwal","photoUrl":"","userId":"13037694610922482904"}}},"source":["# add the parsed features to the networkx nodes\n","parse_nodes(G, ego_nodes)"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wZz3pe64Ep4K","executionInfo":{"status":"ok","timestamp":1628079383051,"user_tz":-330,"elapsed":42,"user":{"displayName":"Sparsh Agarwal","photoUrl":"","userId":"13037694610922482904"}},"outputId":"f46f37c0-3c46-48c4-99ca-3af24901be21"},"source":["# check features has been correctly assigned\n","G.nodes[0]"],"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'features': array([1., 1., 1., ..., 0., 0., 0.])}"]},"metadata":{"tags":[]},"execution_count":10}]},{"cell_type":"markdown","metadata":{"id":"5FnxkwnVFP0E"},"source":["### Data split"]},{"cell_type":"markdown","metadata":{"id":"LABzVTEZNuk6"},"source":["Since we aim to cast this problem as a supervised learning task, we need to create a training and testing dataset. We will therefore create two new subgraphs with the same numbers of nodes but different numbers of edges (as some edges will be removed and treated as positive samples for training/testing the algorithm).\n","\n","We are using the EdgeSplitter class to extract a fraction (p=10%) of all the edges in G, as well as the same number of negative edges, in order to obtain a reduced graph, graph_test. The train_test_split method also returns a list of node pairs, samples_test (where each pair corresponds to an existing or not existing edge in the graph), and a list of binary targets (labels_test) of the same length of the samples_test list. Then, from such a reduced graph, we are repeating the operation to obtain another reduced graph, graph_train, as well as the corresponding samples_train and labels_train lists."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oxX1bEJ0E1Kk","executionInfo":{"status":"ok","timestamp":1628079383053,"user_tz":-330,"elapsed":16,"user":{"displayName":"Sparsh Agarwal","photoUrl":"","userId":"13037694610922482904"}},"outputId":"db6f8d53-785b-45a8-9449-e23b67c136da"},"source":["edgeSplitter = EdgeSplitter(G) \n","graph_test, samples_test, labels_test = edgeSplitter.train_test_split(p=0.1, method=\"global\", seed=24)\n","\n","edgeSplitter = EdgeSplitter(graph_test, G) \n","graph_train, samples_train, labels_train = edgeSplitter.train_test_split(p=0.1, method=\"global\", seed=24)"],"execution_count":11,"outputs":[{"output_type":"stream","text":["** Sampled 8823 positive and 8823 negative edges. **\n","** Sampled 7941 positive and 7941 negative edges. **\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"u7uXYejZF8AU"},"source":["## Modeling"]},{"cell_type":"markdown","metadata":{"id":"v0VscoAYx6_w"},"source":["We will be comparing three different methods for predicting missing edges:\n","- Method1: node2vec will be used to learn a node embedding. Such embeddings will be used to train a Random Forest classifier in a supervised manner\n","- Method2: graphSAGE (with and without features) will be used for link prediction\n","- Method3: hand-crafted features will be extracted and used to train a Random Forest classifier"]},{"cell_type":"markdown","metadata":{"id":"qry5kIaPGOL-"},"source":["### Node2vec"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uK_-DoGzGPNU","executionInfo":{"status":"ok","timestamp":1628079827602,"user_tz":-330,"elapsed":256344,"user":{"displayName":"Sparsh Agarwal","photoUrl":"","userId":"13037694610922482904"}},"outputId":"8f2b19c7-37c1-4810-cf09-adac95f1870c"},"source":["node2vec = Node2Vec(graph_train) \n","model = node2vec.fit() \n","\n","edges_embs = HadamardEmbedder(keyed_vectors=model.wv) \n","train_embeddings = [edges_embs[str(x[0]),str(x[1])] for x in samples_train]\n","\n","edges_embs = HadamardEmbedder(keyed_vectors=model.wv) \n","test_embeddings = [edges_embs[str(x[0]),str(x[1])] for x in samples_test]"],"execution_count":16,"outputs":[{"output_type":"stream","text":["Computing transition probabilities: 100%|██████████| 4039/4039 [00:53<00:00, 75.86it/s] \n","Generating walks (CPU: 1): 100%|██████████| 10/10 [02:44<00:00, 16.48s/it]\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ekmprf5vGzps","executionInfo":{"status":"ok","timestamp":1628079892149,"user_tz":-330,"elapsed":2767,"user":{"displayName":"Sparsh Agarwal","photoUrl":"","userId":"13037694610922482904"}},"outputId":"9d5bac25-f1de-4f74-9523-c2ec1eec9e03"},"source":["rf = RandomForestClassifier(n_estimators=10) \n","rf.fit(train_embeddings, labels_train); \n"," \n","y_pred = rf.predict(test_embeddings) \n","print('Precision:', metrics.precision_score(labels_test, y_pred)) \n","print('Recall:', metrics.recall_score(labels_test, y_pred)) \n","print('F1-Score:', metrics.f1_score(labels_test, y_pred)) "],"execution_count":18,"outputs":[{"output_type":"stream","text":["Precision: 0.9660746812386156\n","Recall: 0.9618043749291624\n","F1-Score: 0.9639347986596241\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"g-t0CBepHIhW"},"source":["### GraphSage with no features"]},{"cell_type":"markdown","metadata":{"id":"__uJwna5OG_r"},"source":["We will build a two-layer GraphSAGE architecture that, given labeled pairs of nodes, outputs a pair of node embeddings. Then, a fully connected neural network will be used to process these embeddings and produce link predictions. Notice that the GraphSAGE model and the fully connected network will be concatenated and trained end to end so that the embeddings learning stage is influenced by the predictions."]},{"cell_type":"code","metadata":{"id":"SRLawCIjHM2S","executionInfo":{"status":"ok","timestamp":1628079898593,"user_tz":-330,"elapsed":490,"user":{"displayName":"Sparsh Agarwal","photoUrl":"","userId":"13037694610922482904"}}},"source":["eye = np.eye(graph_train.number_of_nodes())\n","fake_features = {n:eye[n] for n in G.nodes()}\n","nx.set_node_attributes(graph_train, fake_features, \"fake\")\n","\n","eye = np.eye(graph_test.number_of_nodes())\n","fake_features = {n:eye[n] for n in G.nodes()}\n","nx.set_node_attributes(graph_test, fake_features, \"fake\")"],"execution_count":19,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"du2aFSJKHaCT","executionInfo":{"status":"ok","timestamp":1628079957177,"user_tz":-330,"elapsed":465,"user":{"displayName":"Sparsh Agarwal","photoUrl":"","userId":"13037694610922482904"}},"outputId":"dbc08cc9-e15a-44ef-8653-db0f10f569af"},"source":["graph_train.nodes[0]"],"execution_count":21,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'fake': array([1., 0., 0., ..., 0., 0., 0.]),\n"," 'features': array([1., 1., 1., ..., 0., 0., 0.])}"]},"metadata":{"tags":[]},"execution_count":21}]},{"cell_type":"code","metadata":{"id":"J6ew3tYiHely","executionInfo":{"status":"ok","timestamp":1628080166841,"user_tz":-330,"elapsed":9819,"user":{"displayName":"Sparsh Agarwal","photoUrl":"","userId":"13037694610922482904"}}},"source":["batch_size = 64\n","num_samples = [4, 4]\n","\n","sg_graph_train = StellarGraph.from_networkx(graph_train, node_features=\"fake\")\n","sg_graph_test = StellarGraph.from_networkx(graph_test, node_features=\"fake\")\n","\n","train_gen = GraphSAGELinkGenerator(sg_graph_train, batch_size, num_samples)\n","train_flow = train_gen.flow(samples_train, labels_train, shuffle=True, seed=24)\n","\n","test_gen = GraphSAGELinkGenerator(sg_graph_test, batch_size, num_samples)\n","test_flow = test_gen.flow(samples_test, labels_test, seed=24)"],"execution_count":22,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NIrk79hjHnV5","executionInfo":{"status":"ok","timestamp":1628080180241,"user_tz":-330,"elapsed":833,"user":{"displayName":"Sparsh Agarwal","photoUrl":"","userId":"13037694610922482904"}},"outputId":"418e6894-6e6c-4bc5-847c-ea50a39e31a0"},"source":["layer_sizes = [20, 20]\n","graphsage = GraphSAGE(\n","    layer_sizes=layer_sizes, generator=train_gen, bias=True, dropout=0.3\n",")\n","\n","x_inp, x_out = graphsage.in_out_tensors()\n","\n","prediction = link_classification(\n","    output_dim=1, output_act=\"sigmoid\", edge_embedding_method=\"ip\"\n",")(x_out)\n","\n","model = keras.Model(inputs=x_inp, outputs=prediction)\n","\n","model.compile(\n","    optimizer=keras.optimizers.Adam(learning_rate=1e-3),\n","    loss=keras.losses.mse,\n","    metrics=[\"acc\"],\n",")"],"execution_count":24,"outputs":[{"output_type":"stream","text":["link_classification: using 'ip' method to combine node embeddings into edge embeddings\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IlGlbHawI62y","executionInfo":{"status":"ok","timestamp":1628080922372,"user_tz":-330,"elapsed":734323,"user":{"displayName":"Sparsh Agarwal","photoUrl":"","userId":"13037694610922482904"}},"outputId":"70bb5d2a-4523-479c-e6ae-fe3ccfb0deb6"},"source":["epochs = 10\n","history = model.fit(train_flow, epochs=epochs, validation_data=test_flow)"],"execution_count":25,"outputs":[{"output_type":"stream","text":["Epoch 1/10\n","249/249 [==============================] - 67s 260ms/step - loss: 0.2299 - acc: 0.6080 - val_loss: 0.1921 - val_acc: 0.7242\n","Epoch 2/10\n","249/249 [==============================] - 64s 258ms/step - loss: 0.1957 - acc: 0.7239 - val_loss: 0.1837 - val_acc: 0.7444\n","Epoch 3/10\n","249/249 [==============================] - 65s 259ms/step - loss: 0.1863 - acc: 0.7495 - val_loss: 0.1789 - val_acc: 0.7587\n","Epoch 4/10\n","249/249 [==============================] - 65s 260ms/step - loss: 0.1814 - acc: 0.7656 - val_loss: 0.1764 - val_acc: 0.7814\n","Epoch 5/10\n","249/249 [==============================] - 65s 260ms/step - loss: 0.1775 - acc: 0.7877 - val_loss: 0.1758 - val_acc: 0.7902\n","Epoch 6/10\n","249/249 [==============================] - 64s 257ms/step - loss: 0.1754 - acc: 0.7957 - val_loss: 0.1746 - val_acc: 0.7944\n","Epoch 7/10\n","249/249 [==============================] - 64s 258ms/step - loss: 0.1734 - acc: 0.7985 - val_loss: 0.1741 - val_acc: 0.7993\n","Epoch 8/10\n","249/249 [==============================] - 64s 256ms/step - loss: 0.1719 - acc: 0.8066 - val_loss: 0.1738 - val_acc: 0.8000\n","Epoch 9/10\n","249/249 [==============================] - 64s 256ms/step - loss: 0.1713 - acc: 0.8091 - val_loss: 0.1733 - val_acc: 0.8036\n","Epoch 10/10\n","249/249 [==============================] - 64s 259ms/step - loss: 0.1706 - acc: 0.8080 - val_loss: 0.1734 - val_acc: 0.8048\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9jb3TbirJEX6","executionInfo":{"status":"ok","timestamp":1628081151048,"user_tz":-330,"elapsed":17006,"user":{"displayName":"Sparsh Agarwal","photoUrl":"","userId":"13037694610922482904"}},"outputId":"79f6f2d4-e354-43c0-d3a6-ad432605c19d"},"source":["y_pred = np.round(model.predict(train_flow)).flatten()\n","print('Precision:', metrics.precision_score(labels_train, y_pred)) \n","print('Recall:', metrics.recall_score(labels_train, y_pred)) \n","print('F1-Score:', metrics.f1_score(labels_train, y_pred)) "],"execution_count":26,"outputs":[{"output_type":"stream","text":["Precision: 0.5053176470588235\n","Recall: 0.6761113209923183\n","F1-Score: 0.5783690617257352\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kidk_OzUJGrk","executionInfo":{"status":"ok","timestamp":1628081171676,"user_tz":-330,"elapsed":20655,"user":{"displayName":"Sparsh Agarwal","photoUrl":"","userId":"13037694610922482904"}},"outputId":"0a842f7a-362c-4d39-939b-1f3f55472167"},"source":["y_pred = np.round(model.predict(test_flow)).flatten()\n","print('Precision:', metrics.precision_score(labels_test, y_pred)) \n","print('Recall:', metrics.recall_score(labels_test, y_pred)) \n","print('F1-Score:', metrics.f1_score(labels_test, y_pred)) "],"execution_count":27,"outputs":[{"output_type":"stream","text":["Precision: 0.7233901671908625\n","Recall: 0.9905927688994673\n","F1-Score: 0.8361635972255441\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Ozq8U1ZVJRD0"},"source":["### GraphSage with features"]},{"cell_type":"code","metadata":{"id":"XFYC4CuAJPFY","executionInfo":{"status":"ok","timestamp":1628081181652,"user_tz":-330,"elapsed":10001,"user":{"displayName":"Sparsh Agarwal","photoUrl":"","userId":"13037694610922482904"}}},"source":["sg_graph_train = StellarGraph.from_networkx(graph_train, node_features=\"features\")\n","sg_graph_test = StellarGraph.from_networkx(graph_test, node_features=\"features\")\n","\n","train_gen = GraphSAGELinkGenerator(sg_graph_train, batch_size, num_samples)\n","train_flow = train_gen.flow(samples_train, labels_train, shuffle=True, seed=24)\n","\n","test_gen = GraphSAGELinkGenerator(sg_graph_test, batch_size, num_samples)\n","test_flow = test_gen.flow(samples_test, labels_test, seed=24)"],"execution_count":28,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sd9bEO_qJUL-","executionInfo":{"status":"ok","timestamp":1628081636109,"user_tz":-330,"elapsed":421915,"user":{"displayName":"Sparsh Agarwal","photoUrl":"","userId":"13037694610922482904"}},"outputId":"17923f42-2760-4287-f583-d623e4681847"},"source":["layer_sizes = [20, 20]\n","graphsage = GraphSAGE(\n","    layer_sizes=layer_sizes, generator=train_gen, bias=True, dropout=0.3\n",")\n","\n","x_inp, x_out = graphsage.in_out_tensors()\n","\n","prediction = link_classification(\n","    output_dim=1, output_act=\"sigmoid\", edge_embedding_method=\"ip\"\n",")(x_out)\n","\n","model = keras.Model(inputs=x_inp, outputs=prediction)\n","\n","model.compile(\n","    optimizer=keras.optimizers.Adam(learning_rate=1e-3),\n","    loss=keras.losses.mse,\n","    metrics=[\"acc\"],\n",")\n","\n","epochs = 10\n","history = model.fit(train_flow, epochs=epochs, validation_data=test_flow)"],"execution_count":31,"outputs":[{"output_type":"stream","text":["link_classification: using 'ip' method to combine node embeddings into edge embeddings\n","Epoch 1/10\n","249/249 [==============================] - 61s 240ms/step - loss: 0.1773 - acc: 0.8178 - val_loss: 0.1671 - val_acc: 0.8495\n","Epoch 2/10\n","249/249 [==============================] - 31s 123ms/step - loss: 0.1702 - acc: 0.8561 - val_loss: 0.1666 - val_acc: 0.8629\n","Epoch 3/10\n","249/249 [==============================] - 31s 124ms/step - loss: 0.1684 - acc: 0.8572 - val_loss: 0.1666 - val_acc: 0.8642\n","Epoch 4/10\n","249/249 [==============================] - 30s 122ms/step - loss: 0.1670 - acc: 0.8594 - val_loss: 0.1665 - val_acc: 0.8609\n","Epoch 5/10\n","249/249 [==============================] - 31s 124ms/step - loss: 0.1666 - acc: 0.8714 - val_loss: 0.1666 - val_acc: 0.8607\n","Epoch 6/10\n","249/249 [==============================] - 31s 123ms/step - loss: 0.1664 - acc: 0.8692 - val_loss: 0.1666 - val_acc: 0.8752\n","Epoch 7/10\n","249/249 [==============================] - 31s 124ms/step - loss: 0.1659 - acc: 0.8745 - val_loss: 0.1666 - val_acc: 0.8760\n","Epoch 8/10\n","249/249 [==============================] - 31s 123ms/step - loss: 0.1658 - acc: 0.8731 - val_loss: 0.1666 - val_acc: 0.8729\n","Epoch 9/10\n","249/249 [==============================] - 31s 123ms/step - loss: 0.1656 - acc: 0.8807 - val_loss: 0.1664 - val_acc: 0.8806\n","Epoch 10/10\n","249/249 [==============================] - 31s 123ms/step - loss: 0.1657 - acc: 0.8785 - val_loss: 0.1667 - val_acc: 0.8792\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JsjwnPKpJUIg","executionInfo":{"status":"ok","timestamp":1628081646152,"user_tz":-330,"elapsed":10059,"user":{"displayName":"Sparsh Agarwal","photoUrl":"","userId":"13037694610922482904"}},"outputId":"9318324e-47af-4aca-b960-dedb32d02e9f"},"source":["y_pred = np.round(model.predict(train_flow)).flatten()\n","print('Precision:', metrics.precision_score(labels_train, y_pred)) \n","print('Recall:', metrics.recall_score(labels_train, y_pred)) \n","print('F1-Score:', metrics.f1_score(labels_train, y_pred)) "],"execution_count":32,"outputs":[{"output_type":"stream","text":["Precision: 0.5031298101590559\n","Recall: 0.617428535448936\n","F1-Score: 0.5544498473368765\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"l5CwVYRGJUFA","executionInfo":{"status":"ok","timestamp":1628081656313,"user_tz":-330,"elapsed":10171,"user":{"displayName":"Sparsh Agarwal","photoUrl":"","userId":"13037694610922482904"}},"outputId":"b54c0a30-2838-4d26-9618-a7ac8b668f22"},"source":["y_pred = np.round(model.predict(test_flow)).flatten()\n","print('Precision:', metrics.precision_score(labels_test, y_pred)) \n","print('Recall:', metrics.recall_score(labels_test, y_pred)) \n","print('F1-Score:', metrics.f1_score(labels_test, y_pred)) "],"execution_count":33,"outputs":[{"output_type":"stream","text":["Precision: 0.8077488064634594\n","Recall: 0.9971664966564661\n","F1-Score: 0.8925183870149632\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"qxuv3BlRJUB0"},"source":["### Hand-crafted features"]},{"cell_type":"code","metadata":{"id":"WdJcoFLbJl-Q","executionInfo":{"status":"ok","timestamp":1628081656315,"user_tz":-330,"elapsed":38,"user":{"displayName":"Sparsh Agarwal","photoUrl":"","userId":"13037694610922482904"}}},"source":["def get_shortest_path(G,u,v):\n","  \"\"\" return the shortest path length between u,v \n","      in the graph without the edge (u,v) \"\"\"\n","  removed = False\n","  if G.has_edge(u,v):\n","    removed = True\n","    G.remove_edge(u,v) # temporary remove edge\n","  \n","  try:\n","    sp = len(nx.shortest_path(G, u, v))\n","  except:\n","    sp = 0\n","\n","  if removed:\n","    G.add_edge(u,v) # add back the edge if it was removed\n","\n","  return sp"],"execution_count":34,"outputs":[]},{"cell_type":"code","metadata":{"id":"E24d8RF_JT-t","executionInfo":{"status":"ok","timestamp":1628081747203,"user_tz":-330,"elapsed":707,"user":{"displayName":"Sparsh Agarwal","photoUrl":"","userId":"13037694610922482904"}}},"source":["def get_hc_features(G, samples_edges, labels):\n","  # precompute metrics\n","  centralities = nx.degree_centrality(G)\n","  parts = community_louvain.best_partition(G)\n","  \n","  feats = []\n","  for (u,v),l in zip(samples_edges, labels):\n","    shortest_path = get_shortest_path(G, u, v)\n","    j_coefficient = next(nx.jaccard_coefficient(G, ebunch=[(u, v)]))[-1]\n","    u_centrality = centralities[u]\n","    v_centrality = centralities[v]\n","    u_community = parts.get(u)\n","    v_community = parts.get(v)\n","    # add the feature vector\n","    feats += [[shortest_path, j_coefficient, u_centrality, v_centrality]]\n","  return feats"],"execution_count":38,"outputs":[]},{"cell_type":"code","metadata":{"id":"iYl-bcv5JT7d","executionInfo":{"status":"ok","timestamp":1628081768432,"user_tz":-330,"elapsed":21250,"user":{"displayName":"Sparsh Agarwal","photoUrl":"","userId":"13037694610922482904"}}},"source":["feat_train = get_hc_features(graph_train, samples_train, labels_train)\n","feat_test = get_hc_features(graph_test, samples_test, labels_test)"],"execution_count":39,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"r_CPrp8xJT4k","executionInfo":{"status":"ok","timestamp":1628081779817,"user_tz":-330,"elapsed":424,"user":{"displayName":"Sparsh Agarwal","photoUrl":"","userId":"13037694610922482904"}},"outputId":"fab16ffe-c6b7-4f66-be3f-c8d3eb85d952"},"source":["rf = RandomForestClassifier(n_estimators=10) \n","rf.fit(feat_train, labels_train); \n"," \n","y_pred = rf.predict(feat_test) \n","print('Precision:', metrics.precision_score(labels_test, y_pred)) \n","print('Recall:', metrics.recall_score(labels_test, y_pred)) \n","print('F1-Score:', metrics.f1_score(labels_test, y_pred)) "],"execution_count":40,"outputs":[{"output_type":"stream","text":["Precision: 0.9650459332287699\n","Recall: 0.9763119120480562\n","F1-Score: 0.9706462335906249\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"L4ZqVAYFOmfS"},"source":["## Summary of results"]},{"cell_type":"code","metadata":{"id":"QVYSnNLtPZTG"},"source":["results = pd.DataFrame(columns=['Algorithm','Embedding','Node Features',\n","                                'Precision','Recall','F1-Score'])\n","\n","idx = 0\n","while True:\n","    for col in results.columns:\n","        _col = input(f\"{col}: \")\n","        if _col=='\\stop': break\n","        results.loc[idx,col] = _col\n","    print('\\n{}\\n'.format('='*100))\n","    if _col=='\\stop': break\n","    idx+=1"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":173},"id":"NKBvqRZYPjps","executionInfo":{"status":"ok","timestamp":1628083104400,"user_tz":-330,"elapsed":459,"user":{"displayName":"Sparsh Agarwal","photoUrl":"","userId":"13037694610922482904"}},"outputId":"44c9c1e5-9d86-419e-fe75-2a47166e53a7"},"source":["results"],"execution_count":59,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Algorithm</th>\n","      <th>Embedding</th>\n","      <th>Node Features</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>F1-Score</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>node2vec</td>\n","      <td>Unsupervised</td>\n","      <td>No</td>\n","      <td>0.97</td>\n","      <td>0.96</td>\n","      <td>0.96</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>GraphSAGE</td>\n","      <td>Supervised</td>\n","      <td>No</td>\n","      <td>0.72</td>\n","      <td>0.99</td>\n","      <td>0.84</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>GraphSAGE</td>\n","      <td>Supervised</td>\n","      <td>Yes</td>\n","      <td>0.81</td>\n","      <td>0.99</td>\n","      <td>0.89</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Shallow</td>\n","      <td>Manual</td>\n","      <td>No</td>\n","      <td>0.97</td>\n","      <td>0.98</td>\n","      <td>0.97</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   Algorithm     Embedding Node Features Precision Recall F1-Score\n","0   node2vec  Unsupervised            No      0.97   0.96     0.96\n","1  GraphSAGE    Supervised            No      0.72   0.99     0.84\n","2  GraphSAGE    Supervised           Yes      0.81   0.99     0.89\n","3    Shallow        Manual            No      0.97   0.98     0.97"]},"metadata":{"tags":[]},"execution_count":59}]},{"cell_type":"markdown","metadata":{"id":"-UXCZdSzQTrN"},"source":["The node2vec-based method is already able to achieve a high level of performance without supervision and per-node information. Such high results might be related to the particular structure of the combined ego network. Due to the high sub-modularity of the network (since it is composed of several ego networks), predicting whether two users will be connected or not might be highly related to the way the two candidate nodes are connected inside the network. For example, there might be a systematic situation in which two users, both connected to several users in the same ego network, have a high chance of being connected as well. On the other hand, two users belonging to different ego networks, or very far from each other, are likely to not be connected, making the prediction task easier. This is also confirmed by the high results achieved using the shallow method."]},{"cell_type":"markdown","metadata":{"id":"5kAwJMBxQfxj"},"source":["Such a situation might be confusing, instead, for more complicated algorithms like GraphSAGE, especially when node features are involved. For example, two users might share similar interests, making them very similar. However, they might belong to different ego networks, where the corresponding ego users live in two very different parts of the world. So, similar users, which in principle should be connected, are not. However, it is also possible that such algorithms are predicting something further in the future. Recall that the combined ego network is a timestamp of a particular situation in a given period of time. Who knows how it might have evolved right now!\n","\n","Interpreting machine learning algorithms is probably the most interesting challenge of machine learning itself. For this reason, we should always interpret results with care. Our suggestion is always to dig into the dataset and try to give an explanation of your results.\n","\n","Finally, it is important to remark that each of the algorithms was not tuned for the purpose of this demonstration. Different results can be obtained by properly tuning each hyperparameter."]}]}