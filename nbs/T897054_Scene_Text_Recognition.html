
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Scene Text Recognition &#8212; Reco Book</title>
    
  <link href="../_static/css/theme.css" rel="stylesheet" />
  <link href="../_static/css/index.c5995385ac14fb8791e8eb36b4908be2.css" rel="stylesheet" />

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../_static/sphinx-book-theme.css?digest=c3fdc42140077d1ad13ad2f1588a4309" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../_static/js/index.1c5a1a01449ed65a7b51.js">

    <script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/togglebutton.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../_static/sphinx-book-theme.12a9622fbb08dcb3a2a40b2c02b83a57.js"></script>
    <script async="async" src="https://unpkg.com/thebe@0.5.1/lib/index.js"></script>
    <script >
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Large-scale Document Retrieval with ElasticSearch" href="T034809_Large_scale_Document_Retrieval_with_Elastic_Search.html" />
    <link rel="prev" title="Job scraping and clustering" href="T030890_Job_Scraping_and_Clustering.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../index.html">
      
      
      
      <h1 class="site-logo" id="site-title">Reco Book</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../index.html">
   Tutorials in Jupyter notebook format
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  User Stories
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="US780867_Transformer_based_Recommenders.html">
   Transformer-based Recommenders
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="T034923_BERT4Rec_on_ML1M_in_PyTorch.html">
     BERT4Rec on ML-1M in PyTorch
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="T595874_BERT4Rec_on_ML25M_in_PyTorch_Lightning.html">
     BERT4Rec on ML-25M
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="T088416_BST_Implementation_in_MXNet.html">
     BST Implementation in MXNet
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="T602245_BST_implementation_in_PyTorch.html">
     BST implementation in PyTorch
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="T007665_BST_on_ML1M_in_Keras.html">
     A Transformer-based recommendation system
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="T881207_BST_PTLightning_ML1M.html">
     Rating prediction using the Behavior Sequence Transformer (BST) model on ML-1M dataset in PyTorch Lightning
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="T757997_SASRec_PyTorch.html">
     SASRec implementation with PyTorch Library
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="T225287_SASRec_PaddlePaddle.html">
     SASRec implementation with Paddle Library
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="T701627_SR_SAN_Session_based_Model.html">
     SR-SAN Session-based Recommender
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="T975104_SSEPT_ML1M_Tensorflow1x.html">
     SSE-PT Personalized Transformer Recommender on ML-1M in Tensorflow 1.x
    </a>
   </li>
  </ul>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Prototypes
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="T382881_DeepWalk_Karateclub.html">
   DeepWalk from scratch referencing Karateclub library
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T384270_DeepWalk_pure_python.html">
   DeepWalk in pure python
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T677598_Jaccard_Cosine_SVD_DeepWalk_ML100K.html">
   Recommender System with DeepWalk Graph Embeddings
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T815556_Node2vec_Karateclub.html">
   Node2vec from scratch referencing Karateclub library
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T894941_Node2vec_MovieLens_Keras.html">
   Graph representation learning with node2vec
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T611050_Node2vec_PyG.html">
   Node2vec from scratch in PyTorch Geometric
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T186367_Node2vec_library.html">
   Node2vec from scratch referencing node2vec library
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T331379_bayesian_personalized_ranking.html">
   BPR from scratch
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T081831_Data_Poisoning_Attacks_on_Factorization_Based_Collaborative_Filtering.html">
   Data Poisoning Attacks on Factorization-Based Collaborative Filtering
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T102448_Adversarial_Learning_for_Recommendation.html">
   Adversarial Training (Regularization) on a Recommender System
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T865035_Simulating_Data_Poisoning_Attacks_against_Twitter_Recommender.html">
   Load and process dataset
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T711285_Data_Poisoning_Attack_using_LFM_and_ItemAE_on_Synthetic_Dataset.html">
   Injection attack using LFM and ItemAE model trained on Toy dataset
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T355514_Black_box_Attack_on_Sequential_Recs.html">
   Black-box Attack on Sequential Recs
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T873451_Statistics_fundamentals.html">
   Statictics Fundamentals
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T890478_Batch_Learning_from_Bandit_Feedback_%28BLBF%29.html">
   Imports
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T257798_Off_Policy_Learning_in_Two_stage_Recommender_Systems.html">
   Off-Policy Learning in Two-stage Recommender Systems
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T471827_Adaptive_Estimator_Selection_for_Off_Policy_Evaluation.html">
   Adaptive Estimator Selection for Off-Policy Evaluation
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T902666_Evaluating_the_Robustness_of_Off_Policy_Evaluation.html">
   Evaluating the Robustness of Off-Policy Evaluation
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T705904_Evaluation_of_Multiple_Off_Policy_Estimators_on_Synthetic_Dataset.html">
   Evaluation of Multiple Off-Policy Estimators on Synthetic Dataset
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T874693_Evaluating_Standard_Off_Policy_Estimators_with_Small_Sample_Open_Bandit_Dataset.html">
   Evaluating Standard Off-Policy Estimators with Small Sample Open-Bandit Dataset
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T792262_Optimal_Off_Policy_Evaluation_from_Multiple_Logging_Policies.html">
   Optimal Off-Policy Evaluation from Multiple Logging Policies
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T167249_Offline_Policy_Evaluation_with_VW_Command_Line.html">
   Offline Policy Evaluation with VW Command Line
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T966055_OBP_Library_Workshop_Tutorials.html">
   OBP Library Workshop Tutorials
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T632722_PyTorch_Fundamentals_Part_1.html">
   PyTorch Fundamentals Part 1
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T472467_PyTorch_Fundamentals_Part_2.html">
   PyTorch Fundamentals Part 2
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T206654_PyTorch_Fundamentals_Part_3.html">
   PyTorch Fundamentals Part 3
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T536348_Attention_Mechanisms.html">
   Imports
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T500796_Agricultural_Satellite_Image_Segmentation.html">
   Agricultural Satellite Image Segmentation
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T611432_Image_Analysis_with_Tensorflow.html">
   Image Analysis with Tensorflow
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T925716_MongoDB_to_CSV_Conversion.html">
   MongoDB to CSV conversion
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T396469_PDF_to_Word_Cloud_via_Email.html">
   PDF to WordCloud via Email
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T030890_Job_Scraping_and_Clustering.html">
   Job scraping and clustering
  </a>
 </li>
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   Scene Text Recognition
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T034809_Large_scale_Document_Retrieval_with_Elastic_Search.html">
   Large-scale Document Retrieval with ElasticSearch
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T467251_vowpal_wabbit_contextual_recommender.html">
   Simulating a news personalization scenario using Contextual Bandits
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T686684_similar_product_recommender.html">
   Similar Product Recommender system using Deep Learning for an online e-commerce store
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T132203_Retail_Product_Recommendations_using_Word2vec.html">
   Retail Product Recommendations using word2vec
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T501828_Recommender_Implicit_Negative_Feedback.html">
   Retail Product Recommendation with Negative Implicit Feedback
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T315965_Sequence_Aware_Recommenders_Music.html">
   Sequence Aware Recommender Systems
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T051777_image_similarity_recommendations.html">
   Similar Product Recommendations
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T990172_recobook_diversity_aware_book_recommender.html">
   Diversity Aware Book Recommender
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T488549_Goodreads_Diversity_Aware_Book_Recommender.html">
   Diversity Aware Book Recommender
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T023535_Kafka_MongoDB_Real_time_Streaming.html">
   Kafka MongoDB Real-time Streaming
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T622304_Session_based_Recommender_Using_Word2vec.html">
   Session-based recommendation using word2vec
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T416854_bandit_based_recommender_using_thompson_sampling_app.html">
   Bandit-based Online Learning using Thompson Sampling
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T198578_Booking_dot_com_Trip_Recommendation.html">
   Booking.com Trip Recommendation
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T519734_Vowpal_Wabbit_Contextual_Bandit.html">
   Vowpal Wabbit Contextual Bandit
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T871537_Recommendation_Systems_using_Olist_Dataset.html">
   Recommendation systems using Olist dataset
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T057885_Offline_Replayer_Evaluation.html">
   Offline Replayer Evaluation
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T915054_method_for_effective_online_testing.html">
   Methods for effective online testing
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T513987_Recsys_2020_Feature_Engineering_Tutorial.html">
   Recsys’20 Feature Engineering Tutorial
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T227901_amazon_personalize_batch_job.html">
   Amazon Personalize Batch Job
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T022961_Amazon_Personalize_Workshop.html">
   Amazon Personalize Workshop
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T424437_Collaborative_Filtering_on_ML_latest_small.html">
   Collaborative Filtering on ML-latest-small
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T539160_Building_and_Deploying_ASOS_Fashion_Recommender.html">
   Building and deploying ASOS fashion recommender
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T757697_Simple_Similarity_based_Recommender.html">
   Simple Similarity based Recommmendations
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T051594_Analytics_Zoo.html">
   Analytics Zoo
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T313645_A_B_Testing.html">
   A/B Testing
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T475711_PinSage_Graph_based_Recommender.html">
   PinSage Graph-based Recommender
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T516490_Graph_Embeddings.html">
   Learn Embeddings using Graph Networks
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T822164_movielens_milvus_redis_efficient_retrieval.html">
   Recommender with Redis and Milvus
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T845186_Anime_Recommender.html">
   RekoNet Anime Recommender
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T855843_kafka_spark_streaming_colab.html">
   Kafka and Spark Streaming in Colab
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T460437_Building_Models_From_Scratch.html">
   Building Models from scratch
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T855971_Conet_Model_for_Movie_Recommender.html">
   CoNet model
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T996996_content_based_and_collaborative_movielens.html">
   Movie Recommendation with Content-Based and Collaborative Filtering
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T239418_Simple_Movie_Recommenders.html">
   Simple Movie Recommenders
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T138337_Simple_Movie_Recommender.html">
   Simple movie recommender in implicit, explicit, and cold-start settings
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T935440_The_importance_of_Rating_Normalization.html">
   The importance of Rating Normalization
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T612622_cornac_examples.html">
   Cornac Examples
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T561435_Flower_Classification.html">
   Flower classification
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T680910_Trivago_Session_based_Recommender.html">
   Trivago Session-based Recommender
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T990000_ads_selection_using_bandits.html">
   Best Ads detection using bandit methods
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T990000_book_crossing_surprise_svd_nmf.html">
   Book-Crossing Recommendation System
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T990000_book_recommender_kubeflow.html">
   Books recommendations with Kubeflow Pipelines on Scaleway Kapsule
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T990000_build_a_kubeflow_pipeline.html">
   Build a Kubeflow Pipeline
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T990000_causal_inference.html">
   Causal Inference
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T990000_concept_embedding_nlp.html">
   Exploring Word Embeddings
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T990000_concept_neural_net.html">
   Neural Network
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T990000_concept_nlp_basics.html">
   Natural Language Processing 101
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T990000_concept_transformer_lm.html">
   TransformerLM Quick Start and Guide
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T990000_content_based_music_recommender_lyricsfreak.html">
   Content-based method for song recommendation
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T990000_evaluation_metrics_basics.html">
   Recommender System Evaluations
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T990000_implicit_synthetic.html">
   Comparing Implicit Models on Synthetic Data
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T990000_movie_recommender_tensorflow.html">
   Recommendation Systems with TensorFlow
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T990000_movie_recommender_tensorflow_sagemaker.html">
   Movie recommender using Tensorflow in Sagemaker
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T990000_movielens_eda_modeling.html">
   Movielens EDA and Modeling
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T990000_read_data_from_cassandra_into_pandas.html">
   Read Cassandra Data Snapshot as DataFrame
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T990000_rl_in_action.html">
   Reinforcement Learning fundamentals in action
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T990000_rnn_cnn_basics.html">
   Processing sequences using RNNs and CNNs
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T990000_tf_serving_in_action.html">
   TF Serving in action
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T990000_training_indexing_movie_recommender.html">
   Training and indexing movie recommender
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T207114_EduRec_MOOCCube_Course_Recommender.html">
   EduRec MOOCCube Course Recommender
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T273184_Multi_Task_Learning.html">
   Multi-task Learning
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T661108_Book_Recommender_API.html">
   Book Recommender API
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T912764_Simple_Movie_Recommender_App.html">
   Simple Movie Recommender App
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T964554_Career_Village_Questions_Recommendation.html">
   CareerVillage Questions Recommendation
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T990001_amazon_women_apparel_tfidf_word2vec.html">
   Amazon Product Recommender
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T990001_anime_recommender_graph_network.html">
   Anime Recommender with Bi-partite Graph Network
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T990001_concept_self_attention.html">
   Self-Attention
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T990001_course_recommender_svd_flask.html">
   Course Recommender with SVD based similarity
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T990001_data_mining_similarity_measures.html">
   Concept - Data Mining Similarity Measures
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T990001_jaccard_recommender.html">
   Jaccard Similarity based Recommender
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T990001_live_streamer_recommender.html">
   Live Streamer Recommender with Implicit feedback
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T990001_songs_embedding_skipgram_recommender.html">
   Song Embeddings - Skipgram Recommender
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T990001_toy_example_car_recommender_knn.html">
   Toy example - Car Recommender using KNN method
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T990001_wikirecs_recommender.html">
   WikiRecs
  </a>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../_sources/nbs/T897054_Scene_Text_Recognition.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
        title="Fullscreen mode"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        <a class="binder-button" href="https://mybinder.org/v2/gh/sparsh-ai/reco-book/main?urlpath=tree/nbs/T897054_Scene_Text_Recognition.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Launch Binder" data-toggle="tooltip"
                data-placement="left"><img class="binder-button-logo"
                    src="../_static/images/logo_binder.svg"
                    alt="Interact on binder">Binder</button></a>
        
        
        
        
    </div>
</div>

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show">
            
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="section" id="scene-text-recognition">
<h1>Scene Text Recognition<a class="headerlink" href="#scene-text-recognition" title="Permalink to this headline">¶</a></h1>
<blockquote>
<div><p>Detecting and comprehending text in images using EAST and Tesseract models</p>
</div></blockquote>
<ul class="simple">
<li><p>toc: false</p></li>
<li><p>badges: true</p></li>
<li><p>comments: false</p></li>
<li><p>categories: [SceneText, OCR, ComputerVision]</p></li>
<li><p>image:</p></li>
</ul>
<p>The EAST (which stands for Efficient and Accuracy Scene Text detection) text detector is a powerful pipeline for accurate and fast text detection. The model is an FCN (a single deep neural net) that directly predicts the bounding boxes for the words/text lines present in the input image (with arbitrary orientations), thereby eliminating unnecessary preprocessing steps (such as candidate aggregation and word partitioning). It’s only required to apply thresholding and NMS on predicted geometric shapes, as the post-processing steps. The following diagram shows the EAST pipeline:</p>
<img src='https://s3.us-west-2.amazonaws.com/secure.notion-static.com/7a64d113-319f-45d4-bd2e-f704fc23d699/Untitled.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAT73L2G45O3KS52Y5%2F20211008%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20211008T144812Z&X-Amz-Expires=86400&X-Amz-Signature=269bcbcefe0c8f7fda8c09dc0122a9c0b081dec9f84e157b735a8e76287af11a&X-Amz-SignedHeaders=host&response-content-disposition=filename%20%3D%22Untitled.png%22'><p>Optical Character Recognition (OCR)/ text recognition refers to the task of extracting text from images. In this recipe, we will use Tesseract v4 for text recognition. Tesseract v4, by default, uses an LSTM-based recognition engine. The pytesseract module just provides a wrapper over the Tesseract command-line tool (we can specify the command-line arguments with the config argument).</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>#hide-output
!pip install pytesseract
!sudo apt-get update
!sudo apt-get install tesseract-ocr
!sudo apt-get install libtesseract-dev
!pip install tesseract
!pip install tesseract-ocr
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># import the necessary packages</span>
<span class="kn">from</span> <span class="nn">imutils.object_detection</span> <span class="kn">import</span> <span class="n">non_max_suppression</span>
<span class="kn">from</span> <span class="nn">IPython.display</span> <span class="kn">import</span> <span class="n">Image</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pytesseract</span>
<span class="kn">import</span> <span class="nn">cv2</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">min_confidence</span> <span class="o">=</span> <span class="mf">0.5</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">decode_predictions</span><span class="p">(</span><span class="n">scores</span><span class="p">,</span> <span class="n">geometry</span><span class="p">):</span>
    <span class="sd">&#39;&#39;&#39;grab the number of rows and columns from the scores volume, then</span>
<span class="sd">    initialize our set of bounding box rectangles and corresponding</span>
<span class="sd">    confidence scores</span>
<span class="sd">    &#39;&#39;&#39;</span>

    <span class="p">(</span><span class="n">num_rows</span><span class="p">,</span> <span class="n">num_cols</span><span class="p">)</span> <span class="o">=</span> <span class="n">scores</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">2</span><span class="p">:</span><span class="mi">4</span><span class="p">]</span>
    <span class="n">rects</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">confidences</span> <span class="o">=</span> <span class="p">[]</span>
 
    <span class="c1"># loop over the number of rows</span>
    <span class="k">for</span> <span class="n">y</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">num_rows</span><span class="p">):</span>
        <span class="c1"># extract the scores (probabilities), followed by the</span>
        <span class="c1"># geometrical data used to derive potential bounding box</span>
        <span class="c1"># coordinates that surround text</span>
        <span class="n">scores_data</span> <span class="o">=</span> <span class="n">scores</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">y</span><span class="p">]</span>
        <span class="n">x_data0</span> <span class="o">=</span> <span class="n">geometry</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">y</span><span class="p">]</span>
        <span class="n">x_data1</span> <span class="o">=</span> <span class="n">geometry</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">y</span><span class="p">]</span>
        <span class="n">x_data2</span> <span class="o">=</span> <span class="n">geometry</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">y</span><span class="p">]</span>
        <span class="n">x_data3</span> <span class="o">=</span> <span class="n">geometry</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">y</span><span class="p">]</span>
        <span class="n">angles_data</span> <span class="o">=</span> <span class="n">geometry</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="n">y</span><span class="p">]</span>
 
        <span class="c1"># loop over the number of columns</span>
        <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">num_cols</span><span class="p">):</span>
            <span class="c1"># if our score does not have sufficient probability,</span>
            <span class="c1"># ignore it</span>
            <span class="k">if</span> <span class="n">scores_data</span><span class="p">[</span><span class="n">x</span><span class="p">]</span> <span class="o">&lt;</span> <span class="n">min_confidence</span><span class="p">:</span>
                <span class="k">continue</span>
 
            <span class="c1"># compute the offset factor as our resulting feature</span>
            <span class="c1"># maps will be 4x smaller than the input image</span>
            <span class="p">(</span><span class="n">offset_x</span><span class="p">,</span> <span class="n">offset_y</span><span class="p">)</span> <span class="o">=</span> <span class="p">(</span><span class="n">x</span> <span class="o">*</span> <span class="mf">4.0</span><span class="p">,</span> <span class="n">y</span> <span class="o">*</span> <span class="mf">4.0</span><span class="p">)</span>
 
            <span class="c1"># extract the rotation angle for the prediction and</span>
            <span class="c1"># then compute the sin and cosine</span>
            <span class="n">angle</span> <span class="o">=</span> <span class="n">angles_data</span><span class="p">[</span><span class="n">x</span><span class="p">]</span>
            <span class="n">cos</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">cos</span><span class="p">(</span><span class="n">angle</span><span class="p">)</span>
            <span class="n">sin</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">angle</span><span class="p">)</span>
 
            <span class="c1"># use the geometry volume to derive the width and height</span>
            <span class="c1"># of the bounding box</span>
            <span class="n">h</span> <span class="o">=</span> <span class="n">x_data0</span><span class="p">[</span><span class="n">x</span><span class="p">]</span> <span class="o">+</span> <span class="n">x_data2</span><span class="p">[</span><span class="n">x</span><span class="p">]</span>
            <span class="n">w</span> <span class="o">=</span> <span class="n">x_data1</span><span class="p">[</span><span class="n">x</span><span class="p">]</span> <span class="o">+</span> <span class="n">x_data3</span><span class="p">[</span><span class="n">x</span><span class="p">]</span>
 
            <span class="c1"># compute both the starting and ending (x, y)-coordinates</span>
            <span class="c1"># for the text prediction bounding box</span>
            <span class="n">end_x</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">offset_x</span> <span class="o">+</span> <span class="p">(</span><span class="n">cos</span> <span class="o">*</span> <span class="n">x_data1</span><span class="p">[</span><span class="n">x</span><span class="p">])</span> <span class="o">+</span> <span class="p">(</span><span class="n">sin</span> <span class="o">*</span> <span class="n">x_data2</span><span class="p">[</span><span class="n">x</span><span class="p">]))</span>
            <span class="n">end_y</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">offset_y</span> <span class="o">-</span> <span class="p">(</span><span class="n">sin</span> <span class="o">*</span> <span class="n">x_data1</span><span class="p">[</span><span class="n">x</span><span class="p">])</span> <span class="o">+</span> <span class="p">(</span><span class="n">cos</span> <span class="o">*</span> <span class="n">x_data2</span><span class="p">[</span><span class="n">x</span><span class="p">]))</span>
            <span class="n">start_x</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">end_x</span> <span class="o">-</span> <span class="n">w</span><span class="p">)</span>
            <span class="n">start_y</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">end_y</span> <span class="o">-</span> <span class="n">h</span><span class="p">)</span>
 
            <span class="c1"># add the bounding box coordinates and probability score</span>
            <span class="c1"># to our respective lists</span>
            <span class="n">rects</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">start_x</span><span class="p">,</span> <span class="n">start_y</span><span class="p">,</span> <span class="n">end_x</span><span class="p">,</span> <span class="n">end_y</span><span class="p">))</span>
            <span class="n">confidences</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">scores_data</span><span class="p">[</span><span class="n">x</span><span class="p">])</span>
 
    <span class="c1"># return a tuple of the bounding boxes and associated confidences</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">rects</span><span class="p">,</span> <span class="n">confidences</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span># load the input image and grab the image dimensions
!wget -O img.jpg &#39;https://images.squarespace-cdn.com/content/53fa7ec2e4b0431f98587b1f/1456357172427-ZSESVHLVMN1BCATDSXDD/image-asset.jpeg?content-type=image%2Fjpeg&#39;
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">im</span> <span class="o">=</span> <span class="s1">&#39;img.jpg&#39;</span>
<span class="n">image</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">imread</span><span class="p">(</span><span class="n">im</span><span class="p">)</span>
<span class="n">orig</span> <span class="o">=</span> <span class="n">image</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
<span class="p">(</span><span class="n">origH</span><span class="p">,</span> <span class="n">origW</span><span class="p">)</span> <span class="o">=</span> <span class="n">image</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span><span class="mi">2</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>!wget -O frozen_east_text_detection.pb https://github.com/oyyd/frozen_east_text_detection.pb/blob/master/frozen_east_text_detection.pb?raw=true
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># set the new width and height and then determine the ratio in change</span>
<span class="c1"># for both the width and height</span>
<span class="n">width</span> <span class="o">=</span> <span class="n">height</span> <span class="o">=</span> <span class="mi">32</span><span class="o">*</span><span class="mi">10</span> <span class="c1">#320</span>
<span class="p">(</span><span class="n">w</span><span class="p">,</span> <span class="n">h</span><span class="p">)</span> <span class="o">=</span> <span class="p">(</span><span class="n">width</span><span class="p">,</span> <span class="n">height</span><span class="p">)</span>
<span class="n">rW</span> <span class="o">=</span> <span class="n">origW</span> <span class="o">/</span> <span class="nb">float</span><span class="p">(</span><span class="n">w</span><span class="p">)</span>
<span class="n">rH</span> <span class="o">=</span> <span class="n">origH</span> <span class="o">/</span> <span class="nb">float</span><span class="p">(</span><span class="n">h</span><span class="p">)</span>
 
<span class="c1"># resize the image and grab the new image dimensions</span>
<span class="n">image</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">resize</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="p">(</span><span class="n">w</span><span class="p">,</span> <span class="n">h</span><span class="p">))</span>
<span class="p">(</span><span class="n">H</span><span class="p">,</span> <span class="n">W</span><span class="p">)</span> <span class="o">=</span> <span class="n">image</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span><span class="mi">2</span><span class="p">]</span>

<span class="c1"># define the two output layer names for the EAST detector model that</span>
<span class="c1"># we are interested in -- the first is the output probabilities and the</span>
<span class="c1"># second can be used to derive the bounding box coordinates of text</span>
<span class="n">layerNames</span> <span class="o">=</span> <span class="p">[</span>
    <span class="s2">&quot;feature_fusion/Conv_7/Sigmoid&quot;</span><span class="p">,</span>
    <span class="s2">&quot;feature_fusion/concat_3&quot;</span><span class="p">]</span>
 
<span class="c1"># load the pre-trained EAST text detector</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;loading EAST text detector...&quot;</span><span class="p">)</span>
<span class="n">net</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">dnn</span><span class="o">.</span><span class="n">readNet</span><span class="p">(</span><span class="s1">&#39;frozen_east_text_detection.pb&#39;</span><span class="p">)</span>

<span class="c1"># construct a blob from the image and then perform a forward pass of</span>
<span class="c1"># the model to obtain the two output layer sets</span>
<span class="n">b</span><span class="p">,</span> <span class="n">g</span><span class="p">,</span> <span class="n">r</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">image</span><span class="p">[</span><span class="o">...</span><span class="p">,</span><span class="mi">0</span><span class="p">]),</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">image</span><span class="p">[</span><span class="o">...</span><span class="p">,</span><span class="mi">1</span><span class="p">]),</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">image</span><span class="p">[</span><span class="o">...</span><span class="p">,</span><span class="mi">2</span><span class="p">])</span>
<span class="n">blob</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">dnn</span><span class="o">.</span><span class="n">blobFromImage</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="p">(</span><span class="n">W</span><span class="p">,</span> <span class="n">H</span><span class="p">),</span> <span class="p">(</span><span class="n">b</span><span class="p">,</span> <span class="n">g</span><span class="p">,</span> <span class="n">r</span><span class="p">),</span> <span class="n">swapRB</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">crop</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">net</span><span class="o">.</span><span class="n">setInput</span><span class="p">(</span><span class="n">blob</span><span class="p">)</span>
<span class="p">(</span><span class="n">scores</span><span class="p">,</span> <span class="n">geometry</span><span class="p">)</span> <span class="o">=</span> <span class="n">net</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">layerNames</span><span class="p">)</span>
 
<span class="c1"># decode the predictions, then  apply non-maxima suppression to</span>
<span class="c1"># suppress weak, overlapping bounding boxes</span>
<span class="p">(</span><span class="n">rects</span><span class="p">,</span> <span class="n">confidences</span><span class="p">)</span> <span class="o">=</span> <span class="n">decode_predictions</span><span class="p">(</span><span class="n">scores</span><span class="p">,</span> <span class="n">geometry</span><span class="p">)</span>
<span class="n">boxes</span> <span class="o">=</span> <span class="n">non_max_suppression</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">rects</span><span class="p">),</span> <span class="n">probs</span><span class="o">=</span><span class="n">confidences</span><span class="p">)</span>

<span class="n">padding</span> <span class="o">=</span> <span class="mf">0.001</span> <span class="c1">#0.01 #0.5</span>
<span class="c1"># initialize the list of results</span>
<span class="n">results</span> <span class="o">=</span> <span class="p">[]</span>
 
<span class="c1"># loop over the bounding boxes</span>
<span class="k">for</span> <span class="p">(</span><span class="n">start_x</span><span class="p">,</span> <span class="n">start_y</span><span class="p">,</span> <span class="n">end_x</span><span class="p">,</span> <span class="n">end_y</span><span class="p">)</span> <span class="ow">in</span> <span class="n">boxes</span><span class="p">:</span>
    <span class="c1"># scale the bounding box coordinates based on the respective ratios</span>
    <span class="n">start_x</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">start_x</span> <span class="o">*</span> <span class="n">rW</span><span class="p">)</span>
    <span class="n">start_y</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">start_y</span> <span class="o">*</span> <span class="n">rH</span><span class="p">)</span>
    <span class="n">end_x</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">end_x</span> <span class="o">*</span> <span class="n">rW</span><span class="p">)</span>
    <span class="n">end_y</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">end_y</span> <span class="o">*</span> <span class="n">rH</span><span class="p">)</span>

    <span class="c1"># in order to obtain a better OCR of the text we can potentially</span>
    <span class="c1"># apply a bit of padding surrounding the bounding box -- here we</span>
    <span class="c1"># are computing the deltas in both the x and y directions</span>
    <span class="n">dX</span> <span class="o">=</span> <span class="nb">int</span><span class="p">((</span><span class="n">end_x</span> <span class="o">-</span> <span class="n">start_x</span><span class="p">)</span> <span class="o">*</span> <span class="n">padding</span><span class="p">)</span>
    <span class="n">dY</span> <span class="o">=</span> <span class="nb">int</span><span class="p">((</span><span class="n">end_y</span> <span class="o">-</span> <span class="n">start_y</span><span class="p">)</span> <span class="o">*</span> <span class="n">padding</span><span class="p">)</span>

    <span class="c1"># apply padding to each side of the bounding box, respectively</span>
    <span class="n">start_x</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">start_x</span> <span class="o">-</span> <span class="n">dX</span><span class="o">*</span><span class="mi">2</span><span class="p">)</span>
    <span class="n">start_y</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">start_y</span> <span class="o">-</span> <span class="n">dY</span><span class="o">*</span><span class="mi">2</span><span class="p">)</span>
    <span class="n">end_x</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="n">origW</span><span class="p">,</span> <span class="n">end_x</span> <span class="o">+</span> <span class="p">(</span><span class="n">dX</span> <span class="o">*</span> <span class="mi">2</span><span class="p">))</span>
    <span class="n">end_y</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="n">origH</span><span class="p">,</span> <span class="n">end_y</span> <span class="o">+</span> <span class="p">(</span><span class="n">dY</span> <span class="o">*</span> <span class="mi">2</span><span class="p">))</span>

    <span class="c1"># extract the actual padded ROI</span>
    <span class="n">roi</span> <span class="o">=</span> <span class="n">orig</span><span class="p">[</span><span class="n">start_y</span><span class="p">:</span><span class="n">end_y</span><span class="p">,</span> <span class="n">start_x</span><span class="p">:</span><span class="n">end_x</span><span class="p">]</span>

    <span class="c1"># in order to apply Tesseract v4 to OCR text we must supply</span>
    <span class="c1"># (1) a language, (2) an OEM flag of 4, indicating that the we</span>
    <span class="c1"># wish to use the LSTM neural net model for OCR, and finally</span>
    <span class="c1"># (3) an OEM value, in this case, 7 which implies that we are</span>
    <span class="c1"># treating the ROI as a single line of text</span>
    <span class="n">config</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;-l eng --oem 1 --psm 11&quot;</span><span class="p">)</span>
    <span class="n">text</span> <span class="o">=</span> <span class="n">pytesseract</span><span class="o">.</span><span class="n">image_to_string</span><span class="p">(</span><span class="n">roi</span><span class="p">,</span> <span class="n">config</span><span class="o">=</span><span class="n">config</span><span class="p">)</span>
    <span class="c1">#print(text)</span>

    <span class="c1"># add the bounding box coordinates and OCR&#39;d text to the list</span>
    <span class="c1"># of results</span>
    <span class="n">results</span><span class="o">.</span><span class="n">append</span><span class="p">(((</span><span class="n">start_x</span><span class="p">,</span> <span class="n">start_y</span><span class="p">,</span> <span class="n">end_x</span><span class="p">,</span> <span class="n">end_y</span><span class="p">),</span> <span class="n">text</span><span class="p">))</span>

    <span class="c1"># sort the results bounding box coordinates from top to bottom</span>
    <span class="n">results</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">results</span><span class="p">,</span> <span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">r</span><span class="p">:</span><span class="n">r</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">1</span><span class="p">])</span>
 
<span class="nb">print</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">results</span><span class="p">))</span>
<span class="c1"># loop over the results</span>
<span class="n">output</span> <span class="o">=</span> <span class="n">orig</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
<span class="n">i</span> <span class="o">=</span> <span class="mi">1</span>
<span class="k">for</span> <span class="p">((</span><span class="n">start_x</span><span class="p">,</span> <span class="n">start_y</span><span class="p">,</span> <span class="n">end_x</span><span class="p">,</span> <span class="n">end_y</span><span class="p">),</span> <span class="n">text</span><span class="p">)</span> <span class="ow">in</span> <span class="n">results</span><span class="p">:</span>
    <span class="c1"># display the text OCR&#39;d by Tesseract</span>
    <span class="c1">#print(&quot;OCR TEXT&quot;)</span>
    <span class="c1">#print(&quot;========&quot;)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>

    <span class="c1"># strip out non-ASCII text so we can draw the text on the image</span>
    <span class="c1"># using OpenCV, then draw the text and a bounding box surrounding</span>
    <span class="c1"># the text region of the input image</span>
    <span class="n">text</span> <span class="o">=</span> <span class="s2">&quot;&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">([</span><span class="n">c</span> <span class="k">if</span> <span class="nb">ord</span><span class="p">(</span><span class="n">c</span><span class="p">)</span> <span class="o">&lt;</span> <span class="mi">128</span> <span class="k">else</span> <span class="s2">&quot;&quot;</span> <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="n">text</span><span class="p">])</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span>
    <span class="n">cv2</span><span class="o">.</span><span class="n">rectangle</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="p">(</span><span class="n">start_x</span><span class="p">,</span> <span class="n">start_y</span><span class="p">),</span> <span class="p">(</span><span class="n">end_x</span><span class="p">,</span> <span class="n">end_y</span><span class="p">),</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">255</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span> <span class="mi">2</span><span class="p">)</span>
    <span class="n">cv2</span><span class="o">.</span><span class="n">putText</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">text</span><span class="p">,</span> <span class="p">(</span><span class="n">start_x</span><span class="p">,</span> <span class="n">start_y</span> <span class="o">-</span> <span class="mi">20</span><span class="p">),</span> <span class="n">cv2</span><span class="o">.</span><span class="n">FONT_HERSHEY_SIMPLEX</span><span class="p">,</span> <span class="mf">1.2</span><span class="p">,</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">255</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span> <span class="mi">3</span><span class="p">)</span>

    <span class="c1"># show the output image</span>
    <span class="n">i</span> <span class="o">+=</span> <span class="mi">1</span>
    
<span class="n">cv2</span><span class="o">.</span><span class="n">imwrite</span><span class="p">(</span><span class="s2">&quot;text_&quot;</span> <span class="o">+</span> <span class="n">im</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;/&#39;</span><span class="p">)[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">output</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>loading EAST text detector...
3
TOW

VOU

OV?

</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>True
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Image</span><span class="p">(</span><span class="n">filename</span><span class="o">=</span><span class="s1">&#39;text_img.jpg&#39;</span><span class="p">)</span> 
</pre></div>
</div>
</div>
</div>
<img src='https://s3.us-west-2.amazonaws.com/secure.notion-static.com/209cb2fa-2057-4234-b014-1105877e214b/Untitled.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAT73L2G45O3KS52Y5%2F20211008%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20211008T144842Z&X-Amz-Expires=86400&X-Amz-Signature=3049714221190a169cd517b92d4bf15339b07863670766028acf4f5ed3623f9d&X-Amz-SignedHeaders=host&response-content-disposition=filename%20%3D%22Untitled.png%22'><p>Learn more:</p>
<ul class="simple">
<li><p><a class="reference external" href="https://www.notion.so/knowledgetree/Scene-Text-Recognition-bea147a555fe41dbbe2ab884a00521ae">https://www.notion.so/knowledgetree/Scene-Text-Recognition-bea147a555fe41dbbe2ab884a00521ae</a></p></li>
</ul>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./nbs"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        
            



<div class='prev-next-bottom'>
    
    <div id="prev">
        <a class="left-prev" href="T030890_Job_Scraping_and_Clustering.html" title="previous page">
            <i class="prevnext-label fas fa-angle-left"></i>
            <div class="prevnext-info">
                <p class="prevnext-label">previous</p>
                <p class="prevnext-title">Job scraping and clustering</p>
            </div>
        </a>
    </div>
     <div id="next">
        <a class="right-next" href="T034809_Large_scale_Document_Retrieval_with_Elastic_Search.html" title="next page">
            <div class="prevnext-info">
                <p class="prevnext-label">next</p>
                <p class="prevnext-title">Large-scale Document Retrieval with ElasticSearch</p>
            </div>
            <i class="prevnext-label fas fa-angle-right"></i>
        </a>
     </div>

</div>
        
        </div>
    </div>
    <footer class="footer">
    <div class="container">
      <p>
        
          By Sparsh A.<br/>
        
            &copy; Copyright 2021.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>
  
  <script src="../_static/js/index.1c5a1a01449ed65a7b51.js"></script>

  
  </body>
</html>