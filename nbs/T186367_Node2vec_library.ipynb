{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "T186367 | Node2vec from scratch referencing node2vec library",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOJhwnRdgEGDGV7g0iM58aP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sparsh-ai/reco-book/blob/stage/nbs/T186367_Node2vec_library.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ArIg70Fv6l4b"
      },
      "source": [
        "# Node2vec from scratch referencing node2vec library"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p9zIhcDP6Mu0"
      },
      "source": [
        "## Codebase"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "InamF9NZ6Mr-"
      },
      "source": [
        "import os\n",
        "import random\n",
        "from collections import defaultdict\n",
        "\n",
        "import gensim\n",
        "import networkx as nx\n",
        "import numpy as np\n",
        "import pkg_resources\n",
        "from joblib import Parallel, delayed\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "from abc import ABC, abstractmethod\n",
        "from functools import reduce\n",
        "from itertools import combinations_with_replacement\n",
        "\n",
        "from gensim.models import KeyedVectors"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TkKUFZJa6Moy"
      },
      "source": [
        "def parallel_generate_walks(d_graph: dict, global_walk_length: int, num_walks: int, cpu_num: int,\n",
        "                            sampling_strategy: dict = None, num_walks_key: str = None, walk_length_key: str = None,\n",
        "                            neighbors_key: str = None, probabilities_key: str = None, first_travel_key: str = None,\n",
        "                            quiet: bool = False) -> list:\n",
        "    \"\"\"\n",
        "    Generates the random walks which will be used as the skip-gram input.\n",
        "    :return: List of walks. Each walk is a list of nodes.\n",
        "    \"\"\"\n",
        "\n",
        "    walks = list()\n",
        "\n",
        "    if not quiet:\n",
        "        pbar = tqdm(total=num_walks, desc='Generating walks (CPU: {})'.format(cpu_num))\n",
        "\n",
        "    for n_walk in range(num_walks):\n",
        "\n",
        "        # Update progress bar\n",
        "        if not quiet:\n",
        "            pbar.update(1)\n",
        "\n",
        "        # Shuffle the nodes\n",
        "        shuffled_nodes = list(d_graph.keys())\n",
        "        random.shuffle(shuffled_nodes)\n",
        "\n",
        "        # Start a random walk from every node\n",
        "        for source in shuffled_nodes:\n",
        "\n",
        "            # Skip nodes with specific num_walks\n",
        "            if source in sampling_strategy and \\\n",
        "                    num_walks_key in sampling_strategy[source] and \\\n",
        "                    sampling_strategy[source][num_walks_key] <= n_walk:\n",
        "                continue\n",
        "\n",
        "            # Start walk\n",
        "            walk = [source]\n",
        "\n",
        "            # Calculate walk length\n",
        "            if source in sampling_strategy:\n",
        "                walk_length = sampling_strategy[source].get(walk_length_key, global_walk_length)\n",
        "            else:\n",
        "                walk_length = global_walk_length\n",
        "\n",
        "            # Perform walk\n",
        "            while len(walk) < walk_length:\n",
        "\n",
        "                walk_options = d_graph[walk[-1]].get(neighbors_key, None)\n",
        "\n",
        "                # Skip dead end nodes\n",
        "                if not walk_options:\n",
        "                    break\n",
        "\n",
        "                if len(walk) == 1:  # For the first step\n",
        "                    probabilities = d_graph[walk[-1]][first_travel_key]\n",
        "                    walk_to = np.random.choice(walk_options, size=1, p=probabilities)[0]\n",
        "                else:\n",
        "                    probabilities = d_graph[walk[-1]][probabilities_key][walk[-2]]\n",
        "                    walk_to = np.random.choice(walk_options, size=1, p=probabilities)[0]\n",
        "\n",
        "                walk.append(walk_to)\n",
        "\n",
        "            walk = list(map(str, walk))  # Convert all to strings\n",
        "\n",
        "            walks.append(walk)\n",
        "\n",
        "    if not quiet:\n",
        "        pbar.close()\n",
        "\n",
        "    return walks"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tp_zpf6h62lz"
      },
      "source": [
        "class Node2Vec:\n",
        "    FIRST_TRAVEL_KEY = 'first_travel_key'\n",
        "    PROBABILITIES_KEY = 'probabilities'\n",
        "    NEIGHBORS_KEY = 'neighbors'\n",
        "    WEIGHT_KEY = 'weight'\n",
        "    NUM_WALKS_KEY = 'num_walks'\n",
        "    WALK_LENGTH_KEY = 'walk_length'\n",
        "    P_KEY = 'p'\n",
        "    Q_KEY = 'q'\n",
        "\n",
        "    def __init__(self, graph: nx.Graph, dimensions: int = 128, walk_length: int = 80, num_walks: int = 10, p: float = 1,\n",
        "                 q: float = 1, weight_key: str = 'weight', workers: int = 1, sampling_strategy: dict = None,\n",
        "                 quiet: bool = False, temp_folder: str = None, seed: int = None):\n",
        "        \"\"\"\n",
        "        Initiates the Node2Vec object, precomputes walking probabilities and generates the walks.\n",
        "        :param graph: Input graph\n",
        "        :param dimensions: Embedding dimensions (default: 128)\n",
        "        :param walk_length: Number of nodes in each walk (default: 80)\n",
        "        :param num_walks: Number of walks per node (default: 10)\n",
        "        :param p: Return hyper parameter (default: 1)\n",
        "        :param q: Inout parameter (default: 1)\n",
        "        :param weight_key: On weighted graphs, this is the key for the weight attribute (default: 'weight')\n",
        "        :param workers: Number of workers for parallel execution (default: 1)\n",
        "        :param sampling_strategy: Node specific sampling strategies, supports setting node specific 'q', 'p', 'num_walks' and 'walk_length'.\n",
        "        :param seed: Seed for the random number generator.\n",
        "        Use these keys exactly. If not set, will use the global ones which were passed on the object initialization\n",
        "        :param temp_folder: Path to folder with enough space to hold the memory map of self.d_graph (for big graphs); to be passed joblib.Parallel.temp_folder\n",
        "        \"\"\"\n",
        "\n",
        "        self.graph = graph\n",
        "        self.dimensions = dimensions\n",
        "        self.walk_length = walk_length\n",
        "        self.num_walks = num_walks\n",
        "        self.p = p\n",
        "        self.q = q\n",
        "        self.weight_key = weight_key\n",
        "        self.workers = workers\n",
        "        self.quiet = quiet\n",
        "        self.d_graph = defaultdict(dict)\n",
        "\n",
        "        if sampling_strategy is None:\n",
        "            self.sampling_strategy = {}\n",
        "        else:\n",
        "            self.sampling_strategy = sampling_strategy\n",
        "\n",
        "        self.temp_folder, self.require = None, None\n",
        "        if temp_folder:\n",
        "            if not os.path.isdir(temp_folder):\n",
        "                raise NotADirectoryError(\"temp_folder does not exist or is not a directory. ({})\".format(temp_folder))\n",
        "\n",
        "            self.temp_folder = temp_folder\n",
        "            self.require = \"sharedmem\"\n",
        "\n",
        "        if seed is not None:\n",
        "            random.seed(seed)\n",
        "            np.random.seed(seed)\n",
        "\n",
        "        self._precompute_probabilities()\n",
        "        self.walks = self._generate_walks()\n",
        "\n",
        "    def _precompute_probabilities(self):\n",
        "        \"\"\"\n",
        "        Precomputes transition probabilities for each node.\n",
        "        \"\"\"\n",
        "\n",
        "        d_graph = self.d_graph\n",
        "\n",
        "        nodes_generator = self.graph.nodes() if self.quiet \\\n",
        "            else tqdm(self.graph.nodes(), desc='Computing transition probabilities')\n",
        "\n",
        "        for source in nodes_generator:\n",
        "\n",
        "            # Init probabilities dict for first travel\n",
        "            if self.PROBABILITIES_KEY not in d_graph[source]:\n",
        "                d_graph[source][self.PROBABILITIES_KEY] = dict()\n",
        "\n",
        "            for current_node in self.graph.neighbors(source):\n",
        "\n",
        "                # Init probabilities dict\n",
        "                if self.PROBABILITIES_KEY not in d_graph[current_node]:\n",
        "                    d_graph[current_node][self.PROBABILITIES_KEY] = dict()\n",
        "\n",
        "                unnormalized_weights = list()\n",
        "                d_neighbors = list()\n",
        "\n",
        "                # Calculate unnormalized weights\n",
        "                for destination in self.graph.neighbors(current_node):\n",
        "\n",
        "                    p = self.sampling_strategy[current_node].get(self.P_KEY,\n",
        "                                                                 self.p) if current_node in self.sampling_strategy else self.p\n",
        "                    q = self.sampling_strategy[current_node].get(self.Q_KEY,\n",
        "                                                                 self.q) if current_node in self.sampling_strategy else self.q\n",
        "\n",
        "                    if destination == source:  # Backwards probability\n",
        "                        ss_weight = self.graph[current_node][destination].get(self.weight_key, 1) * 1 / p\n",
        "                    elif destination in self.graph[source]:  # If the neighbor is connected to the source\n",
        "                        ss_weight = self.graph[current_node][destination].get(self.weight_key, 1)\n",
        "                    else:\n",
        "                        ss_weight = self.graph[current_node][destination].get(self.weight_key, 1) * 1 / q\n",
        "\n",
        "                    # Assign the unnormalized sampling strategy weight, normalize during random walk\n",
        "                    unnormalized_weights.append(ss_weight)\n",
        "                    d_neighbors.append(destination)\n",
        "\n",
        "                # Normalize\n",
        "                unnormalized_weights = np.array(unnormalized_weights)\n",
        "                d_graph[current_node][self.PROBABILITIES_KEY][\n",
        "                    source] = unnormalized_weights / unnormalized_weights.sum()\n",
        "\n",
        "            # Calculate first_travel weights for source\n",
        "            first_travel_weights = []\n",
        "\n",
        "            for destination in self.graph.neighbors(source):\n",
        "                first_travel_weights.append(self.graph[source][destination].get(self.weight_key, 1))\n",
        "\n",
        "            first_travel_weights = np.array(first_travel_weights)\n",
        "            d_graph[source][self.FIRST_TRAVEL_KEY] = first_travel_weights / first_travel_weights.sum()\n",
        "\n",
        "            # Save neighbors\n",
        "            d_graph[source][self.NEIGHBORS_KEY] = list(self.graph.neighbors(source))\n",
        "\n",
        "    def _generate_walks(self) -> list:\n",
        "        \"\"\"\n",
        "        Generates the random walks which will be used as the skip-gram input.\n",
        "        :return: List of walks. Each walk is a list of nodes.\n",
        "        \"\"\"\n",
        "\n",
        "        flatten = lambda l: [item for sublist in l for item in sublist]\n",
        "\n",
        "        # Split num_walks for each worker\n",
        "        num_walks_lists = np.array_split(range(self.num_walks), self.workers)\n",
        "\n",
        "        walk_results = Parallel(n_jobs=self.workers, temp_folder=self.temp_folder, require=self.require)(\n",
        "            delayed(parallel_generate_walks)(self.d_graph,\n",
        "                                             self.walk_length,\n",
        "                                             len(num_walks),\n",
        "                                             idx,\n",
        "                                             self.sampling_strategy,\n",
        "                                             self.NUM_WALKS_KEY,\n",
        "                                             self.WALK_LENGTH_KEY,\n",
        "                                             self.NEIGHBORS_KEY,\n",
        "                                             self.PROBABILITIES_KEY,\n",
        "                                             self.FIRST_TRAVEL_KEY,\n",
        "                                             self.quiet) for\n",
        "            idx, num_walks\n",
        "            in enumerate(num_walks_lists, 1))\n",
        "\n",
        "        walks = flatten(walk_results)\n",
        "\n",
        "        return walks\n",
        "\n",
        "    def fit(self, **skip_gram_params) -> gensim.models.Word2Vec:\n",
        "        \"\"\"\n",
        "        Creates the embeddings using gensim's Word2Vec.\n",
        "        :param skip_gram_params: Parameters for gensim.models.Word2Vec - do not supply 'size' / 'vector_size' it is\n",
        "            taken from the Node2Vec 'dimensions' parameter\n",
        "        :type skip_gram_params: dict\n",
        "        :return: A gensim word2vec model\n",
        "        \"\"\"\n",
        "\n",
        "        if 'workers' not in skip_gram_params:\n",
        "            skip_gram_params['workers'] = self.workers\n",
        "\n",
        "        # Figure out gensim version, naming of output dimensions changed from size to vector_size in v4.0.0\n",
        "        gensim_version = pkg_resources.get_distribution(\"gensim\").version\n",
        "        size = 'size' if gensim_version < '4.0.0' else 'vector_size'\n",
        "        if size not in skip_gram_params:\n",
        "            skip_gram_params[size] = self.dimensions\n",
        "\n",
        "        if 'sg' not in skip_gram_params:\n",
        "            skip_gram_params['sg'] = 1\n",
        "\n",
        "        return gensim.models.Word2Vec(self.walks, **skip_gram_params)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8W-kDDU96hhO"
      },
      "source": [
        "class EdgeEmbedder(ABC):\n",
        "    INDEX_MAPPING_KEY = 'index2word' if pkg_resources.get_distribution(\"gensim\").version < '4.0.0' else 'index_to_key'\n",
        "\n",
        "    def __init__(self, keyed_vectors: KeyedVectors, quiet: bool = False):\n",
        "        \"\"\"\n",
        "        :param keyed_vectors: KeyedVectors containing nodes and embeddings to calculate edges for\n",
        "        \"\"\"\n",
        "\n",
        "        self.kv = keyed_vectors\n",
        "        self.quiet = quiet\n",
        "\n",
        "    @abstractmethod\n",
        "    def _embed(self, edge: tuple) -> np.ndarray:\n",
        "        \"\"\"\n",
        "        Abstract method for implementing the embedding method\n",
        "        :param edge: tuple of two nodes\n",
        "        :return: Edge embedding\n",
        "        \"\"\"\n",
        "        pass\n",
        "\n",
        "    def __getitem__(self, edge) -> np.ndarray:\n",
        "        if not isinstance(edge, tuple) or not len(edge) == 2:\n",
        "            raise ValueError('edge must be a tuple of two nodes')\n",
        "\n",
        "        if edge[0] not in getattr(self.kv, self.INDEX_MAPPING_KEY):\n",
        "            raise KeyError('node {} does not exist in given KeyedVectors'.format(edge[0]))\n",
        "\n",
        "        if edge[1] not in getattr(self.kv, self.INDEX_MAPPING_KEY):\n",
        "            raise KeyError('node {} does not exist in given KeyedVectors'.format(edge[1]))\n",
        "\n",
        "        return self._embed(edge)\n",
        "\n",
        "    def as_keyed_vectors(self) -> KeyedVectors:\n",
        "        \"\"\"\n",
        "        Generated a KeyedVectors instance with all the possible edge embeddings\n",
        "        :return: Edge embeddings\n",
        "        \"\"\"\n",
        "\n",
        "        edge_generator = combinations_with_replacement(getattr(self.kv, self.INDEX_MAPPING_KEY), r=2)\n",
        "\n",
        "        if not self.quiet:\n",
        "            vocab_size = len(getattr(self.kv, self.INDEX_MAPPING_KEY))\n",
        "            total_size = reduce(lambda x, y: x * y, range(1, vocab_size + 2)) / \\\n",
        "                         (2 * reduce(lambda x, y: x * y, range(1, vocab_size)))\n",
        "\n",
        "            edge_generator = tqdm(edge_generator, desc='Generating edge features', total=total_size)\n",
        "\n",
        "        # Generate features\n",
        "        tokens = []\n",
        "        features = []\n",
        "        for edge in edge_generator:\n",
        "            token = str(tuple(sorted(edge)))\n",
        "            embedding = self._embed(edge)\n",
        "\n",
        "            tokens.append(token)\n",
        "            features.append(embedding)\n",
        "\n",
        "        # Build KV instance\n",
        "        edge_kv = KeyedVectors(vector_size=self.kv.vector_size)\n",
        "        if pkg_resources.get_distribution(\"gensim\").version < '4.0.0':\n",
        "            edge_kv.add(\n",
        "                entities=tokens,\n",
        "                weights=features)\n",
        "        else:\n",
        "            edge_kv.add_vectors(\n",
        "                keys=tokens,\n",
        "                weights=features)\n",
        "\n",
        "        return edge_kv\n",
        "\n",
        "\n",
        "class AverageEmbedder(EdgeEmbedder):\n",
        "    \"\"\"\n",
        "    Average node features\n",
        "    \"\"\"\n",
        "\n",
        "    def _embed(self, edge: tuple):\n",
        "        return (self.kv[edge[0]] + self.kv[edge[1]]) / 2\n",
        "\n",
        "\n",
        "class HadamardEmbedder(EdgeEmbedder):\n",
        "    \"\"\"\n",
        "    Hadamard product node features\n",
        "    \"\"\"\n",
        "\n",
        "    def _embed(self, edge: tuple):\n",
        "        return self.kv[edge[0]] * self.kv[edge[1]]\n",
        "\n",
        "\n",
        "class WeightedL1Embedder(EdgeEmbedder):\n",
        "    \"\"\"\n",
        "    Weighted L1 node features\n",
        "    \"\"\"\n",
        "\n",
        "    def _embed(self, edge: tuple):\n",
        "        return np.abs(self.kv[edge[0]] - self.kv[edge[1]])\n",
        "\n",
        "\n",
        "class WeightedL2Embedder(EdgeEmbedder):\n",
        "    \"\"\"\n",
        "    Weighted L2 node features\n",
        "    \"\"\"\n",
        "\n",
        "    def _embed(self, edge: tuple):\n",
        "        return (self.kv[edge[0]] - self.kv[edge[1]]) ** 2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ViE6NF85xEN"
      },
      "source": [
        "## Scenario"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HUWh2hZC6KNm"
      },
      "source": [
        "# Create a graph\n",
        "graph = nx.fast_gnp_random_graph(n=100, p=0.5)\n",
        "\n",
        "# Precompute probabilities and generate walks - **ON WINDOWS ONLY WORKS WITH workers=1**\n",
        "node2vec = Node2Vec(graph, dimensions=64, walk_length=30, num_walks=200, workers=4)  # Use temp_folder for big graphs\n",
        "\n",
        "# Embed nodes\n",
        "model = node2vec.fit(window=10, min_count=1, batch_words=4)  # Any keywords acceptable by gensim.Word2Vec can be passed, `dimensions` and `workers` are automatically passed (from the Node2Vec constructor)\n",
        "\n",
        "# Look for most similar nodes\n",
        "model.wv.most_similar('2')  # Output node names are always strings\n",
        "\n",
        "# Save embeddings for later use\n",
        "model.wv.save_word2vec_format('embeddings.p')\n",
        "\n",
        "# Save model for later use\n",
        "model.save('model.p')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZbJC2AMX66GR"
      },
      "source": [
        "edges_embs = HadamardEmbedder(keyed_vectors=model.wv)\n",
        "\n",
        "# Look for embeddings on the fly - here we pass normal tuples\n",
        "edges_embs[('1', '2')]\n",
        "''' OUTPUT\n",
        "array([ 5.75068220e-03, -1.10937878e-02,  3.76693785e-01,  2.69105062e-02,\n",
        "       ... ... ....\n",
        "       ..................................................................],\n",
        "      dtype=float32)\n",
        "'''\n",
        "\n",
        "# Get all edges in a separate KeyedVectors instance - use with caution could be huge for big networks\n",
        "edges_kv = edges_embs.as_keyed_vectors()\n",
        "\n",
        "# Look for most similar edges - this time tuples must be sorted and as str\n",
        "edges_kv.most_similar(str(('1', '2')))\n",
        "\n",
        "# Save embeddings for later use\n",
        "edges_kv.save_word2vec_format('edge_embeddings.p')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "13C-IDZWA5Gc"
      },
      "source": [
        "![image.png](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAA9kAAAAtCAYAAAC6X6h4AAASUUlEQVR4Ae2dy44lRxGG/Vj9AmMxFtis7J0t5J0tNPIeNPYL9Pgie4HEdloajAcjmbNANggWZtQzNhZugWEFEpYQAh6hUGRVZP0RdTm3Gnuqz7doddapqsjIyO9E5J+n+vRTZ2dnDT/EAAZgAAZgAAZgAAZgAAZgAAZgAAaOZ+Apgnh8EIkhMYQBGIABGIABGIABGIABGIABGDAGENl8ks+TDDAAAzAAAzAAAzAAAzAAAzAAAwsxgMheKJDsWrFrBQMwAAMwAAMwAAMwAAMwAAMwgMhGZLNjBQMwAAMwAAMwAAMwAAMwAAMwsBADiOyFAsmOFTtWMAADMAADMAADMAADMAADMAADiGxENjtWMAADMAADMAADMAADMAADMAADCzGAyF4okOxYsWMFAzAAAzAAAzAAAzAAAzAAAzCAyEZks2MFAzAAAzAAAzAAAzAAAzAAAzCwEAMHi+wb3/le84Mf/qj58Vs/a96897D8WNtes3Ps4LCDAwMwAAMwAAMwAAMwAAMwAAMwcGoM7C2yb9x8trn9zgfNOz//fPbHrrFrTy2gjJckAgMwAAMwAAMwAAMwAAMwAAOny8BeIvuFl16dFdZjwtvuAbDTBYy5Z+5hAAZgAAZgAAZgAAZgAAZOiYGdRfaUwP7o0783D//yn/Jj7TGh/fyLryC0F3q+/5TgZKwkYxiAARiAARiAARiAARiAgbUxsJPItse+x8SzierP//q/8DMltJ9+5jmENkIbBmAABmAABmAABmAABmAABmDgWjOwk8ie+hts+wQ7i2x7bUyQv/Heh9c6kGvbXcHf9e4Ifvf+9xt+iAEMwMAaGKDWrLfWMHfMHQzAAAwczsBWkW3fFD4mmu21MZF9+edxkW3X37jJp9nAejisxK6N3RoW1viIAIQBGDAGyNvUPBiAARiAgVNkYKvItn/JNSWy93lc3Gy8fOs2BZdHQ2DgSAYQL4gXGICBtTBwigsrxoyggAEYgAEY2Cqy7X9fT4lse92E9rYvPvP7X3/3PgLrSIHFm5Y37VoW1/iJEIQBGKBmUbNgAAZgAAZOkYGtIvvNew9nRbYL6F1+v/3+o4VF9q3m4sFVc3XV/1zevbVwHwu/MV67aC6vLpuL1xa2u4d4v3X3srl6cNHc2uOe7W8OmYvN+ZM9B4eO+85mJG7nzabyt2nOg+2Zc4WDltvAbHk924msIFwQLjAAA2thYLR2WC6tedPyYKyJ55u+pm/uaP6TOuP3S70pta17PeTVLi+b3dbevJ0zyc+DWnmw7zoOa8/UB60jtb8+RrPjnPNd7Z6dNUvZyXO8mN25scydS+OM/mnccw3ewkW1215XGatz1HNb+J5gc8BUtRvnxGzM8V/7PztryntG+otjbu3q9fn8WR1Dz9ngGvGTc/n9zDFMDBlYRGS/94svGvvZJrRNsC83CV2iDEll7LXhoJfzYTfbIfmVwvDtJrFSAJcW2SVBz4vDXeL+WHxbojB4AUpx07nVto1Vj7V9dtYW6LZ4GrM9D3ZdLKpDxtayuMZPhCAMwMBY3i95PtRuyXNaS7Rd8njMl8G21lZt1/xveddz7YydLj+3giSJKRemB/kuY5ytD/G6In607ujYtF3Gqf5qO9m0a/Vebe9rp8a360NtaXtvu+q/tq0fPdb2yDhH/Ztaq8xx0dv2TYRJ0ZrHXTh29uLaIDCceR+7r7LQjtvXC7rGGFtH7bK2aDd+ej+DbzmOHC+oZ3q2iPn1isVWkT31uPi9T/7WfPzo6+azr/5bv2Hc2h8/+mdj58YEt9laCqCSUGqykUnJSeoJSASa/JYa/zF2xhLwMfbKvRb3sfnYM/6Pxbc9fcixKPN3ddlsNvkJACvIIopLYfXiPXfOiqMXMinqdv8OMUS4IFxgAAbWwkDOp3ZsOXVKoMR6GYVEKww9x0rdd/Er+XPQh+bXkKujnSA+rXak2jawK/Vl1ne5zj/FdoE0N67cf66RwZ8yLq8tQ991LpayU2xKbBezOzeWuXMhzmluR+ZTYzI7D9VuW7MvH0wxPBT9YY6qnRHfBud0HaHt7l5jc2TDJ89By9v4+yaMvzxdIfwM/NnFZ66JMSUepxyPrSI7f/HZT375p+bTL/9dhXX+F15+bNfYtSq2zdYywR5JNpPJoL3WH02rRc13Qjeb5tIfO7uKSagkKj8nxbsteptmUx5V94TUJlbv56qzFWxYMtTi0G0IbOTRuLDwKNd2jx89aPsL58OYp8Zpb3D1bSgWy8KgG+dmY4/x9XEI/msMtO8yDn9MyuOxqz92X9ef2il9jRcrLyqlcPn8uW8aM/mE2LjTcYYNAevX79dxde3zO+3j74PCpXNp1+qxtvO5bj5aFi1O7fjNv57P6cS8lsU1fiIEYQAGhjW/zevjuS7n/HQ8k6tLfhfBkY8tf9f6OWOn1HevSZa7S13ymniE7109KfGYrQ8p9ydf87jCcfB13vdwn9dHj9+sHfGvjOMq1M/D7abYzvkwd07jPNIuddzHmc+b3Zm1gK8jNncSl2on+9b9WcA47xJLtVHb7TqqXyukNYL4W+Ne+vd1Y/dngfZaHXPre12r1tfNF+vP13DbfOP8MLcRE2ISGdgqsvO/8Pr9F//aKrBdaNu1KrLN1iITkAtUTUhxcC4ua2EN93miicWzJqKUKGsCs766JKZJMybumIDDvepDZ6f6V449wUUb3me9Now5Xat9DHb4O/HrhSSMM8UknJt5xKnGJMay+jrmT03s0fcoZOM5L3A+RyWuuhjKxUz9t7aPecsnKVOMRt9cVPuYjT0pUGXME+csXuV8WwhLnOxY/JvywV5HuCBcYAAG1sLAMJd1Ncg3sK/0E8E252tttTzvtaTkYLmvbtCO5PRYk9v65Xbn7JRaq7k45PLDfQ9xCDZT7Qi1ffhptMbDbIZxpjo398nsUXa8fmmcOr+PsqtjnxvL3Dm1MdI2/6rANJZkDLNcmK1ap4drk3Z+x17v1gV37Pt4kvgd8U85af3xdURru/e3O5ZNel8blfvSuMJ7KK2//H0R1jBbfFM/aWftwTFMtAxsFdkWqNvvfFDF8q/+8I+dRbZd6yLbbCwW9JLgXYy2A8mJsySNQSHTx9SGybDY6JJPLhShWFmCD+Iuv6HaQuxJTe22djrfsx0dl7ZLshv6W+O55zg1AQffrB/xaTYGOQHLfSFW3XUDW/X+GCv1bbBJknbbR32XwuL3FxaKf2kXuPqQ52/8OPrmQtkLoN3TFVP7UrvBnMi5kX5tLOqnLQL6whf9WcviGj8RgjAAA7VOed4ruVHyWzhu65zmPq0dJedLjtdjvc76LPm6ignLv32u1vvs2nBstUL6CLk8+Op53scy73uIwz71IfkzO850bfDd49/9PthOqaV9LMO4tm127OHf7GbHPnbCuNs5cjHqawQ/DhxkLsoTaL7unFiPlXn1a7xut2ucnqnsg1+Xfpc4O1t+rrNVxPplc3G3X4sW3zve41rF+ut9KucmP62eX6fkuebY54XfsDDOwE4i+8bNZ6tYNtG82UFo2zUusO232VhuEtpEo4W4ty3nuiQVdi0tOZVENEySfZLqkqDvOtbfE+LYknjo67LRv9fp7XpRnrCjCbrY00I29LeOOfQtu7RlnBIPLzZ2fVlEjNis/W6Jgdvy3/W+HIvsTz4fYzUsDv2nGDZejaW27VxbPKS/bt58syPOUS5e42+QGmO3P1h89cWrXdB0xzqXFqN87HHzc3U+9H6d/94/hAvCBQZgYC0MaA6dave5PNekfNznwWJL8mpvo70mHNt1mrs1/3oOduGhtczO5eN0b99P9jUfi+/idx7HIEbWv/je9zcyzuxrPhbfj7JT/I+fArvfR9kV/wZx17Foe4c5ct9Gf2db6oPOk11XN20m5taukblq+5tYg8mmz8Cv4tP2NYqulzTu+nq7+R/XEnGtJGsY/aBA40B7Qf0ieYC4Xvu47iSyLQG88NKrQTTf/fVXzW8++3rwqfYnn33d2DkV2HbvIIkcCVdJKINkZvBKQisJMiaX3o9hktQkZe0qzrKvg6ScbcVjtRvEVrajCV3bpf9osx+HC7jdx6kJOPhm/YhPszGYi8lecY/jUt98l1nnQf3VdomH+T7KxDCptUVmKmbD681+9M1ZkwIVxm0cTp2L9m0c7YaR3qPteP1aFtf4iRCEARgItSrXje5Ya422vQaMb6jH2lfycxVB+tRam7u1jgx80tytba+JM3VF/dX2vO8pv+c+NU6prs2Nc/DJdbpXx72IneJ3FNuL2LXx55joWObOaex2aavdfL30Y3M7+MCmfmjT1uhyjTDYxrtd4wSG5/q0c7p2yD7Jsfan7TIHzqzZG/jUrynKfX4tIntxraLvOdo9d6cSi51FtgXk+RdfCeLZhPS7H/yx+elHX5Yfa6u4tvbjENjt5FiR8k+lfeLaZNY/ahsFnAvwttjmc/FTUhWb1l9JWr7zWJKgCrSuX09k5Xwv0jX57Syy/YvZ/P9+J5sR0DyWNja+qAi++5egeVINY+nGMTHOaMdj3v0eseP9j8W9Jv00rlAc/JNr97XbQPF7Q1xL4WnHXYtZtwCw42y3zG+1m8YiRUzjPLDh/nXznv3RY22rzcJD9cPizyfZCDOEGQxcHwZCvrPcGmqFH8uGpJ7Xdq6JXsu87pZ8r/nTbUpeLbk918uu7rmd0E+6Nvizj+/DGqM1Qduj8ao1wsXn2DitD/VX28P+w1pEYzeI0RY7dr3d7z6qLW3vbVf71fae4yz9+vjTGqFbU4yvCds+fb0R5yX70/tU1x/Sb1w7jN3b+Vfi5Zvu7nP/2zip66rCojMe16/an92jPmXWyrWVfYtPbzOOufeD14kFDOzGwF4i24L69DPPNW+89+FATGdxbX+Dvewj4uMDKgmjPs4dd1RbCNqkWncgazIZJrrR5FNtS+LJhdaSaXmt2+ncnIfHmus5K0JadLIdPWc2u4RbfN9cNBeT/zLCYjM1zjZuGqfyDeJeEF0olnHGv/Gx+JUEPBYDKSAlznksc/7MxaqOudvEqMcW201zcfey7srm+Sp+hOulIIVxmq00nxKPlpshb1q4+ms07rrxkuckn+vnRQtgZYW/yeYL3u5fH6GFaD7duexzpeRUrQEjuS7Uqztynwtrr0kpb2u9qmKk1KKcfzsBNWEn1N7Uh+bofkO/93HK9yhm7Pq52tHbK/0lH8bH2d2jNTDc145Z681hdsS3vA7ojg+zO/Rvdh72GGdkUOM+/UFNWXeF+Om4h+tHn0+Nr/arMQnC3d4LXT/hGmczfDFg9F37CuuhGpvfNb/1jfs6V4l9/1ClnDf7sjaq9+jYaeu80oaHOQb2Ftlu7MbN55qXb91uXn/3fvP2+4+aN+89bOz/YNu/6VrsW8R5g8ujKyMF6HHERxK+zzW/n6wkgmA5XcHC3DP3a2OA+nFk/aAmyzpox1je2YRPb2Fwx7iVjR9ENrzsygvXbWPlYJG9zTDnj4Uv7SiWnf/lk1/ZOU2f7odd1sch5LG5/6JBYra2RTb+Igxh4HQZYC1w5FoAkb13vTzf5CcXjpwDqb/Xm+e07jyZccPH9eb625tfRPYTnETyo0P6aNByb4j4+JE/trSc/W8P7us6BgTL6QoW5p65XxsD1zUPf2PjKhvs6U+cnuB1yzcWF2Kw9+bD7NzA2bLxhE/ieXbWILJ5I/BGWBkDa1tk4y/CEAZOl4HZhf3Kci9jYdMcBmAABmBgVwYQ2RR5RPbKGECwnK5gYe6Z+7UxsOtihOtYuMIADMAADFwnBhDZKxNY1wk+xnJYMl3bIht/EYYwcLoMkOcPy/PEjbjBAAzAwLoZQGQjsvkkGwZgAAZgAAZgAAZgAAZgAAZgYCEGENkLBZLdpnXvNjF/zB8MwAAMwAAMwAAMwAAMwMASDCCyEdnsWMEADMAADMAADMAADMAADMAADCzEACJ7oUAuseOBDXbOYAAGYAAGYAAGYAAGYAAGYGDdDCCyEdnsWMEADMAADMAADMAADMAADMAADCzEACJ7oUCy27Tu3Sbmj/mDARiAARiAARiAARiAARhYggFENiKbHSsYgAEYgAEYgAEYgAEYgAEYgIGFGEBkLxTIJXY8sMHOGQzAAAzAAAzAAAzAAAzAAAysmwFENiKbHSsYgAEYgAEYgAEYgAEYgAEYgIGFGEBkLxRIdpvWvdvE/DF/MAADMAADMAADMAADMAADSzCAyEZks2MFAzAAAzAAAzAAAzAAAzAAAzCwEAP/B+zp2EYMJfdWAAAAAElFTkSuQmCC)"
      ]
    }
  ]
}