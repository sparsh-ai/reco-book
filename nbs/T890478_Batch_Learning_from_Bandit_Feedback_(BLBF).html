
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Imports &#8212; Reco Book</title>
    
  <link href="../_static/css/theme.css" rel="stylesheet" />
  <link href="../_static/css/index.c5995385ac14fb8791e8eb36b4908be2.css" rel="stylesheet" />

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../_static/sphinx-book-theme.css?digest=c3fdc42140077d1ad13ad2f1588a4309" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../_static/js/index.1c5a1a01449ed65a7b51.js">

    <script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/togglebutton.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../_static/sphinx-book-theme.12a9622fbb08dcb3a2a40b2c02b83a57.js"></script>
    <script async="async" src="https://unpkg.com/thebe@0.5.1/lib/index.js"></script>
    <script >
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Off-Policy Learning in Two-stage Recommender Systems" href="T257798_Off_Policy_Learning_in_Two_stage_Recommender_Systems.html" />
    <link rel="prev" title="Statictics Fundamentals" href="T873451_Statistics_fundamentals.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../index.html">
      
      
      
      <h1 class="site-logo" id="site-title">Reco Book</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../index.html">
   Tutorials in Jupyter notebook format
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  User Stories
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="US780867_Transformer_based_Recommenders.html">
   Transformer-based Recommenders
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="T034923_BERT4Rec_on_ML1M_in_PyTorch.html">
     BERT4Rec on ML-1M in PyTorch
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="T595874_BERT4Rec_on_ML25M_in_PyTorch_Lightning.html">
     BERT4Rec on ML-25M
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="T088416_BST_Implementation_in_MXNet.html">
     BST Implementation in MXNet
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="T602245_BST_implementation_in_PyTorch.html">
     BST implementation in PyTorch
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="T007665_BST_on_ML1M_in_Keras.html">
     A Transformer-based recommendation system
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="T881207_BST_PTLightning_ML1M.html">
     Rating prediction using the Behavior Sequence Transformer (BST) model on ML-1M dataset in PyTorch Lightning
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="T757997_SASRec_PyTorch.html">
     SASRec implementation with PyTorch Library
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="T225287_SASRec_PaddlePaddle.html">
     SASRec implementation with Paddle Library
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="T701627_SR_SAN_Session_based_Model.html">
     SR-SAN Session-based Recommender
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="T975104_SSEPT_ML1M_Tensorflow1x.html">
     SSE-PT Personalized Transformer Recommender on ML-1M in Tensorflow 1.x
    </a>
   </li>
  </ul>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Prototypes
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="T382881_DeepWalk_Karateclub.html">
   DeepWalk from scratch referencing Karateclub library
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T384270_DeepWalk_pure_python.html">
   DeepWalk in pure python
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T677598_Jaccard_Cosine_SVD_DeepWalk_ML100K.html">
   Recommender System with DeepWalk Graph Embeddings
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T815556_Node2vec_Karateclub.html">
   Node2vec from scratch referencing Karateclub library
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T894941_Node2vec_MovieLens_Keras.html">
   Graph representation learning with node2vec
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T611050_Node2vec_PyG.html">
   Node2vec from scratch in PyTorch Geometric
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T186367_Node2vec_library.html">
   Node2vec from scratch referencing node2vec library
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T331379_bayesian_personalized_ranking.html">
   BPR from scratch
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T081831_Data_Poisoning_Attacks_on_Factorization_Based_Collaborative_Filtering.html">
   Data Poisoning Attacks on Factorization-Based Collaborative Filtering
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T102448_Adversarial_Learning_for_Recommendation.html">
   Adversarial Training (Regularization) on a Recommender System
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T865035_Simulating_Data_Poisoning_Attacks_against_Twitter_Recommender.html">
   Load and process dataset
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T711285_Data_Poisoning_Attack_using_LFM_and_ItemAE_on_Synthetic_Dataset.html">
   Injection attack using LFM and ItemAE model trained on Toy dataset
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T355514_Black_box_Attack_on_Sequential_Recs.html">
   Black-box Attack on Sequential Recs
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T873451_Statistics_fundamentals.html">
   Statictics Fundamentals
  </a>
 </li>
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   Imports
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T257798_Off_Policy_Learning_in_Two_stage_Recommender_Systems.html">
   Off-Policy Learning in Two-stage Recommender Systems
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T471827_Adaptive_Estimator_Selection_for_Off_Policy_Evaluation.html">
   Adaptive Estimator Selection for Off-Policy Evaluation
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T902666_Evaluating_the_Robustness_of_Off_Policy_Evaluation.html">
   Evaluating the Robustness of Off-Policy Evaluation
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T705904_Evaluation_of_Multiple_Off_Policy_Estimators_on_Synthetic_Dataset.html">
   Evaluation of Multiple Off-Policy Estimators on Synthetic Dataset
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T874693_Evaluating_Standard_Off_Policy_Estimators_with_Small_Sample_Open_Bandit_Dataset.html">
   Evaluating Standard Off-Policy Estimators with Small Sample Open-Bandit Dataset
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T792262_Optimal_Off_Policy_Evaluation_from_Multiple_Logging_Policies.html">
   Optimal Off-Policy Evaluation from Multiple Logging Policies
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T167249_Offline_Policy_Evaluation_with_VW_Command_Line.html">
   Offline Policy Evaluation with VW Command Line
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T966055_OBP_Library_Workshop_Tutorials.html">
   OBP Library Workshop Tutorials
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T632722_PyTorch_Fundamentals_Part_1.html">
   PyTorch Fundamentals Part 1
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T472467_PyTorch_Fundamentals_Part_2.html">
   PyTorch Fundamentals Part 2
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T206654_PyTorch_Fundamentals_Part_3.html">
   PyTorch Fundamentals Part 3
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T536348_Attention_Mechanisms.html">
   Imports
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T500796_Agricultural_Satellite_Image_Segmentation.html">
   Agricultural Satellite Image Segmentation
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T611432_Image_Analysis_with_Tensorflow.html">
   Image Analysis with Tensorflow
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T925716_MongoDB_to_CSV_Conversion.html">
   MongoDB to CSV conversion
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T396469_PDF_to_Word_Cloud_via_Email.html">
   PDF to WordCloud via Email
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T030890_Job_Scraping_and_Clustering.html">
   Job scraping and clustering
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T897054_Scene_Text_Recognition.html">
   Scene Text Recognition
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T034809_Large_scale_Document_Retrieval_with_Elastic_Search.html">
   Large-scale Document Retrieval with ElasticSearch
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T467251_vowpal_wabbit_contextual_recommender.html">
   Simulating a news personalization scenario using Contextual Bandits
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T686684_similar_product_recommender.html">
   Similar Product Recommender system using Deep Learning for an online e-commerce store
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T132203_Retail_Product_Recommendations_using_Word2vec.html">
   Retail Product Recommendations using word2vec
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T501828_Recommender_Implicit_Negative_Feedback.html">
   Retail Product Recommendation with Negative Implicit Feedback
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T315965_Sequence_Aware_Recommenders_Music.html">
   Sequence Aware Recommender Systems
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T051777_image_similarity_recommendations.html">
   Similar Product Recommendations
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T990172_recobook_diversity_aware_book_recommender.html">
   Diversity Aware Book Recommender
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T488549_Goodreads_Diversity_Aware_Book_Recommender.html">
   Diversity Aware Book Recommender
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T023535_Kafka_MongoDB_Real_time_Streaming.html">
   Kafka MongoDB Real-time Streaming
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T622304_Session_based_Recommender_Using_Word2vec.html">
   Session-based recommendation using word2vec
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T416854_bandit_based_recommender_using_thompson_sampling_app.html">
   Bandit-based Online Learning using Thompson Sampling
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T198578_Booking_dot_com_Trip_Recommendation.html">
   Booking.com Trip Recommendation
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T519734_Vowpal_Wabbit_Contextual_Bandit.html">
   Vowpal Wabbit Contextual Bandit
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T871537_Recommendation_Systems_using_Olist_Dataset.html">
   Recommendation systems using Olist dataset
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T057885_Offline_Replayer_Evaluation.html">
   Offline Replayer Evaluation
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T915054_method_for_effective_online_testing.html">
   Methods for effective online testing
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T513987_Recsys_2020_Feature_Engineering_Tutorial.html">
   Recsys’20 Feature Engineering Tutorial
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T227901_amazon_personalize_batch_job.html">
   Amazon Personalize Batch Job
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T022961_Amazon_Personalize_Workshop.html">
   Amazon Personalize Workshop
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T424437_Collaborative_Filtering_on_ML_latest_small.html">
   Collaborative Filtering on ML-latest-small
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T539160_Building_and_Deploying_ASOS_Fashion_Recommender.html">
   Building and deploying ASOS fashion recommender
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T757697_Simple_Similarity_based_Recommender.html">
   Simple Similarity based Recommmendations
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T051594_Analytics_Zoo.html">
   Analytics Zoo
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T313645_A_B_Testing.html">
   A/B Testing
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T475711_PinSage_Graph_based_Recommender.html">
   PinSage Graph-based Recommender
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T516490_Graph_Embeddings.html">
   Learn Embeddings using Graph Networks
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T822164_movielens_milvus_redis_efficient_retrieval.html">
   Recommender with Redis and Milvus
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T845186_Anime_Recommender.html">
   RekoNet Anime Recommender
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T855843_kafka_spark_streaming_colab.html">
   Kafka and Spark Streaming in Colab
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T460437_Building_Models_From_Scratch.html">
   Building Models from scratch
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T855971_Conet_Model_for_Movie_Recommender.html">
   CoNet model
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T996996_content_based_and_collaborative_movielens.html">
   Movie Recommendation with Content-Based and Collaborative Filtering
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T239418_Simple_Movie_Recommenders.html">
   Simple Movie Recommenders
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T138337_Simple_Movie_Recommender.html">
   Simple movie recommender in implicit, explicit, and cold-start settings
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T935440_The_importance_of_Rating_Normalization.html">
   The importance of Rating Normalization
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T612622_cornac_examples.html">
   Cornac Examples
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T561435_Flower_Classification.html">
   Flower classification
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T680910_Trivago_Session_based_Recommender.html">
   Trivago Session-based Recommender
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T990000_ads_selection_using_bandits.html">
   Best Ads detection using bandit methods
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T990000_book_crossing_surprise_svd_nmf.html">
   Book-Crossing Recommendation System
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T990000_book_recommender_kubeflow.html">
   Books recommendations with Kubeflow Pipelines on Scaleway Kapsule
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T990000_build_a_kubeflow_pipeline.html">
   Build a Kubeflow Pipeline
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T990000_causal_inference.html">
   Causal Inference
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T990000_concept_embedding_nlp.html">
   Exploring Word Embeddings
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T990000_concept_neural_net.html">
   Neural Network
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T990000_concept_nlp_basics.html">
   Natural Language Processing 101
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T990000_concept_transformer_lm.html">
   TransformerLM Quick Start and Guide
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T990000_content_based_music_recommender_lyricsfreak.html">
   Content-based method for song recommendation
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T990000_evaluation_metrics_basics.html">
   Recommender System Evaluations
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T990000_implicit_synthetic.html">
   Comparing Implicit Models on Synthetic Data
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T990000_movie_recommender_tensorflow.html">
   Recommendation Systems with TensorFlow
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T990000_movie_recommender_tensorflow_sagemaker.html">
   Movie recommender using Tensorflow in Sagemaker
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T990000_movielens_eda_modeling.html">
   Movielens EDA and Modeling
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T990000_read_data_from_cassandra_into_pandas.html">
   Read Cassandra Data Snapshot as DataFrame
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T990000_rl_in_action.html">
   Reinforcement Learning fundamentals in action
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T990000_rnn_cnn_basics.html">
   Processing sequences using RNNs and CNNs
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T990000_tf_serving_in_action.html">
   TF Serving in action
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T990000_training_indexing_movie_recommender.html">
   Training and indexing movie recommender
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T207114_EduRec_MOOCCube_Course_Recommender.html">
   EduRec MOOCCube Course Recommender
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T273184_Multi_Task_Learning.html">
   Multi-task Learning
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T661108_Book_Recommender_API.html">
   Book Recommender API
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T912764_Simple_Movie_Recommender_App.html">
   Simple Movie Recommender App
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T964554_Career_Village_Questions_Recommendation.html">
   CareerVillage Questions Recommendation
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T990001_amazon_women_apparel_tfidf_word2vec.html">
   Amazon Product Recommender
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T990001_anime_recommender_graph_network.html">
   Anime Recommender with Bi-partite Graph Network
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T990001_concept_self_attention.html">
   Self-Attention
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T990001_course_recommender_svd_flask.html">
   Course Recommender with SVD based similarity
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T990001_data_mining_similarity_measures.html">
   Concept - Data Mining Similarity Measures
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T990001_jaccard_recommender.html">
   Jaccard Similarity based Recommender
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T990001_live_streamer_recommender.html">
   Live Streamer Recommender with Implicit feedback
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T990001_songs_embedding_skipgram_recommender.html">
   Song Embeddings - Skipgram Recommender
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T990001_toy_example_car_recommender_knn.html">
   Toy example - Car Recommender using KNN method
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T990001_wikirecs_recommender.html">
   WikiRecs
  </a>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../_sources/nbs/T890478_Batch_Learning_from_Bandit_Feedback_(BLBF).ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
        title="Fullscreen mode"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        <a class="binder-button" href="https://mybinder.org/v2/gh/sparsh-ai/reco-book/main?urlpath=tree/nbs/T890478_Batch_Learning_from_Bandit_Feedback_(BLBF).ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Launch Binder" data-toggle="tooltip"
                data-placement="left"><img class="binder-button-logo"
                    src="../_static/images/logo_binder.svg"
                    alt="Interact on binder">Binder</button></a>
        
        
        
        
    </div>
</div>

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show">
            
            <div class="tocsection onthispage pt-5 pb-3">
                <i class="fas fa-list"></i> Contents
            </div>
            <nav id="bd-toc-nav" aria-label="Page">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#">
   Imports
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#utils">
   Utils
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#supervised-to-bandit-transform-stbt">
   Supervised to Bandit Transform (STBT)
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#off-policy-evaluation-estimators">
   Off-Policy Evaluation Estimators
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#sample-datasets-used-in-experiments">
   Sample datasets used in experiments
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#compare-the-following-methods">
   Compare the following methods
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#off-policy-learning-estimators">
   Off-Policy Learning Estimators
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#alternative-using-doubly-robust-as-opposed-to-the-ips-estimator">
   Alternative using Doubly Robust (as opposed to the IPS estimator)
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#read-data">
   Read data
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#perform-supervised-to-bandit-conversion">
   Perform Supervised-to-Bandit Conversion
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#skyline">
   Skyline
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#counterfactual-risk-minimization-crm">
   Counterfactual Risk Minimization (CRM)
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#experiments">
   Experiments
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#references">
   References
  </a>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <p><a href="https://colab.research.google.com/github/sparsh-ai/reco-book/blob/stage/nbs/T890478_Batch_Learning_from_Bandit_Feedback_(BLBF).ipynb" target="_parent"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/></a></p>
<div class="section" id="imports">
<h1>Imports<a class="headerlink" href="#imports" title="Permalink to this headline">¶</a></h1>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">math</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">warnings</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="kn">import</span> <span class="nn">sklearn.model_selection</span>
<span class="kn">import</span> <span class="nn">sklearn.preprocessing</span>
<span class="kn">import</span> <span class="nn">sklearn.linear_model</span> 

<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LogisticRegression</span>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LogisticRegressionCV</span>
<span class="kn">from</span> <span class="nn">sklearn.ensemble.forest</span> <span class="kn">import</span> <span class="n">RandomForestClassifier</span>
<span class="kn">from</span> <span class="nn">sklearn.svm</span> <span class="kn">import</span> <span class="n">SVC</span>
<span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">preprocessing</span>
<span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">load_digits</span><span class="p">,</span> <span class="n">load_breast_cancer</span><span class="p">,</span> <span class="n">load_wine</span><span class="p">,</span> <span class="n">fetch_openml</span>

<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">import</span> <span class="nn">torch.nn.functional</span> <span class="k">as</span> <span class="nn">F</span>
<span class="kn">import</span> <span class="nn">torch.optim</span> <span class="k">as</span> <span class="nn">optim</span>
<span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">Dataset</span><span class="p">,</span> <span class="n">DataLoader</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="utils">
<h1>Utils<a class="headerlink" href="#utils" title="Permalink to this headline">¶</a></h1>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">create_interactions</span><span class="p">(</span><span class="n">X</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">T</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">one_hot_labeler</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">tuple</span><span class="p">:</span>
    <span class="k">if</span> <span class="n">one_hot_labeler</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">lb_fit</span> <span class="o">=</span> <span class="n">sklearn</span><span class="o">.</span><span class="n">preprocessing</span><span class="o">.</span><span class="n">LabelBinarizer</span><span class="p">()</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">T</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">lb_fit</span> <span class="o">=</span> <span class="n">one_hot_labeler</span>
    <span class="n">T</span> <span class="o">=</span> <span class="n">lb_fit</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">T</span><span class="p">)</span>
    <span class="n">XT</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="n">T</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]])</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span>
    <span class="n">cnt</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]):</span>
        <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">T</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]):</span>
            <span class="n">XT</span><span class="p">[:,</span><span class="n">cnt</span><span class="p">]</span><span class="o">=</span> <span class="n">X</span><span class="p">[:,</span> <span class="n">i</span><span class="p">]</span> <span class="o">*</span> <span class="n">T</span><span class="p">[:,</span> <span class="n">j</span><span class="p">]</span>
            <span class="n">cnt</span> <span class="o">+=</span> <span class="mi">1</span>
    <span class="n">X_full</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">column_stack</span><span class="p">((</span><span class="n">X</span><span class="p">,</span> <span class="n">T</span><span class="p">,</span> <span class="n">XT</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">X_full</span><span class="p">,</span> <span class="n">lb_fit</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="supervised-to-bandit-transform-stbt">
<h1>Supervised to Bandit Transform (STBT)<a class="headerlink" href="#supervised-to-bandit-transform-stbt" title="Permalink to this headline">¶</a></h1>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">STBT</span><span class="p">:</span>
   
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Performs Supervised to Bandit Conversion for classification </span>
<span class="sd">    datasets. This conversion is generally used to test the limits of </span>
<span class="sd">    counterfactual learning in a well-controlled environment [1,2,3]. </span>
<span class="sd">    </span>
<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    </span>
<span class="sd">    train_frac : float, default: 0.50</span>
<span class="sd">        It should be between 0.0 and 1.0 and represents the</span>
<span class="sd">        proportion of the dataset to include in the train split.</span>
<span class="sd">        </span>
<span class="sd">    permute : bool, default: False</span>
<span class="sd">        Randomly permute the data before the random split between train and test.</span>
<span class="sd">    logging_type : str, default: &quot;uniform&quot;</span>
<span class="sd">        The type of logging policy. If &quot;uniform&quot;, uniform random samples from the </span>
<span class="sd">        labels $y$ to simulate a logging policy. If &quot;biased&quot;, the logging policy</span>
<span class="sd">        is a stochastic function of the covariates.</span>
<span class="sd">        </span>
<span class="sd">    sample_frac : float, default: None</span>
<span class="sd">        A sample fraction between (0.0,1.0]. This is the sample fraction of the</span>
<span class="sd">        training data used to fit the target policy. By default, the full</span>
<span class="sd">        training set is used. </span>
<span class="sd">     </span>
<span class="sd">    References</span>
<span class="sd">    ----------</span>
<span class="sd">    </span>
<span class="sd">    .. [1] N. Jiang, and  L. Li, Doubly Robust Off-policy Value Evaluation for Reinforcement Learning, </span>
<span class="sd">           Proceedings of Machine Learning Research, 48, 652--661, 2016.</span>
<span class="sd">    .. [2] A. Swaminathan and T. Joachims, Batch Learning from Logged Bandit Feedback through </span>
<span class="sd">           Counterfactual Risk Minimization, Journal of Machine Learning Research, 16(52),</span>
<span class="sd">           1731--1755, 2015.</span>
<span class="sd">    .. [3] A. Swaminathan and T. Joachims, The self-normalized estimator for counterfactual learning, </span>
<span class="sd">           Advances in Neural Information Processing Systems, 28, 16(52), 3231--3239, 2015.</span>
<span class="sd">           </span>
<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; np.random.seed(42)</span>
<span class="sd">    &gt;&gt;&gt; X, y = get_data(dataset=&#39;ecoli&#39;)  </span>
<span class="sd">    &gt;&gt;&gt; obj = STBT()</span>
<span class="sd">    &gt;&gt;&gt; sample_batch = obj.generate_batch(X, y)</span>
<span class="sd">    &gt;&gt;&gt; sample_batch.y_train_logging[0:5]</span>
<span class="sd">    array([1, 1, 0, 0, 0]))</span>
<span class="sd">    </span>
<span class="sd">    &quot;&quot;&quot;</span>
    
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">train_frac</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.50</span><span class="p">,</span> <span class="n">permute</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span> <span class="n">logging_type</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s1">&#39;uniform&#39;</span><span class="p">,</span>
                 <span class="n">sample_frac</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="kc">None</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">train_frac</span> <span class="o">=</span> <span class="n">train_frac</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">permute</span> <span class="o">=</span> <span class="n">permute</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">logging_type</span> <span class="o">=</span> <span class="n">logging_type</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">sample_frac</span> <span class="o">=</span> <span class="n">sample_frac</span>
        
    <span class="k">def</span> <span class="fm">__repr__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        
        <span class="n">items</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;</span><span class="si">%s</span><span class="s2"> = </span><span class="si">%r</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="n">v</span><span class="p">)</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="vm">__dict__</span><span class="o">.</span><span class="n">items</span><span class="p">())</span>
        <span class="k">return</span> <span class="s2">&quot;&lt;</span><span class="si">%s</span><span class="s2">: {</span><span class="si">%s</span><span class="s2">}&gt;&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="p">,</span> <span class="s1">&#39;, &#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">items</span><span class="p">))</span>
    
    <span class="k">def</span> <span class="nf">_validate_input</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">train_frac</span><span class="p">,</span> <span class="nb">float</span><span class="p">)</span> <span class="ow">or</span> <span class="ow">not</span> <span class="p">(</span><span class="mf">0.0</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">train_frac</span> <span class="o">&lt;</span> <span class="mf">1.0</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;`train_frac` should be a float in (0.0,1.0), got </span><span class="si">%s</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">train_frac</span><span class="p">)</span>
            
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">sample_frac</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">sample_frac</span> <span class="ow">is</span> <span class="ow">not</span> <span class="p">(</span><span class="mf">0.0</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">sample_frac</span> <span class="o">&lt;=</span> <span class="mf">1.0</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;`sample_frac` should be a float in (0.0,1.0], got </span><span class="si">%s</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">sample_frac</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">logging_type</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;uniform&#39;</span><span class="p">,</span> <span class="s1">&#39;biased&#39;</span><span class="p">]:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;`logging_type` should be either &#39;uniform&#39; or &#39;biased&#39;, got </span><span class="si">%s</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">logging_type</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">_softmax</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">):</span>
        
        <span class="n">kw</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="n">axis</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">xrel</span> <span class="o">=</span> <span class="n">x</span> <span class="o">-</span> <span class="n">x</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="o">**</span><span class="n">kw</span><span class="p">)</span>
        <span class="n">exp_xrel</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">xrel</span><span class="p">)</span>
        <span class="n">p</span> <span class="o">=</span> <span class="n">exp_xrel</span> <span class="o">/</span> <span class="n">exp_xrel</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="o">**</span><span class="n">kw</span><span class="p">)</span>  
         
        <span class="k">return</span> <span class="n">p</span>
        
         
    <span class="k">def</span> <span class="nf">generate_batch</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">y</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Generate Supervised to Bandit batch</span>
<span class="sd">        </span>
<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X : array of shape (n_samples, n_features)</span>
<span class="sd">            Training vector, where n_samples is the number of samples and</span>
<span class="sd">            n_features is the number of features.</span>
<span class="sd">        y : array of shape (n_samples,)</span>
<span class="sd">            Target vector relative to X.</span>
<span class="sd">        **kwargs : Arguments passed to fit method in </span>
<span class="sd">                   `sklearn.linear_model.LogisticRegression` class.</span>
<span class="sd">        </span>
<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        X_train : array of shape (n_train_samples, n_features)</span>
<span class="sd">        y_train : array of shape (n_train_samples,)</span>
<span class="sd">        X_test : array of shape (n_test_samples, n_features)</span>
<span class="sd">        y_test : array of shape (n_test_samples,)</span>
<span class="sd">        y_train_logging : array of shape (n_train_samples,)</span>
<span class="sd">            Logging policy labels on train data</span>
<span class="sd">        train_logging_probs : array of shape (n_train_samples, n_classes)     </span>
<span class="sd">            Logging policy probabilities on train data</span>
<span class="sd">        train_logging_prob : array of shape (n_train_samples,)</span>
<span class="sd">            Logging policy probability corresponding to the chosen logging label on train data</span>
<span class="sd">        y_train_logging_idx : array of shape (n_train_samples, n_classes)</span>
<span class="sd">            Binary matrix with 1s indicating which action was taken by the logging policy in train data</span>
<span class="sd">           </span>
<span class="sd">        y_test_logging : array of shape (n_test_samples,)</span>
<span class="sd">             Logging policy labels on test data</span>
<span class="sd">        test_logging_probs : array of shape (n_test_samples, n_classes)   </span>
<span class="sd">            Logging policy probabilities on test data</span>
<span class="sd">        test_logging_prob : array of shape (n_test_samples,)</span>
<span class="sd">            Logging policy probability corresponding to the chosen logging label on test data</span>
<span class="sd">       </span>
<span class="sd">        y_train_target : array of shape (n_train_samples,)</span>
<span class="sd">             Target policy labels on train data</span>
<span class="sd">        train_target_prob : array of shape (n_train_samples, n_classes)     </span>
<span class="sd">             Target policy probabilities on train data</span>
<span class="sd">        train_target_probs : array of shape (n_train_samples,)</span>
<span class="sd">            Target policy probability corresponding to the chosen logging label on train data</span>
<span class="sd">       </span>
<span class="sd">        y_test_target : array of shape (n_test_samples,)</span>
<span class="sd">             Target policy labels on test data</span>
<span class="sd">        test_target_prob : array of shape (n_test_samples, n_classes)     </span>
<span class="sd">             Target policy probabilities on test data</span>
<span class="sd">        test_target_probs : array of shape (n_test_samples,)</span>
<span class="sd">            Target policy probability corresponding to the chosen logging label on test data</span>
<span class="sd">       </span>
<span class="sd">        true_target_value_test : float</span>
<span class="sd">            True value of Target policy on test data</span>
<span class="sd">       </span>
<span class="sd">        train_logging_reward : array of shape (n_train_samples,)</span>
<span class="sd">            Observed reward of logging policy on train data </span>
<span class="sd">        test_logging_reward : array of shape (n_test_samples,)</span>
<span class="sd">            Observed reward of logging policy on test data </span>
<span class="sd">            </span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_validate_input</span><span class="p">()</span>
        
        <span class="bp">self</span><span class="o">.</span><span class="n">generate_batch_call</span> <span class="o">=</span> <span class="kc">True</span>
        
        <span class="bp">self</span><span class="o">.</span><span class="n">dual</span> <span class="o">=</span> <span class="kc">False</span>
        
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">permute</span><span class="p">:</span>
            <span class="n">permute</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">permutation</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
            <span class="n">X</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="n">permute</span><span class="p">,</span> <span class="p">:]</span>
            <span class="n">y</span> <span class="o">=</span> <span class="n">y</span><span class="p">[</span><span class="n">permute</span><span class="p">]</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">X_train</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">X_test</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">y_train</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">y_test</span> <span class="o">=</span> \
            <span class="n">sklearn</span><span class="o">.</span><span class="n">model_selection</span><span class="o">.</span><span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span>
                <span class="n">train_size</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">train_frac</span><span class="p">)</span> 
            
        <span class="n">n_train_samples</span><span class="p">,</span> <span class="n">n_features</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">X_train</span><span class="o">.</span><span class="n">shape</span>
        <span class="n">n_test_samples</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">X_test</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

    
        <span class="n">y_train_u</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">y_train</span><span class="p">)</span>
        
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">logging_type</span> <span class="o">==</span> <span class="s1">&#39;uniform&#39;</span><span class="p">:</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">y_train_logging</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">y_train_u</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">n_train_samples</span><span class="p">)</span>  
            <span class="bp">self</span><span class="o">.</span><span class="n">train_logging_prob</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="mf">1.0</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">y_train_u</span><span class="p">),</span> <span class="n">n_train_samples</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">train_logging_probs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">train_logging_prob</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">y_train_u</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">y_test_logging</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">y_train_u</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">n_test_samples</span><span class="p">)</span>  
            <span class="bp">self</span><span class="o">.</span><span class="n">test_logging_prob</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="mf">1.0</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">y_train_u</span><span class="p">),</span> <span class="n">n_test_samples</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">test_logging_probs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">test_logging_prob</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">y_train_u</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
            
            <span class="bp">self</span><span class="o">.</span><span class="n">y_train_logging_idx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">full</span><span class="p">((</span><span class="n">n_train_samples</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">y_train_u</span><span class="p">)),</span> <span class="kc">False</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">bool</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_train_samples</span><span class="p">):</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">y_train_logging_idx</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">y_train_u</span><span class="o">==</span><span class="bp">self</span><span class="o">.</span><span class="n">y_train_logging</span><span class="p">[</span><span class="n">i</span><span class="p">])[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">True</span> 
        
        <span class="k">else</span><span class="p">:</span>
            
            <span class="n">W</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="p">(</span><span class="n">n_features</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">y_train_u</span><span class="p">)))</span>
            <span class="n">lp_train</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">X_train</span> <span class="o">@</span> <span class="n">W</span>
            <span class="n">lp_test</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">X_test</span> <span class="o">@</span> <span class="n">W</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">train_logging_probs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_softmax</span><span class="p">(</span><span class="n">lp_train</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">test_logging_probs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_softmax</span><span class="p">(</span><span class="n">lp_test</span><span class="p">)</span>
            
            <span class="bp">self</span><span class="o">.</span><span class="n">y_train_logging_idx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">full</span><span class="p">((</span><span class="n">n_train_samples</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">y_train_u</span><span class="p">)),</span> <span class="kc">False</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">bool</span><span class="p">)</span>
            <span class="n">y_test_logging_idx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">full</span><span class="p">((</span><span class="n">n_test_samples</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">y_train_u</span><span class="p">)),</span> <span class="kc">False</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">bool</span><span class="p">)</span>
            
            <span class="k">for</span> <span class="n">sample</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_train_samples</span><span class="p">):</span>
                <span class="n">choice</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">multinomial</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">train_logging_probs</span><span class="p">[</span><span class="n">sample</span><span class="p">,:],</span> <span class="n">size</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">y_train_logging_idx</span><span class="p">[</span><span class="n">sample</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">choice</span>
            
            <span class="k">for</span> <span class="n">sample</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_test_samples</span><span class="p">):</span>
                <span class="n">choice</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">multinomial</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">test_logging_probs</span><span class="p">[</span><span class="n">sample</span><span class="p">,:],</span> <span class="n">size</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
                <span class="n">y_test_logging_idx</span><span class="p">[</span><span class="n">sample</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">choice</span>
            
            <span class="bp">self</span><span class="o">.</span><span class="n">y_train_logging</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">y_train_u</span><span class="p">,]</span><span class="o">*</span><span class="n">n_train_samples</span><span class="p">)[</span><span class="bp">self</span><span class="o">.</span><span class="n">y_train_logging_idx</span><span class="p">]</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">y_test_logging</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">y_train_u</span><span class="p">,]</span><span class="o">*</span><span class="n">n_test_samples</span><span class="p">)[</span><span class="n">y_test_logging_idx</span><span class="p">]</span>
            
            <span class="bp">self</span><span class="o">.</span><span class="n">train_logging_prob</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">train_logging_probs</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">y_train_logging_idx</span><span class="p">]</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">test_logging_prob</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">test_logging_probs</span><span class="p">[</span><span class="n">y_test_logging_idx</span><span class="p">]</span>
            
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">sample_frac</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">n_subsamples</span> <span class="o">=</span> <span class="n">math</span><span class="o">.</span><span class="n">ceil</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">sample_frac</span> <span class="o">*</span> <span class="n">n_train_samples</span><span class="p">)</span>
            <span class="n">idx_subsamples</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="n">n_train_samples</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">n_subsamples</span><span class="p">)</span>
            <span class="n">X_train_subsamples</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">X_train</span><span class="p">[</span><span class="n">idx_subsamples</span><span class="p">,</span> <span class="p">:]</span>
            <span class="n">y_train_subsamples</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">y_train</span><span class="p">[</span><span class="n">idx_subsamples</span><span class="p">]</span>
            <span class="k">if</span> <span class="n">n_subsamples</span> <span class="o">&lt;</span> <span class="n">n_features</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">dual</span><span class="o">=</span><span class="kc">True</span>
            <span class="n">target_policy</span> <span class="o">=</span> <span class="n">sklearn</span><span class="o">.</span><span class="n">linear_model</span><span class="o">.</span><span class="n">LogisticRegression</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">,</span> <span class="n">dual</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">dual</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_subsamples</span><span class="p">,</span> <span class="n">y_train_subsamples</span><span class="p">)</span>
       
        <span class="k">else</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">n_train_samples</span> <span class="o">&lt;</span> <span class="n">n_features</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">dual</span><span class="o">=</span><span class="kc">True</span>
            <span class="n">target_policy</span> <span class="o">=</span> <span class="n">sklearn</span><span class="o">.</span><span class="n">linear_model</span><span class="o">.</span><span class="n">LogisticRegression</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">,</span> <span class="n">dual</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">dual</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">X_train</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">y_train</span><span class="p">)</span>
        
        <span class="bp">self</span><span class="o">.</span><span class="n">train_target_probs</span> <span class="o">=</span> <span class="n">target_policy</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">X_train</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">test_target_probs</span> <span class="o">=</span> <span class="n">target_policy</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">X_test</span><span class="p">)</span>
         
        <span class="n">y_train_target</span> <span class="o">=</span> <span class="nb">list</span><span class="p">()</span>
        <span class="n">train_target_prob</span> <span class="o">=</span> <span class="nb">list</span><span class="p">()</span>
        <span class="n">y_test_target</span> <span class="o">=</span> <span class="nb">list</span><span class="p">()</span>
        <span class="n">test_target_prob</span> <span class="o">=</span> <span class="nb">list</span><span class="p">()</span>
         
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_train_samples</span><span class="p">):</span>
            <span class="n">y_train_target_i</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">y_train_u</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> 
                                                 <span class="n">replace</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">train_target_probs</span><span class="p">[</span><span class="n">i</span><span class="p">,:])[</span><span class="mi">0</span><span class="p">]</span>
            <span class="n">y_train_target</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">y_train_target_i</span><span class="p">)</span>
            <span class="n">train_target_prob</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">train_target_probs</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">y_train_u</span><span class="o">==</span><span class="n">y_train_target_i</span><span class="p">)[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]])</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">y_train_target</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">y_train_target</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">train_target_prob</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">train_target_prob</span><span class="p">)</span>
        
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_test_samples</span><span class="p">):</span>
            <span class="n">y_test_target_i</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">y_train_u</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> 
                                                 <span class="n">replace</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">test_target_probs</span><span class="p">[</span><span class="n">i</span><span class="p">,:])[</span><span class="mi">0</span><span class="p">]</span>
            <span class="n">y_test_target</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">y_test_target_i</span><span class="p">)</span>
            <span class="n">test_target_prob</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">test_target_probs</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">y_train_u</span><span class="o">==</span><span class="n">y_test_target_i</span><span class="p">)[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]])</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">y_test_target</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">y_test_target</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">test_target_prob</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">test_target_prob</span><span class="p">)</span>
        
        <span class="bp">self</span><span class="o">.</span><span class="n">true_target_value_test</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="mi">1</span> <span class="o">*</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">y_test</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">y_test_target</span><span class="p">))</span>
        
        <span class="bp">self</span><span class="o">.</span><span class="n">train_logging_reward</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">*</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">y_train</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">y_train_logging</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">test_logging_reward</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">*</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">y_test</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">y_test_logging</span><span class="p">)</span>
           
        <span class="k">return</span> <span class="bp">self</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="off-policy-evaluation-estimators">
<h1>Off-Policy Evaluation Estimators<a class="headerlink" href="#off-policy-evaluation-estimators" title="Permalink to this headline">¶</a></h1>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">PolicyEvaluation</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Performs off-policy evaluation with bandit feedback. </span>
<span class="sd">        </span>
<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        method : str, default: &#39;ips&#39;.</span>
<span class="sd">            The policy evaluation method. The default is &#39;ips&#39;.</span>
<span class="sd">            It should be one of: &#39;ips&#39; (Inverse Propensity Score), </span>
<span class="sd">            &#39;dm&#39; (Direct Method), &#39;dr&#39; (Doubly Robust), &#39;switch&#39;</span>
<span class="sd">            (SWITCH estimator).</span>
<span class="sd">            </span>
<span class="sd">        tau : float, default: 0.001.</span>
<span class="sd">            Hyperparameter added to IPS or SWICTH estimator for numerical stability. </span>
<span class="sd">            </span>
<span class="sd">            For method=&#39;ips&#39;, the logging probabilities in the test set get adjusted by</span>
<span class="sd">            the max(logging probabilities, tau).</span>
<span class="sd">            </span>
<span class="sd">            For method = &#39;switch&#39;, when logging probabilities are larger than this parameter,</span>
<span class="sd">            the &#39;dm&#39; estimator is applied, otherwise the &#39;dr&#39; estimator is applied. </span>
<span class="sd">            </span>
<span class="sd">            </span>
<span class="sd">        References</span>
<span class="sd">        ----------</span>
<span class="sd">    </span>
<span class="sd">        .. [1] Y. Wang, A. Agarwal and M. Dud\&#39;{\i}k, Optimal and Adaptive Off-policy Evaluation in Contextual Bandits, </span>
<span class="sd">               Proceedings of Machine Learning Research, 70, 3589--3597, 2017.</span>
<span class="sd">        .. [2] N. Jiang, and  L. Li, Doubly Robust Off-policy Value Evaluation for Reinforcement Learning, </span>
<span class="sd">               Proceedings of Machine Learning Research, 48, 652--661, 2016.</span>
<span class="sd">        .. [3] K{\&quot;u}nzel, S., Sekhon, J., Bickel, P. and Yu, B., Metalearners for estimating heterogeneous </span>
<span class="sd">               treatment effects using machine learning, Proceedings of the National Academy of Sciences, </span>
<span class="sd">               116(10), 4156--4165, 2019. </span>
<span class="sd">               </span>
<span class="sd">        Examples</span>
<span class="sd">        --------</span>
<span class="sd">        &gt;&gt;&gt; np.random.seed(42)</span>
<span class="sd">        &gt;&gt;&gt; from blbf.STBT import STBT</span>
<span class="sd">        &gt;&gt;&gt; from blbf.PolicyEvaluation import PolicyEvaluation </span>
<span class="sd">        &gt;&gt;&gt; X, y = get_data(dataset=&#39;ecoli&#39;)</span>
<span class="sd">        &gt;&gt;&gt; obj = STBT(train_frac= 0.5)</span>
<span class="sd">        &gt;&gt;&gt; data = obj.generate_batch(X, y, max_iter=1000)</span>
<span class="sd">        &gt;&gt;&gt; PolicyEvaluation(method=&#39;dr&#39;).evaluate_policy(data = data)</span>
<span class="sd">        0.7241601514218099</span>
<span class="sd">        &quot;&quot;&quot;</span>
    
        <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">method</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s1">&#39;ips&#39;</span><span class="p">,</span> <span class="n">tau</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.001</span><span class="p">):</span>
            
            <span class="bp">self</span><span class="o">.</span><span class="n">method</span> <span class="o">=</span> <span class="n">method</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">tau</span> <span class="o">=</span> <span class="n">tau</span> 
            
            <span class="n">valid_methods</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;ips&#39;</span><span class="p">,</span> <span class="s1">&#39;dm&#39;</span><span class="p">,</span> <span class="s1">&#39;dr&#39;</span><span class="p">,</span> <span class="s1">&#39;switch&#39;</span><span class="p">]</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">method</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">valid_methods</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;</span><span class="si">%s</span><span class="s2"> is not a valid method.&quot;</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">method</span><span class="p">)</span>
        
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">tau</span> <span class="o">&lt;=</span> <span class="mi">0</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">tau</span> <span class="o">&gt;</span><span class="mi">1</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;`tau` must be in the (0, 1) interval, got </span><span class="si">%s</span><span class="s2">.&quot;</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">tau</span><span class="p">)</span>
                       
        <span class="k">def</span> <span class="fm">__repr__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
            
            <span class="n">items</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;</span><span class="si">%s</span><span class="s2"> = </span><span class="si">%r</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="n">v</span><span class="p">)</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="vm">__dict__</span><span class="o">.</span><span class="n">items</span><span class="p">())</span>
            <span class="k">return</span> <span class="s2">&quot;&lt;</span><span class="si">%s</span><span class="s2">: {</span><span class="si">%s</span><span class="s2">}&gt;&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="p">,</span> <span class="s1">&#39;, &#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">items</span><span class="p">))</span>
        
        <span class="k">def</span> <span class="nf">evaluate_policy</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">clf</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s1">&#39;LogisticRegression&#39;</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
            <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">            Parameters</span>
<span class="sd">            ----------</span>
<span class="sd">            data : STBT object</span>
<span class="sd">                This must be a Supervised to Bandit Transform (STBT) class with fitted </span>
<span class="sd">                `generate_batch` method.</span>
<span class="sd">                </span>
<span class="sd">            clf : str, default: &#39;LogisticRegression&#39;</span>
<span class="sd">            A sklearn classification estimator. Must be one of &#39;LogisticRegression&#39;, </span>
<span class="sd">            &#39;LogisticRegressionCV&#39;, &#39;RandomForestClassifier&#39;, or &#39;SVC&#39;.</span>
<span class="sd">           </span>
<span class="sd">            **kwargs : Arguments passed to clf.</span>
<span class="sd">    </span>
<span class="sd">            Returns</span>
<span class="sd">            -------</span>
<span class="sd">            float.</span>
<span class="sd">              The estimated value of the policy.</span>
<span class="sd">        </span>
<span class="sd">            &quot;&quot;&quot;</span>
              
            <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="s1">&#39;generate_batch_call&#39;</span><span class="p">):</span>
                <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s2">&quot;The method `generate_batch` must be called first on the instance: </span><span class="si">%s</span><span class="s2">.&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">data</span><span class="p">))</span>
                                    
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">method</span> <span class="o">==</span> <span class="s1">&#39;ips&#39;</span><span class="p">:</span>
                
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">tau</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="n">adj_test_logging_prob</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">maximum</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tau</span><span class="p">,</span> <span class="n">data</span><span class="o">.</span><span class="n">test_logging_prob</span><span class="p">)</span>  
                
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">adj_test_logging_prob</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">test_logging_prob</span>
                
                <span class="n">v</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">test_logging_reward</span> <span class="o">*</span> <span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">y_test_logging</span> <span class="o">==</span> <span class="n">data</span><span class="o">.</span><span class="n">y_test_target</span><span class="p">)</span> <span class="o">/</span> <span class="n">adj_test_logging_prob</span><span class="p">)</span>
                
            <span class="k">else</span><span class="p">:</span>
                <span class="n">XY_train</span><span class="p">,</span> <span class="n">lb_fit</span> <span class="o">=</span> <span class="n">create_interactions</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">X_train</span><span class="p">,</span> <span class="n">data</span><span class="o">.</span><span class="n">y_train_logging</span><span class="p">)</span>
                <span class="n">m</span> <span class="o">=</span> <span class="nb">eval</span><span class="p">(</span><span class="n">clf</span><span class="p">)(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">XY_train</span><span class="p">,</span> <span class="n">data</span><span class="o">.</span><span class="n">train_logging_reward</span><span class="p">)</span>
                <span class="n">XY_test_target</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">create_interactions</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">X_test</span><span class="p">,</span> <span class="n">data</span><span class="o">.</span><span class="n">y_test_target</span><span class="p">,</span> <span class="n">one_hot_labeler</span> <span class="o">=</span> <span class="n">lb_fit</span><span class="p">)</span>
                <span class="n">test_target_pred_reward</span> <span class="o">=</span> <span class="n">m</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">XY_test_target</span><span class="p">)[:,</span><span class="mi">1</span><span class="p">]</span>
                
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">method</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;dr&#39;</span><span class="p">,</span> <span class="s1">&#39;switch&#39;</span><span class="p">]:</span>
                    <span class="n">XY_test_logging</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">create_interactions</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">X_test</span><span class="p">,</span> <span class="n">data</span><span class="o">.</span><span class="n">y_test_logging</span><span class="p">,</span> <span class="n">one_hot_labeler</span> <span class="o">=</span> <span class="n">lb_fit</span><span class="p">)</span>
                    <span class="n">test_logging_pred_reward</span> <span class="o">=</span> <span class="n">m</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">XY_test_logging</span><span class="p">)[:,</span><span class="mi">1</span><span class="p">]</span>
                    <span class="n">dr_adj</span> <span class="o">=</span> <span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">test_logging_reward</span> <span class="o">-</span> <span class="n">test_logging_pred_reward</span><span class="p">)</span> <span class="o">*</span> \
                                 <span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">y_test_logging</span> <span class="o">==</span> <span class="n">data</span><span class="o">.</span><span class="n">y_test_target</span><span class="p">)</span> <span class="o">/</span> <span class="n">data</span><span class="o">.</span><span class="n">test_logging_prob</span>
                
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">method</span> <span class="o">==</span> <span class="s1">&#39;dm&#39;</span><span class="p">:</span>
                    <span class="n">v</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">test_target_pred_reward</span><span class="p">)</span> 
                    
                <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">method</span> <span class="o">==</span> <span class="s1">&#39;dr&#39;</span><span class="p">:</span>
                    <span class="n">v</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">test_target_pred_reward</span> <span class="o">+</span> <span class="n">dr_adj</span><span class="p">)</span>
                        
                <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">method</span> <span class="o">==</span> <span class="s1">&#39;switch&#39;</span><span class="p">:</span>
                    <span class="n">switch_indicator</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">test_logging_prob</span> <span class="o">&lt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tau</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">int</span><span class="p">)</span>
                    <span class="n">switch_estimator_rewards</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">switch_indicator</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="n">dr_adj</span> <span class="o">+</span> <span class="n">test_target_pred_reward</span><span class="p">)</span>
                    <span class="n">switch_estimator_rewards</span> <span class="o">+=</span> <span class="n">switch_indicator</span> <span class="o">*</span> <span class="n">test_target_pred_reward</span>
                    <span class="n">v</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">switch_estimator_rewards</span><span class="p">)</span>
          
            <span class="k">return</span> <span class="n">v</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="sample-datasets-used-in-experiments">
<h1>Sample datasets used in experiments<a class="headerlink" href="#sample-datasets-used-in-experiments" title="Permalink to this headline">¶</a></h1>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">get_data</span><span class="p">(</span><span class="n">dataset</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">scale</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">tuple</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;Get data (features and labels) used in experiments.</span>
<span class="sd">    </span>
<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    </span>
<span class="sd">    dataset : str, default: None </span>
<span class="sd">        It should be one of: &#39;ecoli&#39;, &#39;glass&#39;, &#39;letter-recognition&#39;, </span>
<span class="sd">        &#39;lymphography&#39;, &#39;yeast&#39;, &#39;digits&#39;, &#39;breast-cancer&#39;, &#39;wine&#39;, or </span>
<span class="sd">        &#39;mnist&#39;.</span>
<span class="sd">        </span>
<span class="sd">    scale : bool, default: True</span>
<span class="sd">        Standardize features by zero mean and unit variance.</span>
<span class="sd">        </span>
<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    </span>
<span class="sd">    tuple, length=2 </span>
<span class="sd">        tuple containing features-target split of inputs.</span>
<span class="sd">        </span>
<span class="sd">    References</span>
<span class="sd">    ----------</span>
<span class="sd">    Dua, D. and Graff, C. (2019). UCI Machine Learning Repository [http://archive.ics.uci.edu/ml]. </span>
<span class="sd">    Irvine, CA: University of California, School of Information and Computer Science.</span>
<span class="sd">    </span>
<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; X, y = get_data(dataset=&#39;ecoli&#39;)</span>
<span class="sd">    &gt;&gt;&gt; X[0,:]</span>
<span class="sd">    array([0.49, 0.29, 0.48, 0.5 , 0.56, 0.24, 0.35])</span>
<span class="sd">    </span>
<span class="sd">    &quot;&quot;&quot;</span>
    
    <span class="k">if</span> <span class="n">dataset</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;ecoli&#39;</span><span class="p">,</span> <span class="s1">&#39;glass&#39;</span><span class="p">,</span> <span class="s1">&#39;letter-recognition&#39;</span><span class="p">,</span> <span class="s1">&#39;lymphography&#39;</span><span class="p">,</span> <span class="s1">&#39;yeast&#39;</span><span class="p">,</span> 
                       <span class="s1">&#39;digits&#39;</span><span class="p">,</span> <span class="s1">&#39;breast-cancer&#39;</span><span class="p">,</span> <span class="s1">&#39;wine&#39;</span><span class="p">,</span> <span class="s1">&#39;mnist&#39;</span><span class="p">]:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Invalid dataset provided.&quot;</span><span class="p">)</span>
    
    <span class="k">if</span> <span class="n">dataset</span> <span class="ow">in</span> <span class="n">dataset</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;ecoli&#39;</span><span class="p">,</span> <span class="s1">&#39;glass&#39;</span><span class="p">,</span> <span class="s1">&#39;letter-recognition&#39;</span><span class="p">,</span> <span class="s1">&#39;lymphography&#39;</span><span class="p">,</span> <span class="s1">&#39;yeast&#39;</span><span class="p">]:</span>
        <span class="n">path</span> <span class="o">=</span> <span class="s1">&#39;https://archive.ics.uci.edu/ml/machine-learning-databases/&#39;</span> 
        <span class="n">f</span> <span class="o">=</span> <span class="n">path</span> <span class="o">+</span> <span class="n">dataset</span> <span class="o">+</span> <span class="s2">&quot;/&quot;</span> <span class="o">+</span> <span class="n">dataset</span> <span class="o">+</span> <span class="s2">&quot;.data&quot;</span>
     
    <span class="k">if</span> <span class="n">dataset</span> <span class="ow">in</span>  <span class="p">[</span><span class="s1">&#39;ecoli&#39;</span><span class="p">,</span> <span class="s1">&#39;yeast&#39;</span><span class="p">]:</span>
        <span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_table</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">delim_whitespace</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">header</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">dataset</span> <span class="ow">in</span> <span class="p">[</span> <span class="s1">&#39;glass&#39;</span><span class="p">,</span> <span class="s1">&#39;letter-recognition&#39;</span><span class="p">,</span> <span class="s1">&#39;lymphography&#39;</span><span class="p">]:</span>
        <span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">header</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">dataset</span> <span class="o">==</span> <span class="s1">&#39;digits&#39;</span><span class="p">:</span>
        <span class="n">df</span> <span class="o">=</span> <span class="n">load_digits</span><span class="p">()</span>
        <span class="n">X</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">data</span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">target</span>
    <span class="k">elif</span> <span class="n">dataset</span> <span class="o">==</span> <span class="s1">&#39;breast-cancer&#39;</span><span class="p">:</span>
        <span class="n">df</span> <span class="o">=</span> <span class="n">load_breast_cancer</span><span class="p">()</span>
        <span class="n">X</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">data</span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">target</span>
    <span class="k">elif</span> <span class="n">dataset</span> <span class="o">==</span> <span class="s1">&#39;wine&#39;</span><span class="p">:</span>
        <span class="n">df</span> <span class="o">=</span> <span class="n">load_wine</span><span class="p">()</span>
        <span class="n">X</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">data</span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">target</span>
        
    <span class="k">if</span> <span class="n">dataset</span> <span class="o">==</span> <span class="s1">&#39;ecoli&#39;</span><span class="p">:</span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">preprocessing</span><span class="o">.</span><span class="n">LabelEncoder</span><span class="p">()</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
        <span class="n">X</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span><span class="mi">1</span><span class="p">:</span><span class="mi">8</span><span class="p">]</span><span class="o">.</span><span class="n">values</span>
        
    <span class="k">elif</span> <span class="n">dataset</span> <span class="o">==</span> <span class="s1">&#39;glass&#39;</span><span class="p">:</span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">values</span>
        <span class="n">X</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">:(</span><span class="n">df</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">-</span><span class="mi">1</span><span class="p">)]</span><span class="o">.</span><span class="n">values</span>
        
    <span class="k">elif</span> <span class="n">dataset</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;letter-recognition&#39;</span><span class="p">,</span> <span class="s1">&#39;lymphography&#39;</span><span class="p">]:</span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">preprocessing</span><span class="o">.</span><span class="n">LabelEncoder</span><span class="p">()</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span><span class="mi">0</span><span class="p">])</span>
        <span class="n">X</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">:(</span><span class="n">df</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])]</span><span class="o">.</span><span class="n">values</span>
     
    <span class="k">elif</span> <span class="n">dataset</span> <span class="o">==</span> <span class="s1">&#39;yeast&#39;</span><span class="p">:</span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">preprocessing</span><span class="o">.</span><span class="n">LabelEncoder</span><span class="p">()</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
        <span class="n">X</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span><span class="mi">1</span><span class="p">:</span><span class="mi">9</span><span class="p">]</span><span class="o">.</span><span class="n">values</span>
        
    <span class="k">elif</span> <span class="n">dataset</span> <span class="o">==</span> <span class="s1">&#39;mnist&#39;</span><span class="p">:</span>
        <span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">fetch_openml</span><span class="p">(</span><span class="s1">&#39;mnist_784&#39;</span><span class="p">,</span> <span class="n">version</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">return_X_y</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">y</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s1">&#39;int64&#39;</span><span class="p">)</span> 

    <span class="k">if</span> <span class="n">scale</span><span class="o">==</span><span class="kc">True</span><span class="p">:</span>
        <span class="n">scaler</span> <span class="o">=</span> <span class="n">preprocessing</span><span class="o">.</span><span class="n">StandardScaler</span><span class="p">()</span>
        <span class="n">X</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
    
    <span class="k">return</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="compare-the-following-methods">
<h1>Compare the following methods<a class="headerlink" href="#compare-the-following-methods" title="Permalink to this headline">¶</a></h1>
<ul class="simple">
<li><p>IPS: Inverse Propensity Score</p></li>
<li><p>DM: Direct Method (Reward Prediction)</p></li>
<li><p>DR: Doubly Robust</p></li>
<li><p>SWITCH: Switch Estimator</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">ComparePolicyEvaluation</span><span class="p">:</span>
    
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">B</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">100</span><span class="p">,</span> <span class="n">datasets</span><span class="p">:</span> <span class="nb">list</span> <span class="o">=</span> <span class="kc">None</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">B</span> <span class="o">=</span> <span class="n">B</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">datasets</span> <span class="o">=</span> <span class="n">datasets</span>
        
    <span class="k">def</span> <span class="fm">__repr__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
            
        <span class="n">items</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;</span><span class="si">%s</span><span class="s2"> = </span><span class="si">%r</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="n">v</span><span class="p">)</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="vm">__dict__</span><span class="o">.</span><span class="n">items</span><span class="p">())</span>
        <span class="k">return</span> <span class="s2">&quot;&lt;</span><span class="si">%s</span><span class="s2">: {</span><span class="si">%s</span><span class="s2">}&gt;&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="p">,</span> <span class="s1">&#39;, &#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">items</span><span class="p">))</span>

    <span class="k">def</span> <span class="nf">fit_policies</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">:</span>
        
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">datasets</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">datasets</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;ecoli&#39;</span><span class="p">,</span> <span class="s1">&#39;glass&#39;</span><span class="p">,</span> <span class="s1">&#39;lymphography&#39;</span><span class="p">,</span> <span class="s1">&#39;yeast&#39;</span><span class="p">,</span> 
                        <span class="s1">&#39;digits&#39;</span><span class="p">,</span> <span class="s1">&#39;breast-cancer&#39;</span><span class="p">,</span> <span class="s1">&#39;wine&#39;</span><span class="p">]</span> <span class="c1"># &#39;letter-recognition&#39;</span>
        <span class="n">dat</span> <span class="o">=</span> <span class="nb">list</span><span class="p">()</span>
        <span class="n">true_value</span> <span class="o">=</span> <span class="nb">list</span><span class="p">()</span>
        <span class="n">ips</span> <span class="o">=</span> <span class="nb">list</span><span class="p">()</span>
        <span class="n">dm</span> <span class="o">=</span> <span class="nb">list</span><span class="p">()</span>
        <span class="n">dr</span> <span class="o">=</span> <span class="nb">list</span><span class="p">()</span>
        <span class="n">switch</span> <span class="o">=</span> <span class="nb">list</span><span class="p">()</span>
        
        <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">datasets</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">b</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">B</span><span class="p">):</span>
                <span class="k">if</span> <span class="p">(</span><span class="n">b</span> <span class="o">%</span> <span class="mi">10</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Sample: </span><span class="si">%d</span><span class="s2"> - Dataset: </span><span class="si">%s</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">b</span><span class="p">,</span> <span class="n">s</span><span class="p">))</span>
                <span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">get_data</span><span class="p">(</span><span class="n">dataset</span><span class="o">=</span><span class="n">s</span><span class="p">)</span>
                <span class="n">d</span> <span class="o">=</span> <span class="n">STBT</span><span class="p">()</span><span class="o">.</span><span class="n">generate_batch</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="mi">1000</span><span class="p">)</span>
                <span class="n">dat</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">s</span><span class="p">)</span>
                <span class="n">true_value</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">d</span><span class="o">.</span><span class="n">true_target_value_test</span><span class="p">)</span>
                <span class="n">ips</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">PolicyEvaluation</span><span class="p">(</span><span class="n">method</span><span class="o">=</span><span class="s1">&#39;ips&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">evaluate_policy</span><span class="p">(</span><span class="n">data</span> <span class="o">=</span> <span class="n">d</span><span class="p">))</span>
                <span class="n">dm</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">PolicyEvaluation</span><span class="p">(</span><span class="n">method</span><span class="o">=</span><span class="s1">&#39;dm&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">evaluate_policy</span><span class="p">(</span><span class="n">data</span> <span class="o">=</span> <span class="n">d</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">))</span>
                <span class="n">dr</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">PolicyEvaluation</span><span class="p">(</span><span class="n">method</span><span class="o">=</span><span class="s1">&#39;dr&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">evaluate_policy</span><span class="p">(</span><span class="n">data</span> <span class="o">=</span> <span class="n">d</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">))</span>
                <span class="n">switch</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">PolicyEvaluation</span><span class="p">(</span><span class="n">method</span><span class="o">=</span><span class="s1">&#39;switch&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">evaluate_policy</span><span class="p">(</span><span class="n">data</span> <span class="o">=</span> <span class="n">d</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">))</span>
           
        <span class="n">res</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="o">.</span><span class="n">from_dict</span><span class="p">({</span><span class="s1">&#39;dataset&#39;</span><span class="p">:</span><span class="n">dat</span><span class="p">,</span> <span class="s1">&#39;true_value&#39;</span><span class="p">:</span><span class="n">true_value</span><span class="p">,</span> <span class="s1">&#39;ips&#39;</span><span class="p">:</span><span class="n">ips</span><span class="p">,</span>
                                     <span class="s1">&#39;dm&#39;</span><span class="p">:</span> <span class="n">dm</span><span class="p">,</span> <span class="s1">&#39;dr&#39;</span><span class="p">:</span><span class="n">dr</span><span class="p">,</span> <span class="s1">&#39;switch&#39;</span><span class="p">:</span> <span class="n">switch</span><span class="p">})</span>
    
        <span class="c1"># Bias</span>
        <span class="n">res</span><span class="p">[</span><span class="s1">&#39;ips_bias&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">res</span><span class="p">[</span><span class="s1">&#39;true_value&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span> <span class="o">-</span> <span class="n">res</span><span class="p">[</span><span class="s1">&#39;ips&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span>
        <span class="n">res</span><span class="p">[</span><span class="s1">&#39;dm_bias&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">res</span><span class="p">[</span><span class="s1">&#39;true_value&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span> <span class="o">-</span> <span class="n">res</span><span class="p">[</span><span class="s1">&#39;dm&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span>
        <span class="n">res</span><span class="p">[</span><span class="s1">&#39;dr_bias&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">res</span><span class="p">[</span><span class="s1">&#39;true_value&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span> <span class="o">-</span> <span class="n">res</span><span class="p">[</span><span class="s1">&#39;dr&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span>
        <span class="n">res</span><span class="p">[</span><span class="s1">&#39;switch_bias&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">res</span><span class="p">[</span><span class="s1">&#39;true_value&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span> <span class="o">-</span> <span class="n">res</span><span class="p">[</span><span class="s1">&#39;switch&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span>
        
        <span class="c1"># Relative risk</span>
        <span class="n">res</span><span class="p">[</span><span class="s1">&#39;ips_rr&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">((</span><span class="n">res</span><span class="p">[</span><span class="s1">&#39;true_value&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span> <span class="o">-</span> <span class="n">res</span><span class="p">[</span><span class="s1">&#39;ips&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">)</span><span class="o">/</span><span class="n">res</span><span class="p">[</span><span class="s1">&#39;true_value&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">)</span>
        <span class="n">res</span><span class="p">[</span><span class="s1">&#39;dm_rr&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">((</span><span class="n">res</span><span class="p">[</span><span class="s1">&#39;true_value&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span> <span class="o">-</span> <span class="n">res</span><span class="p">[</span><span class="s1">&#39;dm&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">)</span><span class="o">/</span><span class="n">res</span><span class="p">[</span><span class="s1">&#39;true_value&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">)</span>
        <span class="n">res</span><span class="p">[</span><span class="s1">&#39;dr_rr&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">((</span><span class="n">res</span><span class="p">[</span><span class="s1">&#39;true_value&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span> <span class="o">-</span> <span class="n">res</span><span class="p">[</span><span class="s1">&#39;dr&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">)</span><span class="o">/</span><span class="n">res</span><span class="p">[</span><span class="s1">&#39;true_value&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">)</span>
        <span class="n">res</span><span class="p">[</span><span class="s1">&#39;switch_rr&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">((</span><span class="n">res</span><span class="p">[</span><span class="s1">&#39;true_value&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span> <span class="o">-</span> <span class="n">res</span><span class="p">[</span><span class="s1">&#39;switch&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">)</span><span class="o">/</span><span class="n">res</span><span class="p">[</span><span class="s1">&#39;true_value&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">)</span>
        
        <span class="bp">self</span><span class="o">.</span><span class="n">res</span> <span class="o">=</span> <span class="n">res</span>
       
        <span class="k">return</span> <span class="bp">self</span>
    
    <span class="k">def</span> <span class="nf">get_summary_stats</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        
        <span class="n">res_summary</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">res</span><span class="o">.</span><span class="n">groupby</span><span class="p">([</span><span class="s1">&#39;dataset&#39;</span><span class="p">],</span> <span class="n">as_index</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span><span class="o">.</span><span class="n">agg</span><span class="p">({</span>
                            <span class="s1">&#39;ips_bias&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;mean&#39;</span><span class="p">,</span><span class="s1">&#39;std&#39;</span><span class="p">],</span> 
                            <span class="s1">&#39;dm_bias&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;mean&#39;</span><span class="p">,</span><span class="s1">&#39;std&#39;</span><span class="p">],</span>
                            <span class="s1">&#39;dr_bias&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;mean&#39;</span><span class="p">,</span><span class="s1">&#39;std&#39;</span><span class="p">],</span>
                            <span class="s1">&#39;switch_bias&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;mean&#39;</span><span class="p">,</span><span class="s1">&#39;std&#39;</span><span class="p">],</span>
                            <span class="s1">&#39;ips_rr&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;mean&#39;</span><span class="p">,</span><span class="s1">&#39;std&#39;</span><span class="p">],</span> 
                            <span class="s1">&#39;dm_rr&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;mean&#39;</span><span class="p">,</span><span class="s1">&#39;std&#39;</span><span class="p">],</span>
                            <span class="s1">&#39;dr_rr&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;mean&#39;</span><span class="p">,</span><span class="s1">&#39;std&#39;</span><span class="p">],</span>
                            <span class="s1">&#39;switch_rr&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;mean&#39;</span><span class="p">,</span><span class="s1">&#39;std&#39;</span><span class="p">]</span>
                            <span class="p">})</span>
        
        <span class="bp">self</span><span class="o">.</span><span class="n">res_summary</span> <span class="o">=</span> <span class="n">res_summary</span>
        <span class="k">return</span> <span class="bp">self</span>
    
    <span class="k">def</span> <span class="nf">plot_bias</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        
        <span class="n">res_long</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">melt</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">res</span><span class="p">,</span> <span class="n">id_vars</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;dataset&#39;</span><span class="p">],</span> <span class="n">var_name</span> <span class="o">=</span> <span class="s1">&#39;method&#39;</span><span class="p">,</span> <span class="n">value_name</span> <span class="o">=</span> <span class="s2">&quot;bias&quot;</span><span class="p">,</span>
                  <span class="n">value_vars</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;ips_bias&#39;</span><span class="p">,</span>  <span class="s1">&#39;dm_bias&#39;</span><span class="p">,</span> <span class="s1">&#39;dr_bias&#39;</span><span class="p">,</span> <span class="s1">&#39;switch_bias&#39;</span><span class="p">])</span>

        <span class="n">ax</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">catplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="s2">&quot;method&quot;</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s2">&quot;bias&quot;</span><span class="p">,</span> <span class="n">col</span> <span class="o">=</span> <span class="s2">&quot;dataset&quot;</span><span class="p">,</span> <span class="n">kind</span> <span class="o">=</span> <span class="s2">&quot;box&quot;</span><span class="p">,</span> 
                          <span class="n">col_wrap</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">res_long</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">ax</span><span class="o">.</span><span class="n">axes</span><span class="p">)):</span>
            <span class="n">ax_i</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">axes</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
            <span class="n">ax_i</span><span class="o">.</span><span class="n">axhline</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">ls</span><span class="o">=</span><span class="s2">&quot;--&quot;</span><span class="p">)</span>
        
        <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">cpe</span> <span class="o">=</span> <span class="n">ComparePolicyEvaluation</span><span class="p">(</span><span class="n">B</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span><span class="o">.</span><span class="n">fit_policies</span><span class="p">(</span><span class="n">max_iter</span><span class="o">=</span><span class="mi">1000</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Sample: 0 - Dataset: ecoli
Sample: 10 - Dataset: ecoli
Sample: 20 - Dataset: ecoli
Sample: 30 - Dataset: ecoli
Sample: 40 - Dataset: ecoli
Sample: 50 - Dataset: ecoli
Sample: 60 - Dataset: ecoli
Sample: 70 - Dataset: ecoli
Sample: 80 - Dataset: ecoli
Sample: 90 - Dataset: ecoli
Sample: 0 - Dataset: glass
Sample: 10 - Dataset: glass
Sample: 20 - Dataset: glass
Sample: 30 - Dataset: glass
Sample: 40 - Dataset: glass
Sample: 50 - Dataset: glass
Sample: 60 - Dataset: glass
Sample: 70 - Dataset: glass
Sample: 80 - Dataset: glass
Sample: 90 - Dataset: glass
Sample: 0 - Dataset: lymphography
Sample: 10 - Dataset: lymphography
Sample: 20 - Dataset: lymphography
Sample: 30 - Dataset: lymphography
Sample: 40 - Dataset: lymphography
Sample: 50 - Dataset: lymphography
Sample: 60 - Dataset: lymphography
Sample: 70 - Dataset: lymphography
Sample: 80 - Dataset: lymphography
Sample: 90 - Dataset: lymphography
Sample: 0 - Dataset: yeast
Sample: 10 - Dataset: yeast
Sample: 20 - Dataset: yeast
Sample: 30 - Dataset: yeast
Sample: 40 - Dataset: yeast
Sample: 50 - Dataset: yeast
Sample: 60 - Dataset: yeast
Sample: 70 - Dataset: yeast
Sample: 80 - Dataset: yeast
Sample: 90 - Dataset: yeast
Sample: 0 - Dataset: digits
Sample: 10 - Dataset: digits
Sample: 20 - Dataset: digits
Sample: 30 - Dataset: digits
Sample: 40 - Dataset: digits
Sample: 50 - Dataset: digits
Sample: 60 - Dataset: digits
Sample: 70 - Dataset: digits
Sample: 80 - Dataset: digits
Sample: 90 - Dataset: digits
Sample: 0 - Dataset: breast-cancer
Sample: 10 - Dataset: breast-cancer
Sample: 20 - Dataset: breast-cancer
Sample: 30 - Dataset: breast-cancer
Sample: 40 - Dataset: breast-cancer
Sample: 50 - Dataset: breast-cancer
Sample: 60 - Dataset: breast-cancer
Sample: 70 - Dataset: breast-cancer
Sample: 80 - Dataset: breast-cancer
Sample: 90 - Dataset: breast-cancer
Sample: 0 - Dataset: wine
Sample: 10 - Dataset: wine
Sample: 20 - Dataset: wine
Sample: 30 - Dataset: wine
Sample: 40 - Dataset: wine
Sample: 50 - Dataset: wine
Sample: 60 - Dataset: wine
Sample: 70 - Dataset: wine
Sample: 80 - Dataset: wine
Sample: 90 - Dataset: wine
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">cpe</span><span class="o">.</span><span class="n">get_summary_stats</span><span class="p">()</span>
<span class="n">cpe</span><span class="o">.</span><span class="n">res_summary</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead tr th {
        text-align: left;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr>
      <th></th>
      <th>dataset</th>
      <th colspan="2" halign="left">ips_bias</th>
      <th colspan="2" halign="left">dm_bias</th>
      <th colspan="2" halign="left">dr_bias</th>
      <th colspan="2" halign="left">switch_bias</th>
      <th colspan="2" halign="left">ips_rr</th>
      <th colspan="2" halign="left">dm_rr</th>
      <th colspan="2" halign="left">dr_rr</th>
      <th colspan="2" halign="left">switch_rr</th>
    </tr>
    <tr>
      <th></th>
      <th></th>
      <th>mean</th>
      <th>std</th>
      <th>mean</th>
      <th>std</th>
      <th>mean</th>
      <th>std</th>
      <th>mean</th>
      <th>std</th>
      <th>mean</th>
      <th>std</th>
      <th>mean</th>
      <th>std</th>
      <th>mean</th>
      <th>std</th>
      <th>mean</th>
      <th>std</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>breast-cancer</td>
      <td>0.015439</td>
      <td>0.056258</td>
      <td>0.031097</td>
      <td>0.014548</td>
      <td>0.002050</td>
      <td>0.009696</td>
      <td>0.002050</td>
      <td>0.009696</td>
      <td>0.051048</td>
      <td>0.033579</td>
      <td>0.032639</td>
      <td>0.015079</td>
      <td>0.008363</td>
      <td>0.006185</td>
      <td>0.008363</td>
      <td>0.006185</td>
    </tr>
    <tr>
      <th>1</th>
      <td>digits</td>
      <td>-0.000356</td>
      <td>0.099657</td>
      <td>0.271003</td>
      <td>0.036489</td>
      <td>-0.003003</td>
      <td>0.045847</td>
      <td>-0.003003</td>
      <td>0.045847</td>
      <td>0.086759</td>
      <td>0.063050</td>
      <td>0.291985</td>
      <td>0.039215</td>
      <td>0.039939</td>
      <td>0.029041</td>
      <td>0.039939</td>
      <td>0.029041</td>
    </tr>
    <tr>
      <th>2</th>
      <td>ecoli</td>
      <td>0.036131</td>
      <td>0.159114</td>
      <td>0.221680</td>
      <td>0.069068</td>
      <td>0.021395</td>
      <td>0.082412</td>
      <td>0.021395</td>
      <td>0.082412</td>
      <td>0.168851</td>
      <td>0.126703</td>
      <td>0.288876</td>
      <td>0.088675</td>
      <td>0.086244</td>
      <td>0.068031</td>
      <td>0.086244</td>
      <td>0.068031</td>
    </tr>
    <tr>
      <th>3</th>
      <td>glass</td>
      <td>-0.005234</td>
      <td>0.135409</td>
      <td>0.108039</td>
      <td>0.077705</td>
      <td>-0.015941</td>
      <td>0.102587</td>
      <td>-0.015941</td>
      <td>0.102587</td>
      <td>0.231339</td>
      <td>0.168950</td>
      <td>0.231582</td>
      <td>0.136500</td>
      <td>0.177798</td>
      <td>0.135564</td>
      <td>0.177798</td>
      <td>0.135564</td>
    </tr>
    <tr>
      <th>4</th>
      <td>lymphography</td>
      <td>-0.030135</td>
      <td>0.166516</td>
      <td>0.210184</td>
      <td>0.112056</td>
      <td>-0.006171</td>
      <td>0.097335</td>
      <td>-0.006171</td>
      <td>0.097335</td>
      <td>0.166880</td>
      <td>0.141465</td>
      <td>0.278812</td>
      <td>0.132798</td>
      <td>0.100086</td>
      <td>0.078494</td>
      <td>0.100086</td>
      <td>0.078494</td>
    </tr>
    <tr>
      <th>5</th>
      <td>wine</td>
      <td>0.004831</td>
      <td>0.121543</td>
      <td>0.123857</td>
      <td>0.042780</td>
      <td>-0.000622</td>
      <td>0.038650</td>
      <td>-0.000622</td>
      <td>0.038650</td>
      <td>0.099961</td>
      <td>0.082773</td>
      <td>0.132158</td>
      <td>0.045198</td>
      <td>0.031962</td>
      <td>0.026401</td>
      <td>0.031962</td>
      <td>0.026401</td>
    </tr>
    <tr>
      <th>6</th>
      <td>yeast</td>
      <td>-0.010755</td>
      <td>0.071710</td>
      <td>0.080556</td>
      <td>0.037969</td>
      <td>-0.006330</td>
      <td>0.058608</td>
      <td>-0.006330</td>
      <td>0.058608</td>
      <td>0.127633</td>
      <td>0.097028</td>
      <td>0.178583</td>
      <td>0.078501</td>
      <td>0.105852</td>
      <td>0.077361</td>
      <td>0.105852</td>
      <td>0.077361</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">cpe</span><span class="o">.</span><span class="n">plot_bias</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/T890478_Batch_Learning_from_Bandit_Feedback_(BLBF)_15_0.png" src="../_images/T890478_Batch_Learning_from_Bandit_Feedback_(BLBF)_15_0.png" />
</div>
</div>
</div>
<div class="section" id="off-policy-learning-estimators">
<h1>Off-Policy Learning Estimators<a class="headerlink" href="#off-policy-learning-estimators" title="Permalink to this headline">¶</a></h1>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">EvaluationMetrics</span><span class="p">:</span>
    
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">pass</span>
    
    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">error_rate</span><span class="p">(</span><span class="n">y_pred</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
        <span class="n">er</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="mi">1</span> <span class="o">*</span> <span class="p">(</span><span class="n">y_pred</span> <span class="o">==</span> <span class="n">y</span><span class="p">))</span>
        
        <span class="k">return</span> <span class="n">er</span>

<span class="k">class</span> <span class="nc">BanditDataset</span><span class="p">(</span><span class="n">Dataset</span><span class="p">):</span>
    
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">p0</span><span class="p">,</span> <span class="n">r</span><span class="p">,</span> <span class="n">y_idx</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">X</span> <span class="o">=</span> <span class="n">X</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">y</span> <span class="o">=</span> <span class="n">y</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">p0</span> <span class="o">=</span> <span class="n">p0</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">r</span> <span class="o">=</span> <span class="n">r</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">y_idx</span> <span class="o">=</span> <span class="n">y_idx</span>
        
    <span class="k">def</span> <span class="fm">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">index</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">X</span><span class="p">[</span><span class="n">index</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">y</span><span class="p">[</span><span class="n">index</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">p0</span><span class="p">[</span><span class="n">index</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">r</span><span class="p">[</span><span class="n">index</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">y_idx</span><span class="p">[</span><span class="n">index</span><span class="p">]</span>
        
    <span class="k">def</span> <span class="fm">__len__</span> <span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">X</span><span class="p">)</span>
    
    
<span class="k">class</span> <span class="nc">LinearModel</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">n_features</span><span class="p">,</span> <span class="n">n_actions</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">LinearModel</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">linear</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">n_features</span><span class="p">,</span> <span class="n">n_actions</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">xw_plus_b</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">linear</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">xw_plus_b</span> <span class="c1"># batch size x n_actions</span>
    
<span class="k">class</span> <span class="nc">NonLinearModel</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">n_features</span><span class="p">,</span> <span class="n">n_actions</span><span class="p">,</span> <span class="n">n_hidden</span><span class="o">=</span><span class="mi">3</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">l1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">n_features</span><span class="p">,</span><span class="n">n_hidden</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">l2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">n_hidden</span><span class="p">,</span><span class="n">n_actions</span><span class="p">)</span>
        
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">l2</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">l1</span><span class="p">(</span><span class="n">x</span><span class="p">)))</span>
   

<span class="k">class</span> <span class="nc">RewardPredictor</span><span class="p">(</span><span class="n">EvaluationMetrics</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Performs policy learning using by directly predicting the Reward as a function of covariates, </span>
<span class="sd">    actions and their interaction. </span>
<span class="sd">    </span>
<span class="sd">    References</span>
<span class="sd">    ----------</span>
<span class="sd">    </span>
<span class="sd">    .. [1] A. Swaminathan and T. Joachims, Batch Learning from Logged Bandit Feedback through </span>
<span class="sd">           Counterfactual Risk Minimization, Journal of Machine Learning Research, 16(52),</span>
<span class="sd">           1731--1755, 2015.</span>
<span class="sd">    .. [2] A. Swaminathan and T. Joachims, The self-normalized estimator for counterfactual learning, </span>
<span class="sd">           Advances in Neural Information Processing Systems, 28, 16(52), 3231--3239, 2015.</span>
<span class="sd">    .. [3] A. Swaminathan, T. Joachims, and M. de Rijke, Deep Learning with Logged Bandit Feedback, </span>
<span class="sd">           International Conference on Learning Representations,  2018.</span>
<span class="sd">    </span>
<span class="sd">    &quot;&quot;&quot;</span>
        
    
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">pass</span>
     
    <span class="k">def</span> <span class="fm">__repr__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
    
        <span class="n">items</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;</span><span class="si">%s</span><span class="s2"> = </span><span class="si">%r</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="n">v</span><span class="p">)</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="vm">__dict__</span><span class="o">.</span><span class="n">items</span><span class="p">())</span>
        <span class="k">return</span> <span class="s2">&quot;&lt;</span><span class="si">%s</span><span class="s2">: {</span><span class="si">%s</span><span class="s2">}&gt;&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="p">,</span> <span class="s1">&#39;, &#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">items</span><span class="p">))</span>
    
    <span class="k">def</span> <span class="nf">learn_policy</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">clf</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s1">&#39;LogisticRegression&#39;</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        data : STBT object</span>
<span class="sd">            This must be a Supervised to Bandit Transform (STBT) class with fitted </span>
<span class="sd">            `generate_batch` method.</span>
<span class="sd">            </span>
<span class="sd">        clf : str, default: &#39;LogisticRegression&#39;</span>
<span class="sd">        A sklearn classification estimator. Must be one of &#39;LogisticRegression&#39;, </span>
<span class="sd">        &#39;LogisticRegressionCV&#39;, &#39;RandomForestClassifier&#39;, or &#39;SVC&#39;.</span>
<span class="sd">       </span>
<span class="sd">        **kwargs : Arguments passed to clf.</span>
<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        int.</span>
<span class="sd">          The predicted best policy.</span>
<span class="sd">        </span>
<span class="sd">        &quot;&quot;&quot;</span>    
    
        <span class="n">XY_train</span><span class="p">,</span> <span class="n">lb_fit</span> <span class="o">=</span> <span class="n">create_interactions</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">X_train</span><span class="p">,</span> <span class="n">data</span><span class="o">.</span><span class="n">y_train_logging</span><span class="p">)</span>
        <span class="n">y_train_logging_u</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">y_train_logging</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">train_pred_reward_arr</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="n">data</span><span class="o">.</span><span class="n">X_train</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="nb">len</span><span class="p">(</span><span class="n">y_train_logging_u</span><span class="p">)])</span> 
        <span class="bp">self</span><span class="o">.</span><span class="n">test_pred_reward_arr</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="n">data</span><span class="o">.</span><span class="n">X_test</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="nb">len</span><span class="p">(</span><span class="n">y_train_logging_u</span><span class="p">)])</span> 
        <span class="n">m</span> <span class="o">=</span> <span class="nb">eval</span><span class="p">(</span><span class="n">clf</span><span class="p">)(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">XY_train</span><span class="p">,</span> <span class="n">data</span><span class="o">.</span><span class="n">train_logging_reward</span><span class="p">)</span>
        
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">yval</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">y_train_logging_u</span><span class="p">):</span>
           <span class="n">XY_train_yval</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">create_interactions</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">X_train</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="n">yval</span><span class="p">,</span> <span class="n">data</span><span class="o">.</span><span class="n">X_train</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span> <span class="n">one_hot_labeler</span> <span class="o">=</span> <span class="n">lb_fit</span><span class="p">)</span>
           <span class="n">XY_test_yval</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">create_interactions</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">X_test</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="n">yval</span><span class="p">,</span> <span class="n">data</span><span class="o">.</span><span class="n">X_test</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span> <span class="n">one_hot_labeler</span> <span class="o">=</span> <span class="n">lb_fit</span><span class="p">)</span>
           <span class="bp">self</span><span class="o">.</span><span class="n">train_pred_reward_arr</span><span class="p">[:,</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">m</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">XY_train_yval</span><span class="p">)[:,</span><span class="mi">1</span><span class="p">]</span>
           <span class="bp">self</span><span class="o">.</span><span class="n">test_pred_reward_arr</span><span class="p">[:,</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">m</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">XY_test_yval</span><span class="p">)[:,</span><span class="mi">1</span><span class="p">]</span>
             
        <span class="bp">self</span><span class="o">.</span><span class="n">est_best_policy</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">y_train_logging_u</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">test_pred_reward_arr</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)])</span>
             
        <span class="k">return</span> <span class="bp">self</span>
    
<span class="k">class</span> <span class="nc">OutcomeWeightedLearning</span><span class="p">(</span><span class="n">EvaluationMetrics</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Performs policy learning by transforming the learning problem into a </span>
<span class="sd">    weighted multi-class classification problem. </span>
<span class="sd">    </span>
<span class="sd">    </span>
<span class="sd">    References</span>
<span class="sd">    ----------</span>
<span class="sd">    </span>
<span class="sd">    .. [1] Y. Zhao, D. Zeng, A.J. Rush and M. R. Kosorok, Estimating Individualized Treatment </span>
<span class="sd">           Rules Using Outcome Weighted Learning, Journal of the American Statistical Association, </span>
<span class="sd">           107:499, 1106-1118, 2012, DOI: 10.1080/01621459.2012.695674.</span>
<span class="sd">    &quot;&quot;&quot;</span>
        
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">pass</span>
     
    <span class="k">def</span> <span class="fm">__repr__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
    
        <span class="n">items</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;</span><span class="si">%s</span><span class="s2"> = </span><span class="si">%r</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="n">v</span><span class="p">)</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="vm">__dict__</span><span class="o">.</span><span class="n">items</span><span class="p">())</span>
        <span class="k">return</span> <span class="s2">&quot;&lt;</span><span class="si">%s</span><span class="s2">: {</span><span class="si">%s</span><span class="s2">}&gt;&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="p">,</span> <span class="s1">&#39;, &#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">items</span><span class="p">))</span>
    
    <span class="k">def</span> <span class="nf">learn_policy</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">clf</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s1">&#39;SVC&#39;</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
    
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        data : STBT object</span>
<span class="sd">            This must be a Supervised to Bandit Transform (STBT) class with fitted </span>
<span class="sd">            `generate_batch` method.</span>
<span class="sd">            </span>
<span class="sd">        clf : str, default: &#39;SVC&#39;</span>
<span class="sd">        A sklearn classification estimator. Must be one of &#39;LogisticRegression&#39;, </span>
<span class="sd">        &#39;LogisticRegressionCV&#39;, &#39;RandomForestClassifier&#39;, or &#39;SVC&#39;.</span>
<span class="sd">       </span>
<span class="sd">        **kwargs : Arguments passed to clf.</span>
<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        int.</span>
<span class="sd">          The predicted best policy.</span>
<span class="sd">        </span>
<span class="sd">        &quot;&quot;&quot;</span>    
        
        <span class="n">wt</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">train_logging_reward</span> <span class="o">/</span> <span class="n">data</span><span class="o">.</span><span class="n">train_logging_prob</span>
        
        <span class="k">if</span> <span class="n">clf</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;SVC&#39;</span><span class="p">,</span> <span class="s1">&#39;RandomForestClassifier&#39;</span><span class="p">]:</span>
            <span class="n">m</span> <span class="o">=</span> <span class="nb">eval</span><span class="p">(</span><span class="n">clf</span><span class="p">)(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">X_train</span><span class="p">,</span> <span class="n">data</span><span class="o">.</span><span class="n">y_train_logging</span><span class="p">,</span> <span class="n">sample_weight</span> <span class="o">=</span> <span class="n">wt</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">clf</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;LogisticRegression&#39;</span><span class="p">,</span> <span class="s1">&#39;LogisticRegressionCV&#39;</span><span class="p">]:</span>
            <span class="n">m</span> <span class="o">=</span> <span class="nb">eval</span><span class="p">(</span><span class="n">clf</span><span class="p">)(</span><span class="n">multi_class</span><span class="o">=</span><span class="s1">&#39;multinomial&#39;</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">X_train</span><span class="p">,</span> <span class="n">data</span><span class="o">.</span><span class="n">y_train_logging</span><span class="p">,</span> <span class="n">sample_weight</span> <span class="o">=</span> <span class="n">wt</span><span class="p">)</span>
        
        <span class="bp">self</span><span class="o">.</span><span class="n">est_best_policy</span> <span class="o">=</span> <span class="n">m</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">X_test</span><span class="p">)</span>
        
        <span class="k">return</span> <span class="bp">self</span>
         

<span class="k">class</span> <span class="nc">VowpalWabbit</span><span class="p">(</span><span class="n">EvaluationMetrics</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Performs policy learning using Vowpal Wabbit. </span>
<span class="sd">    </span>
<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    method : str, default: &#39;ips&#39;</span>
<span class="sd">        The policy evaluation approach to optimize a policy. Vowpal Wabbit offers four </span>
<span class="sd">        approaches to specify a contextual bandit approach:</span>
<span class="sd">            * Inverse Propensity Score: &#39;ips&#39;</span>
<span class="sd">            * Doubly Robust: &#39;dr&#39;</span>
<span class="sd">            * Direct Method: &#39;dm&#39;</span>
<span class="sd">            * Multi Task Regression/Importance Weighted Regression: &#39;mtr&#39; </span>
<span class="sd">       </span>
<span class="sd">    References</span>
<span class="sd">    ----------</span>
<span class="sd">    </span>
<span class="sd">    .. [1] A. Bietti and A. Agarwal and J. Langford, A Contextual Bandit Bake-off, </span>
<span class="sd">        arXiv preprint arXiv:1802.04064, 2018.</span>
<span class="sd">    </span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">method</span> <span class="o">=</span> <span class="s1">&#39;dr&#39;</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">method</span> <span class="o">=</span> <span class="n">method</span>
     
    <span class="k">def</span> <span class="fm">__repr__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
    
        <span class="n">items</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;</span><span class="si">%s</span><span class="s2"> = </span><span class="si">%r</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="n">v</span><span class="p">)</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="vm">__dict__</span><span class="o">.</span><span class="n">items</span><span class="p">())</span>
        <span class="k">return</span> <span class="s2">&quot;&lt;</span><span class="si">%s</span><span class="s2">: {</span><span class="si">%s</span><span class="s2">}&gt;&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="p">,</span> <span class="s1">&#39;, &#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">items</span><span class="p">))</span>
    
    <span class="k">def</span> <span class="nf">_train_vw</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">):</span>
        <span class="n">n_actions</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">y_train_logging</span><span class="p">))</span>
        <span class="n">vw</span> <span class="o">=</span> <span class="n">pyvw</span><span class="o">.</span><span class="n">vw</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="s2">&quot;--cb_type&quot;</span><span class="p">)</span> <span class="o">+</span> <span class="s2">&quot; &quot;</span> <span class="o">+</span>  <span class="bp">self</span><span class="o">.</span><span class="n">method</span> <span class="o">+</span> <span class="s2">&quot; &quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">n_actions</span><span class="p">))</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">X_train</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
            <span class="n">action</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">y_train_logging</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
            <span class="n">cost</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">data</span><span class="o">.</span><span class="n">train_logging_reward</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="c1"># input requires cost instead of reward</span>
            <span class="n">probability</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">train_logging_prob</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
            <span class="n">train_features_ls</span> <span class="o">=</span> <span class="nb">list</span><span class="p">()</span>
            <span class="k">for</span> <span class="n">f</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">X_train</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]):</span>
                <span class="n">train_features_ls</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">X_train</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">f</span><span class="p">]))</span>
                <span class="n">train_features</span> <span class="o">=</span> <span class="s2">&quot; &quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">train_features_ls</span><span class="p">)</span>
            <span class="n">learn_example</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="n">action</span><span class="p">)</span> <span class="o">+</span> <span class="s2">&quot;:&quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">cost</span><span class="p">)</span> <span class="o">+</span> <span class="s2">&quot;:&quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">probability</span><span class="p">)</span> <span class="o">+</span> <span class="s2">&quot; | &quot;</span> <span class="o">+</span> <span class="n">train_features</span>
            <span class="n">vw</span><span class="o">.</span><span class="n">learn</span><span class="p">(</span><span class="n">learn_example</span><span class="p">)</span> 
        <span class="k">return</span> <span class="n">vw</span>
    
    <span class="k">def</span> <span class="nf">_predict_vw</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">vw_object</span><span class="p">,</span> <span class="n">data</span><span class="p">):</span>
        <span class="n">test_features_ls</span> <span class="o">=</span> <span class="nb">list</span><span class="p">()</span>
        <span class="n">predictions</span> <span class="o">=</span> <span class="nb">list</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">X_test</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
            <span class="k">for</span> <span class="n">f</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">X_test</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]):</span>
                <span class="n">test_features_ls</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">X_test</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">f</span><span class="p">]))</span>
                <span class="n">features</span> <span class="o">=</span> <span class="s2">&quot; &quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">test_features_ls</span><span class="p">)</span>
            <span class="n">test_example</span> <span class="o">=</span> <span class="s2">&quot; | &quot;</span> <span class="o">+</span> <span class="n">features</span>
            <span class="n">pred</span> <span class="o">=</span> <span class="n">vw_object</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">test_example</span><span class="p">)</span> 
            <span class="n">predictions</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">pred</span><span class="p">)</span>
        <span class="n">predictions</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">predictions</span><span class="p">)</span>
    
        <span class="k">return</span> <span class="n">predictions</span> 
        
    
    <span class="k">def</span> <span class="nf">learn_policy</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        data : STBT object</span>
<span class="sd">            This must be a Supervised to Bandit Transform (STBT) class with fitted </span>
<span class="sd">            `generate_batch` method.</span>
<span class="sd">            </span>
<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        int.</span>
<span class="sd">          The predicted best policy.</span>
<span class="sd">        </span>
<span class="sd">        &quot;&quot;&quot;</span> 
        
        <span class="n">vw_fit</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_train_vw</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">est_best_policy</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_predict_vw</span><span class="p">(</span><span class="n">vw_fit</span><span class="p">,</span> <span class="n">data</span><span class="p">)</span>
        
        <span class="k">return</span> <span class="bp">self</span>

<span class="k">class</span> <span class="nc">CounterfactualRiskMinimization</span><span class="p">(</span><span class="n">EvaluationMetrics</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Performs policy learning using the Counterfactual Risk Minimization </span>
<span class="sd">    approach proposed in [1], and later refined in [2].</span>
<span class="sd">    </span>
<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    </span>
<span class="sd">    batch_size : int, default: 96</span>
<span class="sd">        The number of samples per batch to load </span>
<span class="sd">    learning_rate : float, default: 0.01</span>
<span class="sd">        Stochastic gradient descent learning rate </span>
<span class="sd">    weight_decay : float, default: 0.001</span>
<span class="sd">        L2 regularization on parameters</span>
<span class="sd">    lambda_ : float, default: 0.1</span>
<span class="sd">        Variance regularization. Penalty on the variance of the </span>
<span class="sd">        learnt policy relative to the logging policy.</span>
<span class="sd">    self_normalize: bool, default: True</span>
<span class="sd">        Whether to normalize the IPS estimator. See [2].</span>
<span class="sd">    clipping: float, default: 100.</span>
<span class="sd">        Clipping the importance sample weights. See [1].</span>
<span class="sd">    verbose: bool, default: False</span>
<span class="sd">        Whether to print Poem Loss during training .</span>
<span class="sd">    </span>
<span class="sd">    References</span>
<span class="sd">    ----------</span>
<span class="sd">    </span>
<span class="sd">    .. [1] A. Swaminathan and T. Joachims, Batch Learning from Logged Bandit Feedback through </span>
<span class="sd">            Counterfactual Risk Minimization, Journal of Machine Learning Research, 16(52),</span>
<span class="sd">            1731--1755, 2015.</span>
<span class="sd">    .. [2] A. Swaminathan and T. Joachims, The self-normalized estimator for counterfactual learning, </span>
<span class="sd">            Advances in Neural Information Processing Systems, 28, 16(52), 3231--3239, 2015.</span>
<span class="sd">    .. [3] A. Swaminathan, T. Joachims, and M. de Rijke, Deep Learning with Logged Bandit Feedback, </span>
<span class="sd">            International Conference on Learning Representations,  2018.</span>
<span class="sd">    </span>
<span class="sd">    &quot;&quot;&quot;</span>

    
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">96</span><span class="p">,</span> <span class="n">learning_rate</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.001</span><span class="p">,</span> <span class="n">weight_decay</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.001</span><span class="p">,</span> 
                 <span class="n">lambda_</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.5</span><span class="p">,</span> <span class="n">self_normalize</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span> <span class="n">clipping</span> <span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">100.</span><span class="p">,</span>
                 <span class="n">verbose</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        
        <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span> <span class="o">=</span> <span class="n">batch_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">learning_rate</span> <span class="o">=</span> <span class="n">learning_rate</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">weight_decay</span> <span class="o">=</span> <span class="n">weight_decay</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">lambda_</span> <span class="o">=</span> <span class="n">lambda_</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">self_normalize</span> <span class="o">=</span> <span class="n">self_normalize</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">clipping</span> <span class="o">=</span> <span class="n">clipping</span> 
        <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span> <span class="o">=</span> <span class="n">verbose</span>
       
    <span class="k">def</span> <span class="fm">__repr__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
    
        <span class="n">items</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;</span><span class="si">%s</span><span class="s2"> = </span><span class="si">%r</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="n">v</span><span class="p">)</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="vm">__dict__</span><span class="o">.</span><span class="n">items</span><span class="p">())</span>
        <span class="k">return</span> <span class="s2">&quot;&lt;</span><span class="si">%s</span><span class="s2">: {</span><span class="si">%s</span><span class="s2">}&gt;&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="p">,</span> <span class="s1">&#39;, &#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">items</span><span class="p">))</span>
    
    <span class="k">def</span> <span class="nf">_poem_loss</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">pi</span><span class="p">,</span> <span class="n">p0</span><span class="p">,</span> <span class="n">r</span><span class="p">,</span> <span class="n">y_idx</span><span class="p">,</span> <span class="n">Lambda</span><span class="p">):</span>
        
        <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">r</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span> 
            <span class="n">r</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">repeat_interleave</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="mf">1e-05</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">r</span><span class="p">))</span>
        
        <span class="n">bsz</span> <span class="o">=</span> <span class="n">pi</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">softmax_pi</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">pi</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">pi_i</span> <span class="o">=</span> <span class="n">softmax_pi</span><span class="o">.</span><span class="n">masked_select</span><span class="p">(</span><span class="n">y_idx</span><span class="p">)</span>
        <span class="n">log_importance</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">pi_i</span><span class="p">)</span> <span class="o">-</span> <span class="n">torch</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">p0</span><span class="p">)</span> 
        <span class="n">importance</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">log_importance</span><span class="p">)</span>    
        <span class="n">clip_importance_vals</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">repeat_interleave</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">clipping</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">importance</span><span class="p">))</span>
        <span class="n">importance</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">clip_importance_vals</span><span class="p">,</span> <span class="n">importance</span><span class="p">)</span>
        <span class="n">off_policy_est</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">mul</span><span class="p">(</span><span class="n">importance</span><span class="p">,</span> <span class="n">r</span><span class="p">)</span>
        <span class="c1"># Eq.(8) in [2] </span>
        <span class="n">var_n</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">mul</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="n">r</span><span class="p">,</span> <span class="n">off_policy_est</span><span class="p">),</span> <span class="mi">2</span><span class="p">),</span> <span class="n">torch</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">div</span><span class="p">(</span><span class="n">pi_i</span><span class="p">,</span> <span class="n">p0</span><span class="p">),</span> <span class="mi">2</span><span class="p">)))</span>
        <span class="n">var_d</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">div</span><span class="p">(</span><span class="n">pi_i</span><span class="p">,</span> <span class="n">p0</span><span class="p">)),</span> <span class="mi">2</span><span class="p">)</span>
        <span class="n">empirical_var</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">div</span><span class="p">(</span><span class="n">var_n</span><span class="p">,</span> <span class="n">var_d</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">self_normalize</span><span class="p">:</span>
            <span class="n">effective_sample_size</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">importance</span><span class="p">)</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span> <span class="c1"># turns off requires grad</span>
            <span class="n">mean_off_policy_est</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">div</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">off_policy_est</span><span class="p">),</span> <span class="n">effective_sample_size</span><span class="p">)</span> 
        <span class="k">else</span><span class="p">:</span>
            <span class="n">mean_off_policy_est</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">off_policy_est</span><span class="p">)</span>
        
        <span class="n">penalty</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">mul</span><span class="p">(</span><span class="n">Lambda</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">div</span><span class="p">(</span><span class="n">empirical_var</span><span class="p">,</span> <span class="n">bsz</span><span class="p">)))</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">mul</span><span class="p">(</span><span class="o">-</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">mean_off_policy_est</span><span class="p">)</span> <span class="o">+</span> <span class="n">penalty</span>
        
        <span class="k">return</span> <span class="n">loss</span>

   
    
    <span class="k">def</span> <span class="nf">learn_policy</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">epochs</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">500</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>

        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        data : STBT object</span>
<span class="sd">            This must be a Supervised to Bandit Transform (STBT) class with fitted </span>
<span class="sd">            `generate_batch` method.</span>
<span class="sd">        epochs : int, default </span>
<span class="sd">            Number of training epochs.</span>
<span class="sd">            </span>
<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        int.</span>
<span class="sd">          The predicted best policy.</span>
<span class="sd">        </span>
<span class="sd">        &quot;&quot;&quot;</span> 
        
        <span class="n">train_ds</span> <span class="o">=</span> <span class="n">BanditDataset</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">X_train</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">(),</span>
                                 <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">y_train_logging</span><span class="p">)</span><span class="o">.</span><span class="n">long</span><span class="p">(),</span> 
                                 <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">train_logging_prob</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">(),</span> 
                                 <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">train_logging_reward</span><span class="p">)</span><span class="o">.</span><span class="n">long</span><span class="p">(),</span>
                                 <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">y_train_logging_idx</span><span class="p">)</span><span class="o">.</span><span class="n">bool</span><span class="p">())</span>
        
        
        <span class="n">n_features</span> <span class="o">=</span> <span class="n">train_ds</span><span class="o">.</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
        <span class="n">actions</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">train_ds</span><span class="o">.</span><span class="n">y</span><span class="p">)</span>
        <span class="n">n_actions</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">actions</span><span class="p">)</span>
       
        <span class="n">train_dl</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">train_ds</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">)</span>
        
        <span class="n">Model</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">n_features</span> <span class="o">=</span> <span class="n">n_features</span><span class="p">,</span> <span class="n">n_actions</span> <span class="o">=</span> <span class="n">n_actions</span><span class="p">)</span>
        
        <span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">Model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">learning_rate</span><span class="p">,</span> <span class="n">weight_decay</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">weight_decay</span><span class="p">)</span>  
       
        <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">):</span>
            <span class="n">Model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
            <span class="n">train_epoch_loss</span> <span class="o">=</span> <span class="mf">0.</span>
            <span class="k">for</span> <span class="n">x_batch</span><span class="p">,</span><span class="n">y_batch</span><span class="p">,</span><span class="n">p0_batch</span><span class="p">,</span><span class="n">r_batch</span><span class="p">,</span><span class="n">y_idx_batch</span> <span class="ow">in</span> <span class="n">train_dl</span><span class="p">:</span>
                <span class="n">pi</span> <span class="o">=</span> <span class="n">Model</span><span class="p">(</span><span class="n">x_batch</span><span class="p">)</span>
                <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_poem_loss</span><span class="p">(</span><span class="n">pi</span><span class="p">,</span> <span class="n">p0_batch</span><span class="p">,</span> <span class="n">r_batch</span><span class="p">,</span> <span class="n">y_idx_batch</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">lambda_</span><span class="p">)</span>
                <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
                <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
                <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
                <span class="n">train_epoch_loss</span> <span class="o">+=</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">epoch</span> <span class="o">%</span> <span class="mi">100</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Epoch </span><span class="si">{</span><span class="n">epoch</span><span class="si">}</span><span class="s1">: | Train Poem Loss: </span><span class="si">{</span><span class="n">train_epoch_loss</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">train_dl</span><span class="p">)</span><span class="si">:</span><span class="s1">.5f</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
            
        <span class="n">Model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
            <span class="n">X_test</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">X_test</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>
            <span class="n">pred</span> <span class="o">=</span> <span class="n">Model</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
            <span class="n">est_best_policy</span> <span class="o">=</span> <span class="n">actions</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">pred</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)]</span>
            
        <span class="bp">self</span><span class="o">.</span><span class="n">est_best_policy</span> <span class="o">=</span> <span class="n">est_best_policy</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
         
        <span class="k">return</span> <span class="bp">self</span>
    
    

<span class="k">class</span> <span class="nc">CounterfactualRiskMinimizationCV</span><span class="p">(</span><span class="n">CounterfactualRiskMinimization</span><span class="p">,</span> <span class="n">EvaluationMetrics</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Tune variance penalty for Counterfactual Risk Minimization.</span>
<span class="sd">    </span>
<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    </span>
<span class="sd">    batch_size : int, default: 96</span>
<span class="sd">        The number of samples per batch to load </span>
<span class="sd">    learning_rate : float, default: 0.01</span>
<span class="sd">        Stochastic gradient descent learning rate </span>
<span class="sd">    weight_decay : float, default: 0.001</span>
<span class="sd">        L2 regularization on parameters</span>
<span class="sd">    self_normalize: bool, default: True</span>
<span class="sd">        Whether to normalize the IPS estimator. See [2].</span>
<span class="sd">    clipping: float, default: 100.</span>
<span class="sd">        Clipping the importance sample weights. See [1].</span>
<span class="sd">    verbose: bool, default: True</span>
<span class="sd">        Whether to print Poem Loss during training .</span>
<span class="sd">    lambda_ : 1D array, optional, defaults to grid of values </span>
<span class="sd">        chosen in a logarithmic scale between 1e-4 and 1e+01.</span>
<span class="sd">    </span>
<span class="sd">    &quot;&quot;&quot;</span>
    
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">96</span><span class="p">,</span> <span class="n">learning_rate</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.001</span><span class="p">,</span> <span class="n">weight_decay</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.001</span><span class="p">,</span> 
                 <span class="n">self_normalize</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span> <span class="n">clipping</span> <span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">100.</span><span class="p">,</span> <span class="n">verbose</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span> 
                 <span class="n">lambda_</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        
        <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span> <span class="o">=</span> <span class="n">batch_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">learning_rate</span> <span class="o">=</span> <span class="n">learning_rate</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">weight_decay</span> <span class="o">=</span> <span class="n">weight_decay</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">self_normalize</span> <span class="o">=</span> <span class="n">self_normalize</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">clipping</span> <span class="o">=</span> <span class="n">clipping</span> 
        <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span> <span class="o">=</span> <span class="n">verbose</span>
        
        <span class="k">if</span> <span class="n">lambda_</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">lambda_</span> <span class="o">=</span> <span class="mi">10</span> <span class="o">**</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mf">4.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span> <span class="c1"># search in log scale</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">lambda_</span><span class="o">=</span> <span class="n">lambda_</span>
                           
    <span class="k">def</span> <span class="fm">__repr__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
    
        <span class="n">items</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;</span><span class="si">%s</span><span class="s2"> = </span><span class="si">%r</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="n">v</span><span class="p">)</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="vm">__dict__</span><span class="o">.</span><span class="n">items</span><span class="p">())</span>
        <span class="k">return</span> <span class="s2">&quot;&lt;</span><span class="si">%s</span><span class="s2">: {</span><span class="si">%s</span><span class="s2">}&gt;&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="p">,</span> <span class="s1">&#39;, &#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">items</span><span class="p">))</span>
    
    <span class="k">def</span> <span class="nf">_get_params_min_loss</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
        <span class="n">xmin_idx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">unravel_index</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">argmin</span><span class="p">(),</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
        <span class="n">l_best</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">lambda_</span><span class="p">[</span><span class="n">xmin_idx</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span>
          
        <span class="k">return</span> <span class="n">l_best</span>

    
    <span class="k">def</span> <span class="nf">learn_policy</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">valid_frac</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.5</span><span class="p">,</span> <span class="n">epochs</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">500</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        data : STBT object</span>
<span class="sd">            This must be a Supervised to Bandit Transform (STBT) class with fitted </span>
<span class="sd">            `generate_batch` method.</span>
<span class="sd">        valid_frac : float, default: 0.5</span>
<span class="sd">            Fraction of training data set for validation. Test data are not modified. </span>
<span class="sd">        epochs : int, default: 500</span>
<span class="sd">            Number of training epochs.</span>
<span class="sd">            </span>
<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        int.</span>
<span class="sd">          The predicted best policy.</span>
<span class="sd">        </span>
<span class="sd">        &quot;&quot;&quot;</span> 
        
        <span class="bp">self</span><span class="o">.</span><span class="n">epochs</span> <span class="o">=</span> <span class="n">epochs</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">valid_frac</span> <span class="o">=</span> <span class="n">valid_frac</span>
        
        <span class="n">n_train_samples</span><span class="p">,</span> <span class="n">n_features</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">X_train</span><span class="o">.</span><span class="n">shape</span>
        <span class="n">idx_valid_samples</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">n_train_samples</span><span class="p">),</span> 
                                              <span class="n">size</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">floor</span><span class="p">(</span><span class="n">n_train_samples</span> <span class="o">*</span> <span class="n">valid_frac</span><span class="p">)),</span> <span class="n">replace</span> <span class="o">=</span> <span class="kc">False</span><span class="p">)</span>
        
        <span class="n">train_ds</span> <span class="o">=</span> <span class="n">BanditDataset</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">delete</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">X_train</span><span class="p">,</span> <span class="n">idx_valid_samples</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">))</span><span class="o">.</span><span class="n">float</span><span class="p">(),</span>
                                  <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">delete</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">y_train_logging</span><span class="p">,</span> <span class="n">idx_valid_samples</span><span class="p">))</span><span class="o">.</span><span class="n">long</span><span class="p">(),</span> 
                                  <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">delete</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">train_logging_prob</span><span class="p">,</span> <span class="n">idx_valid_samples</span><span class="p">))</span><span class="o">.</span><span class="n">float</span><span class="p">(),</span> 
                                  <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">delete</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">train_logging_reward</span><span class="p">,</span> <span class="n">idx_valid_samples</span><span class="p">))</span><span class="o">.</span><span class="n">long</span><span class="p">(),</span>
                                  <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">delete</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">y_train_logging_idx</span><span class="p">,</span> <span class="n">idx_valid_samples</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">))</span><span class="o">.</span><span class="n">bool</span><span class="p">())</span>
        
        
        <span class="n">valid_ds</span> <span class="o">=</span> <span class="n">BanditDataset</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">X_train</span><span class="p">[</span><span class="n">idx_valid_samples</span><span class="p">,</span> <span class="p">:])</span><span class="o">.</span><span class="n">float</span><span class="p">(),</span>
                                  <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">y_train_logging</span><span class="p">[</span><span class="n">idx_valid_samples</span><span class="p">])</span><span class="o">.</span><span class="n">long</span><span class="p">(),</span> 
                                  <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">train_logging_prob</span><span class="p">[</span><span class="n">idx_valid_samples</span><span class="p">])</span><span class="o">.</span><span class="n">float</span><span class="p">(),</span> 
                                  <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">train_logging_reward</span><span class="p">[</span><span class="n">idx_valid_samples</span><span class="p">])</span><span class="o">.</span><span class="n">long</span><span class="p">(),</span>
                                  <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">y_train_logging_idx</span><span class="p">[</span><span class="n">idx_valid_samples</span><span class="p">,</span> <span class="p">:])</span><span class="o">.</span><span class="n">bool</span><span class="p">())</span>
            
        <span class="n">y_train</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">delete</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">y_train</span><span class="p">,</span> <span class="n">idx_valid_samples</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="n">y_valid</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">y_train</span><span class="p">[</span><span class="n">idx_valid_samples</span><span class="p">]</span>
        <span class="n">X_test</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">X_test</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>
        
        <span class="n">actions</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">train_ds</span><span class="o">.</span><span class="n">y</span><span class="p">)</span>
        <span class="n">n_actions</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">actions</span><span class="p">)</span>
       
        <span class="n">train_dl</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">train_ds</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">)</span>
        <span class="n">valid_dl</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">valid_ds</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">)</span>
        
        <span class="n">Model</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">n_features</span><span class="o">=</span><span class="n">n_features</span><span class="p">,</span> <span class="n">n_actions</span><span class="o">=</span><span class="n">n_actions</span><span class="p">)</span>
        
        <span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">Model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">learning_rate</span><span class="p">,</span> <span class="n">weight_decay</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">weight_decay</span><span class="p">)</span>  
           
        <span class="bp">self</span><span class="o">.</span><span class="n">train_tot_loss_hist</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">lambda_</span><span class="p">),</span> <span class="n">epochs</span><span class="p">)</span>   
        <span class="bp">self</span><span class="o">.</span><span class="n">valid_tot_loss_hist</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">lambda_</span><span class="p">),</span> <span class="n">epochs</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">valid_acc</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">lambda_</span><span class="p">),</span> <span class="n">epochs</span><span class="p">)</span> 
        <span class="bp">self</span><span class="o">.</span><span class="n">train_acc</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">lambda_</span><span class="p">),</span> <span class="n">epochs</span><span class="p">)</span> 
        <span class="bp">self</span><span class="o">.</span><span class="n">test_acc</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">lambda_</span><span class="p">),</span> <span class="n">epochs</span><span class="p">)</span> 
    
        <span class="k">for</span> <span class="n">l_idx</span><span class="p">,</span> <span class="n">l</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">lambda_</span><span class="p">):</span>
       
            <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">):</span>
                <span class="n">Model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
                <span class="n">train_epoch_loss</span> <span class="o">=</span> <span class="mf">0.</span>
                <span class="k">for</span> <span class="n">x_batch</span><span class="p">,</span><span class="n">y_batch</span><span class="p">,</span><span class="n">p0_batch</span><span class="p">,</span><span class="n">r_batch</span><span class="p">,</span><span class="n">y_idx_batch</span> <span class="ow">in</span> <span class="n">train_dl</span><span class="p">:</span>
                    <span class="n">pi</span> <span class="o">=</span> <span class="n">Model</span><span class="p">(</span><span class="n">x_batch</span><span class="p">)</span>
                    <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_poem_loss</span><span class="p">(</span><span class="n">pi</span><span class="p">,</span> <span class="n">p0_batch</span><span class="p">,</span> <span class="n">r_batch</span><span class="p">,</span> <span class="n">y_idx_batch</span><span class="p">,</span> <span class="n">l</span><span class="p">)</span>
                    <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
                    <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
                    <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
                    <span class="n">train_epoch_loss</span> <span class="o">+=</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">train_tot_loss_hist</span><span class="p">[</span><span class="n">l_idx</span><span class="p">,</span> <span class="n">epoch</span><span class="p">]</span> <span class="o">=</span> <span class="n">train_epoch_loss</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">train_dl</span><span class="p">)</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">:</span>
                    <span class="k">if</span> <span class="n">epoch</span> <span class="o">%</span> <span class="mi">100</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Epoch: </span><span class="si">{</span><span class="n">epoch</span><span class="si">}</span><span class="s1"> | Train Poem Loss: </span><span class="si">{</span><span class="n">train_epoch_loss</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">train_dl</span><span class="p">)</span><span class="si">:</span><span class="s1">.5f</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
                
                <span class="n">Model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
                <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
                    <span class="n">valid_tot_loss</span><span class="o">=</span><span class="mf">0.</span>
                    <span class="k">for</span> <span class="n">x_batch</span><span class="p">,</span><span class="n">y_batch</span><span class="p">,</span><span class="n">p0_batch</span><span class="p">,</span><span class="n">r_batch</span><span class="p">,</span><span class="n">y_idx_batch</span> <span class="ow">in</span> <span class="n">valid_dl</span><span class="p">:</span>
                        <span class="n">pi</span> <span class="o">=</span> <span class="n">Model</span><span class="p">(</span><span class="n">x_batch</span><span class="p">)</span>
                        <span class="n">valid_loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_poem_loss</span><span class="p">(</span><span class="n">pi</span><span class="p">,</span> <span class="n">p0_batch</span><span class="p">,</span> <span class="n">r_batch</span><span class="p">,</span> <span class="n">y_idx_batch</span><span class="p">,</span> <span class="n">l</span><span class="p">)</span>
                        <span class="n">valid_tot_loss</span> <span class="o">+=</span> <span class="n">valid_loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">valid_tot_loss_hist</span><span class="p">[</span><span class="n">l_idx</span><span class="p">,</span> <span class="n">epoch</span><span class="p">]</span> <span class="o">=</span> <span class="n">valid_tot_loss</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">valid_dl</span><span class="p">)</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">:</span>
                      <span class="k">if</span> <span class="n">epoch</span> <span class="o">%</span> <span class="mi">100</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                          <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Epoch: </span><span class="si">{</span><span class="n">epoch</span><span class="si">}</span><span class="s1"> | Valid Poem Loss: </span><span class="si">{</span><span class="n">valid_tot_loss</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">valid_dl</span><span class="p">)</span><span class="si">:</span><span class="s1">.5f</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
                
                <span class="n">pred_train</span> <span class="o">=</span> <span class="n">Model</span><span class="p">(</span><span class="n">train_ds</span><span class="o">.</span><span class="n">X</span><span class="p">)</span>
                <span class="n">est_best_policy_train</span> <span class="o">=</span> <span class="n">actions</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">pred_train</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)]</span>
                <span class="n">est_best_policy_train</span> <span class="o">=</span> <span class="n">est_best_policy_train</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">train_acc</span><span class="p">[</span><span class="n">l_idx</span><span class="p">,</span> <span class="n">epoch</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">error_rate</span><span class="p">(</span><span class="n">est_best_policy_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
                <span class="n">pred_valid</span> <span class="o">=</span> <span class="n">Model</span><span class="p">(</span><span class="n">valid_ds</span><span class="o">.</span><span class="n">X</span><span class="p">)</span>
                <span class="n">est_best_policy_valid</span> <span class="o">=</span> <span class="n">actions</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">pred_valid</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)]</span>
                <span class="n">est_best_policy_valid</span> <span class="o">=</span> <span class="n">est_best_policy_valid</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">valid_acc</span><span class="p">[</span><span class="n">l_idx</span><span class="p">,</span> <span class="n">epoch</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">error_rate</span><span class="p">(</span><span class="n">est_best_policy_valid</span><span class="p">,</span> <span class="n">y_valid</span><span class="p">)</span>
                
                <span class="n">pred_test</span> <span class="o">=</span> <span class="n">Model</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
                <span class="n">est_best_policy_test</span> <span class="o">=</span> <span class="n">actions</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">pred_test</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)]</span>
                <span class="n">est_best_policy_test</span> <span class="o">=</span> <span class="n">est_best_policy_test</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">test_acc</span><span class="p">[</span><span class="n">l_idx</span><span class="p">,</span> <span class="n">epoch</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">error_rate</span><span class="p">(</span><span class="n">est_best_policy_test</span><span class="p">,</span> <span class="n">data</span><span class="o">.</span><span class="n">y_test</span><span class="p">)</span>
            
                          
        <span class="bp">self</span><span class="o">.</span><span class="n">l_best</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_params_min_loss</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">valid_tot_loss_hist</span><span class="p">)</span>
            
    
        
        <span class="n">crm</span> <span class="o">=</span> <span class="n">CounterfactualRiskMinimization</span><span class="p">(</span><span class="n">lambda_</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">l_best</span><span class="p">,</span> <span class="n">batch_size</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,</span>
                                              <span class="n">learning_rate</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">learning_rate</span><span class="p">,</span> <span class="n">weight_decay</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">weight_decay</span><span class="p">,</span>
                                              <span class="n">clipping</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">clipping</span><span class="p">,</span> <span class="n">self_normalize</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">self_normalize</span><span class="p">,</span> <span class="n">verbose</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">)</span>
         
        <span class="n">crm</span><span class="o">.</span><span class="n">learn_policy</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">data</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="n">epochs</span><span class="p">)</span> 
        <span class="bp">self</span><span class="o">.</span><span class="n">est_best_policy</span> <span class="o">=</span> <span class="n">crm</span><span class="o">.</span><span class="n">est_best_policy</span>
                
        <span class="k">return</span> <span class="bp">self</span>
    
    <span class="k">def</span> <span class="nf">plot_cv_loss</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
         
        <span class="n">train_loss_flatten</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">train_tot_loss_hist</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">flatten</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
        <span class="n">valid_loss_flatten</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">valid_tot_loss_hist</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">flatten</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
        
        <span class="n">train_acc_flatten</span> <span class="o">=</span>  <span class="bp">self</span><span class="o">.</span><span class="n">train_acc</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">flatten</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
        <span class="n">valid_acc_flatten</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">valid_acc</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">flatten</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
        <span class="n">test_acc_flatten</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">test_acc</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">flatten</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
        
        <span class="n">fig</span><span class="p">,</span> <span class="n">axs</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
        <span class="n">fs</span> <span class="o">=</span> <span class="mi">8</span>
        
        <span class="k">for</span> <span class="n">l_idx</span><span class="p">,</span> <span class="n">l</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">lambda_</span><span class="p">):</span>
            <span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">train_loss_flatten</span><span class="p">[:,</span><span class="n">l_idx</span><span class="p">],</span> <span class="n">label</span> <span class="o">=</span> <span class="nb">round</span><span class="p">(</span><span class="n">l</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
            <span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">valid_loss_flatten</span><span class="p">[:,</span><span class="n">l_idx</span><span class="p">],</span> <span class="n">label</span> <span class="o">=</span> <span class="nb">round</span><span class="p">(</span><span class="n">l</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
            <span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">train_acc_flatten</span><span class="p">[:,</span><span class="n">l_idx</span><span class="p">],</span> <span class="n">label</span> <span class="o">=</span> <span class="nb">round</span><span class="p">(</span><span class="n">l</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
            <span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">valid_acc_flatten</span><span class="p">[:,</span><span class="n">l_idx</span><span class="p">],</span> <span class="n">label</span> <span class="o">=</span> <span class="nb">round</span><span class="p">(</span><span class="n">l</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
            <span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">test_acc_flatten</span><span class="p">[:,</span><span class="n">l_idx</span><span class="p">],</span> <span class="n">label</span> <span class="o">=</span> <span class="nb">round</span><span class="p">(</span><span class="n">l</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
            
        <span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Train: Poem Loss&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="n">fs</span><span class="p">)</span>
        <span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Validation: Poem Loss&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="n">fs</span><span class="p">)</span>
        <span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Train: Accuracy&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="n">fs</span><span class="p">)</span>
        <span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Validation: Accuracy&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="n">fs</span><span class="p">)</span>
        <span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Test: Accuracy&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="n">fs</span><span class="p">)</span>
        
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">ax</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">axs</span><span class="o">.</span><span class="n">flat</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="mi">2</span><span class="p">:</span>
                <span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="n">xlabel</span><span class="o">=</span><span class="s1">&#39;Epoch&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="n">fs</span><span class="p">)</span>
                <span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="n">ylabel</span><span class="o">=</span><span class="s1">&#39;Loss&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="n">fs</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="n">xlabel</span><span class="o">=</span><span class="s1">&#39;Epoch&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="n">fs</span><span class="p">)</span>
                <span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="n">ylabel</span><span class="o">=</span><span class="s1">&#39;Accuracy&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="n">fs</span><span class="p">)</span>
        <span class="n">fig</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">lambda_</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="s1">&#39;upper right&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="n">fs</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="alternative-using-doubly-robust-as-opposed-to-the-ips-estimator">
<h1>Alternative using Doubly Robust (as opposed to the IPS estimator)<a class="headerlink" href="#alternative-using-doubly-robust-as-opposed-to-the-ips-estimator" title="Permalink to this headline">¶</a></h1>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># class CounterfactualRiskMinimization(EvaluationMetrics):</span>
<span class="c1">#     &quot;&quot;&quot;</span>
<span class="c1">#     Performs policy learning using the Counterfactual Risk Minimization </span>
<span class="c1">#     approach proposed in [1], and later refined in [2].</span>
    
<span class="c1">#     Parameters</span>
<span class="c1">#     ----------</span>
<span class="c1">#     batch_size : int, default: 96</span>
<span class="c1">#         The number of samples per batch to load </span>
<span class="c1">#     learning_rate : float, default: 0.01</span>
<span class="c1">#         Stochastic gradient descent learning rate </span>
<span class="c1">#     weight_decay : float, default: 0.001</span>
<span class="c1">#         L2 regularization on parameters</span>
<span class="c1">#     lambda_ : float, default: 0.1</span>
<span class="c1">#         Variance regularization. Penalty on the variance of the </span>
<span class="c1">#         learnt policy relative to the logging policy.</span>
<span class="c1">#     self_normalize: bool, default: True</span>
<span class="c1">#         Whether to normalize the IPS estimator. See [2].</span>
<span class="c1">#     clipping: float, default: 100.</span>
<span class="c1">#         Clipping the importance sample weights. See [1].</span>
<span class="c1">#     verbose: bool, default: False</span>
<span class="c1">#         Whether to print Poem Loss during training .</span>
    
<span class="c1">#     References</span>
<span class="c1">#     ----------</span>
    
<span class="c1">#     .. [1] A. Swaminathan and T. Joachims, Batch Learning from Logged Bandit Feedback through </span>
<span class="c1">#            Counterfactual Risk Minimization, Journal of Machine Learning Research, 16(52),</span>
<span class="c1">#            1731--1755, 2015.</span>
<span class="c1">#     .. [2] A. Swaminathan and T. Joachims, The self-normalized estimator for counterfactual learning, </span>
<span class="c1">#            Advances in Neural Information Processing Systems, 28, 16(52), 3231--3239, 2015.</span>
<span class="c1">#     .. [3] A. Swaminathan, T. Joachims, and M. de Rijke, Deep Learning with Logged Bandit Feedback, </span>
<span class="c1">#            International Conference on Learning Representations,  2018.</span>
    
<span class="c1">#     &quot;&quot;&quot;</span>

    
<span class="c1">#     def __init__(self, batch_size: int = 96, learning_rate: float = 0.01, weight_decay: float = 0.001, </span>
<span class="c1">#                  lambda_: float = 0.5, self_normalize: bool = True, clipping : float = 100.,</span>
<span class="c1">#                  verbose: bool = False) -&gt; None:</span>
<span class="c1">#         self.batch_size = batch_size</span>
<span class="c1">#         self.learning_rate = learning_rate</span>
<span class="c1">#         self.weight_decay = weight_decay</span>
<span class="c1">#         self.lambda_ = lambda_</span>
<span class="c1">#         self.self_normalize = self_normalize</span>
<span class="c1">#         self.verbose = verbose</span>
<span class="c1">#         self.clipping = clipping </span>
     
<span class="c1">#     def __repr__(self) -&gt; str:</span>
    
<span class="c1">#         items = (&quot;%s = %r&quot; % (k, v) for k, v in self.__dict__.items())</span>
<span class="c1">#         return &quot;&lt;%s: {%s}&gt;&quot; % (self.__class__.__name__, &#39;, &#39;.join(items))</span>
  
<span class="c1">#     def _poem_loss(self, pi, p0, r, r_pred, y_idx, Lambda, self_normalize):</span>
        
<span class="c1">#         #if torch.sum(r) == 0: </span>
<span class="c1">#         #    r = torch.repeat_interleave(torch.tensor(1e-05, dtype=torch.float), len(r))</span>
        
        
<span class="c1">#         bsz = pi.shape[0]</span>
<span class="c1">#         softmax_pi = F.softmax(pi, dim=1)</span>
<span class="c1">#         pi_i = softmax_pi.masked_select(y_idx)</span>
<span class="c1">#         r_pred_i = r_pred.masked_select(y_idx)</span>
<span class="c1">#         importance = torch.div(pi_i, p0) </span>
<span class="c1">#         clip_importance_vals = torch.repeat_interleave(torch.tensor(self.clipping, dtype=torch.float), len(importance))</span>
<span class="c1">#         importance_clipped = torch.min(clip_importance_vals, importance)</span>
<span class="c1">#         reward_residual = torch.sub(r, r_pred_i)</span>
<span class="c1">#         weighted_reward_pred = torch.sum(torch.mul(softmax_pi, r_pred), dim=1)</span>
<span class="c1">#         off_policy_est = torch.add(torch.mul(importance_clipped, reward_residual), weighted_reward_pred)</span>
<span class="c1">#         empirical_var = torch.var(off_policy_est)</span>
        
<span class="c1">#         if self_normalize:</span>
<span class="c1">#             effective_sample_size = torch.sum(importance_clipped).detach() # turns off requires grad</span>
<span class="c1">#             sum_off_policy_est = torch.div(torch.sum(off_policy_est), effective_sample_size) </span>
<span class="c1">#         else:</span>
<span class="c1">#             sum_off_policy_est = torch.sum(off_policy_est)</span>
        
<span class="c1">#         penalty = torch.mul(Lambda, torch.sqrt(torch.div(empirical_var, bsz)))</span>
<span class="c1">#         loss = torch.mul(-1.0, sum_off_policy_est) + penalty</span>
             
<span class="c1">#         return loss</span>

    
<span class="c1">#     def learn_policy(self, model, data, epochs: int = 500) -&gt; None:</span>

<span class="c1">#         &quot;&quot;&quot;</span>
<span class="c1">#         Parameters</span>
<span class="c1">#         ----------</span>
<span class="c1">#         data : STBT object</span>
<span class="c1">#             This must be a Supervised to Bandit Transform (STBT) class with fitted </span>
<span class="c1">#             `generate_batch` method.</span>
<span class="c1">#         epochs : int, default </span>
<span class="c1">#             Number of training epochs.</span>
            
<span class="c1">#         Returns</span>
<span class="c1">#         -------</span>
<span class="c1">#         int.</span>
<span class="c1">#           The predicted best policy.</span>
        
<span class="c1">#         &quot;&quot;&quot; </span>
        
<span class="c1">#         rp = RewardPredictor().learn_policy(data=data, max_iter=1000)</span>
        
<span class="c1">#         train_ds = BanditDataset(torch.from_numpy(data.X_train).float(),</span>
<span class="c1">#                                  torch.from_numpy(data.y_train_logging).long(), </span>
<span class="c1">#                                  torch.from_numpy(data.train_logging_prob).float(), </span>
<span class="c1">#                                  torch.from_numpy(data.train_logging_reward).long(),</span>
<span class="c1">#                                  torch.from_numpy(data.y_train_logging_idx).bool(),</span>
<span class="c1">#                                  torch.from_numpy(rp.train_pred_reward_arr).float() </span>
<span class="c1">#                                  )</span>
        
        
<span class="c1">#         n_features = train_ds.X.shape[1]</span>
<span class="c1">#         actions = torch.unique(train_ds.y)</span>
<span class="c1">#         n_actions = len(actions)</span>
       
<span class="c1">#         train_dl = DataLoader(train_ds, self.batch_size)</span>
        
<span class="c1">#         Model = model(n_features = n_features, n_actions = n_actions)</span>
        
<span class="c1">#         optimizer = torch.optim.SGD(Model.parameters(), lr=self.learning_rate, weight_decay=self.weight_decay)  </span>
        
<span class="c1">#         for epoch in range(epochs):</span>
<span class="c1">#             Model.train()</span>
<span class="c1">#             train_epoch_loss = 0.</span>
<span class="c1">#             for x_batch, y_batch, p0_batch, r_batch, y_idx_batch, r_pred_batch in train_dl:</span>
<span class="c1">#                 pi = Model(x_batch)</span>
<span class="c1">#                 loss = self._poem_loss(pi, p0_batch, r_batch, r_pred_batch, y_idx_batch, self.lambda_, self.self_normalize)</span>
<span class="c1">#                 loss.backward()</span>
<span class="c1">#                 optimizer.step()</span>
<span class="c1">#                 optimizer.zero_grad()</span>
<span class="c1">#                 train_epoch_loss += loss.item()</span>
<span class="c1">#             if self.verbose:</span>
<span class="c1">#                 print(f&#39;Epoch {epoch}: | Train Poem Loss: {train_epoch_loss/len(train_dl):.5f}&#39;)</span>
            
<span class="c1">#         Model.eval()</span>
<span class="c1">#         with torch.no_grad():</span>
<span class="c1">#            X_test = torch.from_numpy(data.X_test).float()</span>
<span class="c1">#            pred = Model(X_test)</span>
<span class="c1">#            est_best_policy = actions[torch.argmax(pred, dim=1)]</span>
            
<span class="c1">#         self.est_best_policy = est_best_policy.numpy()</span>
         
<span class="c1">#         return self</span>
    
    

<span class="c1"># class CounterfactualRiskMinimizationCV(CounterfactualRiskMinimization, EvaluationMetrics):</span>
<span class="c1">#     &quot;&quot;&quot;</span>
<span class="c1">#     Tune variance regularizer for Counterfactual Risk Minimization.</span>
    
<span class="c1">#     Parameters</span>
<span class="c1">#     ----------</span>
    
<span class="c1">#     batch_size : int, default: 96</span>
<span class="c1">#         The number of samples per batch to load </span>
<span class="c1">#     learning_rate : float, default: 0.01</span>
<span class="c1">#         Stochastic gradient descent learning rate </span>
<span class="c1">#     weight_decay : float, default: 0.001</span>
<span class="c1">#         L2 regularization on parameters</span>
<span class="c1">#     clipping: float, default: 100.</span>
<span class="c1">#         Clipping the importance sample weights. See [1].</span>
<span class="c1">#     self_normalize: bool, default: True</span>
<span class="c1">#         Whether to normalize the IPS estimator. See [2].</span>
<span class="c1">#     verbose: bool, default: True</span>
<span class="c1">#         Whether to print Poem Loss during training .</span>
<span class="c1">#     lambda_ : 1D array, optional, defaults to grid of values </span>
<span class="c1">#         chosen in a logarithmic scale between 1e-4 and 1e+01.</span>
    
<span class="c1">#     &quot;&quot;&quot;</span>
    
<span class="c1">#     def __init__(self, batch_size: int = 96, learning_rate: float = 0.01, weight_decay: float = 0.001, </span>
<span class="c1">#                  clipping : float = 100., self_normalize: bool = True, verbose: bool = False, </span>
<span class="c1">#                  lambda_: np.ndarray = None) -&gt; None:</span>
        
<span class="c1">#         self.batch_size = batch_size</span>
<span class="c1">#         self.learning_rate = learning_rate</span>
<span class="c1">#         self.weight_decay = weight_decay</span>
<span class="c1">#         self.clipping = clipping </span>
<span class="c1">#         self.self_normalize = self_normalize</span>
<span class="c1">#         self.verbose = verbose</span>
        
<span class="c1">#         if lambda_ is None:</span>
<span class="c1">#             self.lambda_ = 10 ** np.linspace(-4., 1., 10) # search in log scale</span>
<span class="c1">#         else:</span>
<span class="c1">#             self.lambda_= lambda_</span>
                           
<span class="c1">#     def __repr__(self) -&gt; str:</span>
    
<span class="c1">#         items = (&quot;%s = %r&quot; % (k, v) for k, v in self.__dict__.items())</span>
<span class="c1">#         return &quot;&lt;%s: {%s}&gt;&quot; % (self.__class__.__name__, &#39;, &#39;.join(items))</span>
    
<span class="c1">#     def _get_params_min_loss(self, x):</span>
<span class="c1">#         x = x.numpy()</span>
<span class="c1">#         xmin_idx = np.unravel_index(x.argmin(), x.shape)</span>
<span class="c1">#         l_best = self.lambda_[xmin_idx[0]]</span>
          
<span class="c1">#         return l_best</span>

    
<span class="c1">#     def learn_policy(self, model, data, valid_frac: float = 0.5, epochs: int = 500) -&gt; None:</span>
<span class="c1">#         &quot;&quot;&quot;</span>
<span class="c1">#         Parameters</span>
<span class="c1">#         ----------</span>
<span class="c1">#         data : STBT object</span>
<span class="c1">#             This must be a Supervised to Bandit Transform (STBT) class with fitted </span>
<span class="c1">#             `generate_batch` method.</span>
<span class="c1">#         valid_frac : float, default: 0.5</span>
<span class="c1">#             Fraction of training data set for validation. Test data are not modified. </span>
<span class="c1">#         epochs : int, default: 500</span>
<span class="c1">#             Number of training epochs.</span>
            
<span class="c1">#         Returns</span>
<span class="c1">#         -------</span>
<span class="c1">#         int.</span>
<span class="c1">#           The predicted best policy.</span>
        
<span class="c1">#         &quot;&quot;&quot; </span>
        
<span class="c1">#         self.epochs = epochs</span>
<span class="c1">#         self.valid_frac = valid_frac</span>
        
<span class="c1">#         rp = RewardPredictor().learn_policy(data=data, max_iter=1000)</span>
        
<span class="c1">#         n_train_samples, n_features = data.X_train.shape</span>
<span class="c1">#         idx_valid_samples = np.random.choice(range(n_train_samples), </span>
<span class="c1">#                                              size = int(np.floor(n_train_samples * valid_frac)), replace = False)</span>
        
<span class="c1">#         train_ds = BanditDataset(torch.from_numpy(np.delete(data.X_train, idx_valid_samples, axis=0)).float(),</span>
<span class="c1">#                                  torch.from_numpy(np.delete(data.y_train_logging, idx_valid_samples)).long(), </span>
<span class="c1">#                                  torch.from_numpy(np.delete(data.train_logging_prob, idx_valid_samples)).float(), </span>
<span class="c1">#                                  torch.from_numpy(np.delete(data.train_logging_reward, idx_valid_samples)).long(),</span>
<span class="c1">#                                  torch.from_numpy(np.delete(data.y_train_logging_idx, idx_valid_samples, axis=0)).bool(), </span>
<span class="c1">#                                  torch.from_numpy(np.delete(rp.train_pred_reward_arr, idx_valid_samples, axis=0)).float()</span>
<span class="c1">#                                  )</span>
        
        
<span class="c1">#         valid_ds = BanditDataset(torch.from_numpy(data.X_train[idx_valid_samples, :]).float(),</span>
<span class="c1">#                                  torch.from_numpy(data.y_train_logging[idx_valid_samples]).long(), </span>
<span class="c1">#                                  torch.from_numpy(data.train_logging_prob[idx_valid_samples]).float(), </span>
<span class="c1">#                                  torch.from_numpy(data.train_logging_reward[idx_valid_samples]).long(),</span>
<span class="c1">#                                  torch.from_numpy(data.y_train_logging_idx[idx_valid_samples, :]).bool(),</span>
<span class="c1">#                                  torch.from_numpy(rp.train_pred_reward_arr[idx_valid_samples, :]).float()</span>
<span class="c1">#                                  )</span>
            
<span class="c1">#         y_train = np.delete(data.y_train, idx_valid_samples, axis=0)</span>
<span class="c1">#         y_valid = data.y_train[idx_valid_samples]</span>
<span class="c1">#         X_test = torch.from_numpy(data.X_test).float()</span>
        
<span class="c1">#         actions = torch.unique(train_ds.y)</span>
<span class="c1">#         n_actions = len(actions)</span>
       
<span class="c1">#         train_dl = DataLoader(train_ds, self.batch_size)</span>
<span class="c1">#         valid_dl = DataLoader(valid_ds, self.batch_size)</span>
        
<span class="c1">#         Model = model(n_features=n_features, n_actions=n_actions)</span>
        
<span class="c1">#         optimizer = torch.optim.SGD(Model.parameters(), lr=self.learning_rate, weight_decay=self.weight_decay)  </span>
           
<span class="c1">#         self.train_tot_loss_hist = torch.zeros(len(self.lambda_), epochs)   </span>
<span class="c1">#         self.valid_tot_loss_hist = torch.zeros(len(self.lambda_), epochs)</span>
<span class="c1">#         self.valid_acc = torch.zeros(len(self.lambda_), epochs) </span>
<span class="c1">#         self.train_acc = torch.zeros(len(self.lambda_), epochs) </span>
<span class="c1">#         self.test_acc = torch.zeros(len(self.lambda_), epochs) </span>
    
<span class="c1">#         for l_idx, l in enumerate(self.lambda_):</span>
       
<span class="c1">#             for epoch in range(epochs):</span>
<span class="c1">#                 Model.train()</span>
<span class="c1">#                 train_epoch_loss = 0.</span>
<span class="c1">#                 for x_batch, y_batch, p0_batch,r_batch,y_idx_batch,r_pred_batch in train_dl:</span>
<span class="c1">#                     pi = Model(x_batch)</span>
<span class="c1">#                     loss = self._poem_loss(pi, p0_batch, r_batch, r_pred_batch, y_idx_batch, l, self.self_normalize)</span>
<span class="c1">#                     loss.backward()</span>
<span class="c1">#                     optimizer.step()</span>
<span class="c1">#                     optimizer.zero_grad()</span>
<span class="c1">#                     train_epoch_loss += loss.item()</span>
<span class="c1">#                 self.train_tot_loss_hist[l_idx, epoch] = train_epoch_loss/len(train_dl)</span>
<span class="c1">#                 if self.verbose:</span>
<span class="c1">#                     print(f&#39;Epoch: {epoch} | Train Poem Loss: {train_epoch_loss/len(train_dl):.5f}&#39;)</span>
                
<span class="c1">#                 Model.eval()</span>
<span class="c1">#                 with torch.no_grad():</span>
<span class="c1">#                     valid_tot_loss=0.</span>
<span class="c1">#                     for x_batch,y_batch,p0_batch,r_batch,y_idx_batch,r_pred_batch in valid_dl:</span>
<span class="c1">#                         pi = Model(x_batch)</span>
<span class="c1">#                         valid_loss = self._poem_loss(pi, p0_batch, r_batch, r_pred_batch, y_idx_batch, l, self.self_normalize)</span>
<span class="c1">#                         valid_tot_loss += valid_loss.item()</span>
<span class="c1">#                 self.valid_tot_loss_hist[l_idx, epoch] = valid_tot_loss/len(valid_dl)</span>
<span class="c1">#                 if self.verbose:</span>
<span class="c1">#                       print(f&#39;Epoch: {epoch} | Valid Poem Loss: {valid_tot_loss/len(valid_dl):.5f}&#39;)</span>
                
<span class="c1">#                 pred_train = Model(train_ds.X)</span>
<span class="c1">#                 est_best_policy_train = actions[torch.argmax(pred_train, dim=1)]</span>
<span class="c1">#                 est_best_policy_train = est_best_policy_train.numpy()</span>
<span class="c1">#                 self.train_acc[l_idx, epoch] = self.error_rate(est_best_policy_train, y_train)</span>
<span class="c1">#                 pred_valid = Model(valid_ds.X)</span>
<span class="c1">#                 est_best_policy_valid = actions[torch.argmax(pred_valid, dim=1)]</span>
<span class="c1">#                 est_best_policy_valid = est_best_policy_valid.numpy()</span>
<span class="c1">#                 self.valid_acc[l_idx, epoch] = self.error_rate(est_best_policy_valid, y_valid)</span>
                
<span class="c1">#                 pred_test = Model(X_test)</span>
<span class="c1">#                 est_best_policy_test = actions[torch.argmax(pred_test, dim=1)]</span>
<span class="c1">#                 est_best_policy_test = est_best_policy_test.numpy()</span>
<span class="c1">#                 self.test_acc[l_idx, epoch] = self.error_rate(est_best_policy_test, data.y_test)</span>
            
                          
<span class="c1">#         self.l_best = self._get_params_min_loss(self.valid_tot_loss_hist)</span>
            
    
        
<span class="c1">#         crm = CounterfactualRiskMinimization(lambda_=self.l_best, batch_size = self.batch_size,</span>
<span class="c1">#                                              learning_rate = self.learning_rate, weight_decay = self.weight_decay,</span>
<span class="c1">#                                              clipping = self.clipping, self_normalize = self.self_normalize, verbose = self.verbose)</span>
        
<span class="c1">#         crm.learn_policy(model=model, data=data, epochs=epochs) </span>
<span class="c1">#         self.est_best_policy = crm.est_best_policy</span>
                
<span class="c1">#         return self</span>
    
<span class="c1">#     def plot_cv_loss(self):</span>
         
<span class="c1">#         train_loss_flatten = self.train_tot_loss_hist.T.flatten(1).numpy()</span>
<span class="c1">#         valid_loss_flatten = self.valid_tot_loss_hist.T.flatten(1).numpy()</span>
        
<span class="c1">#         train_acc_flatten =  self.train_acc.T.flatten(1).numpy()</span>
<span class="c1">#         valid_acc_flatten = self.valid_acc.T.flatten(1).numpy()</span>
<span class="c1">#         test_acc_flatten = self.test_acc.T.flatten(1).numpy()</span>
        
<span class="c1">#         fig, axs = plt.subplots(2, 3)</span>
<span class="c1">#         fs = 8</span>
        
<span class="c1">#         for l_idx, l in enumerate(self.lambda_):</span>
<span class="c1">#             axs[0, 0].plot(train_loss_flatten[:,l_idx], label = round(l, 4))</span>
<span class="c1">#             axs[0, 1].plot(valid_loss_flatten[:,l_idx], label = round(l, 4))</span>
<span class="c1">#             axs[1, 0].plot(train_acc_flatten[:,l_idx], label = round(l, 4))</span>
<span class="c1">#             axs[1, 1].plot(valid_acc_flatten[:,l_idx], label = round(l, 4))</span>
<span class="c1">#             axs[1, 2].plot(test_acc_flatten[:,l_idx], label = round(l, 4))</span>
            
<span class="c1">#         axs[0, 0].set_title(&quot;Train: Poem Loss&quot;, fontsize=fs)</span>
<span class="c1">#         axs[0, 1].set_title(&quot;Validation: Poem Loss&quot;, fontsize=fs)</span>
<span class="c1">#         axs[1, 0].set_title(&quot;Train: Accuracy&quot;, fontsize=fs)</span>
<span class="c1">#         axs[1, 1].set_title(&quot;Validation: Accuracy&quot;, fontsize=fs)</span>
<span class="c1">#         axs[1, 2].set_title(&quot;Test: Accuracy&quot;, fontsize=fs)</span>
        
<span class="c1">#         for i, ax in enumerate(axs.flat):</span>
<span class="c1">#             if i &lt; 2:</span>
<span class="c1">#                 ax.set_xlabel(xlabel=&#39;Epoch&#39;, fontsize=fs)</span>
<span class="c1">#                 ax.set_ylabel(ylabel=&#39;Loss&#39;, fontsize=fs)</span>
<span class="c1">#             else:</span>
<span class="c1">#                 ax.set_xlabel(xlabel=&#39;Epoch&#39;, fontsize=fs)</span>
<span class="c1">#                 ax.set_ylabel(ylabel=&#39;Accuracy&#39;, fontsize=fs)</span>
<span class="c1">#         fig.legend(self.lambda_, loc=&#39;upper right&#39;, fontsize=fs)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="read-data">
<h1>Read data<a class="headerlink" href="#read-data" title="Permalink to this headline">¶</a></h1>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">get_data</span><span class="p">(</span><span class="n">dataset</span><span class="o">=</span> <span class="s1">&#39;glass&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="perform-supervised-to-bandit-conversion">
<h1>Perform Supervised-to-Bandit Conversion<a class="headerlink" href="#perform-supervised-to-bandit-conversion" title="Permalink to this headline">¶</a></h1>
<p>Performs Supervised to Bandit Conversion for classification datasets. This conversion is generally used to test the limits of counterfactual learning in a well-controlled environment.</p>
<p>Here, we take a supervised dataset with features x and labeled classes y, and simulate a bandit feedback data set from a logging policy. Basically, this involves: (i) simulating a stochastic logging policy, which may be uniform (logging_type=’uniform’), or given as a function of covariates (logging_type = ‘biased’), (ii) when the logging policy for a given observation equals the optimal policy (true label), a positive reward is observed.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">data</span> <span class="o">=</span> <span class="n">STBT</span><span class="p">(</span><span class="n">train_frac</span><span class="o">=</span> <span class="mf">0.5</span><span class="p">,</span> <span class="n">logging_type</span><span class="o">=</span><span class="s1">&#39;biased&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">generate_batch</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="mi">1000</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="skyline">
<h1>Skyline<a class="headerlink" href="#skyline" title="Permalink to this headline">¶</a></h1>
<p>Best possible error rate, assuming we have full feedback (this can only be tested from the simulation as in practice as we have bandit feedback)x.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">clf</span> <span class="o">=</span> <span class="n">LogisticRegressionCV</span><span class="p">(</span><span class="n">multi_class</span><span class="o">=</span><span class="s1">&#39;multinomial&#39;</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="mi">2000</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">X_train</span><span class="p">,</span> <span class="n">data</span><span class="o">.</span><span class="n">y_train</span><span class="p">)</span>
<span class="n">optimal_policy</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">X_test</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Skyline Error:&quot;</span><span class="p">,</span> <span class="n">EvaluationMetrics</span><span class="o">.</span><span class="n">error_rate</span><span class="p">(</span><span class="n">optimal_policy</span><span class="p">,</span> <span class="n">data</span><span class="o">.</span><span class="n">y_test</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Skyline Error: 0.30841121495327106
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1">## Reward Predictor (RP)</span>
<span class="n">rp</span> <span class="o">=</span> <span class="n">RewardPredictor</span><span class="p">()</span>
<span class="n">rp</span><span class="o">.</span><span class="n">learn_policy</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="mi">1000</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Reward Predictor Error:&quot;</span><span class="p">,</span> <span class="n">rp</span><span class="o">.</span><span class="n">error_rate</span><span class="p">(</span><span class="n">rp</span><span class="o">.</span><span class="n">est_best_policy</span><span class="p">,</span> <span class="n">data</span><span class="o">.</span><span class="n">y_test</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Reward Predictor Error: 0.7009345794392523
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1">## Outcome Weighted Learning (OWL)</span>
<span class="n">owl</span> <span class="o">=</span> <span class="n">OutcomeWeightedLearning</span><span class="p">()</span>
<span class="n">owl</span><span class="o">.</span><span class="n">learn_policy</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">clf</span> <span class="o">=</span> <span class="s1">&#39;LogisticRegressionCV&#39;</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="mi">1000</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;OWL-LR:&quot;</span><span class="p">,</span> <span class="n">owl</span><span class="o">.</span><span class="n">error_rate</span><span class="p">(</span><span class="n">owl</span><span class="o">.</span><span class="n">est_best_policy</span><span class="p">,</span> <span class="n">data</span><span class="o">.</span><span class="n">y_test</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>OWL-LR: 0.7289719626168225
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="counterfactual-risk-minimization-crm">
<h1>Counterfactual Risk Minimization (CRM)<a class="headerlink" href="#counterfactual-risk-minimization-crm" title="Permalink to this headline">¶</a></h1>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">crm</span> <span class="o">=</span> <span class="n">CounterfactualRiskMinimization</span><span class="p">(</span><span class="n">verbose</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">lambda_</span> <span class="o">=</span> <span class="mf">1e-06</span><span class="p">)</span>
<span class="n">crm</span><span class="o">.</span><span class="n">learn_policy</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="n">LinearModel</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">data</span><span class="p">,</span> <span class="n">epochs</span> <span class="o">=</span> <span class="mi">2000</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;CRM:&quot;</span><span class="p">,</span> <span class="n">crm</span><span class="o">.</span><span class="n">error_rate</span><span class="p">(</span><span class="n">crm</span><span class="o">.</span><span class="n">est_best_policy</span><span class="p">,</span> <span class="n">data</span><span class="o">.</span><span class="n">y_test</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 0: | Train Poem Loss: -0.10087
Epoch 100: | Train Poem Loss: -0.23397
Epoch 200: | Train Poem Loss: -0.37680
Epoch 300: | Train Poem Loss: -0.49386
Epoch 400: | Train Poem Loss: -0.54733
Epoch 500: | Train Poem Loss: -0.57395
Epoch 600: | Train Poem Loss: -0.58959
Epoch 700: | Train Poem Loss: -0.60032
Epoch 800: | Train Poem Loss: -0.60866
Epoch 900: | Train Poem Loss: -0.61578
Epoch 1000: | Train Poem Loss: -0.62223
Epoch 1100: | Train Poem Loss: -0.62831
Epoch 1200: | Train Poem Loss: -0.63413
Epoch 1300: | Train Poem Loss: -0.63967
Epoch 1400: | Train Poem Loss: -0.64488
Epoch 1500: | Train Poem Loss: -0.64968
Epoch 1600: | Train Poem Loss: -0.65401
Epoch 1700: | Train Poem Loss: -0.65786
Epoch 1800: | Train Poem Loss: -0.66122
Epoch 1900: | Train Poem Loss: -0.66412
CRM: 0.719626168224299
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="experiments">
<h1>Experiments<a class="headerlink" href="#experiments" title="Permalink to this headline">¶</a></h1>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1">## Params</span>
<span class="n">B</span> <span class="o">=</span> <span class="mi">10</span> <span class="c1"># Number of simulations</span>
<span class="n">EPOCHS</span> <span class="o">=</span> <span class="mi">500</span>
<span class="n">LOGGING_TYPE</span> <span class="o">=</span> <span class="s1">&#39;biased&#39;</span>
<span class="n">MODEL</span> <span class="o">=</span> <span class="n">LinearModel</span>
<span class="n">LAMBDA</span> <span class="o">=</span> <span class="mf">1e-06</span>
<span class="n">DATASETS</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;ecoli&#39;</span><span class="p">,</span> <span class="s1">&#39;glass&#39;</span><span class="p">,</span> <span class="s1">&#39;lymphography&#39;</span><span class="p">,</span> <span class="s1">&#39;yeast&#39;</span><span class="p">,</span> <span class="s1">&#39;digits&#39;</span><span class="p">,</span> <span class="s1">&#39;breast-cancer&#39;</span><span class="p">,</span> <span class="s1">&#39;wine&#39;</span><span class="p">,</span> <span class="s1">&#39;letter-recognition&#39;</span><span class="p">]</span>
<span class="n">dat</span> <span class="o">=</span> <span class="nb">list</span><span class="p">()</span>
<span class="n">skyline_error</span> <span class="o">=</span> <span class="nb">list</span><span class="p">()</span>
<span class="n">randomized_error</span> <span class="o">=</span> <span class="nb">list</span><span class="p">()</span>
<span class="n">reward_predictor_error</span> <span class="o">=</span> <span class="nb">list</span><span class="p">()</span>
<span class="n">owl_lrcv_error</span> <span class="o">=</span> <span class="nb">list</span><span class="p">()</span>
<span class="n">crm_error</span> <span class="o">=</span> <span class="nb">list</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">DATASETS</span><span class="p">:</span>
    
    <span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">get_data</span><span class="p">(</span><span class="n">dataset</span><span class="o">=</span><span class="n">s</span><span class="p">)</span>
    
    <span class="k">for</span> <span class="n">b</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">B</span><span class="p">):</span>
        <span class="k">if</span> <span class="p">(</span><span class="n">b</span> <span class="o">%</span> <span class="mi">10</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Sample: </span><span class="si">%d</span><span class="s2"> - Dataset: </span><span class="si">%s</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">b</span><span class="p">,</span> <span class="n">s</span><span class="p">))</span>
        
        <span class="n">d</span> <span class="o">=</span> <span class="n">STBT</span><span class="p">(</span><span class="n">logging_type</span> <span class="o">=</span> <span class="n">LOGGING_TYPE</span><span class="p">)</span><span class="o">.</span><span class="n">generate_batch</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="mi">1000</span><span class="p">)</span>
        <span class="n">dat</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">s</span><span class="p">)</span>    
       
        <span class="n">skyline</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">(</span><span class="n">multi_class</span><span class="o">=</span><span class="s1">&#39;multinomial&#39;</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="mi">2000</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">d</span><span class="o">.</span><span class="n">X_train</span><span class="p">,</span> <span class="n">d</span><span class="o">.</span><span class="n">y_train</span><span class="p">)</span>
        <span class="n">optimal_policy</span> <span class="o">=</span> <span class="n">skyline</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">d</span><span class="o">.</span><span class="n">X_test</span><span class="p">)</span>
        
        <span class="n">rp</span> <span class="o">=</span> <span class="n">RewardPredictor</span><span class="p">()</span><span class="o">.</span><span class="n">learn_policy</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">d</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="mi">1000</span><span class="p">)</span>
        <span class="n">erm_lrcv</span> <span class="o">=</span> <span class="n">OutcomeWeightedLearning</span><span class="p">()</span><span class="o">.</span><span class="n">learn_policy</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">d</span><span class="p">,</span> <span class="n">clf</span> <span class="o">=</span> <span class="s1">&#39;LogisticRegressionCV&#39;</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="mi">1000</span><span class="p">)</span>
        <span class="n">crm</span> <span class="o">=</span> <span class="n">CounterfactualRiskMinimization</span><span class="p">(</span><span class="n">lambda_</span><span class="o">=</span><span class="n">LAMBDA</span><span class="p">)</span><span class="o">.</span><span class="n">learn_policy</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="n">MODEL</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">d</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="n">EPOCHS</span><span class="p">)</span>     
        
        <span class="n">skyline_error</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">EvaluationMetrics</span><span class="o">.</span><span class="n">error_rate</span><span class="p">(</span><span class="n">optimal_policy</span><span class="p">,</span> <span class="n">d</span><span class="o">.</span><span class="n">y_test</span><span class="p">))</span>
        <span class="n">randomized_error</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">EvaluationMetrics</span><span class="o">.</span><span class="n">error_rate</span><span class="p">(</span><span class="n">d</span><span class="o">.</span><span class="n">y_test_logging</span><span class="p">,</span> <span class="n">d</span><span class="o">.</span><span class="n">y_test</span><span class="p">))</span>
        <span class="n">reward_predictor_error</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">rp</span><span class="o">.</span><span class="n">error_rate</span><span class="p">(</span><span class="n">rp</span><span class="o">.</span><span class="n">est_best_policy</span><span class="p">,</span> <span class="n">d</span><span class="o">.</span><span class="n">y_test</span><span class="p">))</span>
        <span class="n">owl_lrcv_error</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">erm_lrcv</span><span class="o">.</span><span class="n">error_rate</span><span class="p">(</span><span class="n">erm_lrcv</span><span class="o">.</span><span class="n">est_best_policy</span><span class="p">,</span> <span class="n">d</span><span class="o">.</span><span class="n">y_test</span><span class="p">))</span>
        <span class="n">crm_error</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">crm</span><span class="o">.</span><span class="n">error_rate</span><span class="p">(</span><span class="n">crm</span><span class="o">.</span><span class="n">est_best_policy</span><span class="p">,</span> <span class="n">d</span><span class="o">.</span><span class="n">y_test</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Sample: 0 - Dataset: ecoli
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:667: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.
  % (min_groups, self.n_splits)), UserWarning)
/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:667: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.
  % (min_groups, self.n_splits)), UserWarning)
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Sample: 0 - Dataset: glass
Sample: 0 - Dataset: lymphography
Sample: 0 - Dataset: yeast
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)
/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)
/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Sample: 0 - Dataset: digits
Sample: 0 - Dataset: breast-cancer
Sample: 0 - Dataset: wine
Sample: 0 - Dataset: letter-recognition
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">res</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="o">.</span><span class="n">from_dict</span><span class="p">({</span><span class="s1">&#39;dataset&#39;</span><span class="p">:</span><span class="n">dat</span><span class="p">[</span><span class="mi">1</span><span class="p">:],</span> <span class="s1">&#39;skyline_error&#39;</span><span class="p">:</span> <span class="n">skyline_error</span><span class="p">,</span> <span class="s1">&#39;randomized_error&#39;</span><span class="p">:</span><span class="n">randomized_error</span><span class="p">,</span> <span class="s1">&#39;reward_predictor_error&#39;</span><span class="p">:</span><span class="n">reward_predictor_error</span><span class="p">,</span>
                              <span class="s1">&#39;owl_lrcv_error&#39;</span><span class="p">:</span><span class="n">owl_lrcv_error</span><span class="p">,</span> <span class="s1">&#39;crm_error&#39;</span><span class="p">:</span><span class="n">crm_error</span><span class="p">})</span>

<span class="n">res_summary</span> <span class="o">=</span> <span class="n">res</span><span class="o">.</span><span class="n">groupby</span><span class="p">([</span><span class="s1">&#39;dataset&#39;</span><span class="p">],</span> <span class="n">as_index</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span><span class="o">.</span><span class="n">agg</span><span class="p">({</span>
                            <span class="s1">&#39;skyline_error&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;mean&#39;</span><span class="p">,</span><span class="s1">&#39;std&#39;</span><span class="p">],</span> 
                            <span class="s1">&#39;randomized_error&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;mean&#39;</span><span class="p">,</span><span class="s1">&#39;std&#39;</span><span class="p">],</span> 
                            <span class="s1">&#39;reward_predictor_error&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;mean&#39;</span><span class="p">,</span><span class="s1">&#39;std&#39;</span><span class="p">],</span>
                            <span class="s1">&#39;owl_lrcv_error&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;mean&#39;</span><span class="p">,</span><span class="s1">&#39;std&#39;</span><span class="p">],</span>
                            <span class="s1">&#39;crm_error&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;mean&#39;</span><span class="p">,</span><span class="s1">&#39;std&#39;</span><span class="p">]</span>
                            <span class="p">})</span>

<span class="n">res_summary</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead tr th {
        text-align: left;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr>
      <th></th>
      <th>dataset</th>
      <th colspan="2" halign="left">skyline_error</th>
      <th colspan="2" halign="left">randomized_error</th>
      <th colspan="2" halign="left">reward_predictor_error</th>
      <th colspan="2" halign="left">owl_lrcv_error</th>
      <th colspan="2" halign="left">crm_error</th>
    </tr>
    <tr>
      <th></th>
      <th></th>
      <th>mean</th>
      <th>std</th>
      <th>mean</th>
      <th>std</th>
      <th>mean</th>
      <th>std</th>
      <th>mean</th>
      <th>std</th>
      <th>mean</th>
      <th>std</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>breast-cancer</td>
      <td>0.029123</td>
      <td>0.009792</td>
      <td>0.558596</td>
      <td>0.191854</td>
      <td>0.026667</td>
      <td>0.009813</td>
      <td>0.209825</td>
      <td>0.162483</td>
      <td>0.064561</td>
      <td>0.051467</td>
    </tr>
    <tr>
      <th>1</th>
      <td>digits</td>
      <td>0.036151</td>
      <td>0.004104</td>
      <td>0.888432</td>
      <td>0.054886</td>
      <td>0.376529</td>
      <td>0.096568</td>
      <td>0.529366</td>
      <td>0.120459</td>
      <td>0.426251</td>
      <td>0.111795</td>
    </tr>
    <tr>
      <th>2</th>
      <td>ecoli</td>
      <td>0.132937</td>
      <td>0.018231</td>
      <td>0.835714</td>
      <td>0.093679</td>
      <td>0.278175</td>
      <td>0.043127</td>
      <td>0.397619</td>
      <td>0.178276</td>
      <td>0.310714</td>
      <td>0.080024</td>
    </tr>
    <tr>
      <th>3</th>
      <td>glass</td>
      <td>0.401869</td>
      <td>0.037642</td>
      <td>0.825234</td>
      <td>0.061372</td>
      <td>0.588785</td>
      <td>0.103134</td>
      <td>0.591589</td>
      <td>0.080883</td>
      <td>0.629907</td>
      <td>0.093996</td>
    </tr>
    <tr>
      <th>4</th>
      <td>letter-recognition</td>
      <td>0.228200</td>
      <td>0.004190</td>
      <td>0.966280</td>
      <td>0.011429</td>
      <td>0.737560</td>
      <td>0.031631</td>
      <td>0.713590</td>
      <td>0.030353</td>
      <td>0.741250</td>
      <td>0.028611</td>
    </tr>
    <tr>
      <th>5</th>
      <td>lymphography</td>
      <td>0.168919</td>
      <td>0.032638</td>
      <td>0.748649</td>
      <td>0.075965</td>
      <td>0.295946</td>
      <td>0.067553</td>
      <td>0.347297</td>
      <td>0.111444</td>
      <td>0.410811</td>
      <td>0.119722</td>
    </tr>
    <tr>
      <th>6</th>
      <td>wine</td>
      <td>0.026966</td>
      <td>0.022596</td>
      <td>0.723596</td>
      <td>0.098695</td>
      <td>0.065169</td>
      <td>0.047611</td>
      <td>0.365169</td>
      <td>0.104097</td>
      <td>0.158427</td>
      <td>0.094074</td>
    </tr>
    <tr>
      <th>7</th>
      <td>yeast</td>
      <td>0.411456</td>
      <td>0.011078</td>
      <td>0.901482</td>
      <td>0.024659</td>
      <td>0.516981</td>
      <td>0.058388</td>
      <td>0.606334</td>
      <td>0.062139</td>
      <td>0.569946</td>
      <td>0.045408</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
</div>
<div class="section" id="references">
<h1>References<a class="headerlink" href="#references" title="Permalink to this headline">¶</a></h1>
<p>[1] A. Swaminathan and T. Joachims, Batch Learning from Logged Bandit Feedback through Counterfactual Risk Minimization, Journal of Machine Learning Research, 16(52), 1731–1755, 2015.</p>
<p>[2] A. Swaminathan and T. Joachims, The self-normalized estimator for counterfactual learning, Advances in Neural Information Processing Systems, 28, 16(52), 3231–3239, 2015.</p>
<p>[3] A. Swaminathan, T. Joachims, and M. de Rijke, Deep Learning with Logged Bandit Feedback, International Conference on Learning Representations, 2018.</p>
<p>[4] Y. Zhao, D. Zeng, A.J. Rush and M. R. Kosorok, Estimating Individualized Treatment Rules Using Outcome Weighted Learning, Journal of the American Statistical Association, 107:499, 1106-1118, 2012, DOI: 10.1080/01621459.2012.695674.</p>
<p>[5] Y. Wang, A. Agarwal and M. Dud’{\i}k, Optimal and Adaptive Off-policy Evaluation in Contextual Bandits, Proceedings of Machine Learning Research, 70, 3589–3597, 2017.</p>
<p>[6] M. Dudik and J. Langford and L. Li, Doubly Robust Policy Evaluation and Learning, CoRR, 2011. <a class="reference external" href="http://arxiv.org/abs/1103.4601">http://arxiv.org/abs/1103.4601</a></p>
<p>[7] K{“u}nzel, S., Sekhon, J., Bickel, P. and Yu, B., Metalearners for estimating heterogeneous treatment effects using machine learning, Proceedings of the National Academy of Sciences, 116(10), 4156–4165, 2019.</p>
<p>[8] Batch Learning from Bandit Feedback (BLBF). <a class="reference external" href="https://github.com/leoguelman/BLBF">https://github.com/leoguelman/BLBF</a>.</p>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./nbs"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        
            



<div class='prev-next-bottom'>
    
    <div id="prev">
        <a class="left-prev" href="T873451_Statistics_fundamentals.html" title="previous page">
            <i class="prevnext-label fas fa-angle-left"></i>
            <div class="prevnext-info">
                <p class="prevnext-label">previous</p>
                <p class="prevnext-title">Statictics Fundamentals</p>
            </div>
        </a>
    </div>
     <div id="next">
        <a class="right-next" href="T257798_Off_Policy_Learning_in_Two_stage_Recommender_Systems.html" title="next page">
            <div class="prevnext-info">
                <p class="prevnext-label">next</p>
                <p class="prevnext-title">Off-Policy Learning in Two-stage Recommender Systems</p>
            </div>
            <i class="prevnext-label fas fa-angle-right"></i>
        </a>
     </div>

</div>
        
        </div>
    </div>
    <footer class="footer">
    <div class="container">
      <p>
        
          By Sparsh A.<br/>
        
            &copy; Copyright 2021.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>
  
  <script src="../_static/js/index.1c5a1a01449ed65a7b51.js"></script>

  
  </body>
</html>