{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"rec-tut-gml-04-sgl-feature-based-methods.ipynb","provenance":[],"authorship_tag":"ABX9TyNcCuWRVtwxsP6nEmXEdlGD"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"YpmJoZkdZLce"},"source":["<font color='006A58'>**Supervised Graph Learning**</font>"]},{"cell_type":"markdown","metadata":{"id":"tLhE97YxdbZP"},"source":["Feature-based method is a very naive (yet powerful) approach for solving graph-based supervised machine learning. The idea rely on the classic machine learning approach of handcrafted feature extraction. In this demo, we will be using the PROTEINS dataset, already integrated in StellarGraph."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ggUY9-07el4g","executionInfo":{"status":"ok","timestamp":1627985199941,"user_tz":-330,"elapsed":4262,"user":{"displayName":"Sparsh Agarwal","photoUrl":"","userId":"13037694610922482904"}},"outputId":"4d459dfd-9e96-424f-a700-df8673f2e0e9"},"source":["!pip install -q stellargraph"],"execution_count":1,"outputs":[{"output_type":"stream","text":["\u001b[?25l\r\u001b[K     |▊                               | 10 kB 24.5 MB/s eta 0:00:01\r\u001b[K     |█▌                              | 20 kB 31.0 MB/s eta 0:00:01\r\u001b[K     |██▎                             | 30 kB 24.1 MB/s eta 0:00:01\r\u001b[K     |███                             | 40 kB 19.6 MB/s eta 0:00:01\r\u001b[K     |███▊                            | 51 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |████▌                           | 61 kB 9.3 MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 71 kB 9.7 MB/s eta 0:00:01\r\u001b[K     |██████                          | 81 kB 10.8 MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 92 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 102 kB 9.3 MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 112 kB 9.3 MB/s eta 0:00:01\r\u001b[K     |█████████                       | 122 kB 9.3 MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 133 kB 9.3 MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 143 kB 9.3 MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 153 kB 9.3 MB/s eta 0:00:01\r\u001b[K     |████████████                    | 163 kB 9.3 MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 174 kB 9.3 MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 184 kB 9.3 MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 194 kB 9.3 MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 204 kB 9.3 MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 215 kB 9.3 MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 225 kB 9.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 235 kB 9.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 245 kB 9.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 256 kB 9.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 266 kB 9.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 276 kB 9.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 286 kB 9.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 296 kB 9.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 307 kB 9.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 317 kB 9.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 327 kB 9.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 337 kB 9.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 348 kB 9.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 358 kB 9.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 368 kB 9.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 378 kB 9.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 389 kB 9.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 399 kB 9.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 409 kB 9.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 419 kB 9.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 430 kB 9.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 435 kB 9.3 MB/s \n","\u001b[?25h"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"4C_QuFGKeocA","executionInfo":{"status":"ok","timestamp":1627985579807,"user_tz":-330,"elapsed":513,"user":{"displayName":"Sparsh Agarwal","photoUrl":"","userId":"13037694610922482904"}}},"source":["from stellargraph import datasets\n","import numpy as np\n","import pandas as pd\n","import networkx as nx\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler\n","from sklearn import svm\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":69},"id":"ovY_nEDNesU1","executionInfo":{"status":"ok","timestamp":1627985223389,"user_tz":-330,"elapsed":8789,"user":{"displayName":"Sparsh Agarwal","photoUrl":"","userId":"13037694610922482904"}},"outputId":"385307d5-e1a2-4b8e-8d12-6e3ad81e484b"},"source":["dataset = datasets.PROTEINS()\n","graphs, graph_labels = dataset.load()\n","dataset.description"],"execution_count":3,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'Each graph represents a protein and graph labels represent whether they are are enzymes or non-enzymes. The dataset includes 1113 graphs with 39 nodes and 73 edges on average for each graph. Graph nodes have 4 attributes (including a one-hot encoding of their label), and each graph is labelled as belonging to 1 of 2 classes.'"]},"metadata":{"tags":[]},"execution_count":3}]},{"cell_type":"markdown","metadata":{"id":"WFP9i0ynevm_"},"source":["To compute the graph metrics, one way is to retrieve the adjacency matrix representation of each graph."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dOUe8tcegBCi","executionInfo":{"status":"ok","timestamp":1627985619868,"user_tz":-330,"elapsed":418,"user":{"displayName":"Sparsh Agarwal","photoUrl":"","userId":"13037694610922482904"}},"outputId":"263659a8-ee19-4073-b7cb-0ece0f8e8dd9"},"source":["pd.Series(graph_labels).value_counts(dropna=False)"],"execution_count":16,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1    663\n","2    450\n","Name: label, dtype: int64"]},"metadata":{"tags":[]},"execution_count":16}]},{"cell_type":"code","metadata":{"id":"jvypaxbue6FG","executionInfo":{"status":"ok","timestamp":1627985474577,"user_tz":-330,"elapsed":8843,"user":{"displayName":"Sparsh Agarwal","photoUrl":"","userId":"13037694610922482904"}}},"source":["# convert graphs from StellarGraph format to numpy adj matrices\n","adjs = [graph.to_adjacency_matrix().A for graph in graphs]\n","\n","# convert labes fom Pandas.Series to numpy array\n","labels = graph_labels.to_numpy(dtype=int)\n","\n","metrics = []\n","\n","for adj in adjs:\n","  G = nx.from_numpy_matrix(adj)\n","  # basic properties\n","  num_edges = G.number_of_edges()\n","  # clustering measures\n","  cc = nx.average_clustering(G)\n","  # measure of efficiency\n","  eff = nx.global_efficiency(G)\n","\n","  metrics.append([num_edges, cc, eff])"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"ujzccftdfs5m","executionInfo":{"status":"ok","timestamp":1627985474587,"user_tz":-330,"elapsed":17,"user":{"displayName":"Sparsh Agarwal","photoUrl":"","userId":"13037694610922482904"}}},"source":["X_train, X_test, y_train, y_test = train_test_split(metrics, labels, test_size=0.3, random_state=42)"],"execution_count":7,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kBhdOAdOfuh-"},"source":["As commonly done in many Machine Learning workflows, we preprocess features to have zero mean and unit standard deviation"]},{"cell_type":"code","metadata":{"id":"N8v2fJYSfxRI","executionInfo":{"status":"ok","timestamp":1627985501583,"user_tz":-330,"elapsed":420,"user":{"displayName":"Sparsh Agarwal","photoUrl":"","userId":"13037694610922482904"}}},"source":["scaler = StandardScaler()\n","scaler.fit(X_train)\n","\n","X_train_scaled = scaler.transform(X_train)\n","X_test_scaled = scaler.transform(X_test)"],"execution_count":9,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HL7-58Awf1k4"},"source":["It's now time for training a proper algorithm. We chose a support vector machine for this task"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TiWPOmKxf3gL","executionInfo":{"status":"ok","timestamp":1627985535161,"user_tz":-330,"elapsed":459,"user":{"displayName":"Sparsh Agarwal","photoUrl":"","userId":"13037694610922482904"}},"outputId":"41087831-0dfb-469e-cba2-cef5b52d28a7"},"source":["clf = svm.SVC()\n","clf.fit(X_train_scaled, y_train)\n","\n","y_pred = clf.predict(X_test_scaled)\n","\n","print('Accuracy', accuracy_score(y_test,y_pred))\n","print('Precision', precision_score(y_test,y_pred))\n","print('Recall', recall_score(y_test,y_pred))\n","print('F1-score', f1_score(y_test,y_pred))"],"execution_count":11,"outputs":[{"output_type":"stream","text":["Accuracy 0.7455089820359282\n","Precision 0.7709251101321586\n","Recall 0.8413461538461539\n","F1-score 0.8045977011494253\n"],"name":"stdout"}]}]}