
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Causal Inference &#8212; Reco Book</title>
    
  <link href="../_static/css/theme.css" rel="stylesheet" />
  <link href="../_static/css/index.c5995385ac14fb8791e8eb36b4908be2.css" rel="stylesheet" />

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../_static/sphinx-book-theme.css?digest=c3fdc42140077d1ad13ad2f1588a4309" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../_static/js/index.1c5a1a01449ed65a7b51.js">

    <script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/togglebutton.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../_static/sphinx-book-theme.12a9622fbb08dcb3a2a40b2c02b83a57.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["\\(", "\\)"]], "displayMath": [["\\[", "\\]"]], "processRefs": false, "processEnvironments": false}})</script>
    <script async="async" src="https://unpkg.com/thebe@0.5.1/lib/index.js"></script>
    <script >
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Exploring Word Embeddings" href="T990000_concept_embedding_nlp.html" />
    <link rel="prev" title="Build a Kubeflow Pipeline" href="T990000_build_a_kubeflow_pipeline.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../index.html">
      
      
      
      <h1 class="site-logo" id="site-title">Reco Book</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../index.html">
   Tutorials in Jupyter notebook format
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  User Stories
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="US780867_Transformer_based_Recommenders.html">
   Transformer-based Recommenders
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="T034923_BERT4Rec_on_ML1M_in_PyTorch.html">
     BERT4Rec on ML-1M in PyTorch
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="T595874_BERT4Rec_on_ML25M_in_PyTorch_Lightning.html">
     BERT4Rec on ML-25M
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="T088416_BST_Implementation_in_MXNet.html">
     BST Implementation in MXNet
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="T602245_BST_implementation_in_PyTorch.html">
     BST implementation in PyTorch
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="T007665_BST_on_ML1M_in_Keras.html">
     A Transformer-based recommendation system
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="T881207_BST_PTLightning_ML1M.html">
     Rating prediction using the Behavior Sequence Transformer (BST) model on ML-1M dataset in PyTorch Lightning
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="T757997_SASRec_PyTorch.html">
     SASRec implementation with PyTorch Library
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="T225287_SASRec_PaddlePaddle.html">
     SASRec implementation with Paddle Library
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="T701627_SR_SAN_Session_based_Model.html">
     SR-SAN Session-based Recommender
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="T975104_SSEPT_ML1M_Tensorflow1x.html">
     SSE-PT Personalized Transformer Recommender on ML-1M in Tensorflow 1.x
    </a>
   </li>
  </ul>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Prototypes
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="T382881_DeepWalk_Karateclub.html">
   DeepWalk from scratch referencing Karateclub library
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T384270_DeepWalk_pure_python.html">
   DeepWalk in pure python
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T677598_Jaccard_Cosine_SVD_DeepWalk_ML100K.html">
   Recommender System with DeepWalk Graph Embeddings
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T815556_Node2vec_Karateclub.html">
   Node2vec from scratch referencing Karateclub library
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T894941_Node2vec_MovieLens_Keras.html">
   Graph representation learning with node2vec
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T611050_Node2vec_PyG.html">
   Node2vec from scratch in PyTorch Geometric
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T186367_Node2vec_library.html">
   Node2vec from scratch referencing node2vec library
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T331379_bayesian_personalized_ranking.html">
   BPR from scratch
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T081831_Data_Poisoning_Attacks_on_Factorization_Based_Collaborative_Filtering.html">
   Data Poisoning Attacks on Factorization-Based Collaborative Filtering
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T102448_Adversarial_Learning_for_Recommendation.html">
   Adversarial Training (Regularization) on a Recommender System
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T865035_Simulating_Data_Poisoning_Attacks_against_Twitter_Recommender.html">
   Load and process dataset
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T711285_Data_Poisoning_Attack_using_LFM_and_ItemAE_on_Synthetic_Dataset.html">
   Injection attack using LFM and ItemAE model trained on Toy dataset
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T355514_Black_box_Attack_on_Sequential_Recs.html">
   Black-box Attack on Sequential Recs
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T873451_Statistics_fundamentals.html">
   Statictics Fundamentals
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T890478_Batch_Learning_from_Bandit_Feedback_%28BLBF%29.html">
   Imports
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T257798_Off_Policy_Learning_in_Two_stage_Recommender_Systems.html">
   Off-Policy Learning in Two-stage Recommender Systems
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T471827_Adaptive_Estimator_Selection_for_Off_Policy_Evaluation.html">
   Adaptive Estimator Selection for Off-Policy Evaluation
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T902666_Evaluating_the_Robustness_of_Off_Policy_Evaluation.html">
   Evaluating the Robustness of Off-Policy Evaluation
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T705904_Evaluation_of_Multiple_Off_Policy_Estimators_on_Synthetic_Dataset.html">
   Evaluation of Multiple Off-Policy Estimators on Synthetic Dataset
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T874693_Evaluating_Standard_Off_Policy_Estimators_with_Small_Sample_Open_Bandit_Dataset.html">
   Evaluating Standard Off-Policy Estimators with Small Sample Open-Bandit Dataset
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T792262_Optimal_Off_Policy_Evaluation_from_Multiple_Logging_Policies.html">
   Optimal Off-Policy Evaluation from Multiple Logging Policies
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T167249_Offline_Policy_Evaluation_with_VW_Command_Line.html">
   Offline Policy Evaluation with VW Command Line
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T966055_OBP_Library_Workshop_Tutorials.html">
   OBP Library Workshop Tutorials
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T632722_PyTorch_Fundamentals_Part_1.html">
   PyTorch Fundamentals Part 1
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T472467_PyTorch_Fundamentals_Part_2.html">
   PyTorch Fundamentals Part 2
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T206654_PyTorch_Fundamentals_Part_3.html">
   PyTorch Fundamentals Part 3
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T536348_Attention_Mechanisms.html">
   Imports
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T500796_Agricultural_Satellite_Image_Segmentation.html">
   Agricultural Satellite Image Segmentation
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T611432_Image_Analysis_with_Tensorflow.html">
   Image Analysis with Tensorflow
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T925716_MongoDB_to_CSV_Conversion.html">
   MongoDB to CSV conversion
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T396469_PDF_to_Word_Cloud_via_Email.html">
   PDF to WordCloud via Email
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T030890_Job_Scraping_and_Clustering.html">
   Job scraping and clustering
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T897054_Scene_Text_Recognition.html">
   Scene Text Recognition
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T034809_Large_scale_Document_Retrieval_with_Elastic_Search.html">
   Large-scale Document Retrieval with ElasticSearch
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T467251_vowpal_wabbit_contextual_recommender.html">
   Simulating a news personalization scenario using Contextual Bandits
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T686684_similar_product_recommender.html">
   Similar Product Recommender system using Deep Learning for an online e-commerce store
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T132203_Retail_Product_Recommendations_using_Word2vec.html">
   Retail Product Recommendations using word2vec
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T501828_Recommender_Implicit_Negative_Feedback.html">
   Retail Product Recommendation with Negative Implicit Feedback
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T315965_Sequence_Aware_Recommenders_Music.html">
   Sequence Aware Recommender Systems
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T051777_image_similarity_recommendations.html">
   Similar Product Recommendations
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T990172_recobook_diversity_aware_book_recommender.html">
   Diversity Aware Book Recommender
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T488549_Goodreads_Diversity_Aware_Book_Recommender.html">
   Diversity Aware Book Recommender
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T023535_Kafka_MongoDB_Real_time_Streaming.html">
   Kafka MongoDB Real-time Streaming
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T622304_Session_based_Recommender_Using_Word2vec.html">
   Session-based recommendation using word2vec
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T416854_bandit_based_recommender_using_thompson_sampling_app.html">
   Bandit-based Online Learning using Thompson Sampling
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T198578_Booking_dot_com_Trip_Recommendation.html">
   Booking.com Trip Recommendation
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T519734_Vowpal_Wabbit_Contextual_Bandit.html">
   Vowpal Wabbit Contextual Bandit
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T871537_Recommendation_Systems_using_Olist_Dataset.html">
   Recommendation systems using Olist dataset
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T057885_Offline_Replayer_Evaluation.html">
   Offline Replayer Evaluation
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T915054_method_for_effective_online_testing.html">
   Methods for effective online testing
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T513987_Recsys_2020_Feature_Engineering_Tutorial.html">
   Recsys’20 Feature Engineering Tutorial
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T227901_amazon_personalize_batch_job.html">
   Amazon Personalize Batch Job
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T022961_Amazon_Personalize_Workshop.html">
   Amazon Personalize Workshop
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T424437_Collaborative_Filtering_on_ML_latest_small.html">
   Collaborative Filtering on ML-latest-small
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T539160_Building_and_Deploying_ASOS_Fashion_Recommender.html">
   Building and deploying ASOS fashion recommender
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T757697_Simple_Similarity_based_Recommender.html">
   Simple Similarity based Recommmendations
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T051594_Analytics_Zoo.html">
   Analytics Zoo
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T313645_A_B_Testing.html">
   A/B Testing
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T475711_PinSage_Graph_based_Recommender.html">
   PinSage Graph-based Recommender
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T516490_Graph_Embeddings.html">
   Learn Embeddings using Graph Networks
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T822164_movielens_milvus_redis_efficient_retrieval.html">
   Recommender with Redis and Milvus
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T845186_Anime_Recommender.html">
   RekoNet Anime Recommender
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T855843_kafka_spark_streaming_colab.html">
   Kafka and Spark Streaming in Colab
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T460437_Building_Models_From_Scratch.html">
   Building Models from scratch
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T855971_Conet_Model_for_Movie_Recommender.html">
   CoNet model
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T996996_content_based_and_collaborative_movielens.html">
   Movie Recommendation with Content-Based and Collaborative Filtering
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T239418_Simple_Movie_Recommenders.html">
   Simple Movie Recommenders
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T138337_Simple_Movie_Recommender.html">
   Simple movie recommender in implicit, explicit, and cold-start settings
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T935440_The_importance_of_Rating_Normalization.html">
   The importance of Rating Normalization
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T612622_cornac_examples.html">
   Cornac Examples
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T561435_Flower_Classification.html">
   Flower classification
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T680910_Trivago_Session_based_Recommender.html">
   Trivago Session-based Recommender
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T990000_ads_selection_using_bandits.html">
   Best Ads detection using bandit methods
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T990000_book_crossing_surprise_svd_nmf.html">
   Book-Crossing Recommendation System
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T990000_book_recommender_kubeflow.html">
   Books recommendations with Kubeflow Pipelines on Scaleway Kapsule
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T990000_build_a_kubeflow_pipeline.html">
   Build a Kubeflow Pipeline
  </a>
 </li>
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   Causal Inference
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T990000_concept_embedding_nlp.html">
   Exploring Word Embeddings
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T990000_concept_neural_net.html">
   Neural Network
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T990000_concept_nlp_basics.html">
   Natural Language Processing 101
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T990000_concept_transformer_lm.html">
   TransformerLM Quick Start and Guide
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T990000_content_based_music_recommender_lyricsfreak.html">
   Content-based method for song recommendation
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T990000_evaluation_metrics_basics.html">
   Recommender System Evaluations
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T990000_implicit_synthetic.html">
   Comparing Implicit Models on Synthetic Data
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T990000_movie_recommender_tensorflow.html">
   Recommendation Systems with TensorFlow
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T990000_movie_recommender_tensorflow_sagemaker.html">
   Movie recommender using Tensorflow in Sagemaker
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T990000_movielens_eda_modeling.html">
   Movielens EDA and Modeling
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T990000_read_data_from_cassandra_into_pandas.html">
   Read Cassandra Data Snapshot as DataFrame
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T990000_rl_in_action.html">
   Reinforcement Learning fundamentals in action
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T990000_rnn_cnn_basics.html">
   Processing sequences using RNNs and CNNs
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T990000_tf_serving_in_action.html">
   TF Serving in action
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T990000_training_indexing_movie_recommender.html">
   Training and indexing movie recommender
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T207114_EduRec_MOOCCube_Course_Recommender.html">
   EduRec MOOCCube Course Recommender
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T273184_Multi_Task_Learning.html">
   Multi-task Learning
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T661108_Book_Recommender_API.html">
   Book Recommender API
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T912764_Simple_Movie_Recommender_App.html">
   Simple Movie Recommender App
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T964554_Career_Village_Questions_Recommendation.html">
   CareerVillage Questions Recommendation
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T990001_amazon_women_apparel_tfidf_word2vec.html">
   Amazon Product Recommender
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T990001_anime_recommender_graph_network.html">
   Anime Recommender with Bi-partite Graph Network
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T990001_concept_self_attention.html">
   Self-Attention
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T990001_course_recommender_svd_flask.html">
   Course Recommender with SVD based similarity
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T990001_data_mining_similarity_measures.html">
   Concept - Data Mining Similarity Measures
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T990001_jaccard_recommender.html">
   Jaccard Similarity based Recommender
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T990001_live_streamer_recommender.html">
   Live Streamer Recommender with Implicit feedback
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T990001_songs_embedding_skipgram_recommender.html">
   Song Embeddings - Skipgram Recommender
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T990001_toy_example_car_recommender_knn.html">
   Toy example - Car Recommender using KNN method
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="T990001_wikirecs_recommender.html">
   WikiRecs
  </a>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../_sources/nbs/T990000_causal_inference.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
        title="Fullscreen mode"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        <a class="binder-button" href="https://mybinder.org/v2/gh/sparsh-ai/reco-book/main?urlpath=tree/nbs/T990000_causal_inference.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Launch Binder" data-toggle="tooltip"
                data-placement="left"><img class="binder-button-logo"
                    src="../_static/images/logo_binder.svg"
                    alt="Interact on binder">Binder</button></a>
        
        
        
        
    </div>
</div>

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show">
            
            <div class="tocsection onthispage pt-5 pb-3">
                <i class="fas fa-list"></i> Contents
            </div>
            <nav id="bd-toc-nav" aria-label="Page">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#introduction">
   Introduction
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#conditioning-based-methods">
   Conditioning-based methods
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#natural-experiments">
   Natural Experiments
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#sensitivity-analysis">
   Sensitivity Analysis
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#now-the-process-of-matching-and-stratafication">
   Now the process of matching and stratafication
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#and-then-with-a-bit-of-matching">
     And then with a bit of matching
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#propensity-score">
   Propensity Score
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#stratification">
     Stratification
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#weighting">
   Weighting
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#simple-regression">
   Simple Regression
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#doubly-robust">
   Doubly robust
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#synthetic-controls">
   Synthetic Controls
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#natural-experiment">
   Natural Experiment
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#simple-natural-experiment">
   Simple Natural Experiment
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#instrumental-variables">
   Instrumental Variables
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#refutations">
   Refutations
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#other">
   Other
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#dowhy">
   Dowhy
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#first-example">
   First Example
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#regression">
     Regression
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id1">
     Stratification
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#matching">
     Matching
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id2">
     Weighting
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#instrumental-variable">
     Instrumental Variable
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#regression-discontinuity">
     Regression Discontinuity
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#now-refuting">
   Now Refuting
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#instrumental-variable-application">
     Instrumental Variable Application
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#different-way-to-create-graphs">
     Different way to create graphs
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#using-pandas-api-do-sampler">
   Using Pandas API (do sampler)
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#treatment-effect-estimation">
     Treatment Effect Estimation
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#further-elaboration-on-pearlian-intervention">
     Further Elaboration on Pearlian Intervention
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#pearlian-interventions">
   Pearlian Interventions
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#statefulness">
   Statefulness
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#integration">
   Integration
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#specifying-interventions">
   Specifying Interventions
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#demo">
   Demo
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#uplift-cate-ate-ite">
   Uplift (CATE, ATE, ITE)
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#average-treatment-effect-estimation-with-s-t-x-and-r-learners">
   Average Treatment Effect Estimation with S, T, X, and R Learners
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#calculate-individual-treatment-effect-ite-cate">
   Calculate Individual Treatment Effect (ITE/CATE)
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#validity-of-meta-learner">
   Validity of Meta-Learner
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#propensity-matching-and-estimation">
   Propensity Matching and Estimation
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#confidence-intervals">
     Confidence Intervals
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#a-b-testing">
   A/B Testing
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#calculate-the-necessary-sample-size">
   Calculate The Necessary Sample Size
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#frequentist">
   Frequentist
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#regression-approach">
   Regression Approach
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#increasing-the-power">
   Increasing the Power
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#bayesian">
   Bayesian
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#fit-the-model">
     Fit the model
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#another-approach">
     Another Approach
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#causal-discovery">
   Causal Discovery
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#time-series-causal-discovery-tcdf">
     Time Series Causal Discovery - TCDF
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#time-series-causal-discovery-trig">
     Time Series Causal Discovery - Trig
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#cross-sectional-causal-discovery">
     Cross-sectional Causal Discovery
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id3">
   Causal Inference
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#potential-outcomes">
   Potential Outcomes
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#goals">
   Goals
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#making-assumptions">
   Making Assumptions
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#modeling-the-counterfactual">
   Modeling the Counterfactual
  </a>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="section" id="causal-inference">
<h1>Causal Inference<a class="headerlink" href="#causal-inference" title="Permalink to this headline">¶</a></h1>
<blockquote>
<div><p>Concepts of causal inferencing with code.</p>
</div></blockquote>
<div class="section" id="introduction">
<h2>Introduction<a class="headerlink" href="#introduction" title="Permalink to this headline">¶</a></h2>
<p>To tackle such questions, we will introduce the key ingredient that causal analysis depends on—counterfactual reasoning—and describe the two most popular frameworks based on Bayesian graphical models and potential outcomes. Intuitively, the counterfactual framework measures causal effects by comparing measured outcomes in two almost-identical worlds—imagine two parallel universes, identical in every way up until the point where a some “treatment” occurs in one world but not the other.</p>
<p>Building upon the counterfactual framework, we introduce causal graphs, which are a tool for formalizing implicit assumptions about causal mechanisms (e.g., encoding domain knowledge about causal mechanisms into an analysis); and potential outcomes methods, which are statistical tools for estimating causal effects. — Where some intuition comes in.</p>
<p>We close our introduction by presenting the randomized experiment as the simplest method for causal inference. We describe the randomized experiment in the language of the counterfactual framework, providing a causal graph and associated potential outcomes formulation, and show how this conceptually clean and simple method addresses the challenges of causal inference.</p>
</div>
<div class="section" id="conditioning-based-methods">
<h2>Conditioning-based methods<a class="headerlink" href="#conditioning-based-methods" title="Permalink to this headline">¶</a></h2>
<p>Conditioning-based methods are the workhorse of causal inference when running active experiments is not feasible. We discuss these methods by showing how each one is, in its own way, attempting to approximate the gold standard randomized experiment. <strong>Conditioning</strong> on key causal variables is the simplest method for isolating causal effect. <strong>Matching and stratification</strong> approximates conditioning at high-diemensions an continuous variable settings. <strong>Regression</strong> can also be used. <strong>Doubly robust estimators</strong> provides the best of conditioning and regression by combining propensity-based and regression-based methods. <strong>Synthetic control method</strong> can be used if none of the above suits, it is especially usefull when the treatment is applied to the entire population.</p>
</div>
<div class="section" id="natural-experiments">
<h2>Natural Experiments<a class="headerlink" href="#natural-experiments" title="Permalink to this headline">¶</a></h2>
<p>Conditioning methods can fail if important confounders and unobserved. Here we smiply attempt to find an observed variable that acts like the randomised arm of an experiment. <strong>Simple natural experiment</strong> can be used, the type we see in the field, in the lab or occur as a result of some exogenous phenomena. <strong>Instrumental variables</strong> method ensures that we obtain the true causal effect even when there are unobserved confounders. <strong>Regresion discontinuity</strong> is the process to look for dicontinuity in bserved data.</p>
</div>
<div class="section" id="sensitivity-analysis">
<h2>Sensitivity Analysis<a class="headerlink" href="#sensitivity-analysis" title="Permalink to this headline">¶</a></h2>
<p>At the end we have to see how the results change once we alter the assumptions for both observational studies and natural experiments.</p>
<p>Think of smoking as the confound to red-meat eating and heart attacks.</p>
<p>Here we want to study the effect of treatment <span class="math notranslate nohighlight">\(T\)</span> on the outcome <span class="math notranslate nohighlight">\(Y\)</span>, however as shown in the digraph, there is a confound <span class="math notranslate nohighlight">\(X\)</span> that influences both <span class="math notranslate nohighlight">\(Y\)</span> and <span class="math notranslate nohighlight">\(T\)</span>. Therefore to estimate <span class="math notranslate nohighlight">\(T\rightarrow Y\)</span> we have to break the dependence <span class="math notranslate nohighlight">\(X\rightarrow T\)</span> so that <span class="math notranslate nohighlight">\(T \perp X\)</span>. And <span class="math notranslate nohighlight">\(Y \perp X\)</span> could also work but less practical.</p>
<p>By using random experiment you actively assign a treatment unrelted to any confound. And by constructiona well run random experiment is <span class="math notranslate nohighlight">\(T \perp X\)</span>. The confound is equally split between the two groups as long as there is no selection bias in the sample selection procedure.</p>
<center><img>  <img src="https://cdn.mathpix.com/snip/images/Ssb3nBeds2f8J8ulnQCQhX0N6ktxFk-wopFwExxKtrc.original.fullsize.png" height="200"/>
<p>Lets try a new one. Our goal is to estimate the effect of excerise on cholesterol. But your age influences both your level of excercise and cholesterol. So to estimate the effect of excerices on cholesteral we are to break the dependence of age on excercies. So in a random experiment we can actively assign excercise independent of age.</p>
<p>If we can’t actively intervene, we have to simulate random experiments through observational studies using on of six observational techniques. The first technique we will look at is <strong>conditioning</strong>. So clearly there is some relationship, but there is a confounder, so we can emperically define the relationship yet. Currently it looks like more stationary biking is related to higher cholesterol. In this example, older people are more likley to participate in stationary biking. We can condition on age by analysing each age group separately.</p>
<p><img> <img src="https://cdn.mathpix.com/snip/images/m6ZsRIvxmY6Cac8LTsy3kMKO-HBAn0SbrOHWVReaZvk.original.fullsize.png" /></p>
<div class="math notranslate nohighlight">
\[
P\left(\text {Cholesterol } | \operatorname{do}\left(S_{-} B i k i n g\right)\right)=\sum_{\text {age}} P\left(\text {Cholesterol } | S_{-} \text {Biking,age}\right) P(\text {age})
\]</div>
<p>So naturally in this example, we make a few critical assumptions.</p>
<ul class="simple">
<li><p>Age is the only confounder, this is called the <strong>ignorability</strong> or selection of obserables assumption.</p></li>
<li><p><strong>SUTVA assumption</strong> says that a subject’s potential outcome is not affected by other subjects’ exposure to the treatment. There are not alternative treatment allocations that would lead to different outcomes due to network effects, such that of friends.</p></li>
<li><p>The observations cover similar people, the common support or <strong>overlap assumption</strong>.</p></li>
<li><p>Don’t include all age groups and the effect on excerciese, so will it <strong>generalise</strong> beyond observed region.</p></li>
</ul>
<p>Note it becomes very hard to know what to condition on when the dimensionality of X increases. In business X is large, it is therefore unlikley that you would make use of the conditioning techinque.</p>
<p>You have to use the backdoor criterion to ensure that you have the right variables. So the casual effect is only true if the assumed graphical model is in fact correct.</p>
<p><img>  <img src="https://cdn.mathpix.com/snip/images/tQvXOSUS1s-mLpBuDWQPNsWkbGZO3vskiGvRgoy5DiY.original.fullsize.png" /></p>
</div>
<div class="section" id="now-the-process-of-matching-and-stratafication">
<h2>Now the process of matching and stratafication<a class="headerlink" href="#now-the-process-of-matching-and-stratafication" title="Permalink to this headline">¶</a></h2>
<p><img alt="" src="https://cdn.mathpix.com/snip/images/4sRHsu93WmElDVquTWmRAYVH27PKQiNYZErZ5ntYeaw.original.fullsize.png" /></p>
<div class="section" id="and-then-with-a-bit-of-matching">
<h3>And then with a bit of matching<a class="headerlink" href="#and-then-with-a-bit-of-matching" title="Permalink to this headline">¶</a></h3>
<p><img alt="" src="https://cdn.mathpix.com/snip/images/l4Na-bCxsC1NTDQR5tEVneAsg6yUOxU2mJXhEI9KnU0.original.fullsize.png" /></p>
<p>Here we therefore find individual pairs of treated and untreated indviduals that are veery siilar to eachother. And this paired individuals then provide the counterfactual estimate for each other. You then simply average the difference in outcome within pairs to calucalte the average-treatment-effect (ATE) on the treated.</p>
<p>The mahalanobis distance accounts for the unit differences by normalising each dimesions by the standard deviation. Here <span class="math notranslate nohighlight">\(S\)</span> is the covariance matrix.</p>
<div class="math notranslate nohighlight">
\[
\text {Mahalanobis }\left(\vec{x}_{i}, \vec{x}_{j}\right)=\sqrt{(\overrightarrow{x_{i}}-\overrightarrow{x_{j}})^{T} S^{-1}(\overrightarrow{x_{i}}-\overrightarrow{x_{j}})}
\]</div>
</div>
</div>
<div class="section" id="propensity-score">
<h2>Propensity Score<a class="headerlink" href="#propensity-score" title="Permalink to this headline">¶</a></h2>
<p>This is the individual’s propensity to be treated, these scores are estimated, you can then use the propensity socre to subdivide the observational data so that <span class="math notranslate nohighlight">\( T \perp X |score\)</span>. It therefore breaks the infleunce of confound <span class="math notranslate nohighlight">\(X\)</span> and allows for the estimation of the true treatment effect.</p>
<p>This is where a few machine learning models can be used for good measure. Here one tries to predict all the label (i.e. the treatment states) based on the observed covariates. You can use any model where the score is well calibrated so that <span class="math notranslate nohighlight">\((100 \times p)\%\)</span> of indviduals with score <span class="math notranslate nohighlight">\(p\)</span> are observed to be treated. You can therefore use logistic regressions, SVMs and GAMs.</p>
<p><a class="reference external" href="https://onlinelibrary.wiley.com/doi/abs/10.1002/bimj.201800132">https://onlinelibrary.wiley.com/doi/abs/10.1002/bimj.201800132</a></p>
<p>And then distance is the distance between propensity scores:</p>
<div class="math notranslate nohighlight">
\[
\text { Distance }(\overrightarrow{x_{i}}, \overrightarrow{x_{j}})=|\hat{e}(\overrightarrow{x_{i}})-\hat{e}(\overrightarrow{x_{j}})|
\]</div>
<p>Propensity score matching works because individuals with similar covariates have similar scores and similar treatment likelihoods. It doesn’t really matter whether or not the propensity score is accurate, the role is simply to characterise covariates and not to actually identify the treated from the untreated. If fact if the propensity score is too accurate, it means you can’t disentable the covariates from the treatement status and as a reslt, any effect we observe could be due either to the treatment or to the correlated covariate, in such senario, you should not dumb down the model, instead you should redefine the problem statement and the treatment.</p>
<p>The code to this problem is very easy, use a machine learning model to predict the covariate status</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># learn propensity score model</span>
<span class="n">psmodel</span> <span class="o">=</span> <span class="n">linear_model</span><span class="o">.</span><span class="n">LinearRegression</span><span class="p">()</span>
<span class="n">psmodel</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">covariates</span><span class="p">,</span> <span class="n">treatment_status</span><span class="p">)</span>
<span class="n">data</span><span class="p">[</span><span class="s1">&#39;ps&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">psmodel</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">covariates</span><span class="p">)</span>
<span class="c1"># find nearest neighbor matches</span>
<span class="n">controlMatcher</span> <span class="o">=</span> <span class="n">NearestNeighbors</span><span class="p">()</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">untreated</span><span class="p">[</span><span class="s1">&#39;ps’])</span>
<span class="n">distances</span><span class="p">,</span> <span class="n">matchIndex</span> <span class="o">=</span> <span class="n">controlMatch</span><span class="o">.</span><span class="n">kneighbors</span><span class="p">(</span><span class="n">treated</span><span class="p">[</span><span class="s1">&#39;ps&#39;</span><span class="p">])</span>
<span class="c1"># iterate over matched pairs and sum difference in outcomes</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">numtreatedunits</span><span class="p">):</span>
    <span class="n">treated_outcome</span> <span class="o">=</span> <span class="n">treated</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">outcome_name</span><span class="p">]</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
    <span class="n">untreated_outcome</span> <span class="o">=</span> <span class="n">untreated</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">matchIndex</span><span class="p">[</span><span class="n">i</span><span class="p">]][</span><span class="n">outcome_name</span><span class="p">]</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
    <span class="n">att</span> <span class="o">+=</span> <span class="n">treated_outcome</span> <span class="o">-</span> <span class="n">untreated_outcome</span>
<span class="c1"># normalize </span>
<span class="n">att</span> <span class="o">/=</span> <span class="n">numtreatedunits</span>
</pre></div>
</div>
</div>
</div>
<p>With mathching we can choose to allow for replacement, it is a bias variance trade off. And if the nearest neighbour is too far away, it is advisible to use a caliper threshold to limit the acceptable distance. One should also be sure that all treated are not matched to untreated. You are more likley to used propensity score matching than Mahalanobis distance matching. Remember one central problem still remains with al these methods and it is unobserved confounds.</p>
<div class="section" id="stratification">
<h3>Stratification<a class="headerlink" href="#stratification" title="Permalink to this headline">¶</a></h3>
<p>In matching it is one to one, in stratification it is many to many matching. Stratification identifies paired subpopulation with similar covariate distributions.</p>
<p>We can use propensity scores to stratify populations. So we once more calculate the propensity score per individual but now instead of match we stratify them into groups. Once the groups have been established you can calculate the average treatment effect (ATE) as the weighted average of outcome differences per strata.</p>
<div class="math notranslate nohighlight">
\[
ATT =\sum_{s \in s t r a t a} \frac{1}{N_{s, T=1}}\left(\bar{Y}_{s, T=1}-\bar{Y}_{s, T=0}\right)
\]</div>
<p>where <span class="math notranslate nohighlight">\(
\bar{Y}_{S, T}
\)</span> is the average outcome at strata <span class="math notranslate nohighlight">\(s\)</span> and treatment status <span class="math notranslate nohighlight">\(T\)</span> and <span class="math notranslate nohighlight">\(
N_{S, T=1}
\)</span> is the number of treated individuals in strata <span class="math notranslate nohighlight">\(s\)</span>.</p>
<center><img><img src="https://cdn.mathpix.com/snip/images/4S4eJJY3e5RBvMQjHfm9sNMV5r8hCrXoZNEy7ZgJHfg.original.fullsize.png" height=300/></center>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span># build propensity score model and assign each item a score as earlier…

# create a column &#39;strata&#39; for each element that marks what strata it belongs to
data[&#39;strata&#39;] = ((data[&#39;ps&#39;].rank(ascending=True) / numrows) * numStrata).round(0)
data[&#39;T_y&#39;] = data[&#39;T&#39;] * data[&#39;outcome’]            # T_y = outcome iff treated
data[&#39;Tbar&#39;] = 1 - data[&#39;treated’]                   # Tbar = 1 iff untreated
data[&#39;Tbar_y&#39;] = data[&#39;Tbar&#39;] * data[&#39;outcome&#39;]      # Tbar_y = outcome iff untreated
stratified = data.groupby(&#39;strata&#39;)
# sum weighted outcomes over all strata  (weight by treated population)
outcomes = stratified.agg({&#39;T&#39;:[&#39;sum&#39;],&#39;Tbar&#39;:[&#39;sum&#39;],&#39;T_y&#39;:[&#39;sum&#39;],&#39;Tbar_y&#39;:[&#39;sum&#39;]})
# calculate per-strata effect
outcomes[‘T_y_mean&#39;] = outcomes[‘T_y_sum&#39;] / outcomes[&#39;T&#39;]
outcomes[‘Tbar_y_mean&#39;] = outcomes[‘Tbar_y_sum&#39;] / outcomes[&#39;dbar_sum&#39;]
outcomes[&#39;effect&#39;] = outcomes[‘T_y_mean&#39;] - outcomes[‘Tbar_y_mean’]
# weighted sum of effects over all strata
att = (outcomes[&#39;effect&#39;] * outcomes[&#39;T&#39;]).sum() / totaltreatmentpopulation
</pre></div>
</div>
</div>
</div>
<p>We would also have to choose how many strata to select, if you have around 100 data points, you can pick five. If you have 10k - 1mn pick 100-1000 strata. We don’t wat to pick a small nuber of strata as it is a bias-variance trade-off. Matching is high variance, low bias. Often times we find that there might not be enough treated and untreated indviduals in a stratum tyically near propensity scores of 0.0 and 1.0, in which case we clip the strata from the analyis, which technically means we are now calcualting a local-average-treatment-effet.</p>
</div>
</div>
<div class="section" id="weighting">
<h2>Weighting<a class="headerlink" href="#weighting" title="Permalink to this headline">¶</a></h2>
<p>This is the next mechanism that is an alternative to conditioning. Is it possible ot assign weights to observations to simulate a randomised experiment. So with stratification we know that we weigh each strata’s total impact by the number of treated. So weighting argues that the weighting of the treated population is similar to weighting by propensity score, so they calculate the effect by weighted sum over all individual outcomes.</p>
<div class="math notranslate nohighlight">
\[
A T E=\frac{1}{N_{T=1}} \sum_{i \in \text {treated}} w_{i} Y_{i}-\frac{1}{N_{T=0}} \sum_{j \in u n t r e a t e d} w_{j} Y_{j}
\]</div>
<p>And the Inverse Probability of Treatment Weighting (IPTW)</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned} w_{i}=&amp; \frac{T}{e}+\frac{1-T}{1-e} \\ \mathrm{N}_{\mathrm{T}=1}=&amp; \sum \frac{T}{e} ; \quad N_{T=0}=\sum \frac{1-T}{1-e} \end{aligned}
\end{split}\]</div>
<p>Weights on each individual act to balance the distribution of covariates in the treated and untreated groups.  (i.e., break the dependence between treatment status and covariates)</p>
<p>You obtain a high variance when <span class="math notranslate nohighlight">\(e\)</span> is close to 0 or 1. Note <span class="math notranslate nohighlight">\(e\)</span> is the propensity scores. As such it might become crucuial to clip weights. This model assumes that propensity scores are correctly specified. There are variants to this generalised weighting protocol such as the ATE on treated only.</p>
</div>
<div class="section" id="simple-regression">
<h2>Simple Regression<a class="headerlink" href="#simple-regression" title="Permalink to this headline">¶</a></h2>
<p>Here regression and supervised learning can be used interchangably. In regression analysis, we build a model of <span class="math notranslate nohighlight">\(Y\)</span> as a function of covariates <span class="math notranslate nohighlight">\(X\)</span> and <span class="math notranslate nohighlight">\(T\)</span>, amnd interpret the coeffients of the covariates and treatment causally.</p>
<div class="math notranslate nohighlight">
\[
E(Y | X, T)=\alpha_{1} X_{1}+\alpha_{2} X_{2}+\cdots \alpha_{n} X_{n}+\alpha_{T} T
\]</div>
<p>for example</p>
<div class="math notranslate nohighlight">
\[
\text { Cholesterol }=\alpha_{\text {age}} A g e+\alpha_{\text {exercise}} \text {Exercise}
\]</div>
<p>The bigger the coefficient the stronger the causal relationship to the outcome, <span class="math notranslate nohighlight">\(Y\)</span>. The problem is that the causal interpretation of regressions require many assumptions. <strong>Model Correctness</strong> what if we use a linear model and a causal model is non-linear. <strong>Multicollinearity</strong> if the covariates are correlated, you can’t get accurate coefficients. <strong>Ignorability</strong> omission of confounds will invalidate findings. This method should largely be ignored, unless you are asbolutely sure about what you are doing.</p>
</div>
<div class="section" id="doubly-robust">
<h2>Doubly robust<a class="headerlink" href="#doubly-robust" title="Permalink to this headline">¶</a></h2>
<p>This method makes use of both propensity score and regression methods. Both of which uses models that have to be correctly specified, i.e. not linear when the relationship is non-linear. With this method, if either propensity score <strong>or</strong> regression is correctly specified, then doubly robust is correct. As a result, it seems that the doubly robust method should always stritly be better than each method indvidually, but that is not entirely true, if both models are slightly incorrect, then doubly robust can become very biased.</p>
<div class="math notranslate nohighlight">
\[\begin{split}
D R_{1}=\left\{\begin{array}{ll}{\frac{Y}{\hat{e}}-\frac{\hat{Y}_{T=1}(1-\hat{e})}{\hat{e}},} &amp; {T=1} \\ {\hat{Y}_{T=1},} &amp; {T=0}\end{array}\right.
\end{split}\]</div>
<div class="math notranslate nohighlight">
\[\begin{split}
D R_{0}=\left\{\begin{array}{ll}{\hat{Y}_{T=0},} &amp; {T=1} \\ {\frac{Y}{1-\hat{e}}-\frac{\hat{Y}_{T=1} \hat{e}}{1-\hat{e}},} &amp; {T=0}\end{array}\right.
\end{split}\]</div>
<p>The idea is to calculate the first and second estimators for each individual and then to calucalte the mean of the two estimators over the whole study population and take the difference as the causal effect of <span class="math notranslate nohighlight">\(T\)</span>.</p>
</div>
<div class="section" id="synthetic-controls">
<h2>Synthetic Controls<a class="headerlink" href="#synthetic-controls" title="Permalink to this headline">¶</a></h2>
<p>All the previous methods require that we observe both the treated and untreated individuals. There could be a global policy change tht would lead to eveeryone being treated. It is possible to do a pre/post comparison but it is not robust to dynamics like seasonality. The alternative is to build synthetic controls that estimate what <span class="math notranslate nohighlight">\(\bar{Y}_{T=0}\)</span> would have been for a population were it not for the treatment. There is more to be said here, but I will leave it for later.</p>
</div>
<div class="section" id="natural-experiment">
<h2>Natural Experiment<a class="headerlink" href="#natural-experiment" title="Permalink to this headline">¶</a></h2>
</div>
<div class="section" id="simple-natural-experiment">
<h2>Simple Natural Experiment<a class="headerlink" href="#simple-natural-experiment" title="Permalink to this headline">¶</a></h2>
<p>Under natural experiments we have simple natural experiments, instrumental variabls, and regression discontinuities. Natural here means, as if nature conducted an experiment. Here instead of just assuming ignorability, we find data sets that approximate an experiment. Here we have A/B testing, Lottery, Randomised policy, and an external shock to the treatment. It is never truly random, so you exploit and as-if random assignment to meature the effect of the treatment on the outcome.</p>
</div>
<div class="section" id="instrumental-variables">
<h2>Instrumental Variables<a class="headerlink" href="#instrumental-variables" title="Permalink to this headline">¶</a></h2>
<p>At first you have to attempt to find an instrument variable which is anything that affects the cause but not the outcome.</p>
<center> <img> <img src="https://cdn.mathpix.com/snip/images/jvKsKCDIsPX1Cd2URnxOkozLtWLnIATanMYt2JdoxeU.original.fullsize.png" height=250 /><p>As a result, a change in Y is a product of the change in Z -&gt; X and X -&gt; Y. And the causal effect is</p>
<div class="math notranslate nohighlight">
\[
\text { Causal effect }(X-&gt;Y)=\frac{Y_{Z=1}-Y_{Z=0}}{X_{Z=1}-X_{Z=0}}
\]</div>
<p>Due to it being an external event you can look at it as-if it is random variation. Example: What is the effect of recommendations on an app store?
Instrumental Variable: External sources that drive sudden, large traffic to an app. Because IVs are not influenced by confounds, IVs’ indirect effect on outcome Y is independent of confounds too.  Because IVs do not directly influence outcome, their effect must be due to the effect of the treatment. They seem very common now. You then of course get regression discontinuities, that are quite common and can be thought of as a special case of an instrumental variable.</p>
</div>
<div class="section" id="refutations">
<h2>Refutations<a class="headerlink" href="#refutations" title="Permalink to this headline">¶</a></h2>
<p>Causal inference is only possible with assumptions. It is critical to review your assumptions, but the question is, how can this be done.</p>
<p>DoWhy focuses attention on the assumptions required for causal inference.</p>
<p>Provides estimation methods such as matching and IV so that you can focus on the identifying assumptions.</p>
<ul class="simple">
<li><p>Models assumptions explicitly using causal graphical model.</p></li>
<li><p>Provides an easy way to test them (if possible) or analyze sensitivity to violations.</p></li>
</ul>
<p>Unifies all methods to yield four verbs for causal inference:</p>
<ul class="simple">
<li><p>Model</p></li>
<li><p>Identify</p></li>
<li><p>Estimate</p></li>
<li><p>Refute</p></li>
</ul>
<p>Can add randomly drawn covariates into data</p>
<p>Rerun your analysis.</p>
<p>Does the causal estimate change?  (Hint: it shouldn’t)</p>
<hr class="docutils" />
<p>Randomize or permute the treatment.</p>
<p>Rerun your analysis.</p>
<p>Does the causal estimate change? (Hint: it should become 0)</p>
<hr class="docutils" />
<p>Create subsets of your data.</p>
<p>Rerun your analysis.</p>
<p>Does the causal estimate vary across subsets?  (Hint: it shouldn’t vary significantly)</p>
<hr class="docutils" />
<p>Many methods (e.g., matching, stratification, weighting, regression discontinuity) depend on balancing of covariates</p>
<p>Can test this.</p>
<hr class="docutils" />
<p>Question: How sensitive is your estimate to minor violations of assumptions?</p>
<p>E.g. How big should the effect of a confounder be so that your estimate reverses in direction?</p>
<p>Use simulation to add effect of unknown confounders.</p>
<p>Domain knowledge helps to guide reasonable values of the simulation.</p>
<p>Make comparisons to other known estimates.</p>
<p><img alt="" src="https://cdn.mathpix.com/snip/images/fuJzJybm6NgRKslmS5dS1tyMzUPuYcA2eTi0DnLCqyg.original.fullsize.png" /></p>
<hr class="docutils" />
<p>Always follow the four steps: Model, Identify, Estimate, Refute.
Refute is the most important step.</p>
<p>Aim for simplicity.
If your analysis is too complicated, it is most likely wrong.</p>
<p>Try at least two methods with different assumptions.
Higher confidence in estimate if both methods agree.</p>
<hr class="docutils" />
<p>•Input: Observational data,  Causal graph
•Output: Causal effect between desired variables, “What-if” analysis</p>
<hr class="docutils" />
<p>When you have high dimensional problems you can use dimensionality reduction tehcniques or regularised models.</p>
<hr class="docutils" />
<p>And network effects complicate causal inference. An individual outcomes should not depend on another’s treatment status. One can then consider partitioned sub-networks as a unit of analysis.</p>
<hr class="docutils" />
<p>WEIRD problem in social studies, might not  generalise to other users, platforms or cultures. So you can coroborate findings accorss. And be explicity of the potential of non-generalisability.</p>
<hr class="docutils" />
<p>There is a few common confounders that can lead to selection bias, theses are structured (demographics, usage patterns) and unstructures (activity, preferences). Time spent on page is not important without page, more activity can simply mean more activity at that time consider that schools are closed.</p>
</div>
<div class="section" id="other">
<h2>Other<a class="headerlink" href="#other" title="Permalink to this headline">¶</a></h2>
<p>Causal discovery is a harder problem than causal inference. Causal inference looks at the effects of causes, and causal discovery at the causes of effects.</p>
<p>Heterogeneuos treatment effects. Average causal effect does not capture individual-level variations. Stratification is one of the simplest methods for hetrongenous treatment by strata, typical strata are demographics. You need more data when you stratify to detect statistical differences, otherwise it can purely be down to noise. For high dimensions we can use machine learning methods like random forests such as those by Susan Athey.</p>
<p>Machine learning can also use causal inference methods for robust generalisable prediction. And causal inference can use ML algorithms to better model the non-linear effects of confounders.</p>
<p>RL and causal inference can be used together. You can feed in A/B test into multi-armed bandits, MDPs and POMDPs to generalise a randomised experiment. So you can have two goals, one is to show the best known algorithm to the users as a recommender, and the second to keep randomising to update knowledge about competing algorithms.</p>
<p>As a pratical example, you can look at contextual bandits for Yahoo News. The action is to display different news articles, this is done using an episilon greedy policy.</p>
</div>
<div class="section" id="dowhy">
<h2>Dowhy<a class="headerlink" href="#dowhy" title="Permalink to this headline">¶</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span># !git clone https://github.com/microsoft/dowhy.git
# !pip install -r dowhy/requirements.txt
# !python dowhy/setup.py install

!pip install dowhy
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="first-example">
<h2>First Example<a class="headerlink" href="#first-example" title="Permalink to this headline">¶</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="c1">#from dowhy import CausalModel</span>
<span class="kn">from</span> <span class="nn">dowhy.do_why</span> <span class="kn">import</span> <span class="n">CausalModel</span>
<span class="kn">import</span> <span class="nn">dowhy.datasets</span> <span class="k">as</span> <span class="nn">ds</span>
<span class="kn">import</span> <span class="nn">logging</span>

<span class="c1">## beta 10 is what I want the cause to be. </span>
<span class="n">data</span> <span class="o">=</span> <span class="n">ds</span><span class="o">.</span><span class="n">linear_dataset</span><span class="p">(</span><span class="n">beta</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
        <span class="n">num_common_causes</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
        <span class="n">num_instruments</span> <span class="o">=</span> <span class="mi">2</span><span class="p">,</span>
        <span class="n">num_samples</span><span class="o">=</span><span class="mi">10000</span><span class="p">,</span> 
        <span class="n">treatment_is_binary</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="s2">&quot;df&quot;</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="s2">&quot;dot_graph&quot;</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="s2">&quot;gml_graph&quot;</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>    Z0        Z1        X0        X1  ...        X3        X4    v          y
0  0.0  0.174714 -0.399804 -0.107714  ...  1.821615 -0.202443  1.0  10.306148
1  0.0  0.049295 -0.308593  1.455492  ...  0.763214 -0.910582  1.0  12.634204
2  0.0  0.475725 -0.396744 -2.586876  ... -0.624382  1.430882  1.0   7.815953
3  0.0  0.067478  0.583631  0.361288  ... -0.293668 -2.068990  0.0  -6.583293
4  0.0  0.058039 -1.783720  0.078355  ...  0.284110 -1.381946  0.0  -6.185724

[5 rows x 9 columns]
digraph { v -&gt;y; U[label=&quot;Unobserved Confounders&quot;]; U-&gt;v; U-&gt;y;X0-&gt; v; X1-&gt; v; X2-&gt; v; X3-&gt; v; X4-&gt; v;X0-&gt; y; X1-&gt; y; X2-&gt; y; X3-&gt; y; X4-&gt; y;Z0-&gt; v; Z1-&gt; v;}


graph[directed 1node[ id &quot;v&quot; label &quot;v&quot;]node[ id &quot;y&quot; label &quot;y&quot;]node[ id &quot;Unobserved Confounders&quot; label &quot;Unobserved Confounders&quot;]edge[source &quot;v&quot; target &quot;y&quot;]edge[source &quot;Unobserved Confounders&quot; target &quot;v&quot;]edge[source &quot;Unobserved Confounders&quot; target &quot;y&quot;]node[ id &quot;X0&quot; label &quot;X0&quot;] edge[ source &quot;X0&quot; target &quot;v&quot;] node[ id &quot;X1&quot; label &quot;X1&quot;] edge[ source &quot;X1&quot; target &quot;v&quot;] node[ id &quot;X2&quot; label &quot;X2&quot;] edge[ source &quot;X2&quot; target &quot;v&quot;] node[ id &quot;X3&quot; label &quot;X3&quot;] edge[ source &quot;X3&quot; target &quot;v&quot;] node[ id &quot;X4&quot; label &quot;X4&quot;] edge[ source &quot;X4&quot; target &quot;v&quot;]edge[ source &quot;X0&quot; target &quot;y&quot;] edge[ source &quot;X1&quot; target &quot;y&quot;] edge[ source &quot;X2&quot; target &quot;y&quot;] edge[ source &quot;X3&quot; target &quot;y&quot;] edge[ source &quot;X4&quot; target &quot;y&quot;]node[ id &quot;Z0&quot; label &quot;Z0&quot;] edge[ source &quot;Z0&quot; target &quot;v&quot;] node[ id &quot;Z1&quot; label &quot;Z1&quot;] edge[ source &quot;Z1&quot; target &quot;v&quot;]]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># We now input a causal graph in the GML graph format (recommended). </span>
<span class="c1"># You can also use the DOT format.</span>
<span class="c1"># We are not going to change the format</span>
<span class="c1"># You only need the graph when you don&#39;t specify the common causes and instruments</span>
<span class="c1"># If you don&#39;t add the graph not common causes or instruments, it&#39;ll be ignored as such</span>
<span class="c1"># With graph</span>

<span class="n">model</span><span class="o">=</span><span class="n">CausalModel</span><span class="p">(</span>
        <span class="n">data</span> <span class="o">=</span> <span class="n">df</span><span class="p">,</span>
        <span class="n">treatment</span><span class="o">=</span><span class="n">data</span><span class="p">[</span><span class="s2">&quot;treatment_name&quot;</span><span class="p">],</span>
        <span class="n">outcome</span><span class="o">=</span><span class="n">data</span><span class="p">[</span><span class="s2">&quot;outcome_name&quot;</span><span class="p">],</span>
        <span class="n">graph</span><span class="o">=</span><span class="n">data</span><span class="p">[</span><span class="s2">&quot;gml_graph&quot;</span><span class="p">],</span>
        <span class="n">instruments</span><span class="o">=</span><span class="n">data</span><span class="p">[</span><span class="s2">&quot;instrument_names&quot;</span><span class="p">],</span>
        <span class="n">logging_level</span> <span class="o">=</span> <span class="n">logging</span><span class="o">.</span><span class="n">INFO</span>
        <span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>INFO:dowhy.do_why:Model to find the causal effect of treatment [&#39;v&#39;] on outcome [&#39;y&#39;]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">view_model</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>WARNING:dowhy.causal_graph:Warning: Pygraphviz cannot be loaded. Check that graphviz and pygraphviz are installed.
INFO:dowhy.causal_graph:Using Matplotlib for plotting
</pre></div>
</div>
<img alt="../_images/T990000_causal_inference_40_1.png" src="../_images/T990000_causal_inference_40_1.png" />
</div>
</div>
<p>The above causal graph shows the assumptions encoded in the causal model. We can now use this graph to first identify the causal effect (go from a causal estimand to a probability expression), and then estimate the causal effect.</p>
<p>DoWhy philosophy: Keep identification and estimation separate</p>
<p>Identification can be achieved without access to the data, acccesing only the graph. This results in an expression to be computed. This expression can then be evaluated using the available data in the estimation step. It is important to understand that these are orthogonal steps.</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>Identification
</pre></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1">#identified_estimand = model.identify_effect()</span>
<span class="n">identified_estimand</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">identify_effect</span><span class="p">(</span><span class="n">proceed_when_unidentifiable</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">identified_estimand</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>INFO:dowhy.causal_identifier:Common causes of treatment and outcome:[&#39;X1&#39;, &#39;X3&#39;, &#39;Unobserved Confounders&#39;, &#39;X0&#39;, &#39;X2&#39;, &#39;X4&#39;]
WARNING:dowhy.causal_identifier:There are unobserved common causes. Causal effect cannot be identified.
INFO:dowhy.causal_identifier:Continuing by ignoring these unobserved confounders because proceed_when_unidentifiable flag is True.
INFO:dowhy.causal_identifier:Instrumental variables for treatment and outcome:[&#39;Z0&#39;, &#39;Z1&#39;]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Estimand type: ate
### Estimand : 1
Estimand name: backdoor
Estimand expression:
d                                
──(Expectation(y|X1,X3,X0,X2,X4))
dv                               
Estimand assumption 1, Unconfoundedness: If U→v and U→y then P(y|v,X1,X3,X0,X2,X4,U) = P(y|v,X1,X3,X0,X2,X4)
### Estimand : 2
Estimand name: iv
Estimand expression:
Expectation(Derivative(y, Z0)/Derivative(v, Z0))
Estimand assumption 1, As-if-random: If U→→y then ¬(U →→Z0,Z1)
Estimand assumption 2, Exclusion: If we remove {Z0,Z1}→v, then ¬(Z0,Z1→y)
</pre></div>
</div>
</div>
</div>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>Estimation
</pre></div>
</div>
<div class="section" id="regression">
<h3>Regression<a class="headerlink" href="#regression" title="Permalink to this headline">¶</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">causal_estimate_reg</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">estimate_effect</span><span class="p">(</span><span class="n">identified_estimand</span><span class="p">,</span>
        <span class="n">method_name</span><span class="o">=</span><span class="s2">&quot;backdoor.linear_regression&quot;</span><span class="p">,</span>
        <span class="n">test_significance</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">causal_estimate_reg</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Causal Estimate is &quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">causal_estimate_reg</span><span class="o">.</span><span class="n">value</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>INFO:dowhy.causal_estimator:INFO: Using Linear Regression Estimator
INFO:dowhy.causal_estimator:b: y~v+X1+X3+X0+X2+X4
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>*** Causal Estimate ***

## Target estimand
Estimand type: ate
### Estimand : 1
Estimand name: backdoor
Estimand expression:
d                                
──(Expectation(y|X1,X3,X0,X2,X4))
dv                               
Estimand assumption 1, Unconfoundedness: If U→v and U→y then P(y|v,X1,X3,X0,X2,X4,U) = P(y|v,X1,X3,X0,X2,X4)
### Estimand : 2
Estimand name: iv
Estimand expression:
Expectation(Derivative(y, Z0)/Derivative(v, Z0))
Estimand assumption 1, As-if-random: If U→→y then ¬(U →→Z0,Z1)
Estimand assumption 2, Exclusion: If we remove {Z0,Z1}→v, then ¬(Z0,Z1→y)

## Realized estimand
b: y~v+X1+X3+X0+X2+X4
## Estimate
Value: 10.00000000000001

## Statistical Significance
p-value: &lt;0.001

Causal Estimate is 10.00000000000001
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="id1">
<h3>Stratification<a class="headerlink" href="#id1" title="Permalink to this headline">¶</a></h3>
<p>We will be using propensity scores to stratify units in the data.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">causal_estimate_strat</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">estimate_effect</span><span class="p">(</span><span class="n">identified_estimand</span><span class="p">,</span>
        <span class="n">method_name</span><span class="o">=</span><span class="s2">&quot;backdoor.propensity_score_stratification&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">causal_estimate_strat</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Causal Estimate is &quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">causal_estimate_strat</span><span class="o">.</span><span class="n">value</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>INFO:dowhy.causal_estimator:INFO: Using Propensity Score Stratification Estimator
INFO:dowhy.causal_estimator:b: y~v+X1+X3+X0+X2+X4
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>*** Causal Estimate ***

## Target estimand
Estimand type: ate
### Estimand : 1
Estimand name: backdoor
Estimand expression:
d                                
──(Expectation(y|X1,X3,X0,X2,X4))
dv                               
Estimand assumption 1, Unconfoundedness: If U→v and U→y then P(y|v,X1,X3,X0,X2,X4,U) = P(y|v,X1,X3,X0,X2,X4)
### Estimand : 2
Estimand name: iv
Estimand expression:
Expectation(Derivative(y, Z0)/Derivative(v, Z0))
Estimand assumption 1, As-if-random: If U→→y then ¬(U →→Z0,Z1)
Estimand assumption 2, Exclusion: If we remove {Z0,Z1}→v, then ¬(Z0,Z1→y)

## Realized estimand
b: y~v+X1+X3+X0+X2+X4
## Estimate
Value: 9.946431839515096

Causal Estimate is 9.946431839515096
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to &#39;lbfgs&#39; in 0.22. Specify a solver to silence this warning.
  FutureWarning)
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="matching">
<h3>Matching<a class="headerlink" href="#matching" title="Permalink to this headline">¶</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">causal_estimate_match</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">estimate_effect</span><span class="p">(</span><span class="n">identified_estimand</span><span class="p">,</span>
        <span class="n">method_name</span><span class="o">=</span><span class="s2">&quot;backdoor.propensity_score_matching&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">causal_estimate_match</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Causal Estimate is &quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">causal_estimate_match</span><span class="o">.</span><span class="n">value</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>INFO:dowhy.causal_estimator:INFO: Using Propensity Score Matching Estimator
INFO:dowhy.causal_estimator:b: y~v+X1+X3+X0+X2+X4
/usr/local/lib/python3.6/dist-packages/dowhy/causal_estimators/propensity_score_matching_estimator.py:51: FutureWarning: `item` has been deprecated and will be removed in a future version
  control_outcome = control.iloc[indices[i]][self._outcome_name].item()
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>*** Causal Estimate ***

## Target estimand
Estimand type: ate
### Estimand : 1
Estimand name: backdoor
Estimand expression:
d                                
──(Expectation(y|X1,X3,X0,X2,X4))
dv                               
Estimand assumption 1, Unconfoundedness: If U→v and U→y then P(y|v,X1,X3,X0,X2,X4,U) = P(y|v,X1,X3,X0,X2,X4)
### Estimand : 2
Estimand name: iv
Estimand expression:
Expectation(Derivative(y, Z0)/Derivative(v, Z0))
Estimand assumption 1, As-if-random: If U→→y then ¬(U →→Z0,Z1)
Estimand assumption 2, Exclusion: If we remove {Z0,Z1}→v, then ¬(Z0,Z1→y)

## Realized estimand
b: y~v+X1+X3+X0+X2+X4
## Estimate
Value: 11.813653143950052

Causal Estimate is 11.813653143950052
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="id2">
<h3>Weighting<a class="headerlink" href="#id2" title="Permalink to this headline">¶</a></h3>
<p>We will be using (inverse) propensity scores to assign weights to units in the data. DoWhy supports a few different weighting schemes:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>Vanilla Inverse Propensity Score weighting (IPS)
Self-normalized IPS weighting (also known as the Hajek estimator)
Stabilized IPS weighting
</pre></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">causal_estimate_ipw</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">estimate_effect</span><span class="p">(</span><span class="n">identified_estimand</span><span class="p">,</span>
        <span class="n">method_name</span><span class="o">=</span><span class="s2">&quot;backdoor.propensity_score_weighting&quot;</span><span class="p">,</span> <span class="n">method_params</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;weighting_scheme&quot;</span><span class="p">:</span><span class="s2">&quot;ips_weight&quot;</span><span class="p">})</span>
<span class="nb">print</span><span class="p">(</span><span class="n">causal_estimate_ipw</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Causal Estimate is &quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">causal_estimate_ipw</span><span class="o">.</span><span class="n">value</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>INFO:dowhy.causal_estimator:INFO: Using Propensity Score Weighting Estimator
INFO:dowhy.causal_estimator:b: y~v+X1+X3+X0+X2+X4
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>*** Causal Estimate ***

## Target estimand
Estimand type: ate
### Estimand : 1
Estimand name: backdoor
Estimand expression:
d                                
──(Expectation(y|X1,X3,X0,X2,X4))
dv                               
Estimand assumption 1, Unconfoundedness: If U→v and U→y then P(y|v,X1,X3,X0,X2,X4,U) = P(y|v,X1,X3,X0,X2,X4)
### Estimand : 2
Estimand name: iv
Estimand expression:
Expectation(Derivative(y, Z0)/Derivative(v, Z0))
Estimand assumption 1, As-if-random: If U→→y then ¬(U →→Z0,Z1)
Estimand assumption 2, Exclusion: If we remove {Z0,Z1}→v, then ¬(Z0,Z1→y)

## Realized estimand
b: y~v+X1+X3+X0+X2+X4
## Estimate
Value: 14.327456158855973

Causal Estimate is 14.327456158855973
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to &#39;lbfgs&#39; in 0.22. Specify a solver to silence this warning.
  FutureWarning)
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="instrumental-variable">
<h3>Instrumental Variable<a class="headerlink" href="#instrumental-variable" title="Permalink to this headline">¶</a></h3>
<p>We will be using the Wald estimator for the provided instrumental variable.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">causal_estimate_iv</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">estimate_effect</span><span class="p">(</span><span class="n">identified_estimand</span><span class="p">,</span>
        <span class="n">method_name</span><span class="o">=</span><span class="s2">&quot;iv.instrumental_variable&quot;</span><span class="p">,</span> <span class="n">method_params</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;iv_instrument_name&#39;</span><span class="p">:</span><span class="s1">&#39;Z0&#39;</span><span class="p">})</span>
<span class="nb">print</span><span class="p">(</span><span class="n">causal_estimate_iv</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Causal Estimate is &quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">causal_estimate_iv</span><span class="o">.</span><span class="n">value</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>INFO:dowhy.causal_estimator:INFO: Using Instrumental Variable Estimator
INFO:dowhy.causal_estimator:Realized estimand: Wald Estimator
Realized estimand type: ate
Estimand expression:
                                                             -1
Expectation(Derivative(y, Z0))⋅Expectation(Derivative(v, Z0))  
Estimand assumption 1, As-if-random: If U→→y then ¬(U →→Z0,Z1)
Estimand assumption 2, Exclusion: If we remove {Z0,Z1}→v, then ¬(Z0,Z1→y)
Estimand assumption 3, treatment_effect_homogeneity: Each unit&#39;s treatment v isaffected in the same way by common causes of v and y
Estimand assumption 4, outcome_effect_homogeneity: Each unit&#39;s outcome y isaffected in the same way by common causes of v and y
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>*** Causal Estimate ***

## Target estimand
Estimand type: ate
### Estimand : 1
Estimand name: backdoor
Estimand expression:
d                                
──(Expectation(y|X1,X3,X0,X2,X4))
dv                               
Estimand assumption 1, Unconfoundedness: If U→v and U→y then P(y|v,X1,X3,X0,X2,X4,U) = P(y|v,X1,X3,X0,X2,X4)
### Estimand : 2
Estimand name: iv
Estimand expression:
Expectation(Derivative(y, Z0)/Derivative(v, Z0))
Estimand assumption 1, As-if-random: If U→→y then ¬(U →→Z0,Z1)
Estimand assumption 2, Exclusion: If we remove {Z0,Z1}→v, then ¬(Z0,Z1→y)

## Realized estimand
Realized estimand: Wald Estimator
Realized estimand type: ate
Estimand expression:
                                                             -1
Expectation(Derivative(y, Z0))⋅Expectation(Derivative(v, Z0))  
Estimand assumption 1, As-if-random: If U→→y then ¬(U →→Z0,Z1)
Estimand assumption 2, Exclusion: If we remove {Z0,Z1}→v, then ¬(Z0,Z1→y)
Estimand assumption 3, treatment_effect_homogeneity: Each unit&#39;s treatment v isaffected in the same way by common causes of v and y
Estimand assumption 4, outcome_effect_homogeneity: Each unit&#39;s outcome y isaffected in the same way by common causes of v and y

## Estimate
Value: 11.656398956650099

Causal Estimate is 11.656398956650099
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="regression-discontinuity">
<h3>Regression Discontinuity<a class="headerlink" href="#regression-discontinuity" title="Permalink to this headline">¶</a></h3>
<p>We will be internally converting this to an equivalent instrumental variables problem.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">causal_estimate_regdist</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">estimate_effect</span><span class="p">(</span><span class="n">identified_estimand</span><span class="p">,</span>
        <span class="n">method_name</span><span class="o">=</span><span class="s2">&quot;iv.regression_discontinuity&quot;</span><span class="p">,</span> 
        <span class="n">method_params</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;rd_variable_name&#39;</span><span class="p">:</span><span class="s1">&#39;Z1&#39;</span><span class="p">,</span>
                       <span class="s1">&#39;rd_threshold_value&#39;</span><span class="p">:</span><span class="mf">0.5</span><span class="p">,</span>
                       <span class="s1">&#39;rd_bandwidth&#39;</span><span class="p">:</span> <span class="mf">0.1</span><span class="p">})</span>
<span class="nb">print</span><span class="p">(</span><span class="n">causal_estimate_regdist</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Causal Estimate is &quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">causal_estimate_regdist</span><span class="o">.</span><span class="n">value</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>INFO:dowhy.causal_estimator:Using Regression Discontinuity Estimator
INFO:dowhy.causal_estimator:
INFO:dowhy.causal_estimator:INFO: Using Instrumental Variable Estimator
INFO:dowhy.causal_estimator:Realized estimand: Wald Estimator
Realized estimand type: ate
Estimand expression:
                                                             -1
Expectation(Derivative(y, Z0))⋅Expectation(Derivative(v, Z0))  
Estimand assumption 1, As-if-random: If U→→y then ¬(U →→Z0,Z1)
Estimand assumption 2, Exclusion: If we remove {Z0,Z1}→v, then ¬(Z0,Z1→y)
Estimand assumption 3, treatment_effect_homogeneity: Each unit&#39;s treatment local_treatment isaffected in the same way by common causes of local_treatment and local_outcome
Estimand assumption 4, outcome_effect_homogeneity: Each unit&#39;s outcome local_outcome isaffected in the same way by common causes of local_treatment and local_outcome
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>*** Causal Estimate ***

## Target estimand
Estimand type: ate
### Estimand : 1
Estimand name: backdoor
Estimand expression:
d                                
──(Expectation(y|X1,X3,X0,X2,X4))
dv                               
Estimand assumption 1, Unconfoundedness: If U→v and U→y then P(y|v,X1,X3,X0,X2,X4,U) = P(y|v,X1,X3,X0,X2,X4)
### Estimand : 2
Estimand name: iv
Estimand expression:
Expectation(Derivative(y, Z0)/Derivative(v, Z0))
Estimand assumption 1, As-if-random: If U→→y then ¬(U →→Z0,Z1)
Estimand assumption 2, Exclusion: If we remove {Z0,Z1}→v, then ¬(Z0,Z1→y)

## Realized estimand
Realized estimand: Wald Estimator
Realized estimand type: ate
Estimand expression:
                                                             -1
Expectation(Derivative(y, Z0))⋅Expectation(Derivative(v, Z0))  
Estimand assumption 1, As-if-random: If U→→y then ¬(U →→Z0,Z1)
Estimand assumption 2, Exclusion: If we remove {Z0,Z1}→v, then ¬(Z0,Z1→y)
Estimand assumption 3, treatment_effect_homogeneity: Each unit&#39;s treatment local_treatment isaffected in the same way by common causes of local_treatment and local_outcome
Estimand assumption 4, outcome_effect_homogeneity: Each unit&#39;s outcome local_outcome isaffected in the same way by common causes of local_treatment and local_outcome

## Estimate
Value: -0.7623223405070391

Causal Estimate is -0.7623223405070391
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1">## Now without the graph, and instead common causes</span>
<span class="c1">## The point here is to ignore the entire graph, except for commone causes (ie. no instrument)</span>
<span class="c1">## Confounds are always assumed regardless </span>

<span class="c1"># Without graph                                       </span>
<span class="n">model</span><span class="o">=</span> <span class="n">CausalModel</span><span class="p">(</span>                             
        <span class="n">data</span><span class="o">=</span><span class="n">df</span><span class="p">,</span>                                      
        <span class="n">treatment</span><span class="o">=</span><span class="n">data</span><span class="p">[</span><span class="s2">&quot;treatment_name&quot;</span><span class="p">],</span>             
        <span class="n">outcome</span><span class="o">=</span><span class="n">data</span><span class="p">[</span><span class="s2">&quot;outcome_name&quot;</span><span class="p">],</span>                 
        <span class="n">common_causes</span><span class="o">=</span><span class="n">data</span><span class="p">[</span><span class="s2">&quot;common_causes_names&quot;</span><span class="p">])</span>  

<span class="n">model</span><span class="o">.</span><span class="n">view_model</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>WARNING:dowhy.do_why:Causal Graph not provided. DoWhy will construct a graph based on data inputs.
INFO:dowhy.do_why:Model to find the causal effect of treatment [&#39;v&#39;] on outcome [&#39;y&#39;]
WARNING:dowhy.causal_graph:Warning: Pygraphviz cannot be loaded. Check that graphviz and pygraphviz are installed.
INFO:dowhy.causal_graph:Using Matplotlib for plotting
</pre></div>
</div>
<img alt="../_images/T990000_causal_inference_56_1.png" src="../_images/T990000_causal_inference_56_1.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1">## We get the same causal graph. Now identification and estimation is done as before.</span>
<span class="n">identified_estimand</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">identify_effect</span><span class="p">(</span><span class="n">proceed_when_unidentifiable</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="n">estimate</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">estimate_effect</span><span class="p">(</span><span class="n">identified_estimand</span><span class="p">,</span>
                                 <span class="n">method_name</span><span class="o">=</span><span class="s2">&quot;backdoor.propensity_score_stratification&quot;</span><span class="p">)</span>         
<span class="nb">print</span><span class="p">(</span><span class="n">estimate</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Causal Estimate is &quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">estimate</span><span class="o">.</span><span class="n">value</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>INFO:dowhy.causal_identifier:Common causes of treatment and outcome:[&#39;X1&#39;, &#39;X3&#39;, &#39;X0&#39;, &#39;X2&#39;, &#39;X4&#39;, &#39;U&#39;]
WARNING:dowhy.causal_identifier:There are unobserved common causes. Causal effect cannot be identified.
INFO:dowhy.causal_identifier:Continuing by ignoring these unobserved confounders because proceed_when_unidentifiable flag is True.
INFO:dowhy.causal_identifier:Instrumental variables for treatment and outcome:[]
INFO:dowhy.causal_estimator:INFO: Using Propensity Score Stratification Estimator
INFO:dowhy.causal_estimator:b: y~v+X1+X3+X0+X2+X4
/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to &#39;lbfgs&#39; in 0.22. Specify a solver to silence this warning.
  FutureWarning)
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>*** Causal Estimate ***

## Target estimand
Estimand type: ate
### Estimand : 1
Estimand name: backdoor
Estimand expression:
d                                
──(Expectation(y|X1,X3,X0,X2,X4))
dv                               
Estimand assumption 1, Unconfoundedness: If U→v and U→y then P(y|v,X1,X3,X0,X2,X4,U) = P(y|v,X1,X3,X0,X2,X4)
### Estimand : 2
Estimand name: iv
No such variable found!

## Realized estimand
b: y~v+X1+X3+X0+X2+X4
## Estimate
Value: 9.946431839515096

Causal Estimate is 9.946431839515096
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="section" id="now-refuting">
<h2>Now Refuting<a class="headerlink" href="#now-refuting" title="Permalink to this headline">¶</a></h2>
<p>Let us now look at ways of refuting the estimate obtained.</p>
<p>Adding a random common cause variable</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">res_random</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">refute_estimate</span><span class="p">(</span><span class="n">identified_estimand</span><span class="p">,</span> <span class="n">estimate</span><span class="p">,</span> <span class="n">method_name</span><span class="o">=</span><span class="s2">&quot;random_common_cause&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">res_random</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>INFO:dowhy.causal_estimator:INFO: Using Propensity Score Stratification Estimator
INFO:dowhy.causal_estimator:b: y~v+X1+X3+X0+X2+X4+w_random
/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to &#39;lbfgs&#39; in 0.22. Specify a solver to silence this warning.
  FutureWarning)
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Refute: Add a Random Common Cause
Estimated effect:(9.946431839515096,)
New effect:(9.960595760592396,)
</pre></div>
</div>
</div>
</div>
<p>Adding an unobserved common cause variable</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">res_unobserved</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">refute_estimate</span><span class="p">(</span><span class="n">identified_estimand</span><span class="p">,</span> <span class="n">estimate</span><span class="p">,</span> <span class="n">method_name</span><span class="o">=</span><span class="s2">&quot;add_unobserved_common_cause&quot;</span><span class="p">,</span>
                                     <span class="n">confounders_effect_on_treatment</span><span class="o">=</span><span class="s2">&quot;binary_flip&quot;</span><span class="p">,</span> <span class="n">confounders_effect_on_outcome</span><span class="o">=</span><span class="s2">&quot;linear&quot;</span><span class="p">,</span>
                                    <span class="n">effect_strength_on_treatment</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span> <span class="n">effect_strength_on_outcome</span><span class="o">=</span><span class="mf">0.02</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">res_unobserved</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Replacing treatment with a random (placebo) variable</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">res_placebo</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">refute_estimate</span><span class="p">(</span><span class="n">identified_estimand</span><span class="p">,</span> <span class="n">estimate</span><span class="p">,</span>
        <span class="n">method_name</span><span class="o">=</span><span class="s2">&quot;placebo_treatment_refuter&quot;</span><span class="p">,</span> <span class="n">placebo_type</span><span class="o">=</span><span class="s2">&quot;permute&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">res_placebo</span><span class="p">)</span>
<span class="c1">## We want the effect close to zero</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>INFO:dowhy.causal_estimator:INFO: Using Propensity Score Stratification Estimator
INFO:dowhy.causal_estimator:b: y~placebo+X1+X3+X0+X2+X4
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Refute: Use a Placebo Treatment
Estimated effect:(9.946431839515096,)
New effect:(0.019121484649084346,)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to &#39;lbfgs&#39; in 0.22. Specify a solver to silence this warning.
  FutureWarning)
</pre></div>
</div>
</div>
</div>
<p>Removing a random subset of the data</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">res_subset</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">refute_estimate</span><span class="p">(</span><span class="n">identified_estimand</span><span class="p">,</span> <span class="n">estimate</span><span class="p">,</span>
        <span class="n">method_name</span><span class="o">=</span><span class="s2">&quot;data_subset_refuter&quot;</span><span class="p">,</span> <span class="n">subset_fraction</span><span class="o">=</span><span class="mf">0.9</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">res_subset</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>INFO:dowhy.causal_estimator:INFO: Using Propensity Score Stratification Estimator
INFO:dowhy.causal_estimator:b: y~v+X1+X3+X0+X2+X4
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Refute: Use a subset of data
Estimated effect:(9.946431839515096,)
New effect:(9.886889613668945,)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to &#39;lbfgs&#39; in 0.22. Specify a solver to silence this warning.
  FutureWarning)
</pre></div>
</div>
</div>
</div>
<p>As you can see, the propensity score stratification estimator is reasonably robust to refutations. For reproducibility, you can add a parameter “random_seed” to any refutation method, as shown below.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">res_subset</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">refute_estimate</span><span class="p">(</span><span class="n">identified_estimand</span><span class="p">,</span> <span class="n">estimate</span><span class="p">,</span>
        <span class="n">method_name</span><span class="o">=</span><span class="s2">&quot;data_subset_refuter&quot;</span><span class="p">,</span> <span class="n">subset_fraction</span><span class="o">=</span><span class="mf">0.9</span><span class="p">,</span> <span class="n">random_seed</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">res_subset</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>INFO:dowhy.causal_estimator:INFO: Using Propensity Score Stratification Estimator
INFO:dowhy.causal_estimator:b: y~v+X1+X3+X0+X2+X4
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Refute: Use a subset of data
Estimated effect:(9.946431839515096,)
New effect:(10.059557168227766,)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to &#39;lbfgs&#39; in 0.22. Specify a solver to silence this warning.
  FutureWarning)
</pre></div>
</div>
</div>
</div>
<div class="section" id="instrumental-variable-application">
<h3>Instrumental Variable Application<a class="headerlink" href="#instrumental-variable-application" title="Permalink to this headline">¶</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">patsy</span> <span class="k">as</span> <span class="nn">ps</span> <span class="c1"># describing statistical models </span>

<span class="kn">from</span> <span class="nn">statsmodels.sandbox.regression.gmm</span> <span class="kn">import</span> <span class="n">IV2SLS</span>
<span class="kn">import</span> <span class="nn">os</span><span class="o">,</span> <span class="nn">sys</span>
<span class="n">sys</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">abspath</span><span class="p">(</span><span class="s2">&quot;../../../&quot;</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">n_points</span> <span class="o">=</span> <span class="mi">1000</span>
<span class="n">education_abilty</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">education_voucher</span> <span class="o">=</span> <span class="mf">0.5</span>
<span class="n">income_abilty</span> <span class="o">=</span> <span class="mi">2</span>
<span class="n">income_education</span> <span class="o">=</span> <span class="mi">4</span>


<span class="c1"># confounder</span>
<span class="n">ability</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">n_points</span><span class="p">)</span>

<span class="c1"># instrument</span>
<span class="n">voucher</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">n_points</span><span class="p">)</span> 

<span class="c1"># treatment</span>
<span class="n">education</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">n_points</span><span class="p">)</span> <span class="o">+</span> <span class="n">education_abilty</span> <span class="o">*</span> <span class="n">ability</span> <span class="o">+</span>\
            <span class="n">education_voucher</span> <span class="o">*</span> <span class="n">voucher</span>

<span class="c1"># outcome</span>
<span class="n">income</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">n_points</span><span class="p">)</span> <span class="o">+</span>\
         <span class="n">income_abilty</span> <span class="o">*</span> <span class="n">ability</span> <span class="o">+</span> <span class="n">income_education</span> <span class="o">*</span> <span class="n">education</span>

<span class="c1"># build dataset</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span><span class="n">ability</span><span class="p">,</span> <span class="n">education</span><span class="p">,</span> <span class="n">income</span><span class="p">,</span> <span class="n">voucher</span><span class="p">])</span><span class="o">.</span><span class="n">T</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">columns</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;ability&#39;</span><span class="p">,</span> <span class="s1">&#39;education&#39;</span><span class="p">,</span> <span class="s1">&#39;income&#39;</span><span class="p">,</span> <span class="s1">&#39;voucher&#39;</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>ability</th>
      <th>education</th>
      <th>income</th>
      <th>voucher</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>2.530185</td>
      <td>9.425180</td>
      <td>54.891295</td>
      <td>1.188695</td>
    </tr>
    <tr>
      <th>1</th>
      <td>-1.677691</td>
      <td>2.355344</td>
      <td>11.912406</td>
      <td>1.339673</td>
    </tr>
    <tr>
      <th>2</th>
      <td>-2.680661</td>
      <td>0.731042</td>
      <td>5.140462</td>
      <td>0.447118</td>
    </tr>
    <tr>
      <th>3</th>
      <td>3.510673</td>
      <td>8.788867</td>
      <td>51.939000</td>
      <td>2.403189</td>
    </tr>
    <tr>
      <th>4</th>
      <td>2.269907</td>
      <td>6.725102</td>
      <td>40.847582</td>
      <td>0.838029</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">income_vec</span><span class="p">,</span> <span class="n">endog</span> <span class="o">=</span> <span class="n">ps</span><span class="o">.</span><span class="n">dmatrices</span><span class="p">(</span><span class="s2">&quot;income ~ education&quot;</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">df</span><span class="p">)</span>
<span class="n">exog</span> <span class="o">=</span> <span class="n">ps</span><span class="o">.</span><span class="n">dmatrix</span><span class="p">(</span><span class="s2">&quot;voucher&quot;</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">df</span><span class="p">)</span> <span class="c1"># creates intercept</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;income&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">income_vec</span><span class="p">[:</span><span class="mi">5</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;endog&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">endog</span><span class="p">[:</span><span class="mi">5</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;exog&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">exog</span><span class="p">[:</span><span class="mi">5</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>income
[[54.89129549]
 [11.91240627]
 [ 5.14046152]
 [51.93900016]
 [40.84758241]]
endog
[[1.         9.42518024]
 [1.         2.3553439 ]
 [1.         0.73104227]
 [1.         8.78886679]
 [1.         6.72510169]]
exog
[[1.         1.1886947 ]
 [1.         1.3396729 ]
 [1.         0.44711844]
 [1.         2.40318908]
 [1.         0.8380294 ]]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># outcome, treatment, instrument</span>
<span class="n">m</span> <span class="o">=</span> <span class="n">IV2SLS</span><span class="p">(</span><span class="n">income_vec</span><span class="p">,</span> <span class="n">endog</span><span class="p">,</span> <span class="n">exog</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
<span class="n">m</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><table class="simpletable">
<caption>IV2SLS Regression Results</caption>
<tr>
  <th>Dep. Variable:</th>         <td>income</td>      <th>  R-squared:         </th> <td>   0.896</td>
</tr>
<tr>
  <th>Model:</th>                 <td>IV2SLS</td>      <th>  Adj. R-squared:    </th> <td>   0.896</td>
</tr>
<tr>
  <th>Method:</th>               <td>Two Stage</td>    <th>  F-statistic:       </th> <td>   207.2</td>
</tr>
<tr>
  <th></th>                    <td>Least Squares</td>  <th>  Prob (F-statistic):</th> <td>8.07e-43</td>
</tr>
<tr>
  <th>Date:</th>             <td>Tue, 03 Dec 2019</td> <th>                     </th>     <td> </td>   
</tr>
<tr>
  <th>Time:</th>                 <td>04:01:35</td>     <th>                     </th>     <td> </td>   
</tr>
<tr>
  <th>No. Observations:</th>      <td>  1000</td>      <th>                     </th>     <td> </td>   
</tr>
<tr>
  <th>Df Residuals:</th>          <td>   998</td>      <th>                     </th>     <td> </td>   
</tr>
<tr>
  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>     <td> </td>   
</tr>
</table>
<table class="simpletable">
<tr>
      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  
</tr>
<tr>
  <th>Intercept</th> <td>    8.0329</td> <td>    1.814</td> <td>    4.429</td> <td> 0.000</td> <td>    4.474</td> <td>   11.592</td>
</tr>
<tr>
  <th>education</th> <td>    4.3111</td> <td>    0.300</td> <td>   14.393</td> <td> 0.000</td> <td>    3.723</td> <td>    4.899</td>
</tr>
</table>
<table class="simpletable">
<tr>
  <th>Omnibus:</th>       <td> 0.027</td> <th>  Durbin-Watson:     </th> <td>   2.010</td>
</tr>
<tr>
  <th>Prob(Omnibus):</th> <td> 0.987</td> <th>  Jarque-Bera (JB):  </th> <td>   0.021</td>
</tr>
<tr>
  <th>Skew:</th>          <td>-0.011</td> <th>  Prob(JB):          </th> <td>   0.989</td>
</tr>
<tr>
  <th>Kurtosis:</th>      <td> 2.995</td> <th>  Cond. No.          </th> <td>    15.1</td>
</tr>
</table></div></div>
</div>
<p>Now using dowhy</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">=</span><span class="n">CausalModel</span><span class="p">(</span>
        <span class="n">data</span> <span class="o">=</span> <span class="n">df</span><span class="p">,</span>
        <span class="n">treatment</span><span class="o">=</span><span class="s1">&#39;education&#39;</span><span class="p">,</span>
        <span class="n">outcome</span><span class="o">=</span><span class="s1">&#39;income&#39;</span><span class="p">,</span>
        <span class="n">common_causes</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;ability&#39;</span><span class="p">],</span>
        <span class="n">instruments</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;voucher&#39;</span><span class="p">]</span>
        <span class="p">)</span>

<span class="n">identified_estimand</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">identify_effect</span><span class="p">()</span>

<span class="n">estimate</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">estimate_effect</span><span class="p">(</span><span class="n">identified_estimand</span><span class="p">,</span>
        <span class="n">method_name</span><span class="o">=</span><span class="s2">&quot;iv.instrumental_variable&quot;</span><span class="p">,</span> <span class="n">test_significance</span><span class="o">=</span><span class="kc">True</span>
<span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">estimate</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>WARNING:dowhy.do_why:Causal Graph not provided. DoWhy will construct a graph based on data inputs.
INFO:dowhy.do_why:Model to find the causal effect of treatment [&#39;education&#39;] on outcome [&#39;income&#39;]
INFO:dowhy.causal_identifier:Common causes of treatment and outcome:[&#39;ability&#39;, &#39;U&#39;]
WARNING:dowhy.causal_identifier:There are unobserved common causes. Causal effect cannot be identified.
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>WARN: Do you want to continue by ignoring these unobserved confounders? [y/n] y
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>INFO:dowhy.causal_identifier:Instrumental variables for treatment and outcome:[&#39;voucher&#39;]
INFO:dowhy.causal_estimator:INFO: Using Instrumental Variable Estimator
INFO:dowhy.causal_estimator:Realized estimand: Wald Estimator
Realized estimand type: ate
Estimand expression:
                                                                              
Expectation(Derivative(income, voucher))⋅Expectation(Derivative(education, vou

      -1
cher))  
Estimand assumption 1, As-if-random: If U→→income then ¬(U →→voucher)
Estimand assumption 2, Exclusion: If we remove {voucher}→education, then ¬(voucher→income)
Estimand assumption 3, treatment_effect_homogeneity: Each unit&#39;s treatment education isaffected in the same way by common causes of education and income
Estimand assumption 4, outcome_effect_homogeneity: Each unit&#39;s outcome income isaffected in the same way by common causes of education and income
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>*** Causal Estimate ***

## Target estimand
Estimand type: ate
### Estimand : 1
Estimand name: backdoor
Estimand expression:
    d                                  
──────────(Expectation(income|ability))
deducation                             
Estimand assumption 1, Unconfoundedness: If U→education and U→income then P(income|education,ability,U) = P(income|education,ability)
### Estimand : 2
Estimand name: iv
Estimand expression:
Expectation(Derivative(income, voucher)/Derivative(education, voucher))
Estimand assumption 1, As-if-random: If U→→income then ¬(U →→voucher)
Estimand assumption 2, Exclusion: If we remove {voucher}→education, then ¬(voucher→income)

## Realized estimand
Realized estimand: Wald Estimator
Realized estimand type: ate
Estimand expression:
                                                                              
Expectation(Derivative(income, voucher))⋅Expectation(Derivative(education, vou

      -1
cher))  
Estimand assumption 1, As-if-random: If U→→income then ¬(U →→voucher)
Estimand assumption 2, Exclusion: If we remove {voucher}→education, then ¬(voucher→income)
Estimand assumption 3, treatment_effect_homogeneity: Each unit&#39;s treatment education isaffected in the same way by common causes of education and income
Estimand assumption 4, outcome_effect_homogeneity: Each unit&#39;s outcome income isaffected in the same way by common causes of education and income

## Estimate
Value: 5.577575917315314

## Statistical Significance
p-value: &lt;0.001
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="different-way-to-create-graphs">
<h3>Different way to create graphs<a class="headerlink" href="#different-way-to-create-graphs" title="Permalink to this headline">¶</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">random</span>
<span class="n">z</span><span class="o">=</span><span class="p">[</span><span class="n">i</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">10</span><span class="p">)]</span>
<span class="n">random</span><span class="o">.</span><span class="n">shuffle</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">data</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;K&#39;</span><span class="p">:</span> <span class="n">z</span><span class="p">,</span> <span class="s1">&#39;X&#39;</span><span class="p">:</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">10</span><span class="p">),</span> <span class="s1">&#39;Y&#39;</span><span class="p">:</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">100</span><span class="p">,</span><span class="mi">10</span><span class="p">)})</span>
<span class="n">df</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>K</th>
      <th>X</th>
      <th>Y</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>6</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>8</td>
      <td>1</td>
      <td>10</td>
    </tr>
    <tr>
      <th>2</th>
      <td>3</td>
      <td>2</td>
      <td>20</td>
    </tr>
    <tr>
      <th>3</th>
      <td>1</td>
      <td>3</td>
      <td>30</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0</td>
      <td>4</td>
      <td>40</td>
    </tr>
    <tr>
      <th>5</th>
      <td>9</td>
      <td>5</td>
      <td>50</td>
    </tr>
    <tr>
      <th>6</th>
      <td>5</td>
      <td>6</td>
      <td>60</td>
    </tr>
    <tr>
      <th>7</th>
      <td>2</td>
      <td>7</td>
      <td>70</td>
    </tr>
    <tr>
      <th>8</th>
      <td>7</td>
      <td>8</td>
      <td>80</td>
    </tr>
    <tr>
      <th>9</th>
      <td>4</td>
      <td>9</td>
      <td>90</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># GML format </span>

<span class="c1"># With GML string</span>
<span class="n">model</span><span class="o">=</span><span class="n">CausalModel</span><span class="p">(</span>
        <span class="n">data</span> <span class="o">=</span> <span class="n">df</span><span class="p">,</span>
        <span class="n">treatment</span><span class="o">=</span><span class="s1">&#39;X&#39;</span><span class="p">,</span>
        <span class="n">outcome</span><span class="o">=</span><span class="s1">&#39;Y&#39;</span><span class="p">,</span>
        <span class="n">graph</span><span class="o">=</span><span class="s2">&quot;&quot;&quot;graph[directed 1 node[id &quot;K&quot; label &quot;K&quot;]  </span>
<span class="s2">                    node[id &quot;X&quot; label &quot;X&quot;]</span>
<span class="s2">                    node[id &quot;Y&quot; label &quot;Y&quot;]      </span>
<span class="s2">                    edge[source &quot;K&quot; target &quot;X&quot;]    </span>
<span class="s2">                    edge[source &quot;K&quot; target &quot;Y&quot;]     </span>
<span class="s2">                    edge[source &quot;X&quot; target &quot;Y&quot;]]&quot;&quot;&quot;</span>
                    
        <span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">view_model</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>INFO:dowhy.do_why:Model to find the causal effect of treatment [&#39;X&#39;] on outcome [&#39;Y&#39;]
WARNING:dowhy.causal_graph:Warning: Pygraphviz cannot be loaded. Check that graphviz and pygraphviz are installed.
INFO:dowhy.causal_graph:Using Matplotlib for plotting
</pre></div>
</div>
<img alt="../_images/T990000_causal_inference_78_1.png" src="../_images/T990000_causal_inference_78_1.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># # With GML file</span>
<span class="c1"># model=CausalModel(</span>
<span class="c1">#         data = df,</span>
<span class="c1">#         treatment=&#39;X&#39;,</span>
<span class="c1">#         outcome=&#39;Y&#39;,</span>
<span class="c1">#         graph=&quot;example_graphs/simple_graph_example.gml&quot;</span>
<span class="c1">#         )</span>
<span class="c1"># model.view_model()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># With DOT string</span>
<span class="n">model</span><span class="o">=</span><span class="n">CausalModel</span><span class="p">(</span>
        <span class="n">data</span> <span class="o">=</span> <span class="n">df</span><span class="p">,</span>
        <span class="n">treatment</span><span class="o">=</span><span class="s1">&#39;X&#39;</span><span class="p">,</span>
        <span class="n">outcome</span><span class="o">=</span><span class="s1">&#39;Y&#39;</span><span class="p">,</span>
        <span class="n">graph</span><span class="o">=</span><span class="s2">&quot;digraph {Z -&gt; X;Z -&gt; Y;X -&gt; Y;}&quot;</span>
        <span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">view_model</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>ERROR:dowhy.causal_graph:Error: Pygraphviz cannot be loaded. No module named &#39;pygraphviz&#39;
Trying pydot ...
INFO:dowhy.do_why:Model to find the causal effect of treatment [&#39;X&#39;] on outcome [&#39;Y&#39;]
WARNING:dowhy.causal_graph:Warning: Pygraphviz cannot be loaded. Check that graphviz and pygraphviz are installed.
INFO:dowhy.causal_graph:Using Matplotlib for plotting
</pre></div>
</div>
<img alt="../_images/T990000_causal_inference_80_1.png" src="../_images/T990000_causal_inference_80_1.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># # With DOT file</span>
<span class="c1"># model=CausalModel(</span>
<span class="c1">#         data = df,</span>
<span class="c1">#         treatment=&#39;X&#39;,</span>
<span class="c1">#         outcome=&#39;Y&#39;,</span>
<span class="c1">#         graph=&quot;example_graphs/simple_graph_example.dot&quot;</span>
<span class="c1">#         )</span>
<span class="c1"># model.view_model()</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="section" id="using-pandas-api-do-sampler">
<h2>Using Pandas API (do sampler)<a class="headerlink" href="#using-pandas-api-do-sampler" title="Permalink to this headline">¶</a></h2>
<p>The user should note that this is still an area of active research, so you should be careful about being too confident in bootstrapped error bars from do-samplers. Pearlian inference focuses on more fundamental quantities like the joint distribution of a set of outcomes Y, 𝑃(𝑌), which can be used to derive other statistics of interest. Inverse Probability Weighing of do-adjustment.</p>
<p><a class="reference external" href="https://medium.com/&#64;akelleh/introducing-the-do-sampler-for-causal-inference-a3296ea9e78d">https://medium.com/&#64;akelleh/introducing-the-do-sampler-for-causal-inference-a3296ea9e78d</a></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># the data already loaded in the previous cell. we include the import</span>
<span class="c1"># here you so you don&#39;t have to keep re-downloading it.</span>

<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">dowhy.api</span>

<span class="n">lalonde</span><span class="o">=</span><span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">&quot;https://raw.githubusercontent.com/sanadhis/ITT-ADA-2017/master/04%20-%20Applied%20ML/lalonde.csv&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>The key feature here is the do method, which produces a new dataframe replacing the treatment variable with values specified, and the outcome with a sample from the interventional distribution of the outcome. If you don’t specify a value for the treatment, it leaves the treatment untouched:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">do_df</span> <span class="o">=</span> <span class="n">lalonde</span><span class="o">.</span><span class="n">causal</span><span class="o">.</span><span class="n">do</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="s1">&#39;treat&#39;</span><span class="p">,</span>
                          <span class="n">outcome</span><span class="o">=</span><span class="s1">&#39;re78&#39;</span><span class="p">,</span>
                          <span class="n">common_causes</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;nodegr&#39;</span><span class="p">,</span> <span class="s1">&#39;black&#39;</span><span class="p">,</span> <span class="s1">&#39;hisp&#39;</span><span class="p">,</span> <span class="s1">&#39;age&#39;</span><span class="p">,</span> <span class="s1">&#39;educ&#39;</span><span class="p">,</span> <span class="s1">&#39;married&#39;</span><span class="p">],</span>
                          <span class="n">variable_types</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;age&#39;</span><span class="p">:</span> <span class="s1">&#39;c&#39;</span><span class="p">,</span> <span class="s1">&#39;educ&#39;</span><span class="p">:</span><span class="s1">&#39;c&#39;</span><span class="p">,</span> <span class="s1">&#39;black&#39;</span><span class="p">:</span> <span class="s1">&#39;d&#39;</span><span class="p">,</span> <span class="s1">&#39;hisp&#39;</span><span class="p">:</span> <span class="s1">&#39;d&#39;</span><span class="p">,</span> 
                                          <span class="s1">&#39;married&#39;</span><span class="p">:</span> <span class="s1">&#39;d&#39;</span><span class="p">,</span> <span class="s1">&#39;nodegr&#39;</span><span class="p">:</span> <span class="s1">&#39;d&#39;</span><span class="p">,</span><span class="s1">&#39;re78&#39;</span><span class="p">:</span> <span class="s1">&#39;c&#39;</span><span class="p">,</span> <span class="s1">&#39;treat&#39;</span><span class="p">:</span> <span class="s1">&#39;b&#39;</span><span class="p">})</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>WARNING:dowhy.do_why:Causal Graph not provided. DoWhy will construct a graph based on data inputs.
INFO:dowhy.do_why:Model to find the causal effect of treatment [&#39;treat&#39;] on outcome [&#39;re78&#39;]
INFO:dowhy.causal_identifier:Common causes of treatment and outcome:[&#39;age&#39;, &#39;educ&#39;, &#39;hisp&#39;, &#39;nodegr&#39;, &#39;black&#39;, &#39;married&#39;]
WARNING:dowhy.causal_identifier:There are unobserved common causes. Causal effect cannot be identified.
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>WARN: Do you want to continue by ignoring these unobserved confounders? [y/n] y
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>INFO:dowhy.causal_identifier:Instrumental variables for treatment and outcome:[]
INFO:dowhy.do_sampler:Using WeightingSampler for do sampling.
INFO:dowhy.do_sampler:Caution: do samplers assume iid data.
</pre></div>
</div>
</div>
</div>
<p>Notice you get the usual output and prompts about identifiability. This is all dowhy under the hood!</p>
<p>We now have an interventional sample in do_df. It looks very similar to the original dataframe. Compare them:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">lalonde</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="n">lalonde</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(614, 11)
</pre></div>
</div>
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>id</th>
      <th>treat</th>
      <th>age</th>
      <th>educ</th>
      <th>black</th>
      <th>hispan</th>
      <th>married</th>
      <th>nodegree</th>
      <th>re74</th>
      <th>re75</th>
      <th>re78</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>NSW1</td>
      <td>1</td>
      <td>37</td>
      <td>11</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>9930.0460</td>
    </tr>
    <tr>
      <th>1</th>
      <td>NSW2</td>
      <td>1</td>
      <td>22</td>
      <td>9</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>3595.8940</td>
    </tr>
    <tr>
      <th>2</th>
      <td>NSW3</td>
      <td>1</td>
      <td>30</td>
      <td>12</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>24909.4500</td>
    </tr>
    <tr>
      <th>3</th>
      <td>NSW4</td>
      <td>1</td>
      <td>27</td>
      <td>11</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>7506.1460</td>
    </tr>
    <tr>
      <th>4</th>
      <td>NSW5</td>
      <td>1</td>
      <td>33</td>
      <td>8</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>289.7899</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">do_df</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="n">do_df</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="s2">&quot;id&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(614, 13)
</pre></div>
</div>
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>id</th>
      <th>treat</th>
      <th>age</th>
      <th>educ</th>
      <th>black</th>
      <th>hispan</th>
      <th>married</th>
      <th>nodegree</th>
      <th>re74</th>
      <th>re75</th>
      <th>re78</th>
      <th>propensity_score</th>
      <th>weight</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>128</th>
      <td>NSW1</td>
      <td>1</td>
      <td>37</td>
      <td>11</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>9930.046</td>
      <td>0.472864</td>
      <td>2.114773</td>
    </tr>
    <tr>
      <th>288</th>
      <td>NSW1</td>
      <td>1</td>
      <td>37</td>
      <td>11</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>9930.046</td>
      <td>0.472864</td>
      <td>2.114773</td>
    </tr>
    <tr>
      <th>92</th>
      <td>NSW10</td>
      <td>1</td>
      <td>33</td>
      <td>12</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>12418.070</td>
      <td>0.056610</td>
      <td>17.664643</td>
    </tr>
    <tr>
      <th>275</th>
      <td>NSW10</td>
      <td>1</td>
      <td>33</td>
      <td>12</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>12418.070</td>
      <td>0.056610</td>
      <td>17.664643</td>
    </tr>
    <tr>
      <th>162</th>
      <td>NSW10</td>
      <td>1</td>
      <td>33</td>
      <td>12</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>12418.070</td>
      <td>0.056610</td>
      <td>17.664643</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<div class="section" id="treatment-effect-estimation">
<h3>Treatment Effect Estimation<a class="headerlink" href="#treatment-effect-estimation" title="Permalink to this headline">¶</a></h3>
<p>We could get a naive estimate before for a treatment effect by doing</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">((</span><span class="n">lalonde</span><span class="p">[</span><span class="n">lalonde</span><span class="p">[</span><span class="s1">&#39;treat&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span> <span class="o">-</span> <span class="n">lalonde</span><span class="p">[</span><span class="n">lalonde</span><span class="p">[</span><span class="s1">&#39;treat&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">())[</span><span class="s1">&#39;re78&#39;</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-635.0262120374273
</pre></div>
</div>
</div>
</div>
<p>We can do the same with our new sample from the interventional distribution to get a causal effect estimate</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">((</span><span class="n">do_df</span><span class="p">[</span><span class="n">do_df</span><span class="p">[</span><span class="s1">&#39;treat&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span> <span class="o">-</span> <span class="n">do_df</span><span class="p">[</span><span class="n">do_df</span><span class="p">[</span><span class="s1">&#39;treat&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">())[</span><span class="s1">&#39;re78&#39;</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>781.568394350249
</pre></div>
</div>
</div>
</div>
<p>We could get some rough error bars on the outcome using the normal approximation for a 95% confidence interval, like</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="nb">print</span><span class="p">(</span><span class="mf">1.96</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">((</span><span class="n">do_df</span><span class="p">[</span><span class="n">do_df</span><span class="p">[</span><span class="s1">&#39;treat&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">var</span><span class="p">()</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">do_df</span><span class="p">[</span><span class="n">do_df</span><span class="p">[</span><span class="s1">&#39;treat&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span><span class="p">]))</span> <span class="o">+</span> 
             <span class="p">(</span><span class="n">do_df</span><span class="p">[</span><span class="n">do_df</span><span class="p">[</span><span class="s1">&#39;treat&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">var</span><span class="p">()</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">do_df</span><span class="p">[</span><span class="n">do_df</span><span class="p">[</span><span class="s1">&#39;treat&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="mi">0</span><span class="p">])))[</span><span class="s1">&#39;re78&#39;</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>1205.2460397301224
</pre></div>
</div>
</div>
</div>
<p>but note that these DO NOT contain propensity score estimation error. For that, a bootstrapping procedure might be more appropriate.</p>
<p>This is just one statistic we can compute from the interventional distribution of ‘re78’. We can get all of the interventional moments as well, including functions of ‘re78’. We can leverage the full power of pandas, like</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">do_df</span><span class="p">[</span><span class="s1">&#39;re78&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">describe</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>count      614.000000
mean      7100.633234
std       7594.109038
min          0.000000
25%        672.877300
50%       5130.757500
75%      11142.870000
max      60307.930000
Name: re78, dtype: float64
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">%</span><span class="n">matplotlib</span> <span class="n">inline</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>

<span class="n">sns</span><span class="o">.</span><span class="n">barplot</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">do_df</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="s1">&#39;treat&#39;</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s1">&#39;re78&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;matplotlib.axes._subplots.AxesSubplot at 0x7fe19494b160&gt;
</pre></div>
</div>
<img alt="../_images/T990000_causal_inference_97_1.png" src="../_images/T990000_causal_inference_97_1.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">sns</span><span class="o">.</span><span class="n">barplot</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">lalonde</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="s1">&#39;treat&#39;</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s1">&#39;re78&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;matplotlib.axes._subplots.AxesSubplot at 0x7fe194900898&gt;
</pre></div>
</div>
<img alt="../_images/T990000_causal_inference_98_1.png" src="../_images/T990000_causal_inference_98_1.png" />
</div>
</div>
</div>
<div class="section" id="further-elaboration-on-pearlian-intervention">
<h3>Further Elaboration on Pearlian Intervention<a class="headerlink" href="#further-elaboration-on-pearlian-intervention" title="Permalink to this headline">¶</a></h3>
<p>The “do-sampler” is a new feature in do-why. While most potential-outcomes oriented estimators focus on estimating the specific contrast <span class="math notranslate nohighlight">\(E[Y_0 - Y_1]\)</span>, Pearlian inference focuses on more fundamental quantities like the joint distribution of a set of outcomes Y, <span class="math notranslate nohighlight">\(P(Y)\)</span>, which can be used to derive other statistics of interest.</p>
<p>Generally, it’s hard to represent a probability distribution non-parametrically. Even if you could, you wouldn’t want to gloss over finite-sample problems with you data you used to generate it. With these issues in mind, we decided to represent interventional distributions by sampling from them with an object called to “do-sampler”. With these samples, we can hope to compute finite-sample statistics of our interventional data. If we bootstrap many such samples, we can even hope for good sampling distributions for these statistics. (Something that can still be tested)</p>
<p>The user should note that this is still an area of active research, so you should be careful about being too confident in bootstrapped error bars from do-samplers.</p>
<p>Note that do samplers sample from the outcome distribution, and so will vary significantly from sample to sample. To use them to compute outcomes, it’s recommended to generate several such samples to get an idea of the posterior variance of your statistic of interest.</p>
</div>
</div>
<div class="section" id="pearlian-interventions">
<h2>Pearlian Interventions<a class="headerlink" href="#pearlian-interventions" title="Permalink to this headline">¶</a></h2>
<p>Following the notion of an intervention in a Pearlian causal model, our do-samplers implement a sequence of steps:</p>
<ol class="simple">
<li><p>Disrupt causes</p></li>
<li><p>Make Effective</p></li>
<li><p>Propagate and sample</p></li>
</ol>
<p>In the first stage, we imagine cutting the in-edges to all of the variables we’re intervening on. In the second stage, we set the value of those variables to their interventional quantities. In the third stage, we propagate that value forward through our model to compute interventional outcomes with a sampling procedure.</p>
<p>In practice, there are many ways we can implement these steps. They’re most explicit when we build the model as a linear bayesian network in PyMC3, which is what underlies the MCMC do sampler. In that case, we fit one bayesian network to the data, then construct a new network representing the interventional network. The structural equations are set with the parameters fit in the initial network, and we sample from that new network to get our do sample.</p>
<p>In the weighting do sampler, we abstractly think of “disrupting the causes” by accounting for selection into the causal state through propensity score estimation. These scores contain the information used to block back-door paths, and so have the same statistics effect as cutting edges into the causal state. We make the treatment effective by selecting the subset of our data set with the correct value of the causal state. Finally, we generated a weighted random sample using inverse propensity weighting to get our do sample.</p>
<p>There are other ways you could implement these three steps, but the formula is the same. We’ve abstracted them out as abstract class methods which you should override if you’d like to create your own do sampler!</p>
</div>
<div class="section" id="statefulness">
<h2>Statefulness<a class="headerlink" href="#statefulness" title="Permalink to this headline">¶</a></h2>
<p>The do sampler when accessed through the high-level pandas API is stateless by default.This makes it intuitive to work with, and you can generate different samples with repeated calls to the <code class="docutils literal notranslate"><span class="pre">pandas.DataFrame.causal.do</span></code>. It can be made stateful, which is sometimes useful.</p>
<p>The 3-stage process we mentioned before is implemented by passing an internal <code class="docutils literal notranslate"><span class="pre">pandas.DataFrame</span></code> through each of the three stages, but regarding it as temporary. The internal dataframe is reset by default before returning the result.</p>
<p>It can be much more efficient to maintain state in the do sampler between generating samples. This is especially true when step 1 requires fitting an expensive model, as is the case with the MCMC do sampler, the kernel density sampler, and the weighting sampler.</p>
<p>Instead of re-fitting the model for each sample, you’d like to fit it once, and then generate many samples from the do sampler. You can do this by setting the kwarg <code class="docutils literal notranslate"><span class="pre">stateful=True</span></code> when you call the <code class="docutils literal notranslate"><span class="pre">pandas.DataFrame.causal.do</span></code> method. To reset the state of the dataframe (deleting the model as well as the internal dataframe), you can call the <code class="docutils literal notranslate"><span class="pre">pandas.DataFrame.causal.reset</span></code> method.</p>
<p>Through the lower-level API, the sampler is stateful by default. The assumption is that a “power user” who is using the low-level API will want more control over the sampling process. In this case, state is carried by internal dataframe <code class="docutils literal notranslate"><span class="pre">self._df</span></code>, which is a copy of the dataframe passed on instantiation. The original dataframe is kept in <code class="docutils literal notranslate"><span class="pre">self._data</span></code>, and is used when the user resets state.</p>
</div>
<div class="section" id="integration">
<h2>Integration<a class="headerlink" href="#integration" title="Permalink to this headline">¶</a></h2>
<p>The do-sampler is built on top of the identification abstraction used throughout do-why. It uses a <code class="docutils literal notranslate"><span class="pre">dowhy.CausalModel</span></code> to perform identification, and builds any models it needs automatically using this identification.</p>
</div>
<div class="section" id="specifying-interventions">
<h2>Specifying Interventions<a class="headerlink" href="#specifying-interventions" title="Permalink to this headline">¶</a></h2>
<p>There is a kwarg on the <code class="docutils literal notranslate"><span class="pre">dowhy.do_sampler.DoSampler</span></code> object called <code class="docutils literal notranslate"><span class="pre">keep_original_treatment</span></code>. While an intervention might be to set all units treatment values to some specific value, it’s often natural to keep them set as they were, and instead remove confounding bias during effect estimation. If you’d prefer not to specify an intervention, you can set the kwarg like <code class="docutils literal notranslate"><span class="pre">keep_original_treatment=True</span></code>, and the second stage of the 3-stage process will be skipped. In that case, any intervention specified on sampling will be ignored.</p>
<p>If the <code class="docutils literal notranslate"><span class="pre">keep_original_treatment</span></code> flag is set to false (it is by default), then you must specify an intervention when you sample from the do sampler. For details, see the demo below!</p>
</div>
<div class="section" id="demo">
<h2>Demo<a class="headerlink" href="#demo" title="Permalink to this headline">¶</a></h2>
<p>First, let’s generate some data and a causal model. Here, Z confounds our causal state, D, with the outcome, Y.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">N</span> <span class="o">=</span> <span class="mi">5000</span>

<span class="n">z</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="n">N</span><span class="p">)</span>
<span class="n">d</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">binomial</span><span class="p">(</span><span class="mf">1.</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mf">1.</span><span class="o">/</span><span class="p">(</span><span class="mf">1.</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="mf">5.</span> <span class="o">*</span> <span class="n">z</span><span class="p">)))</span>
<span class="n">y</span> <span class="o">=</span> <span class="mf">2.</span> <span class="o">*</span> <span class="n">z</span> <span class="o">+</span> <span class="n">d</span> <span class="o">+</span> <span class="mf">0.1</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="n">N</span><span class="p">)</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s1">&#39;Z&#39;</span><span class="p">:</span> <span class="n">z</span><span class="p">,</span> <span class="s1">&#39;D&#39;</span><span class="p">:</span> <span class="n">d</span><span class="p">,</span> <span class="s1">&#39;Y&#39;</span><span class="p">:</span> <span class="n">y</span><span class="p">})</span>

<span class="nb">print</span><span class="p">((</span><span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="o">.</span><span class="n">D</span> <span class="o">==</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span> <span class="o">-</span> <span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="o">.</span><span class="n">D</span> <span class="o">==</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">())[</span><span class="s1">&#39;Y&#39;</span><span class="p">])</span>


<span class="n">causes</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;D&#39;</span><span class="p">]</span>
<span class="n">outcomes</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;Y&#39;</span><span class="p">]</span>
<span class="n">common_causes</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;Z&#39;</span><span class="p">]</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">CausalModel</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> 
                    <span class="n">causes</span><span class="p">,</span>
                    <span class="n">outcomes</span><span class="p">,</span>
                    <span class="n">common_causes</span><span class="o">=</span><span class="n">common_causes</span><span class="p">)</span>


<span class="c1">## Idnetification</span>

<span class="n">identification</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">identify_effect</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>WARNING:dowhy.do_why:Causal Graph not provided. DoWhy will construct a graph based on data inputs.
INFO:dowhy.do_why:Model to find the causal effect of treatment [&#39;D&#39;] on outcome [&#39;Y&#39;]
INFO:dowhy.causal_identifier:Common causes of treatment and outcome:[&#39;Z&#39;, &#39;U&#39;]
WARNING:dowhy.causal_identifier:There are unobserved common causes. Causal effect cannot be identified.
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>1.621574181853743
WARN: Do you want to continue by ignoring these unobserved confounders? [y/n] y
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>INFO:dowhy.causal_identifier:Instrumental variables for treatment and outcome:[]
</pre></div>
</div>
</div>
</div>
<p>Identification works! We didn’t actually need to do this yet, since it will happen internally with the do sampler, but it can’t hurt to check that identification works before proceeding. Now, let’s build the sampler.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">dowhy.do_samplers.weighting_sampler</span> <span class="kn">import</span> <span class="n">WeightingSampler</span>

<span class="n">sampler</span> <span class="o">=</span> <span class="n">WeightingSampler</span><span class="p">(</span><span class="n">df</span><span class="p">,</span>
                           <span class="n">causal_model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span>
                           <span class="n">keep_original_treatment</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                           <span class="n">variable_types</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;D&#39;</span><span class="p">:</span> <span class="s1">&#39;b&#39;</span><span class="p">,</span> <span class="s1">&#39;Z&#39;</span><span class="p">:</span> <span class="s1">&#39;c&#39;</span><span class="p">,</span> <span class="s1">&#39;Y&#39;</span><span class="p">:</span> <span class="s1">&#39;c&#39;</span><span class="p">})</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>INFO:dowhy.causal_identifier:Common causes of treatment and outcome:[&#39;Z&#39;, &#39;U&#39;]
WARNING:dowhy.causal_identifier:There are unobserved common causes. Causal effect cannot be identified.
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>WARN: Do you want to continue by ignoring these unobserved confounders? [y/n] y
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>INFO:dowhy.causal_identifier:Instrumental variables for treatment and outcome:[]
INFO:dowhy.do_sampler:Using WeightingSampler for do sampling.
INFO:dowhy.do_sampler:Caution: do samplers assume iid data.
</pre></div>
</div>
</div>
</div>
<p>Now, we can just sample from the interventional distribution! Since we set the keep_original_treatment flag to False, any treatment we pass here will be ignored. Here, we’ll just pass None to acknowledge that we know we don’t want to pass anything.</p>
<p>If you’d prefer to specify an intervention, you can just put the interventional value here instead as a list or numpy array.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">interventional_df</span> <span class="o">=</span> <span class="n">sampler</span><span class="o">.</span><span class="n">do_sample</span><span class="p">(</span><span class="kc">None</span><span class="p">)</span>
<span class="nb">print</span><span class="p">((</span><span class="n">interventional_df</span><span class="p">[</span><span class="n">interventional_df</span><span class="o">.</span><span class="n">D</span> <span class="o">==</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span> <span class="o">-</span> <span class="n">interventional_df</span><span class="p">[</span><span class="n">interventional_df</span><span class="o">.</span><span class="n">D</span> <span class="o">==</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">())[</span><span class="s1">&#39;Y&#39;</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.9980454437666204
</pre></div>
</div>
</div>
</div>
<p>Now we’re much closer to the true effect, which is around 1.0!</p>
</div>
<div class="section" id="uplift-cate-ate-ite">
<h2>Uplift (CATE, ATE, ITE)<a class="headerlink" href="#uplift-cate-ate-ite" title="Permalink to this headline">¶</a></h2>
<p>We consider a functional parameter called the conditional average treatment effect (CATE), designed to capture the heterogeneity of a treatment effect across subpopulations when the unconfoundedness assumption applies. In contrast to quantile regressions, the subpopulations of interest are defined in terms of the possible values of a set of continuous covariates rather than the quantiles of the potential outcome distributions.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">similar</span> <span class="n">project</span> <span class="n">by</span> <span class="n">microsoft</span>

<span class="n">https</span><span class="p">:</span><span class="o">//</span><span class="n">github</span><span class="o">.</span><span class="n">com</span><span class="o">/</span><span class="n">microsoft</span><span class="o">/</span><span class="n">EconML</span>
</pre></div>
</div>
</div>
</div>
<p>The most famous use case of Uplift Modeling would be the 44th US president Barack Obama’s 2nd presidential campaign in 2012. Obama’s team used Uplift Modeling to find which voters could be persuaded to vote for him. Here are some articles.</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>What is ‘Persuasion Modeling’, and how did it help Obama to win the elections?
How Obama’s Team Used Big Data to Rally Voters
How uplift modeling helped Obama&#39;s campaign -- and can aid marketers
</pre></div>
</div>
<p>Uplift Modeling estimates uplift scores (a.k.a. CATE: Conditional Average Treatment Effect or ITE: Individual Treatment Effect). Uplift score is how much the estimated conversion rate will increase by the campaign.</p>
<p>Suppose you are in charge of a marketing campaign to sell a product, and the estimated conversion rate (probability to buy a product) of a customer is 50 % if targeted and the estimated conversion rate is 40 % if not targeted, then the uplift score of the customer is (50–40) = +10 % points. Likewise, suppose the estimated conversion rate if targeted is 20 % and the estimated conversion rate if not targeted is 80%, the uplift score is (20–80) = -60 % points (negative value).</p>
<p>The range of uplift scores is between -100 and +100 % points (-1 and +1). It is recommended to target customers with high uplift scores and avoid customers with negative uplift scores to optimize the marketing campaign.</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>CausalLift works with both A/B testing results and observational datasets.
CausalLift can output intuitive metrics for evaluation.
</pre></div>
</div>
<p>In a word, to use for real-world business.</p>
<p>Existing packages for Uplift Modeling assumes the dataset is from A/B Testing (a.k.a. Randomized Controlled Trial). In real-world business, however, observational datasets in which treatment (campaign) targets were not chosen randomly are more common especially in the early stage of evidence-based decision making. CausalLift supports observational datasets using a basic methodology in Causal Inference called “Inverse Probability Weighting” based on the assumption that propensity to be treated can be inferred from the available features.</p>
<p>There are 2 challenges of Uplift Modeling; explainability of the model and evaluation. CausalLift utilizes a basic methodology of Uplift Modeling called Two Models approach (training 2 models independently for treated and untreated samples to compute the CATE (Conditional Average Treatment Effects) or uplift scores) to address these challenges.</p>
<p>Explainability of the model - Since it is relatively simple, it is less challenging to explain how it works to stakeholders in the business.</p>
<p>Explainability of evaluation - To evaluate Uplift Modeling, metrics such as Qini and AUUC (Area Under the Uplift Curve) are used in research, but these metrics are difficult to explain to the stakeholders. For business, a metric that can estimate how much more profit can be earned is more practical. Since CausalLift adopted the Two-Model approach, the 2 models can be reused to simulate the outcome of following the recommendation by the Uplift Model and can estimate how much conversion rate (the proportion of people who took the desired action such as buying a product) will increase using the uplift model.</p>
<p>A meta-algorithm uses either a single base learner while having the treatment indicator as a feature (e.g. S-learner), or multiple base learners separately for each of the treatment and control groups (e.g. T-learner, X-learner and R-learner).</p>
<p>Causal ML is a Python package that provides a suite of uplift modeling and causal inference methods using machine learning algorithms based on recent research. It provides a standard interface that allows user to estimate the Conditional Average Treatment Effect (CATE) or Individual Treatment Effect (ITE) from experimental or observational data. Essentially, it estimates the causal impact of intervention T on outcome Y for users with observed features X, without strong assumptions on the model form. Typical use cases include</p>
<ul class="simple">
<li><p>Campaign targeting optimization: An important lever to increase ROI in an advertising campaign is to target the ad to the set of customers who will have a favorable response in a given KPI such as engagement or sales. CATE identifies these customers by estimating the effect of the KPI from ad exposure at the individual level from A/B experiment or historical observational data.</p></li>
<li><p>Personalized engagement: A company has multiple options to interact with its customers such as different product choices in up-sell or messaging channels for communications. One can use CATE to estimate the heterogeneous treatment effect for each customer and treatment option combination for an optimal personalized recommendation system.</p></li>
</ul>
<p>The package currently supports the following methods</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>Tree-based algorithms
    Uplift tree/random forests on KL divergence, Euclidean Distance, and Chi-Square
    Uplift tree/random forests on Contextual Treatment Selection
Meta-learner algorithms
    S-learner
    T-learner
    X-learner
    R-learner
</pre></div>
</div>
<p>Table data including the following columns:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>Features
    a.k.a independent variables, explanatory variables, covariates
    e.g. customer gender, age range, etc.
    Note: Categorical variables need to be one-hot coded so propensity can be estimated using logistic regression. pandas.get_dummies can be used.
Outcome: binary (0 or 1)
    a.k.a dependent variable, target variable, label
    e.g. whether the customer bought a product, clicked a link, etc.
Treatment: binary (0 or 1)
    a variable you can control and want to optimize for each individual (customer)
    a.k.a intervention
    e.g. whether an advertising campaign was executed, whether a discount was offered, etc.
    Note: if you cannot find a treatment column, you may need to ask stakeholders to get the data, which might take hours to years.
[Optional] Propensity: continuous between 0 and 1
    propensity (or probability) to be treated for observational datasets (not needed for A/B Testing results)
    If not provided, CausalLift can estimate from the features using logistic regression.
</pre></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>!pip install causalml
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Collecting causalml
?25l  Downloading https://files.pythonhosted.org/packages/8d/22/cce4ae1c8979eefee8afba96653ff088ab5bcd61b98dcd4897c9340685ce/causalml-0.5.0.tar.gz (3.9MB)
     |████████████████████████████████| 3.9MB 5.2MB/s 
?25hRequirement already satisfied: setuptools&gt;=41.0.0 in /usr/local/lib/python3.6/dist-packages (from causalml) (41.6.0)
Requirement already satisfied: pip&gt;=10.0 in /usr/local/lib/python3.6/dist-packages (from causalml) (19.3.1)
Requirement already satisfied: numpy&gt;=0.16.0 in /usr/local/lib/python3.6/dist-packages (from causalml) (1.17.4)
Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from causalml) (1.3.2)
Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from causalml) (3.1.1)
Requirement already satisfied: pandas&gt;=0.24.1 in /usr/local/lib/python3.6/dist-packages (from causalml) (0.25.3)
Requirement already satisfied: scikit-learn&gt;=0.21.0 in /usr/local/lib/python3.6/dist-packages (from causalml) (0.21.3)
Requirement already satisfied: statsmodels&gt;=0.9.0 in /usr/local/lib/python3.6/dist-packages (from causalml) (0.10.1)
Requirement already satisfied: seaborn in /usr/local/lib/python3.6/dist-packages (from causalml) (0.9.0)
Requirement already satisfied: Cython in /usr/local/lib/python3.6/dist-packages (from causalml) (0.29.14)
Requirement already satisfied: xgboost in /usr/local/lib/python3.6/dist-packages (from causalml) (0.90)
Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from causalml) (0.16.0)
Requirement already satisfied: pydotplus in /usr/local/lib/python3.6/dist-packages (from causalml) (2.0.2)
Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from causalml) (4.28.1)
Collecting eli5
?25l  Downloading https://files.pythonhosted.org/packages/97/2f/c85c7d8f8548e460829971785347e14e45fa5c6617da374711dec8cb38cc/eli5-0.10.1-py2.py3-none-any.whl (105kB)
     |████████████████████████████████| 112kB 45.3MB/s 
?25hCollecting shap
?25l  Downloading https://files.pythonhosted.org/packages/57/43/08f152a59a1d60f0328b476bdd58c791498989981ab9c6d595ec5448a86a/shap-0.32.1.tar.gz (259kB)
     |████████████████████████████████| 266kB 47.8MB/s 
?25hRequirement already satisfied: dill in /usr/local/lib/python3.6/dist-packages (from causalml) (0.3.1.1)
Requirement already satisfied: lightgbm in /usr/local/lib/python3.6/dist-packages (from causalml) (2.2.3)
Collecting pygam
?25l  Downloading https://files.pythonhosted.org/packages/13/be/775033ef08a8945bec6ad7973b161ca909f852442e0d7cfb8d1a214de1ac/pygam-0.8.0-py2.py3-none-any.whl (1.8MB)
     |████████████████████████████████| 1.8MB 34.5MB/s 
?25hRequirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,&gt;=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib-&gt;causalml) (2.4.5)
Requirement already satisfied: cycler&gt;=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib-&gt;causalml) (0.10.0)
Requirement already satisfied: python-dateutil&gt;=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib-&gt;causalml) (2.6.1)
Requirement already satisfied: kiwisolver&gt;=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib-&gt;causalml) (1.1.0)
Requirement already satisfied: pytz&gt;=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas&gt;=0.24.1-&gt;causalml) (2018.9)
Requirement already satisfied: joblib&gt;=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn&gt;=0.21.0-&gt;causalml) (0.14.0)
Requirement already satisfied: patsy&gt;=0.4.0 in /usr/local/lib/python3.6/dist-packages (from statsmodels&gt;=0.9.0-&gt;causalml) (0.5.1)
Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from eli5-&gt;causalml) (1.12.0)
Requirement already satisfied: tabulate&gt;=0.7.7 in /usr/local/lib/python3.6/dist-packages (from eli5-&gt;causalml) (0.8.5)
Requirement already satisfied: graphviz in /usr/local/lib/python3.6/dist-packages (from eli5-&gt;causalml) (0.10.1)
Requirement already satisfied: jinja2 in /usr/local/lib/python3.6/dist-packages (from eli5-&gt;causalml) (2.10.3)
Requirement already satisfied: attrs&gt;16.0.0 in /usr/local/lib/python3.6/dist-packages (from eli5-&gt;causalml) (19.3.0)
Requirement already satisfied: progressbar2 in /usr/local/lib/python3.6/dist-packages (from pygam-&gt;causalml) (3.38.0)
Requirement already satisfied: MarkupSafe&gt;=0.23 in /usr/local/lib/python3.6/dist-packages (from jinja2-&gt;eli5-&gt;causalml) (1.1.1)
Requirement already satisfied: python-utils&gt;=2.3.0 in /usr/local/lib/python3.6/dist-packages (from progressbar2-&gt;pygam-&gt;causalml) (2.3.0)
Building wheels for collected packages: causalml, shap
  Building wheel for causalml (setup.py) ... ?25l?25hdone
  Created wheel for causalml: filename=causalml-0.5.0-cp36-cp36m-linux_x86_64.whl size=419825 sha256=a35818bc4f4647036a8656f9650be252b1b59d60b112436ba6eea049611e9808
  Stored in directory: /root/.cache/pip/wheels/f5/a3/be/76fbcf6d0dbbbbad24113748894117411b7d124dc74c45ad70
  Building wheel for shap (setup.py) ... ?25l?25hdone
  Created wheel for shap: filename=shap-0.32.1-cp36-cp36m-linux_x86_64.whl size=376829 sha256=0672a862c8a8113798e69f38e1d01403843e7a38851d34653f10a7701385f7bd
  Stored in directory: /root/.cache/pip/wheels/8e/b2/50/8fadb5a59789cb5bdeb01b800223be540651ae92915172050b
Successfully built causalml shap
Installing collected packages: eli5, shap, pygam, causalml
Successfully installed causalml-0.5.0 eli5-0.10.1 pygam-0.8.0 shap-0.32.1
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="average-treatment-effect-estimation-with-s-t-x-and-r-learners">
<h2>Average Treatment Effect Estimation with S, T, X, and R Learners<a class="headerlink" href="#average-treatment-effect-estimation-with-s-t-x-and-r-learners" title="Permalink to this headline">¶</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">causalml.inference.meta</span> <span class="kn">import</span> <span class="n">LRSRegressor</span>
<span class="kn">from</span> <span class="nn">causalml.inference.meta</span> <span class="kn">import</span> <span class="n">XGBTRegressor</span><span class="p">,</span> <span class="n">MLPTRegressor</span>
<span class="kn">from</span> <span class="nn">causalml.inference.meta</span> <span class="kn">import</span> <span class="n">BaseXRegressor</span>
<span class="kn">from</span> <span class="nn">causalml.inference.meta</span> <span class="kn">import</span> <span class="n">BaseRRegressor</span>
<span class="kn">from</span> <span class="nn">xgboost</span> <span class="kn">import</span> <span class="n">XGBRegressor</span>
<span class="kn">from</span> <span class="nn">causalml.dataset</span> <span class="kn">import</span> <span class="n">synthetic_data</span>

<span class="n">y</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">treatment</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">e</span> <span class="o">=</span> <span class="n">synthetic_data</span><span class="p">(</span><span class="n">mode</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">n</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="mf">1.0</span><span class="p">)</span>

<span class="n">lr</span> <span class="o">=</span> <span class="n">LRSRegressor</span><span class="p">()</span>
<span class="n">te</span><span class="p">,</span> <span class="n">lb</span><span class="p">,</span> <span class="n">ub</span> <span class="o">=</span> <span class="n">lr</span><span class="o">.</span><span class="n">estimate_ate</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">treatment</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Average Treatment Effect (Linear Regression): </span><span class="si">{:.2f}</span><span class="s1"> (</span><span class="si">{:.2f}</span><span class="s1">, </span><span class="si">{:.2f}</span><span class="s1">)&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">te</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">lb</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">ub</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>

<span class="n">xg</span> <span class="o">=</span> <span class="n">XGBTRegressor</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="n">te</span><span class="p">,</span> <span class="n">lb</span><span class="p">,</span> <span class="n">ub</span> <span class="o">=</span> <span class="n">xg</span><span class="o">.</span><span class="n">estimate_ate</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">treatment</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Average Treatment Effect (XGBoost): </span><span class="si">{:.2f}</span><span class="s1"> (</span><span class="si">{:.2f}</span><span class="s1">, </span><span class="si">{:.2f}</span><span class="s1">)&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">te</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">lb</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">ub</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>

<span class="n">nn</span> <span class="o">=</span> <span class="n">MLPTRegressor</span><span class="p">(</span><span class="n">hidden_layer_sizes</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">),</span>
                 <span class="n">learning_rate_init</span><span class="o">=</span><span class="mf">.1</span><span class="p">,</span>
                 <span class="n">early_stopping</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                 <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="n">te</span><span class="p">,</span> <span class="n">lb</span><span class="p">,</span> <span class="n">ub</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">estimate_ate</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">treatment</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Average Treatment Effect (Neural Network (MLP)): </span><span class="si">{:.2f}</span><span class="s1"> (</span><span class="si">{:.2f}</span><span class="s1">, </span><span class="si">{:.2f}</span><span class="s1">)&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">te</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">lb</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">ub</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>

<span class="c1">## for some reason add this e</span>
<span class="n">xl</span> <span class="o">=</span> <span class="n">BaseXRegressor</span><span class="p">(</span><span class="n">learner</span><span class="o">=</span><span class="n">XGBRegressor</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">))</span>
<span class="n">te</span><span class="p">,</span> <span class="n">lb</span><span class="p">,</span> <span class="n">ub</span> <span class="o">=</span> <span class="n">xl</span><span class="o">.</span><span class="n">estimate_ate</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">e</span><span class="p">,</span> <span class="n">treatment</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Average Treatment Effect (BaseXRegressor using XGBoost): </span><span class="si">{:.2f}</span><span class="s1"> (</span><span class="si">{:.2f}</span><span class="s1">, </span><span class="si">{:.2f}</span><span class="s1">)&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">te</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">lb</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">ub</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>

<span class="n">rl</span> <span class="o">=</span> <span class="n">BaseRRegressor</span><span class="p">(</span><span class="n">learner</span><span class="o">=</span><span class="n">XGBRegressor</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">))</span>
<span class="n">te</span><span class="p">,</span> <span class="n">lb</span><span class="p">,</span> <span class="n">ub</span> <span class="o">=</span>  <span class="n">rl</span><span class="o">.</span><span class="n">estimate_ate</span><span class="p">(</span><span class="n">X</span><span class="o">=</span><span class="n">X</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="n">e</span><span class="p">,</span> <span class="n">treatment</span><span class="o">=</span><span class="n">treatment</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Average Treatment Effect (BaseRRegressor using XGBoost): </span><span class="si">{:.2f}</span><span class="s1"> (</span><span class="si">{:.2f}</span><span class="s1">, </span><span class="si">{:.2f}</span><span class="s1">)&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">te</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">lb</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">ub</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Using TensorFlow backend.
</pre></div>
</div>
<div class="output text_html"><p style="color: red;">
The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>
We recommend you <a href="https://www.tensorflow.org/guide/migrate" target="_blank">upgrade</a> now 
or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:
<a href="https://colab.research.google.com/notebooks/tensorflow_version.ipynb" target="_blank">more info</a>.</p>
</div><div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Average Treatment Effect (Linear Regression): 0.61 (0.47, 0.76)
[05:01:45] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>INFO:causalml:Error metrics for group 1
INFO:causalml:    RMSE   (Control):     0.6662
INFO:causalml:    RMSE (Treatment):     0.7097
INFO:causalml:   sMAPE   (Control):     0.6223
INFO:causalml:   sMAPE (Treatment):     0.3938
INFO:causalml:    Gini   (Control):     0.8048
INFO:causalml:    Gini (Treatment):     0.7758
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[05:01:45] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
Average Treatment Effect (XGBoost): 0.56 (0.46, 0.65)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>INFO:causalml:Error metrics for group 1
INFO:causalml:    RMSE   (Control):     0.9830
INFO:causalml:    RMSE (Treatment):     1.0484
INFO:causalml:   sMAPE   (Control):     0.7681
INFO:causalml:   sMAPE (Treatment):     0.4899
INFO:causalml:    Gini   (Control):     0.3172
INFO:causalml:    Gini (Treatment):     0.3908
INFO:causalml:Error metrics for group 1
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Average Treatment Effect (Neural Network (MLP)): 0.74 (0.62, 0.87)
[05:01:45] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
[05:01:45] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
[05:01:45] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
[05:01:45] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>INFO:causalml:    RMSE   (Control):     0.6662
INFO:causalml:    RMSE (Treatment):     0.7097
INFO:causalml:   sMAPE   (Control):     0.6223
INFO:causalml:   sMAPE (Treatment):     0.3938
INFO:causalml:    Gini   (Control):     0.8048
INFO:causalml:    Gini (Treatment):     0.7758
INFO:causalml:generating out-of-fold CV outcome estimates
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Average Treatment Effect (BaseXRegressor using XGBoost): 0.55 (0.46, 0.63)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>INFO:causalml:training the treatment effect model for 1 with R-loss
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[05:01:48] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
Average Treatment Effect (BaseRRegressor using XGBoost): 0.55 (0.55, 0.56)
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="calculate-individual-treatment-effect-ite-cate">
<h2>Calculate Individual Treatment Effect (ITE/CATE)<a class="headerlink" href="#calculate-individual-treatment-effect-ite-cate" title="Permalink to this headline">¶</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">causalml.inference.meta</span> <span class="kn">import</span> <span class="n">LRSRegressor</span>
<span class="kn">from</span> <span class="nn">causalml.inference.meta</span> <span class="kn">import</span> <span class="n">XGBTRegressor</span><span class="p">,</span> <span class="n">MLPTRegressor</span>
<span class="kn">from</span> <span class="nn">causalml.inference.meta</span> <span class="kn">import</span> <span class="n">BaseXRegressor</span><span class="p">,</span> <span class="n">BaseRRegressor</span><span class="p">,</span> <span class="n">BaseSRegressor</span><span class="p">,</span> <span class="n">BaseTRegressor</span>
<span class="kn">from</span> <span class="nn">causalml.match</span> <span class="kn">import</span> <span class="n">NearestNeighborMatch</span><span class="p">,</span> <span class="n">MatchOptimizer</span><span class="p">,</span> <span class="n">create_table_one</span>
<span class="kn">from</span> <span class="nn">causalml.propensity</span> <span class="kn">import</span> <span class="n">ElasticNetPropensityModel</span>
<span class="kn">from</span> <span class="nn">causalml.dataset</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">causalml.metrics</span> <span class="kn">import</span> <span class="o">*</span>
</pre></div>
</div>
</div>
</div>
<p><strong>S-learner</strong> estimates the treatment effect using a single machine learning model as follows:</p>
<p><strong>Stage 1</strong></p>
<p>Estimate the average outcomes 𝜇(𝑥)
with covariates 𝑋 and an indicator variable for treatment effect 𝑊:</p>
<div class="math notranslate nohighlight">
\[
\mu(x)=E[Y | X=x, W=w]
\]</div>
<p>using a machine learning model.</p>
<p><strong>Stage 2</strong></p>
<p>Define the CATE estimate as:</p>
<div class="math notranslate nohighlight">
\[
\hat{\tau}(x)=\hat{\mu}(x, W=1)-\hat{\mu}(x, W=0)
\]</div>
<p>Including the propensity score in the model can reduce bias from regularization induced confounding [hahn2017bayesian].</p>
<p>When the control and treatment groups are very different in covariates, a single linear model is not sufficient to encode the different relevant dimensions and smoothness of features for the control and treatment groups [alaa2018limits].</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># S Learner</span>
<span class="c1"># S-learner estimates the treatment effect using a single machine learning model</span>
<span class="c1"># It does nothave ITEs</span>
<span class="n">learner_s</span> <span class="o">=</span> <span class="n">LRSRegressor</span><span class="p">()</span>
<span class="n">cate_s</span> <span class="o">=</span> <span class="n">learner_s</span><span class="o">.</span><span class="n">fit_predict</span><span class="p">(</span><span class="n">X</span><span class="o">=</span><span class="n">X</span><span class="p">,</span> <span class="n">treatment</span><span class="o">=</span><span class="n">treatment</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>INFO:causalml:Error metrics for group 1
INFO:causalml:    RMSE   (Control):     0.9806
INFO:causalml:    RMSE (Treatment):     1.0203
INFO:causalml:   sMAPE   (Control):     0.7745
INFO:causalml:   sMAPE (Treatment):     0.4910
INFO:causalml:    Gini   (Control):     0.3145
INFO:causalml:    Gini (Treatment):     0.3964
</pre></div>
</div>
</div>
</div>
<p><strong>T-learner</strong> [kunzel2019metalearners] consists of two stages as follows:</p>
<p><strong>Stage 1</strong></p>
<p>Estimate the average outcomes 𝜇0(𝑥) and 𝜇1(𝑥):</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{array}{l}{\mu_{0}(x)=E[Y(0) | X=x] \text { and }} \\ {\mu_{1}(x)=E[Y(1) | X=x]}\end{array}
\end{split}\]</div>
<p>using machine learning models.</p>
<p><strong>Stage 2</strong>
Define the CATE estimate as:</p>
<div class="math notranslate nohighlight">
\[
\hat{\tau}(x)=\hat{\mu}_{1}(x)-\hat{\mu}_{0}(x)
\]</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># T Learner</span>
<span class="c1"># T-learner [kunzel2019metalearners] consists of two stages as follows:</span>
<span class="n">learner_t</span> <span class="o">=</span> <span class="n">BaseTRegressor</span><span class="p">(</span><span class="n">learner</span><span class="o">=</span><span class="n">XGBRegressor</span><span class="p">())</span>
<span class="n">cate_t</span> <span class="o">=</span> <span class="n">learner_t</span><span class="o">.</span><span class="n">fit_predict</span><span class="p">(</span><span class="n">X</span><span class="o">=</span><span class="n">X</span><span class="p">,</span> <span class="n">treatment</span><span class="o">=</span><span class="n">treatment</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p><strong>X-learner</strong> [kunzel2019metalearners] is an extension of T-learner, and consists of three stages as follows:</p>
<p><strong>Stage 1</strong></p>
<p>Estimate the average outcomes 𝜇0(𝑥) and 𝜇1(𝑥):</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{array}{l}{\mu_{0}(x)=E[Y(0) | X=x] \text { and }} \\ {\mu_{1}(x)=E[Y(1) | X=x]}\end{array}
\end{split}\]</div>
<p>using machine learning models.</p>
<p><strong>Stage 2</strong></p>
<p>Impute the user level treatment effects, 𝐷1𝑖
and 𝐷0𝑗 for user 𝑖 in the treatment group based on 𝜇0(𝑥), and user 𝑗 in the control groups based on 𝜇1(𝑥):</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned} D_{i}^{1} &amp;=Y_{i}^{1}-\hat{\mu}_{0}\left(X_{i}^{1}\right), \text { and } \\ D_{i}^{0} &amp;=\hat{\mu}_{1}\left(X_{i}^{0}\right)-Y^{\wedge} 0i \end{aligned}
\end{split}\]</div>
<p>Then estimate <span class="math notranslate nohighlight">\( \tau_{0}(x)=E\left[D^{0} | X=x\right]\)</span> and <span class="math notranslate nohighlight">\(\tau_{0}(x)=E\left[D^{0} | X=x\right]\)</span> using machine learning models</p>
<p><strong>Stage 3</strong>
Define the CATE estimate by a weighted average of 𝜏1(𝑥)
and 𝜏0(𝑥):</p>
<div class="math notranslate nohighlight">
\[
\tau(x)=g(x) \tau_{0}(x)+(1-g(x)) \tau_{1}(x)
\]</div>
<p>where 𝑔∈[0,1]. We can use propensity scores for 𝑔(𝑥).</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># X Learner</span>
<span class="c1"># Extension of T learner with ability to take on additional treatments</span>
<span class="n">learner_x</span> <span class="o">=</span> <span class="n">BaseXRegressor</span><span class="p">(</span><span class="n">learner</span><span class="o">=</span><span class="n">XGBRegressor</span><span class="p">())</span>
<span class="n">cate_x</span> <span class="o">=</span> <span class="n">learner_x</span><span class="o">.</span><span class="n">fit_predict</span><span class="p">(</span><span class="n">X</span><span class="o">=</span><span class="n">X</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="n">e</span><span class="p">,</span> <span class="n">treatment</span><span class="o">=</span><span class="n">treatment</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>INFO:causalml:Error metrics for group 1
INFO:causalml:    RMSE   (Control):     0.6662
INFO:causalml:    RMSE (Treatment):     0.7097
INFO:causalml:   sMAPE   (Control):     0.6223
INFO:causalml:   sMAPE (Treatment):     0.3938
INFO:causalml:    Gini   (Control):     0.8048
INFO:causalml:    Gini (Treatment):     0.7758
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[05:43:32] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
[05:43:32] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
[05:43:32] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
[05:43:32] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
</pre></div>
</div>
</div>
</div>
<p><strong>R-learner</strong> [nie2017quasi] uses the cross-validation out-of-fold estimates of outcomes 𝑚̂^(−𝑖) times (𝑥𝑖)
and propensity scores 𝑒̂^(−𝑖) times (𝑥𝑖). It consists of two stages as follows:</p>
<p><strong>Stage 1</strong>
Fit 𝑚̂ (𝑥)
and 𝑒̂ (𝑥) with machine learning models using cross-validation.</p>
<p><strong>Stage 2</strong>
Estimate treatment effects by minimising the R-loss, 𝐿̂ 𝑛(𝜏(𝑥))
:</p>
<div class="math notranslate nohighlight">
\[
\hat{L}_{n}(\tau(x))=\frac{1}{n} \sum_{i=1}^{n}\left(\left(Y_{i}-\hat{m}^{(-i)}\left(X_{i}\right)\right)-\left(W_{i}-\hat{e}^{(-i)}\left(X_{i}\right)\right) \tau\left(X_{i}\right)\right)^{2}
\]</div>
<p>where 𝑒^(−𝑖) times (𝑋𝑖), etc. denote the out-of-fold held-out predictions made without using the 𝑖-th training sample.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># R Learner uses propensity scores </span>
<span class="n">learner_r</span> <span class="o">=</span> <span class="n">BaseRRegressor</span><span class="p">(</span><span class="n">learner</span><span class="o">=</span><span class="n">XGBRegressor</span><span class="p">())</span>
<span class="n">cate_r</span> <span class="o">=</span> <span class="n">learner_r</span><span class="o">.</span><span class="n">fit_predict</span><span class="p">(</span><span class="n">X</span><span class="o">=</span><span class="n">X</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="n">e</span><span class="p">,</span> <span class="n">treatment</span><span class="o">=</span><span class="n">treatment</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">matplotlib</span> <span class="kn">import</span> <span class="n">pyplot</span> <span class="k">as</span> <span class="n">plt</span>

<span class="n">alpha</span><span class="o">=</span><span class="mf">0.2</span>
<span class="n">bins</span><span class="o">=</span><span class="mi">30</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span><span class="mi">8</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">cate_t</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="n">alpha</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="n">bins</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;T Learner&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">cate_x</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="n">alpha</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="n">bins</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;X Learner&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">cate_r</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="n">alpha</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="n">bins</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;R Learner&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">vlines</span><span class="p">(</span><span class="n">cate_s</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">0</span><span class="p">,</span> <span class="n">plt</span><span class="o">.</span><span class="n">axes</span><span class="p">()</span><span class="o">.</span><span class="n">get_ylim</span><span class="p">()[</span><span class="mi">1</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;S Learner&#39;</span><span class="p">,</span>
           <span class="n">linestyles</span><span class="o">=</span><span class="s1">&#39;dotted&#39;</span><span class="p">,</span> <span class="n">colors</span><span class="o">=</span><span class="s1">&#39;green&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Distribution of CATE Predictions by Meta Learner&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Individual Treatment Effect (ITE/CATE)&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;# of Samples&#39;</span><span class="p">)</span>
<span class="n">_</span><span class="o">=</span><span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/T990000_causal_inference_130_0.png" src="../_images/T990000_causal_inference_130_0.png" />
</div>
</div>
</div>
<div class="section" id="validity-of-meta-learner">
<h2>Validity of Meta-Learner<a class="headerlink" href="#validity-of-meta-learner" title="Permalink to this headline">¶</a></h2>
<p>We will validate the meta-learners’ performance based on the same synthetic data generation method in Part A (simulate_nuisance_and_easy_treatment).</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">train_summary</span><span class="p">,</span> <span class="n">validation_summary</span> <span class="o">=</span> <span class="n">get_synthetic_summary_holdout</span><span class="p">(</span><span class="n">simulate_nuisance_and_easy_treatment</span><span class="p">,</span>
                                                                  <span class="n">n</span><span class="o">=</span><span class="mi">10000</span><span class="p">,</span>
                                                                  <span class="n">valid_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span>
                                                                  <span class="n">k</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>


<span class="n">train_summary</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>INFO:causalml:AUC score: 0.804268
INFO:causalml:AUC score: 0.806955
INFO:causalml:Error metrics for group 1
INFO:causalml:    RMSE   (Control):     1.0433
INFO:causalml:    RMSE (Treatment):     1.0318
INFO:causalml:   sMAPE   (Control):     0.8394
INFO:causalml:   sMAPE (Treatment):     0.4889
INFO:causalml:    Gini   (Control):     0.2768
INFO:causalml:    Gini (Treatment):     0.3797
INFO:causalml:Error metrics for group 1
INFO:causalml:    RMSE   (Control):     1.0248
INFO:causalml:    RMSE (Treatment):     1.0349
INFO:causalml:   sMAPE   (Control):     0.8052
INFO:causalml:   sMAPE (Treatment):     0.4905
INFO:causalml:    Gini   (Control):     0.3268
INFO:causalml:    Gini (Treatment):     0.3840
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[05:09:36] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>INFO:causalml:Error metrics for group 1
INFO:causalml:    RMSE   (Control):     0.9689
INFO:causalml:    RMSE (Treatment):     0.9784
INFO:causalml:   sMAPE   (Control):     0.8124
INFO:causalml:   sMAPE (Treatment):     0.4754
INFO:causalml:    Gini   (Control):     0.4409
INFO:causalml:    Gini (Treatment):     0.4817
INFO:causalml:Error metrics for group 1
INFO:causalml:    RMSE   (Control):     1.0024
INFO:causalml:    RMSE (Treatment):     1.0094
INFO:causalml:   sMAPE   (Control):     0.7971
INFO:causalml:   sMAPE (Treatment):     0.4850
INFO:causalml:    Gini   (Control):     0.3809
INFO:causalml:    Gini (Treatment):     0.4369
INFO:causalml:Error metrics for group 1
INFO:causalml:    RMSE   (Control):     1.0364
INFO:causalml:    RMSE (Treatment):     1.0234
INFO:causalml:   sMAPE   (Control):     0.8299
INFO:causalml:   sMAPE (Treatment):     0.4901
INFO:causalml:    Gini   (Control):     0.2855
INFO:causalml:    Gini (Treatment):     0.3913
INFO:causalml:Error metrics for group 1
INFO:causalml:    RMSE   (Control):     1.0150
INFO:causalml:    RMSE (Treatment):     1.0323
INFO:causalml:   sMAPE   (Control):     0.7941
INFO:causalml:   sMAPE (Treatment):     0.4941
INFO:causalml:    Gini   (Control):     0.3513
INFO:causalml:    Gini (Treatment):     0.3863
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[05:09:37] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
[05:09:37] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>INFO:causalml:Error metrics for group 1
INFO:causalml:    RMSE   (Control):     0.9423
INFO:causalml:    RMSE (Treatment):     0.9456
INFO:causalml:   sMAPE   (Control):     0.7981
INFO:causalml:   sMAPE (Treatment):     0.4664
INFO:causalml:    Gini   (Control):     0.5050
INFO:causalml:    Gini (Treatment):     0.5244
INFO:causalml:Error metrics for group 1
INFO:causalml:    RMSE   (Control):     1.0033
INFO:causalml:    RMSE (Treatment):     1.0145
INFO:causalml:   sMAPE   (Control):     0.7930
INFO:causalml:   sMAPE (Treatment):     0.4885
INFO:causalml:    Gini   (Control):     0.3797
INFO:causalml:    Gini (Treatment):     0.4245
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[05:09:37] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
[05:09:38] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
[05:09:38] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
[05:09:38] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>INFO:causalml:generating out-of-fold CV outcome estimates
INFO:causalml:training the treatment effect model for 1 with R-loss
INFO:causalml:generating out-of-fold CV outcome estimates
INFO:causalml:training the treatment effect model for 1 with R-loss
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[05:09:43] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>INFO:causalml:AUC score: 0.803987
INFO:causalml:AUC score: 0.801489
INFO:causalml:Error metrics for group 1
INFO:causalml:    RMSE   (Control):     1.0414
INFO:causalml:    RMSE (Treatment):     1.0476
INFO:causalml:   sMAPE   (Control):     0.8484
INFO:causalml:   sMAPE (Treatment):     0.5069
INFO:causalml:    Gini   (Control):     0.3213
INFO:causalml:    Gini (Treatment):     0.3907
INFO:causalml:Error metrics for group 1
INFO:causalml:    RMSE   (Control):     1.0238
INFO:causalml:    RMSE (Treatment):     1.0142
INFO:causalml:   sMAPE   (Control):     0.8313
INFO:causalml:   sMAPE (Treatment):     0.4819
INFO:causalml:    Gini   (Control):     0.2661
INFO:causalml:    Gini (Treatment):     0.3764
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[05:09:44] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>INFO:causalml:Error metrics for group 1
INFO:causalml:    RMSE   (Control):     0.9780
INFO:causalml:    RMSE (Treatment):     0.9889
INFO:causalml:   sMAPE   (Control):     0.8226
INFO:causalml:   sMAPE (Treatment):     0.4888
INFO:causalml:    Gini   (Control):     0.4546
INFO:causalml:    Gini (Treatment):     0.4962
INFO:causalml:Error metrics for group 1
INFO:causalml:    RMSE   (Control):     0.9890
INFO:causalml:    RMSE (Treatment):     1.0007
INFO:causalml:   sMAPE   (Control):     0.8251
INFO:causalml:   sMAPE (Treatment):     0.4830
INFO:causalml:    Gini   (Control):     0.3465
INFO:causalml:    Gini (Treatment):     0.3997
INFO:causalml:Error metrics for group 1
INFO:causalml:    RMSE   (Control):     1.0361
INFO:causalml:    RMSE (Treatment):     1.0419
INFO:causalml:   sMAPE   (Control):     0.8378
INFO:causalml:   sMAPE (Treatment):     0.5062
INFO:causalml:    Gini   (Control):     0.3294
INFO:causalml:    Gini (Treatment):     0.3993
INFO:causalml:Error metrics for group 1
INFO:causalml:    RMSE   (Control):     1.0117
INFO:causalml:    RMSE (Treatment):     1.0099
INFO:causalml:   sMAPE   (Control):     0.8180
INFO:causalml:   sMAPE (Treatment):     0.4815
INFO:causalml:    Gini   (Control):     0.2804
INFO:causalml:    Gini (Treatment):     0.3844
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[05:09:45] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
[05:09:45] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>INFO:causalml:Error metrics for group 1
INFO:causalml:    RMSE   (Control):     0.9556
INFO:causalml:    RMSE (Treatment):     0.9537
INFO:causalml:   sMAPE   (Control):     0.8129
INFO:causalml:   sMAPE (Treatment):     0.4783
INFO:causalml:    Gini   (Control):     0.5015
INFO:causalml:    Gini (Treatment):     0.5447
INFO:causalml:Error metrics for group 1
INFO:causalml:    RMSE   (Control):     0.9933
INFO:causalml:    RMSE (Treatment):     1.0035
INFO:causalml:   sMAPE   (Control):     0.8268
INFO:causalml:   sMAPE (Treatment):     0.4855
INFO:causalml:    Gini   (Control):     0.3398
INFO:causalml:    Gini (Treatment):     0.3958
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[05:09:46] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
[05:09:46] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
[05:09:46] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
[05:09:46] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>INFO:causalml:generating out-of-fold CV outcome estimates
INFO:causalml:training the treatment effect model for 1 with R-loss
INFO:causalml:generating out-of-fold CV outcome estimates
INFO:causalml:training the treatment effect model for 1 with R-loss
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[05:09:52] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>INFO:causalml:AUC score: 0.809579
INFO:causalml:AUC score: 0.801193
INFO:causalml:Error metrics for group 1
INFO:causalml:    RMSE   (Control):     1.0327
INFO:causalml:    RMSE (Treatment):     1.0187
INFO:causalml:   sMAPE   (Control):     0.8359
INFO:causalml:   sMAPE (Treatment):     0.4866
INFO:causalml:    Gini   (Control):     0.3124
INFO:causalml:    Gini (Treatment):     0.3883
INFO:causalml:Error metrics for group 1
INFO:causalml:    RMSE   (Control):     1.0468
INFO:causalml:    RMSE (Treatment):     1.0635
INFO:causalml:   sMAPE   (Control):     0.8546
INFO:causalml:   sMAPE (Treatment):     0.5144
INFO:causalml:    Gini   (Control):     0.3522
INFO:causalml:    Gini (Treatment):     0.3939
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[05:09:53] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>INFO:causalml:Error metrics for group 1
INFO:causalml:    RMSE   (Control):     0.9667
INFO:causalml:    RMSE (Treatment):     0.9615
INFO:causalml:   sMAPE   (Control):     0.8058
INFO:causalml:   sMAPE (Treatment):     0.4706
INFO:causalml:    Gini   (Control):     0.4520
INFO:causalml:    Gini (Treatment):     0.4941
INFO:causalml:Error metrics for group 1
INFO:causalml:    RMSE   (Control):     1.0277
INFO:causalml:    RMSE (Treatment):     1.0527
INFO:causalml:   sMAPE   (Control):     0.8569
INFO:causalml:   sMAPE (Treatment):     0.5140
INFO:causalml:    Gini   (Control):     0.3987
INFO:causalml:    Gini (Treatment):     0.4190
INFO:causalml:Error metrics for group 1
INFO:causalml:    RMSE   (Control):     1.0267
INFO:causalml:    RMSE (Treatment):     1.0119
INFO:causalml:   sMAPE   (Control):     0.8258
INFO:causalml:   sMAPE (Treatment):     0.4864
INFO:causalml:    Gini   (Control):     0.3201
INFO:causalml:    Gini (Treatment):     0.4008
INFO:causalml:Error metrics for group 1
INFO:causalml:    RMSE   (Control):     1.0448
INFO:causalml:    RMSE (Treatment):     1.0541
INFO:causalml:   sMAPE   (Control):     0.8483
INFO:causalml:   sMAPE (Treatment):     0.5135
INFO:causalml:    Gini   (Control):     0.3611
INFO:causalml:    Gini (Treatment):     0.4153
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[05:09:53] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
[05:09:53] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>INFO:causalml:Error metrics for group 1
INFO:causalml:    RMSE   (Control):     0.9417
INFO:causalml:    RMSE (Treatment):     0.9314
INFO:causalml:   sMAPE   (Control):     0.7892
INFO:causalml:   sMAPE (Treatment):     0.4600
INFO:causalml:    Gini   (Control):     0.5038
INFO:causalml:    Gini (Treatment):     0.5340
INFO:causalml:Error metrics for group 1
INFO:causalml:    RMSE   (Control):     1.0304
INFO:causalml:    RMSE (Treatment):     1.0491
INFO:causalml:   sMAPE   (Control):     0.8540
INFO:causalml:   sMAPE (Treatment):     0.5151
INFO:causalml:    Gini   (Control):     0.3905
INFO:causalml:    Gini (Treatment):     0.4184
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[05:09:54] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
[05:09:54] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
[05:09:54] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
[05:09:55] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>INFO:causalml:generating out-of-fold CV outcome estimates
INFO:causalml:training the treatment effect model for 1 with R-loss
INFO:causalml:generating out-of-fold CV outcome estimates
INFO:causalml:training the treatment effect model for 1 with R-loss
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[05:10:00] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>INFO:causalml:AUC score: 0.808206
INFO:causalml:AUC score: 0.784190
INFO:causalml:Error metrics for group 1
INFO:causalml:    RMSE   (Control):     1.0358
INFO:causalml:    RMSE (Treatment):     1.0394
INFO:causalml:   sMAPE   (Control):     0.8367
INFO:causalml:   sMAPE (Treatment):     0.4950
INFO:causalml:    Gini   (Control):     0.2901
INFO:causalml:    Gini (Treatment):     0.3464
INFO:causalml:Error metrics for group 1
INFO:causalml:    RMSE   (Control):     1.0165
INFO:causalml:    RMSE (Treatment):     1.0409
INFO:causalml:   sMAPE   (Control):     0.8124
INFO:causalml:   sMAPE (Treatment):     0.5134
INFO:causalml:    Gini   (Control):     0.3018
INFO:causalml:    Gini (Treatment):     0.3141
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[05:10:01] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>INFO:causalml:Error metrics for group 1
INFO:causalml:    RMSE   (Control):     0.9617
INFO:causalml:    RMSE (Treatment):     0.9774
INFO:causalml:   sMAPE   (Control):     0.8102
INFO:causalml:   sMAPE (Treatment):     0.4765
INFO:causalml:    Gini   (Control):     0.4527
INFO:causalml:    Gini (Treatment):     0.4775
INFO:causalml:Error metrics for group 1
INFO:causalml:    RMSE   (Control):     1.0011
INFO:causalml:    RMSE (Treatment):     1.0141
INFO:causalml:   sMAPE   (Control):     0.8231
INFO:causalml:   sMAPE (Treatment):     0.5069
INFO:causalml:    Gini   (Control):     0.3478
INFO:causalml:    Gini (Treatment):     0.3815
INFO:causalml:Error metrics for group 1
INFO:causalml:    RMSE   (Control):     1.0306
INFO:causalml:    RMSE (Treatment):     1.0338
INFO:causalml:   sMAPE   (Control):     0.8313
INFO:causalml:   sMAPE (Treatment):     0.4937
INFO:causalml:    Gini   (Control):     0.2995
INFO:causalml:    Gini (Treatment):     0.3612
INFO:causalml:Error metrics for group 1
INFO:causalml:    RMSE   (Control):     1.0145
INFO:causalml:    RMSE (Treatment):     1.0320
INFO:causalml:   sMAPE   (Control):     0.8144
INFO:causalml:   sMAPE (Treatment):     0.5126
INFO:causalml:    Gini   (Control):     0.3061
INFO:causalml:    Gini (Treatment):     0.3369
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[05:10:01] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
[05:10:02] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>INFO:causalml:Error metrics for group 1
INFO:causalml:    RMSE   (Control):     0.9358
INFO:causalml:    RMSE (Treatment):     0.9528
INFO:causalml:   sMAPE   (Control):     0.7926
INFO:causalml:   sMAPE (Treatment):     0.4704
INFO:causalml:    Gini   (Control):     0.5078
INFO:causalml:    Gini (Treatment):     0.5152
INFO:causalml:Error metrics for group 1
INFO:causalml:    RMSE   (Control):     1.0078
INFO:causalml:    RMSE (Treatment):     1.0176
INFO:causalml:   sMAPE   (Control):     0.8272
INFO:causalml:   sMAPE (Treatment):     0.5090
INFO:causalml:    Gini   (Control):     0.3318
INFO:causalml:    Gini (Treatment):     0.3732
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[05:10:02] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
[05:10:02] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
[05:10:03] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
[05:10:03] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>INFO:causalml:generating out-of-fold CV outcome estimates
INFO:causalml:training the treatment effect model for 1 with R-loss
INFO:causalml:generating out-of-fold CV outcome estimates
INFO:causalml:training the treatment effect model for 1 with R-loss
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[05:10:08] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>INFO:causalml:AUC score: 0.797272
INFO:causalml:AUC score: 0.800964
INFO:causalml:Error metrics for group 1
INFO:causalml:    RMSE   (Control):     1.0242
INFO:causalml:    RMSE (Treatment):     1.0312
INFO:causalml:   sMAPE   (Control):     0.8414
INFO:causalml:   sMAPE (Treatment):     0.4831
INFO:causalml:    Gini   (Control):     0.3164
INFO:causalml:    Gini (Treatment):     0.3885
INFO:causalml:Error metrics for group 1
INFO:causalml:    RMSE   (Control):     1.0519
INFO:causalml:    RMSE (Treatment):     1.0257
INFO:causalml:   sMAPE   (Control):     0.8645
INFO:causalml:   sMAPE (Treatment):     0.4725
INFO:causalml:    Gini   (Control):     0.2908
INFO:causalml:    Gini (Treatment):     0.3392
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[05:10:09] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>INFO:causalml:Error metrics for group 1
INFO:causalml:    RMSE   (Control):     0.9518
INFO:causalml:    RMSE (Treatment):     0.9706
INFO:causalml:   sMAPE   (Control):     0.8105
INFO:causalml:   sMAPE (Treatment):     0.4652
INFO:causalml:    Gini   (Control):     0.4679
INFO:causalml:    Gini (Treatment):     0.5007
INFO:causalml:Error metrics for group 1
INFO:causalml:    RMSE   (Control):     1.0351
INFO:causalml:    RMSE (Treatment):     1.0081
INFO:causalml:   sMAPE   (Control):     0.8605
INFO:causalml:   sMAPE (Treatment):     0.4713
INFO:causalml:    Gini   (Control):     0.3362
INFO:causalml:    Gini (Treatment):     0.3761
INFO:causalml:Error metrics for group 1
INFO:causalml:    RMSE   (Control):     1.0194
INFO:causalml:    RMSE (Treatment):     1.0254
INFO:causalml:   sMAPE   (Control):     0.8312
INFO:causalml:   sMAPE (Treatment):     0.4834
INFO:causalml:    Gini   (Control):     0.3205
INFO:causalml:    Gini (Treatment):     0.3976
INFO:causalml:Error metrics for group 1
INFO:causalml:    RMSE   (Control):     1.0424
INFO:causalml:    RMSE (Treatment):     1.0177
INFO:causalml:   sMAPE   (Control):     0.8529
INFO:causalml:   sMAPE (Treatment):     0.4750
INFO:causalml:    Gini   (Control):     0.3086
INFO:causalml:    Gini (Treatment):     0.3621
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[05:10:10] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
[05:10:10] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>INFO:causalml:Error metrics for group 1
INFO:causalml:    RMSE   (Control):     0.9300
INFO:causalml:    RMSE (Treatment):     0.9435
INFO:causalml:   sMAPE   (Control):     0.7964
INFO:causalml:   sMAPE (Treatment):     0.4573
INFO:causalml:    Gini   (Control):     0.5063
INFO:causalml:    Gini (Treatment):     0.5396
INFO:causalml:Error metrics for group 1
INFO:causalml:    RMSE   (Control):     1.0370
INFO:causalml:    RMSE (Treatment):     1.0191
INFO:causalml:   sMAPE   (Control):     0.8630
INFO:causalml:   sMAPE (Treatment):     0.4777
INFO:causalml:    Gini   (Control):     0.3443
INFO:causalml:    Gini (Treatment):     0.3671
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[05:10:10] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
[05:10:11] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
[05:10:11] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
[05:10:11] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>INFO:causalml:generating out-of-fold CV outcome estimates
INFO:causalml:training the treatment effect model for 1 with R-loss
INFO:causalml:generating out-of-fold CV outcome estimates
INFO:causalml:training the treatment effect model for 1 with R-loss
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[05:10:17] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>INFO:causalml:AUC score: 0.806111
INFO:causalml:AUC score: 0.825484
INFO:causalml:Error metrics for group 1
INFO:causalml:    RMSE   (Control):     1.0400
INFO:causalml:    RMSE (Treatment):     1.0219
INFO:causalml:   sMAPE   (Control):     0.8344
INFO:causalml:   sMAPE (Treatment):     0.4847
INFO:causalml:    Gini   (Control):     0.2921
INFO:causalml:    Gini (Treatment):     0.3678
INFO:causalml:Error metrics for group 1
INFO:causalml:    RMSE   (Control):     0.9898
INFO:causalml:    RMSE (Treatment):     1.0499
INFO:causalml:   sMAPE   (Control):     0.7729
INFO:causalml:   sMAPE (Treatment):     0.4896
INFO:causalml:    Gini   (Control):     0.3385
INFO:causalml:    Gini (Treatment):     0.3474
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[05:10:17] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>INFO:causalml:Error metrics for group 1
INFO:causalml:    RMSE   (Control):     0.9635
INFO:causalml:    RMSE (Treatment):     0.9571
INFO:causalml:   sMAPE   (Control):     0.8096
INFO:causalml:   sMAPE (Treatment):     0.4664
INFO:causalml:    Gini   (Control):     0.4580
INFO:causalml:    Gini (Treatment):     0.4930
INFO:causalml:Error metrics for group 1
INFO:causalml:    RMSE   (Control):     0.9831
INFO:causalml:    RMSE (Treatment):     1.0320
INFO:causalml:   sMAPE   (Control):     0.7824
INFO:causalml:   sMAPE (Treatment):     0.4918
INFO:causalml:    Gini   (Control):     0.3469
INFO:causalml:    Gini (Treatment):     0.3912
INFO:causalml:Error metrics for group 1
INFO:causalml:    RMSE   (Control):     1.0336
INFO:causalml:    RMSE (Treatment):     1.0138
INFO:causalml:   sMAPE   (Control):     0.8262
INFO:causalml:   sMAPE (Treatment):     0.4845
INFO:causalml:    Gini   (Control):     0.3025
INFO:causalml:    Gini (Treatment):     0.3843
INFO:causalml:Error metrics for group 1
INFO:causalml:    RMSE   (Control):     0.9855
INFO:causalml:    RMSE (Treatment):     1.0427
INFO:causalml:   sMAPE   (Control):     0.7658
INFO:causalml:   sMAPE (Treatment):     0.4884
INFO:causalml:    Gini   (Control):     0.3495
INFO:causalml:    Gini (Treatment):     0.3624
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[05:10:18] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
[05:10:18] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>INFO:causalml:Error metrics for group 1
INFO:causalml:    RMSE   (Control):     0.9384
INFO:causalml:    RMSE (Treatment):     0.9254
INFO:causalml:   sMAPE   (Control):     0.7961
INFO:causalml:   sMAPE (Treatment):     0.4584
INFO:causalml:    Gini   (Control):     0.5090
INFO:causalml:    Gini (Treatment):     0.5368
INFO:causalml:Error metrics for group 1
INFO:causalml:    RMSE   (Control):     0.9934
INFO:causalml:    RMSE (Treatment):     1.0383
INFO:causalml:   sMAPE   (Control):     0.7823
INFO:causalml:   sMAPE (Treatment):     0.4944
INFO:causalml:    Gini   (Control):     0.3266
INFO:causalml:    Gini (Treatment):     0.3723
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[05:10:19] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
[05:10:19] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
[05:10:19] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
[05:10:19] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>INFO:causalml:generating out-of-fold CV outcome estimates
INFO:causalml:training the treatment effect model for 1 with R-loss
INFO:causalml:generating out-of-fold CV outcome estimates
INFO:causalml:training the treatment effect model for 1 with R-loss
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[05:10:25] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>INFO:causalml:AUC score: 0.806224
INFO:causalml:AUC score: 0.795743
INFO:causalml:Error metrics for group 1
INFO:causalml:    RMSE   (Control):     1.0438
INFO:causalml:    RMSE (Treatment):     1.0245
INFO:causalml:   sMAPE   (Control):     0.8584
INFO:causalml:   sMAPE (Treatment):     0.4852
INFO:causalml:    Gini   (Control):     0.2975
INFO:causalml:    Gini (Treatment):     0.3759
INFO:causalml:Error metrics for group 1
INFO:causalml:    RMSE   (Control):     1.0473
INFO:causalml:    RMSE (Treatment):     1.0858
INFO:causalml:   sMAPE   (Control):     0.8487
INFO:causalml:   sMAPE (Treatment):     0.5355
INFO:causalml:    Gini   (Control):     0.3300
INFO:causalml:    Gini (Treatment):     0.3635
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[05:10:26] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>INFO:causalml:Error metrics for group 1
INFO:causalml:    RMSE   (Control):     0.9746
INFO:causalml:    RMSE (Treatment):     0.9639
INFO:causalml:   sMAPE   (Control):     0.8281
INFO:causalml:   sMAPE (Treatment):     0.4686
INFO:causalml:    Gini   (Control):     0.4542
INFO:causalml:    Gini (Treatment):     0.4891
INFO:causalml:Error metrics for group 1
INFO:causalml:    RMSE   (Control):     1.0378
INFO:causalml:    RMSE (Treatment):     1.0584
INFO:causalml:   sMAPE   (Control):     0.8457
INFO:causalml:   sMAPE (Treatment):     0.5285
INFO:causalml:    Gini   (Control):     0.3443
INFO:causalml:    Gini (Treatment):     0.4084
INFO:causalml:Error metrics for group 1
INFO:causalml:    RMSE   (Control):     1.0373
INFO:causalml:    RMSE (Treatment):     1.0170
INFO:causalml:   sMAPE   (Control):     0.8495
INFO:causalml:   sMAPE (Treatment):     0.4856
INFO:causalml:    Gini   (Control):     0.3088
INFO:causalml:    Gini (Treatment):     0.3891
INFO:causalml:Error metrics for group 1
INFO:causalml:    RMSE   (Control):     1.0402
INFO:causalml:    RMSE (Treatment):     1.0745
INFO:causalml:   sMAPE   (Control):     0.8420
INFO:causalml:   sMAPE (Treatment):     0.5344
INFO:causalml:    Gini   (Control):     0.3493
INFO:causalml:    Gini (Treatment):     0.3859
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[05:10:26] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
[05:10:27] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>INFO:causalml:Error metrics for group 1
INFO:causalml:    RMSE   (Control):     0.9490
INFO:causalml:    RMSE (Treatment):     0.9368
INFO:causalml:   sMAPE   (Control):     0.8147
INFO:causalml:   sMAPE (Treatment):     0.4603
INFO:causalml:    Gini   (Control):     0.5000
INFO:causalml:    Gini (Treatment):     0.5303
INFO:causalml:Error metrics for group 1
INFO:causalml:    RMSE   (Control):     1.0376
INFO:causalml:    RMSE (Treatment):     1.0609
INFO:causalml:   sMAPE   (Control):     0.8517
INFO:causalml:   sMAPE (Treatment):     0.5342
INFO:causalml:    Gini   (Control):     0.3486
INFO:causalml:    Gini (Treatment):     0.4099
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[05:10:27] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
[05:10:27] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
[05:10:28] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
[05:10:28] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>INFO:causalml:generating out-of-fold CV outcome estimates
INFO:causalml:training the treatment effect model for 1 with R-loss
INFO:causalml:generating out-of-fold CV outcome estimates
INFO:causalml:training the treatment effect model for 1 with R-loss
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[05:10:33] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>INFO:causalml:AUC score: 0.798686
INFO:causalml:AUC score: 0.808161
INFO:causalml:Error metrics for group 1
INFO:causalml:    RMSE   (Control):     1.0570
INFO:causalml:    RMSE (Treatment):     1.0464
INFO:causalml:   sMAPE   (Control):     0.8568
INFO:causalml:   sMAPE (Treatment):     0.5016
INFO:causalml:    Gini   (Control):     0.3144
INFO:causalml:    Gini (Treatment):     0.3762
INFO:causalml:Error metrics for group 1
INFO:causalml:    RMSE   (Control):     1.0638
INFO:causalml:    RMSE (Treatment):     1.0526
INFO:causalml:   sMAPE   (Control):     0.8719
INFO:causalml:   sMAPE (Treatment):     0.5160
INFO:causalml:    Gini   (Control):     0.3118
INFO:causalml:    Gini (Treatment):     0.3791
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[05:10:34] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>INFO:causalml:Error metrics for group 1
INFO:causalml:    RMSE   (Control):     0.9843
INFO:causalml:    RMSE (Treatment):     0.9810
INFO:causalml:   sMAPE   (Control):     0.8303
INFO:causalml:   sMAPE (Treatment):     0.4808
INFO:causalml:    Gini   (Control):     0.4649
INFO:causalml:    Gini (Treatment):     0.4983
INFO:causalml:Error metrics for group 1
INFO:causalml:    RMSE   (Control):     1.0459
INFO:causalml:    RMSE (Treatment):     1.0379
INFO:causalml:   sMAPE   (Control):     0.8702
INFO:causalml:   sMAPE (Treatment):     0.5179
INFO:causalml:    Gini   (Control):     0.3492
INFO:causalml:    Gini (Treatment):     0.4097
INFO:causalml:Error metrics for group 1
INFO:causalml:    RMSE   (Control):     1.0496
INFO:causalml:    RMSE (Treatment):     1.0370
INFO:causalml:   sMAPE   (Control):     0.8478
INFO:causalml:   sMAPE (Treatment):     0.5002
INFO:causalml:    Gini   (Control):     0.3321
INFO:causalml:    Gini (Treatment):     0.3951
INFO:causalml:Error metrics for group 1
INFO:causalml:    RMSE   (Control):     1.0630
INFO:causalml:    RMSE (Treatment):     1.0457
INFO:causalml:   sMAPE   (Control):     0.8700
INFO:causalml:   sMAPE (Treatment):     0.5167
INFO:causalml:    Gini   (Control):     0.3045
INFO:causalml:    Gini (Treatment):     0.3937
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[05:10:35] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
[05:10:35] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>INFO:causalml:Error metrics for group 1
INFO:causalml:    RMSE   (Control):     0.9580
INFO:causalml:    RMSE (Treatment):     0.9450
INFO:causalml:   sMAPE   (Control):     0.8171
INFO:causalml:   sMAPE (Treatment):     0.4692
INFO:causalml:    Gini   (Control):     0.5145
INFO:causalml:    Gini (Treatment):     0.5480
INFO:causalml:Error metrics for group 1
INFO:causalml:    RMSE   (Control):     1.0450
INFO:causalml:    RMSE (Treatment):     1.0364
INFO:causalml:   sMAPE   (Control):     0.8652
INFO:causalml:   sMAPE (Treatment):     0.5212
INFO:causalml:    Gini   (Control):     0.3551
INFO:causalml:    Gini (Treatment):     0.4097
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[05:10:35] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
[05:10:36] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
[05:10:36] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
[05:10:36] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>INFO:causalml:generating out-of-fold CV outcome estimates
INFO:causalml:training the treatment effect model for 1 with R-loss
INFO:causalml:generating out-of-fold CV outcome estimates
INFO:causalml:training the treatment effect model for 1 with R-loss
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[05:10:41] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>INFO:causalml:AUC score: 0.809268
INFO:causalml:AUC score: 0.814661
INFO:causalml:Error metrics for group 1
INFO:causalml:    RMSE   (Control):     1.0362
INFO:causalml:    RMSE (Treatment):     1.0409
INFO:causalml:   sMAPE   (Control):     0.8421
INFO:causalml:   sMAPE (Treatment):     0.4832
INFO:causalml:    Gini   (Control):     0.3226
INFO:causalml:    Gini (Treatment):     0.3644
INFO:causalml:Error metrics for group 1
INFO:causalml:    RMSE   (Control):     1.0397
INFO:causalml:    RMSE (Treatment):     1.0378
INFO:causalml:   sMAPE   (Control):     0.8601
INFO:causalml:   sMAPE (Treatment):     0.4827
INFO:causalml:    Gini   (Control):     0.3192
INFO:causalml:    Gini (Treatment):     0.3790
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[05:10:42] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>INFO:causalml:Error metrics for group 1
INFO:causalml:    RMSE   (Control):     0.9735
INFO:causalml:    RMSE (Treatment):     0.9825
INFO:causalml:   sMAPE   (Control):     0.8197
INFO:causalml:   sMAPE (Treatment):     0.4642
INFO:causalml:    Gini   (Control):     0.4584
INFO:causalml:    Gini (Treatment):     0.4853
INFO:causalml:Error metrics for group 1
INFO:causalml:    RMSE   (Control):     1.0244
INFO:causalml:    RMSE (Treatment):     1.0121
INFO:causalml:   sMAPE   (Control):     0.8605
INFO:causalml:   sMAPE (Treatment):     0.4767
INFO:causalml:    Gini   (Control):     0.3569
INFO:causalml:    Gini (Treatment):     0.4299
INFO:causalml:Error metrics for group 1
INFO:causalml:    RMSE   (Control):     1.0325
INFO:causalml:    RMSE (Treatment):     1.0363
INFO:causalml:   sMAPE   (Control):     0.8371
INFO:causalml:   sMAPE (Treatment):     0.4834
INFO:causalml:    Gini   (Control):     0.3292
INFO:causalml:    Gini (Treatment):     0.3743
INFO:causalml:Error metrics for group 1
INFO:causalml:    RMSE   (Control):     1.0402
INFO:causalml:    RMSE (Treatment):     1.0326
INFO:causalml:   sMAPE   (Control):     0.8564
INFO:causalml:   sMAPE (Treatment):     0.4834
INFO:causalml:    Gini   (Control):     0.3174
INFO:causalml:    Gini (Treatment):     0.3837
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[05:10:43] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
[05:10:43] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>INFO:causalml:Error metrics for group 1
INFO:causalml:    RMSE   (Control):     0.9494
INFO:causalml:    RMSE (Treatment):     0.9536
INFO:causalml:   sMAPE   (Control):     0.8053
INFO:causalml:   sMAPE (Treatment):     0.4553
INFO:causalml:    Gini   (Control):     0.5081
INFO:causalml:    Gini (Treatment):     0.5239
INFO:causalml:Error metrics for group 1
INFO:causalml:    RMSE   (Control):     1.0272
INFO:causalml:    RMSE (Treatment):     1.0127
INFO:causalml:   sMAPE   (Control):     0.8610
INFO:causalml:   sMAPE (Treatment):     0.4783
INFO:causalml:    Gini   (Control):     0.3528
INFO:causalml:    Gini (Treatment):     0.4289
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[05:10:44] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
[05:10:44] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
[05:10:44] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
[05:10:45] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>INFO:causalml:generating out-of-fold CV outcome estimates
INFO:causalml:training the treatment effect model for 1 with R-loss
INFO:causalml:generating out-of-fold CV outcome estimates
INFO:causalml:training the treatment effect model for 1 with R-loss
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[05:10:50] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>INFO:causalml:AUC score: 0.804757
INFO:causalml:AUC score: 0.801460
INFO:causalml:Error metrics for group 1
INFO:causalml:    RMSE   (Control):     1.0515
INFO:causalml:    RMSE (Treatment):     1.0508
INFO:causalml:   sMAPE   (Control):     0.8627
INFO:causalml:   sMAPE (Treatment):     0.4957
INFO:causalml:    Gini   (Control):     0.2869
INFO:causalml:    Gini (Treatment):     0.3847
INFO:causalml:Error metrics for group 1
INFO:causalml:    RMSE   (Control):     1.0477
INFO:causalml:    RMSE (Treatment):     1.0065
INFO:causalml:   sMAPE   (Control):     0.8121
INFO:causalml:   sMAPE (Treatment):     0.4701
INFO:causalml:    Gini   (Control):     0.2826
INFO:causalml:    Gini (Treatment):     0.3393
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[05:10:51] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>INFO:causalml:Error metrics for group 1
INFO:causalml:    RMSE   (Control):     0.9771
INFO:causalml:    RMSE (Treatment):     0.9858
INFO:causalml:   sMAPE   (Control):     0.8338
INFO:causalml:   sMAPE (Treatment):     0.4797
INFO:causalml:    Gini   (Control):     0.4505
INFO:causalml:    Gini (Treatment):     0.5034
INFO:causalml:Error metrics for group 1
INFO:causalml:    RMSE   (Control):     1.0235
INFO:causalml:    RMSE (Treatment):     1.0000
INFO:causalml:   sMAPE   (Control):     0.8152
INFO:causalml:   sMAPE (Treatment):     0.4753
INFO:causalml:    Gini   (Control):     0.3442
INFO:causalml:    Gini (Treatment):     0.3631
INFO:causalml:Error metrics for group 1
INFO:causalml:    RMSE   (Control):     1.0445
INFO:causalml:    RMSE (Treatment):     1.0425
INFO:causalml:   sMAPE   (Control):     0.8505
INFO:causalml:   sMAPE (Treatment):     0.4963
INFO:causalml:    Gini   (Control):     0.2940
INFO:causalml:    Gini (Treatment):     0.3976
INFO:causalml:Error metrics for group 1
INFO:causalml:    RMSE   (Control):     1.0398
INFO:causalml:    RMSE (Treatment):     1.0056
INFO:causalml:   sMAPE   (Control):     0.7994
INFO:causalml:   sMAPE (Treatment):     0.4731
INFO:causalml:    Gini   (Control):     0.3017
INFO:causalml:    Gini (Treatment):     0.3525
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[05:10:51] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
[05:10:52] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>INFO:causalml:Error metrics for group 1
INFO:causalml:    RMSE   (Control):     0.9506
INFO:causalml:    RMSE (Treatment):     0.9559
INFO:causalml:   sMAPE   (Control):     0.8163
INFO:causalml:   sMAPE (Treatment):     0.4716
INFO:causalml:    Gini   (Control):     0.5076
INFO:causalml:    Gini (Treatment):     0.5412
INFO:causalml:Error metrics for group 1
INFO:causalml:    RMSE   (Control):     1.0285
INFO:causalml:    RMSE (Treatment):     1.0049
INFO:causalml:   sMAPE   (Control):     0.8151
INFO:causalml:   sMAPE (Treatment):     0.4795
INFO:causalml:    Gini   (Control):     0.3342
INFO:causalml:    Gini (Treatment):     0.3577
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[05:10:52] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
[05:10:52] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
[05:10:53] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
[05:10:53] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>INFO:causalml:generating out-of-fold CV outcome estimates
INFO:causalml:training the treatment effect model for 1 with R-loss
INFO:causalml:generating out-of-fold CV outcome estimates
INFO:causalml:training the treatment effect model for 1 with R-loss
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[05:10:58] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
</pre></div>
</div>
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Abs % Error of ATE</th>
      <th>MSE</th>
      <th>KL Divergence</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Actuals</th>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>S Learner (LR)</th>
      <td>0.388954</td>
      <td>0.080117</td>
      <td>3.818102</td>
    </tr>
    <tr>
      <th>S Learner (XGB)</th>
      <td>0.170903</td>
      <td>0.026048</td>
      <td>0.169165</td>
    </tr>
    <tr>
      <th>T Learner (LR)</th>
      <td>0.367001</td>
      <td>0.041178</td>
      <td>0.345389</td>
    </tr>
    <tr>
      <th>T Learner (XGB)</th>
      <td>0.167180</td>
      <td>0.077904</td>
      <td>0.329255</td>
    </tr>
    <tr>
      <th>X Learner (LR)</th>
      <td>0.367001</td>
      <td>0.041178</td>
      <td>0.345389</td>
    </tr>
    <tr>
      <th>X Learner (XGB)</th>
      <td>0.080251</td>
      <td>0.035612</td>
      <td>0.113922</td>
    </tr>
    <tr>
      <th>R Learner (LR)</th>
      <td>0.314180</td>
      <td>0.039644</td>
      <td>0.328597</td>
    </tr>
    <tr>
      <th>R Learner (XGB)</th>
      <td>0.064824</td>
      <td>0.058672</td>
      <td>0.081420</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">train_summary</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Abs % Error of ATE</th>
      <th>MSE</th>
      <th>KL Divergence</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Actuals</th>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>S Learner (LR)</th>
      <td>0.388954</td>
      <td>0.080117</td>
      <td>3.818102</td>
    </tr>
    <tr>
      <th>S Learner (XGB)</th>
      <td>0.170903</td>
      <td>0.026048</td>
      <td>0.169165</td>
    </tr>
    <tr>
      <th>T Learner (LR)</th>
      <td>0.367001</td>
      <td>0.041178</td>
      <td>0.345389</td>
    </tr>
    <tr>
      <th>T Learner (XGB)</th>
      <td>0.167180</td>
      <td>0.077904</td>
      <td>0.329255</td>
    </tr>
    <tr>
      <th>X Learner (LR)</th>
      <td>0.367001</td>
      <td>0.041178</td>
      <td>0.345389</td>
    </tr>
    <tr>
      <th>X Learner (XGB)</th>
      <td>0.080251</td>
      <td>0.035612</td>
      <td>0.113922</td>
    </tr>
    <tr>
      <th>R Learner (LR)</th>
      <td>0.314180</td>
      <td>0.039644</td>
      <td>0.328597</td>
    </tr>
    <tr>
      <th>R Learner (XGB)</th>
      <td>0.064824</td>
      <td>0.058672</td>
      <td>0.081420</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">validation_summary</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Abs % Error of ATE</th>
      <th>MSE</th>
      <th>KL Divergence</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Actuals</th>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>S Learner (LR)</th>
      <td>0.391030</td>
      <td>0.080125</td>
      <td>3.852796</td>
    </tr>
    <tr>
      <th>S Learner (XGB)</th>
      <td>0.171938</td>
      <td>0.026233</td>
      <td>0.211149</td>
    </tr>
    <tr>
      <th>T Learner (LR)</th>
      <td>0.367846</td>
      <td>0.041114</td>
      <td>0.367778</td>
    </tr>
    <tr>
      <th>T Learner (XGB)</th>
      <td>0.165467</td>
      <td>0.071834</td>
      <td>0.337448</td>
    </tr>
    <tr>
      <th>X Learner (LR)</th>
      <td>0.367846</td>
      <td>0.041114</td>
      <td>0.367778</td>
    </tr>
    <tr>
      <th>X Learner (XGB)</th>
      <td>0.079152</td>
      <td>0.033613</td>
      <td>0.135387</td>
    </tr>
    <tr>
      <th>R Learner (LR)</th>
      <td>0.315344</td>
      <td>0.039538</td>
      <td>0.352431</td>
    </tr>
    <tr>
      <th>R Learner (XGB)</th>
      <td>0.067368</td>
      <td>0.055667</td>
      <td>0.099292</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">scatter_plot_summary_holdout</span><span class="p">(</span><span class="n">train_summary</span><span class="p">,</span>
                             <span class="n">validation_summary</span><span class="p">,</span>
                             <span class="n">k</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
                             <span class="n">label</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;Train&#39;</span><span class="p">,</span> <span class="s1">&#39;Validation&#39;</span><span class="p">],</span>
                             <span class="n">drop_learners</span><span class="o">=</span><span class="p">[],</span>
                             <span class="n">drop_cols</span><span class="o">=</span><span class="p">[])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/T990000_causal_inference_135_0.png" src="../_images/T990000_causal_inference_135_0.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">bar_plot_summary_holdout</span><span class="p">(</span><span class="n">train_summary</span><span class="p">,</span>
                         <span class="n">validation_summary</span><span class="p">,</span>
                         <span class="n">k</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
                         <span class="n">drop_learners</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;S Learner (LR)&#39;</span><span class="p">],</span>
                         <span class="n">drop_cols</span><span class="o">=</span><span class="p">[])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/T990000_causal_inference_136_0.png" src="../_images/T990000_causal_inference_136_0.png" />
<img alt="../_images/T990000_causal_inference_136_1.png" src="../_images/T990000_causal_inference_136_1.png" />
<img alt="../_images/T990000_causal_inference_136_2.png" src="../_images/T990000_causal_inference_136_2.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Single simulation</span>
<span class="n">train_preds</span><span class="p">,</span> <span class="n">valid_preds</span> <span class="o">=</span> <span class="n">get_synthetic_preds_holdout</span><span class="p">(</span><span class="n">simulate_nuisance_and_easy_treatment</span><span class="p">,</span>
                                                       <span class="n">n</span><span class="o">=</span><span class="mi">50000</span><span class="p">,</span>
                                                       <span class="n">valid_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>INFO:causalml:AUC score: 0.808340
INFO:causalml:AUC score: 0.803637
INFO:causalml:Error metrics for group 1
INFO:causalml:    RMSE   (Control):     1.0322
INFO:causalml:    RMSE (Treatment):     1.0299
INFO:causalml:   sMAPE   (Control):     0.8363
INFO:causalml:   sMAPE (Treatment):     0.4875
INFO:causalml:    Gini   (Control):     0.3099
INFO:causalml:    Gini (Treatment):     0.3835
INFO:causalml:Error metrics for group 1
INFO:causalml:    RMSE   (Control):     1.0477
INFO:causalml:    RMSE (Treatment):     1.0259
INFO:causalml:   sMAPE   (Control):     0.8509
INFO:causalml:   sMAPE (Treatment):     0.4873
INFO:causalml:    Gini   (Control):     0.3224
INFO:causalml:    Gini (Treatment):     0.3676
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[05:12:38] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>INFO:causalml:Error metrics for group 1
INFO:causalml:    RMSE   (Control):     0.9920
INFO:causalml:    RMSE (Treatment):     0.9923
INFO:causalml:   sMAPE   (Control):     0.8229
INFO:causalml:   sMAPE (Treatment):     0.4772
INFO:causalml:    Gini   (Control):     0.4011
INFO:causalml:    Gini (Treatment):     0.4544
INFO:causalml:Error metrics for group 1
INFO:causalml:    RMSE   (Control):     1.0167
INFO:causalml:    RMSE (Treatment):     1.0025
INFO:causalml:   sMAPE   (Control):     0.8411
INFO:causalml:   sMAPE (Treatment):     0.4803
INFO:causalml:    Gini   (Control):     0.3882
INFO:causalml:    Gini (Treatment):     0.4157
INFO:causalml:Error metrics for group 1
INFO:causalml:    RMSE   (Control):     1.0275
INFO:causalml:    RMSE (Treatment):     1.0244
INFO:causalml:   sMAPE   (Control):     0.8272
INFO:causalml:   sMAPE (Treatment):     0.4873
INFO:causalml:    Gini   (Control):     0.3173
INFO:causalml:    Gini (Treatment):     0.3931
INFO:causalml:Error metrics for group 1
INFO:causalml:    RMSE   (Control):     1.0403
INFO:causalml:    RMSE (Treatment):     1.0224
INFO:causalml:   sMAPE   (Control):     0.8417
INFO:causalml:   sMAPE (Treatment):     0.4870
INFO:causalml:    Gini   (Control):     0.3349
INFO:causalml:    Gini (Treatment):     0.3771
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[05:12:41] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
[05:12:42] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>INFO:causalml:Error metrics for group 1
INFO:causalml:    RMSE   (Control):     0.9837
INFO:causalml:    RMSE (Treatment):     0.9819
INFO:causalml:   sMAPE   (Control):     0.8170
INFO:causalml:   sMAPE (Treatment):     0.4746
INFO:causalml:    Gini   (Control):     0.4184
INFO:causalml:    Gini (Treatment):     0.4679
INFO:causalml:Error metrics for group 1
INFO:causalml:    RMSE   (Control):     1.0158
INFO:causalml:    RMSE (Treatment):     1.0022
INFO:causalml:   sMAPE   (Control):     0.8379
INFO:causalml:   sMAPE (Treatment):     0.4814
INFO:causalml:    Gini   (Control):     0.3895
INFO:causalml:    Gini (Treatment):     0.4150
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[05:12:43] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
[05:12:44] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
[05:12:45] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
[05:12:46] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>INFO:causalml:generating out-of-fold CV outcome estimates
INFO:causalml:training the treatment effect model for 1 with R-loss
INFO:causalml:generating out-of-fold CV outcome estimates
INFO:causalml:training the treatment effect model for 1 with R-loss
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[05:13:00] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1">#distribution plot for signle simulation of Training</span>
<span class="n">distr_plot_single_sim</span><span class="p">(</span><span class="n">train_preds</span><span class="p">,</span> <span class="n">kind</span><span class="o">=</span><span class="s1">&#39;kde&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">bw_method</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span>
                      <span class="n">drop_learners</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;S Learner (LR)&#39;</span><span class="p">,</span><span class="s1">&#39; S Learner (XGB)&#39;</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/T990000_causal_inference_138_0.png" src="../_images/T990000_causal_inference_138_0.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Scatter Plots for a Single Simulation of Training Data</span>
<span class="n">scatter_plot_single_sim</span><span class="p">(</span><span class="n">train_preds</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/T990000_causal_inference_139_0.png" src="../_images/T990000_causal_inference_139_0.png" />
</div>
</div>
</div>
<div class="section" id="propensity-matching-and-estimation">
<h2>Propensity Matching and Estimation<a class="headerlink" href="#propensity-matching-and-estimation" title="Permalink to this headline">¶</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Estimation</span>
<span class="kn">from</span> <span class="nn">causalml.propensity</span> <span class="kn">import</span> <span class="n">ElasticNetPropensityModel</span>

<span class="n">pm</span> <span class="o">=</span> <span class="n">ElasticNetPropensityModel</span><span class="p">(</span><span class="n">n_fold</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="n">ps</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">fit_predict</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Matching</span>

<span class="kn">from</span> <span class="nn">causalml.match</span> <span class="kn">import</span> <span class="n">NearestNeigoborMatch</span><span class="p">,</span> <span class="n">create_table_one</span>

<span class="n">psm</span> <span class="o">=</span> <span class="n">NearestNeighborMatch</span><span class="p">(</span><span class="n">replace</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                           <span class="n">ratio</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                           <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="n">matched</span> <span class="o">=</span> <span class="n">psm</span><span class="o">.</span><span class="n">match_by_group</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">df</span><span class="p">,</span>
                             <span class="n">treatment_col</span><span class="o">=</span><span class="n">treatment_col</span><span class="p">,</span>
                             <span class="n">score_col</span><span class="o">=</span><span class="n">score_col</span><span class="p">,</span>
                             <span class="n">groupby_col</span><span class="o">=</span><span class="n">groupby_col</span><span class="p">)</span>

<span class="n">create_table_one</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">matched</span><span class="p">,</span>
                 <span class="n">treatment_col</span><span class="o">=</span><span class="n">treatment_col</span><span class="p">,</span>
                 <span class="n">features</span><span class="o">=</span><span class="n">covariates</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="confidence-intervals">
<h3>Confidence Intervals<a class="headerlink" href="#confidence-intervals" title="Permalink to this headline">¶</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Generate synthetic data using mode 1</span>
<span class="n">y</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">treatment</span><span class="p">,</span> <span class="n">tau</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">e</span> <span class="o">=</span> <span class="n">synthetic_data</span><span class="p">(</span><span class="n">mode</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">n</span><span class="o">=</span><span class="mi">10000</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="mf">1.0</span><span class="p">)</span>

<span class="n">treatment</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="s1">&#39;treatment_a&#39;</span> <span class="k">if</span> <span class="n">val</span><span class="o">==</span><span class="mi">1</span> <span class="k">else</span> <span class="s1">&#39;control&#39;</span> <span class="k">for</span> <span class="n">val</span> <span class="ow">in</span> <span class="n">treatment</span><span class="p">])</span>

<span class="c1"># Normal</span>
<span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.05</span>
<span class="n">learner_s</span> <span class="o">=</span> <span class="n">BaseSRegressor</span><span class="p">(</span><span class="n">XGBRegressor</span><span class="p">(),</span> <span class="n">ate_alpha</span><span class="o">=</span><span class="n">alpha</span><span class="p">,</span> <span class="n">control_name</span><span class="o">=</span><span class="s1">&#39;control&#39;</span><span class="p">)</span>
<span class="n">ate_s</span><span class="p">,</span> <span class="n">ate_s_lb</span><span class="p">,</span> <span class="n">ate_s_ub</span> <span class="o">=</span> <span class="n">learner_s</span><span class="o">.</span><span class="n">estimate_ate</span><span class="p">(</span><span class="n">X</span><span class="o">=</span><span class="n">X</span><span class="p">,</span> <span class="n">treatment</span><span class="o">=</span><span class="n">treatment</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">,</span> <span class="n">return_ci</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
                                                   
<span class="nb">print</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">vstack</span><span class="p">((</span><span class="n">ate_s_lb</span><span class="p">,</span> <span class="n">ate_s</span><span class="p">,</span> <span class="n">ate_s_ub</span><span class="p">)))</span>

<span class="n">ate_s_b</span><span class="p">,</span> <span class="n">ate_s_lb_b</span><span class="p">,</span> <span class="n">ate_s_ub_b</span> <span class="o">=</span> <span class="n">learner_s</span><span class="o">.</span><span class="n">estimate_ate</span><span class="p">(</span><span class="n">X</span><span class="o">=</span><span class="n">X</span><span class="p">,</span> <span class="n">treatment</span><span class="o">=</span><span class="n">treatment</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">,</span> <span class="n">return_ci</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                                                         <span class="n">bootstrap_ci</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">n_bootstraps</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">bootstrap_size</span><span class="o">=</span><span class="mi">5000</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">vstack</span><span class="p">((</span><span class="n">ate_s_lb_b</span><span class="p">,</span> <span class="n">ate_s_b</span><span class="p">,</span> <span class="n">ate_s_ub_b</span><span class="p">)))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[06:30:00] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>INFO:causalml:Error metrics for group treatment_a
INFO:causalml:    RMSE   (Control):     0.9792
INFO:causalml:    RMSE (Treatment):     0.9679
INFO:causalml:   sMAPE   (Control):     0.8232
INFO:causalml:   sMAPE (Treatment):     0.4678
INFO:causalml:    Gini   (Control):     0.4547
INFO:causalml:    Gini (Treatment):     0.4886
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[[0.57165861]
 [0.60995507]
 [0.64825154]]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1">## CATE CIs</span>

<span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.05</span>
<span class="n">learner_s</span> <span class="o">=</span> <span class="n">BaseSRegressor</span><span class="p">(</span><span class="n">XGBRegressor</span><span class="p">(),</span> <span class="n">ate_alpha</span><span class="o">=</span><span class="n">alpha</span><span class="p">,</span> <span class="n">control_name</span><span class="o">=</span><span class="s1">&#39;control&#39;</span><span class="p">)</span>
<span class="n">cate_s</span><span class="p">,</span> <span class="n">cate_s_lb</span><span class="p">,</span> <span class="n">cate_s_ub</span> <span class="o">=</span> <span class="n">learner_s</span><span class="o">.</span><span class="n">fit_predict</span><span class="p">(</span><span class="n">X</span><span class="o">=</span><span class="n">X</span><span class="p">,</span> <span class="n">treatment</span><span class="o">=</span><span class="n">treatment</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">,</span> <span class="n">return_ci</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                               <span class="n">n_bootstraps</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">bootstrap_size</span><span class="o">=</span><span class="mi">5000</span><span class="p">)</span>

<span class="n">cate_s</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[06:30:42] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>INFO:causalml:Error metrics for group treatment_a
INFO:causalml:    RMSE   (Control):     0.9792
INFO:causalml:    RMSE (Treatment):     0.9679
INFO:causalml:   sMAPE   (Control):     0.8232
INFO:causalml:   sMAPE (Treatment):     0.4678
INFO:causalml:    Gini   (Control):     0.4547
INFO:causalml:    Gini (Treatment):     0.4886
INFO:causalml:Bootstrap Confidence Intervals
  0%|          | 0/100 [00:00&lt;?, ?it/s]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[06:30:43] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
[06:30:43] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>  1%|          | 1/100 [00:00&lt;00:43,  2.29it/s]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[06:30:43] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>  2%|▏         | 2/100 [00:00&lt;00:42,  2.30it/s]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[06:30:44] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>  3%|▎         | 3/100 [00:01&lt;00:42,  2.30it/s]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[06:30:44] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>  4%|▍         | 4/100 [00:01&lt;00:42,  2.27it/s]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[06:30:45] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>  5%|▌         | 5/100 [00:02&lt;00:41,  2.28it/s]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[06:30:45] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>  6%|▌         | 6/100 [00:02&lt;00:41,  2.28it/s]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[06:30:46] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>  7%|▋         | 7/100 [00:03&lt;00:40,  2.30it/s]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[06:30:46] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>  8%|▊         | 8/100 [00:03&lt;00:40,  2.29it/s]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[06:30:46] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>  9%|▉         | 9/100 [00:03&lt;00:39,  2.29it/s]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[06:30:47] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 10%|█         | 10/100 [00:04&lt;00:39,  2.30it/s]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[06:30:47] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 11%|█         | 11/100 [00:04&lt;00:38,  2.30it/s]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[06:30:48] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 12%|█▏        | 12/100 [00:05&lt;00:38,  2.31it/s]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[06:30:48] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 13%|█▎        | 13/100 [00:05&lt;00:37,  2.32it/s]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[06:30:49] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 14%|█▍        | 14/100 [00:06&lt;00:37,  2.31it/s]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[06:30:49] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 15%|█▌        | 15/100 [00:06&lt;00:36,  2.30it/s]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[06:30:49] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 16%|█▌        | 16/100 [00:06&lt;00:36,  2.30it/s]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[06:30:50] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 17%|█▋        | 17/100 [00:07&lt;00:36,  2.29it/s]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[06:30:50] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 18%|█▊        | 18/100 [00:07&lt;00:35,  2.29it/s]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[06:30:51] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 19%|█▉        | 19/100 [00:08&lt;00:35,  2.29it/s]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[06:30:51] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 20%|██        | 20/100 [00:08&lt;00:34,  2.29it/s]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[06:30:52] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 21%|██        | 21/100 [00:09&lt;00:34,  2.30it/s]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[06:30:52] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 22%|██▏       | 22/100 [00:09&lt;00:34,  2.29it/s]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[06:30:52] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 23%|██▎       | 23/100 [00:10&lt;00:33,  2.27it/s]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[06:30:53] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 24%|██▍       | 24/100 [00:10&lt;00:33,  2.29it/s]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[06:30:53] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 25%|██▌       | 25/100 [00:10&lt;00:32,  2.28it/s]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[06:30:54] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 26%|██▌       | 26/100 [00:11&lt;00:32,  2.29it/s]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[06:30:54] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 27%|██▋       | 27/100 [00:11&lt;00:32,  2.28it/s]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[06:30:55] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 28%|██▊       | 28/100 [00:12&lt;00:31,  2.29it/s]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[06:30:55] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 29%|██▉       | 29/100 [00:12&lt;00:31,  2.24it/s]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[06:30:56] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 30%|███       | 30/100 [00:13&lt;00:30,  2.26it/s]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[06:30:56] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 31%|███       | 31/100 [00:13&lt;00:30,  2.27it/s]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[06:30:56] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 32%|███▏      | 32/100 [00:13&lt;00:29,  2.28it/s]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[06:30:57] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 33%|███▎      | 33/100 [00:14&lt;00:29,  2.28it/s]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[06:30:57] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 34%|███▍      | 34/100 [00:14&lt;00:28,  2.29it/s]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[06:30:58] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 35%|███▌      | 35/100 [00:15&lt;00:28,  2.29it/s]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[06:30:58] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 36%|███▌      | 36/100 [00:15&lt;00:28,  2.29it/s]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[06:30:59] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 37%|███▋      | 37/100 [00:16&lt;00:27,  2.28it/s]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[06:30:59] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 38%|███▊      | 38/100 [00:16&lt;00:27,  2.28it/s]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[06:31:00] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 39%|███▉      | 39/100 [00:17&lt;00:26,  2.29it/s]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[06:31:00] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 40%|████      | 40/100 [00:17&lt;00:26,  2.28it/s]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[06:31:00] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 41%|████      | 41/100 [00:17&lt;00:25,  2.29it/s]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[06:31:01] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 42%|████▏     | 42/100 [00:18&lt;00:25,  2.30it/s]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[06:31:01] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 43%|████▎     | 43/100 [00:18&lt;00:24,  2.29it/s]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[06:31:02] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 44%|████▍     | 44/100 [00:19&lt;00:24,  2.29it/s]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[06:31:02] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 45%|████▌     | 45/100 [00:19&lt;00:23,  2.30it/s]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[06:31:03] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 46%|████▌     | 46/100 [00:20&lt;00:23,  2.30it/s]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[06:31:03] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 47%|████▋     | 47/100 [00:20&lt;00:22,  2.31it/s]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[06:31:03] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 48%|████▊     | 48/100 [00:20&lt;00:22,  2.30it/s]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[06:31:04] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 49%|████▉     | 49/100 [00:21&lt;00:22,  2.28it/s]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[06:31:04] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 50%|█████     | 50/100 [00:21&lt;00:21,  2.29it/s]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[06:31:05] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 51%|█████     | 51/100 [00:22&lt;00:21,  2.29it/s]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[06:31:05] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 52%|█████▏    | 52/100 [00:22&lt;00:21,  2.28it/s]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[06:31:06] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 53%|█████▎    | 53/100 [00:23&lt;00:20,  2.26it/s]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[06:31:06] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 54%|█████▍    | 54/100 [00:23&lt;00:20,  2.27it/s]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[06:31:07] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 55%|█████▌    | 55/100 [00:24&lt;00:19,  2.29it/s]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[06:31:07] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 56%|█████▌    | 56/100 [00:24&lt;00:19,  2.29it/s]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[06:31:07] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 57%|█████▋    | 57/100 [00:24&lt;00:18,  2.28it/s]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[06:31:08] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 58%|█████▊    | 58/100 [00:25&lt;00:18,  2.28it/s]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[06:31:08] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 59%|█████▉    | 59/100 [00:25&lt;00:17,  2.28it/s]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[06:31:09] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 60%|██████    | 60/100 [00:26&lt;00:17,  2.28it/s]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[06:31:09] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 61%|██████    | 61/100 [00:26&lt;00:17,  2.29it/s]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[06:31:10] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 62%|██████▏   | 62/100 [00:27&lt;00:16,  2.29it/s]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[06:31:10] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 63%|██████▎   | 63/100 [00:27&lt;00:16,  2.28it/s]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[06:31:10] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 64%|██████▍   | 64/100 [00:27&lt;00:15,  2.27it/s]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[06:31:11] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 65%|██████▌   | 65/100 [00:28&lt;00:15,  2.28it/s]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[06:31:11] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 66%|██████▌   | 66/100 [00:28&lt;00:14,  2.28it/s]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[06:31:12] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 67%|██████▋   | 67/100 [00:29&lt;00:14,  2.28it/s]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[06:31:12] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 68%|██████▊   | 68/100 [00:29&lt;00:14,  2.28it/s]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[06:31:13] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 69%|██████▉   | 69/100 [00:30&lt;00:13,  2.28it/s]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[06:31:13] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 70%|███████   | 70/100 [00:30&lt;00:13,  2.29it/s]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[06:31:14] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 71%|███████   | 71/100 [00:31&lt;00:12,  2.30it/s]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[06:31:14] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 72%|███████▏  | 72/100 [00:31&lt;00:12,  2.30it/s]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[06:31:14] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 73%|███████▎  | 73/100 [00:31&lt;00:11,  2.30it/s]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[06:31:15] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 74%|███████▍  | 74/100 [00:32&lt;00:11,  2.30it/s]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[06:31:15] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 75%|███████▌  | 75/100 [00:32&lt;00:10,  2.30it/s]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[06:31:16] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 76%|███████▌  | 76/100 [00:33&lt;00:10,  2.28it/s]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[06:31:16] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 77%|███████▋  | 77/100 [00:33&lt;00:10,  2.29it/s]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[06:31:17] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 78%|███████▊  | 78/100 [00:34&lt;00:09,  2.30it/s]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[06:31:17] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 79%|███████▉  | 79/100 [00:34&lt;00:09,  2.31it/s]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[06:31:17] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 80%|████████  | 80/100 [00:34&lt;00:08,  2.31it/s]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[06:31:18] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 81%|████████  | 81/100 [00:35&lt;00:08,  2.30it/s]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[06:31:18] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 82%|████████▏ | 82/100 [00:35&lt;00:07,  2.29it/s]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[06:31:19] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 83%|████████▎ | 83/100 [00:36&lt;00:07,  2.29it/s]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[06:31:19] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 84%|████████▍ | 84/100 [00:36&lt;00:06,  2.30it/s]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[06:31:20] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 85%|████████▌ | 85/100 [00:37&lt;00:06,  2.30it/s]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[06:31:20] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 86%|████████▌ | 86/100 [00:37&lt;00:06,  2.31it/s]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[06:31:20] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 87%|████████▋ | 87/100 [00:38&lt;00:05,  2.29it/s]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[06:31:21] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 88%|████████▊ | 88/100 [00:38&lt;00:05,  2.28it/s]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[06:31:21] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 89%|████████▉ | 89/100 [00:38&lt;00:04,  2.29it/s]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[06:31:22] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 90%|█████████ | 90/100 [00:39&lt;00:04,  2.29it/s]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[06:31:22] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 91%|█████████ | 91/100 [00:39&lt;00:03,  2.29it/s]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[06:31:23] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 92%|█████████▏| 92/100 [00:40&lt;00:03,  2.29it/s]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[06:31:23] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 93%|█████████▎| 93/100 [00:40&lt;00:03,  2.29it/s]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[06:31:24] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 94%|█████████▍| 94/100 [00:41&lt;00:02,  2.27it/s]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[06:31:24] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 95%|█████████▌| 95/100 [00:41&lt;00:02,  2.28it/s]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[06:31:24] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 96%|█████████▌| 96/100 [00:41&lt;00:01,  2.29it/s]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[06:31:25] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 97%|█████████▋| 97/100 [00:42&lt;00:01,  2.29it/s]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[06:31:25] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 98%|█████████▊| 98/100 [00:42&lt;00:00,  2.27it/s]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[06:31:26] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 99%|█████████▉| 99/100 [00:43&lt;00:00,  2.29it/s]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[06:31:26] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>100%|██████████| 100/100 [00:43&lt;00:00,  2.27it/s]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[06:31:27] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([[0.63715827],
       [0.73582286],
       [0.56132948],
       ...,
       [0.82233089],
       [0.79830194],
       [0.80349147]])
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1">### For work on other CIs and multiple treatments</span>

<span class="n">https</span><span class="p">:</span><span class="o">//</span><span class="n">github</span><span class="o">.</span><span class="n">com</span><span class="o">/</span><span class="n">uber</span><span class="o">/</span><span class="n">causalml</span><span class="o">/</span><span class="n">blob</span><span class="o">/</span><span class="n">master</span><span class="o">/</span><span class="n">examples</span><span class="o">/</span><span class="n">meta_learners_with_synthetic_data_multiple_treatment</span><span class="o">.</span><span class="n">ipynb</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="section" id="a-b-testing">
<h2>A/B Testing<a class="headerlink" href="#a-b-testing" title="Permalink to this headline">¶</a></h2>
<p>Can be divided into frequentist and bayesian A/B testing. Functionally quite similar except for bayesian techniques providing us with more information around point estimates. If we stick with linear models, we could frame the problem in a bayesian way, but it feels like this approach is very similar to covariate adjustment.</p>
<p>For both, we would want to define the power we want and hence the required sample size. <a class="reference external" href="https://www.firmai.org/documents/Power%20analysis%20for%20AB%20tests/#ab-testing">https://www.firmai.org/documents/Power analysis for AB tests/#ab-testing</a></p>
</div>
<div class="section" id="calculate-the-necessary-sample-size">
<h2>Calculate The Necessary Sample Size<a class="headerlink" href="#calculate-the-necessary-sample-size" title="Permalink to this headline">¶</a></h2>
<p>Before running an A/B test to compare a new website design (labeled the B design) to the existing design (labeled A), it is a good idea to determine how many users will be needed to evaluate if the new design performs better than the old one. The t-test is an effective statistical tool to evaulate significance once the experiment is over, and there are many online tutorials explaining how to use it. I didn’t find a comparable resource explaining the calculation of sample sizes, so I put together this notebook to demonstrate the (simple) steps.</p>
<p>Calculating necessary sample sizes given</p>
<ul class="simple">
<li><p>null hypothesis</p></li>
<li><p>expected effect size</p></li>
<li><p>false positive rate</p></li>
<li><p>false negative rate.</p></li>
</ul>
<p>Now, I’ll enter some numbers to make the discussion more concrete. Imagine we have a click through rate of 5% with the original design. Call this p_a for probability(A). Suppose in addition that we decide that the click through rate must increase to at least 7% to make changing the design worthwhile. Call this p_b. Finally, we’ll calculate the average click through rate, p, assuming that our sample sizes will be equal.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ion</span><span class="p">()</span>
<span class="kn">import</span> <span class="nn">scipy.stats</span>


<span class="n">p_a</span> <span class="o">=</span> <span class="mf">.05</span> <span class="c1"># assume we have a base click rate of 5% for our original design (A group)</span>
<span class="n">p_b</span> <span class="o">=</span> <span class="mf">.07</span> <span class="c1"># we want to detect an increase in click rate to 7%, otherwise not worth changing the design</span>

<span class="n">p</span> <span class="o">=</span> <span class="p">(</span><span class="n">p_a</span> <span class="o">+</span> <span class="n">p_b</span><span class="p">)</span><span class="o">/</span><span class="mf">2.</span>
</pre></div>
</div>
</div>
</div>
<p>n addition to these two values, we’ll need to decide on false positive and false negative rates. We can use these to look up values from the Normal distribution (results are labeled Z below). Here we chose 5% false positive rate (also called Type I error rate) and 80% power, equivalent to a 20% false negative rate (or Type II error rate). These rates are fairly standard, but completely arbitrary. These choices mean that we expect to falsely say that B is an improvement 5% of the time when actually it is no better than A, and we expect to falsely say B is not and improvement 20% of the time when actually it is better than A.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Z8</span> <span class="o">=</span> <span class="n">scipy</span><span class="o">.</span><span class="n">stats</span><span class="o">.</span><span class="n">norm</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="mf">.8</span><span class="p">)</span> <span class="c1"># we will need this to ensure 80% power (20% false negative rate)</span>
<span class="n">Z95</span> <span class="o">=</span> <span class="n">scipy</span><span class="o">.</span><span class="n">stats</span><span class="o">.</span><span class="n">norm</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="mf">.05</span><span class="p">)</span> <span class="c1"># we will need this for 5% false positive rate (95% confidence level), one-tailed</span>
<span class="n">Z975</span> <span class="o">=</span> <span class="n">scipy</span><span class="o">.</span><span class="n">stats</span><span class="o">.</span><span class="n">norm</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="mf">.025</span><span class="p">)</span> <span class="c1"># 5% false positive rate for two-tailed case</span>

<span class="n">ES</span> <span class="o">=</span> <span class="nb">abs</span><span class="p">(</span><span class="n">p_b</span> <span class="o">-</span> <span class="n">p_a</span><span class="p">)</span><span class="o">/</span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">p</span><span class="o">*</span><span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">p</span><span class="p">))</span>

<span class="n">num_tails</span> <span class="o">=</span> <span class="mi">1</span> <span class="c1"># presumably we are testing design b because we think it will improve the click rate...</span>

<span class="k">if</span> <span class="n">num_tails</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
    <span class="n">n</span> <span class="o">=</span> <span class="mi">2</span><span class="o">*</span><span class="p">((</span><span class="n">Z975</span> <span class="o">+</span> <span class="n">Z8</span><span class="p">)</span><span class="o">/</span><span class="n">ES</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span>  <span class="c1"># two-tailed</span>
<span class="k">else</span><span class="p">:</span>
    <span class="n">n</span> <span class="o">=</span> <span class="mi">2</span><span class="o">*</span><span class="p">((</span><span class="n">Z95</span> <span class="o">+</span> <span class="n">Z8</span><span class="p">)</span><span class="o">/</span><span class="n">ES</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span> <span class="c1"># one-tailed</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;You need&#39;</span><span class="p">,</span> <span class="nb">round</span><span class="p">(</span><span class="n">n</span><span class="p">),</span> <span class="s1">&#39; samples in each group to get a 5</span><span class="si">% f</span><span class="s1">alse positive and 20</span><span class="si">% f</span><span class="s1">alse negative rate given effect size&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>You need 1743.0  samples in each group to get a 5% false positive and 20% false negative rate given effect size
</pre></div>
</div>
</div>
</div>
<p>That’s it! We have the sample sizes necessary given our requirements. In this case, we need about 1743 people to experience the A design and 1743 people to experience the B design.</p>
<p>Let’s convince ourselves that we actually meet our specs by simulating two experimental results. In one experiment the B design results in a minimal improvement (to 7% click rate). In the other (labeled null) there is no change in the click rate.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">n_a</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="nb">round</span><span class="p">(</span><span class="n">n</span><span class="p">))</span>
<span class="n">n_b</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="nb">round</span><span class="p">(</span><span class="n">n</span><span class="p">))</span>

<span class="n">num_experiments</span> <span class="o">=</span> <span class="mi">10000</span>

<span class="n">conversions_a</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">((</span><span class="n">n_a</span><span class="p">,</span> <span class="n">num_experiments</span><span class="p">))</span> <span class="o">&lt;</span> <span class="n">p_a</span>
<span class="n">conversions_b_null</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">((</span><span class="n">n_b</span><span class="p">,</span> <span class="n">num_experiments</span><span class="p">))</span> <span class="o">&lt;</span> <span class="n">p_a</span>
<span class="n">conversions_b</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">((</span><span class="n">n_b</span><span class="p">,</span> <span class="n">num_experiments</span><span class="p">))</span> <span class="o">&lt;</span> <span class="n">p_b</span>

<span class="n">mean_a</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">conversions_a</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">mean_b_null</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">conversions_b_null</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">mean_b</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">conversions_b</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="c1">#s_a = np.std(conversions_a, ddof=1)</span>
<span class="c1">#s_b_null = np.std(conversions_b_null, ddof=1)</span>
<span class="c1">#s_b = np.std(conversions_b, ddof=1)</span>
<span class="c1"># equivalent:</span>
<span class="n">s_a</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">((</span><span class="n">conversions_a</span> <span class="o">-</span> <span class="n">mean_a</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">,</span> <span class="p">:])</span><span class="o">**</span><span class="mi">2</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">/</span><span class="p">(</span><span class="n">n_a</span> <span class="o">-</span> <span class="mi">1</span><span class="p">))</span>
<span class="n">s_b_null</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">((</span><span class="n">conversions_b_null</span> <span class="o">-</span> <span class="n">mean_b_null</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">,</span> <span class="p">:])</span><span class="o">**</span><span class="mi">2</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">/</span><span class="p">(</span><span class="n">n_b</span> <span class="o">-</span> <span class="mi">1</span><span class="p">))</span>
<span class="n">s_b</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">((</span><span class="n">conversions_b</span> <span class="o">-</span> <span class="n">mean_b</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">,</span> <span class="p">:])</span><span class="o">**</span><span class="mi">2</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">/</span><span class="p">(</span><span class="n">n_b</span> <span class="o">-</span> <span class="mi">1</span><span class="p">))</span>

<span class="n">sp</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">s_a</span><span class="o">**</span><span class="mi">2</span><span class="o">/</span><span class="n">n_a</span> <span class="o">+</span> <span class="n">s_b</span><span class="o">**</span><span class="mi">2</span><span class="o">/</span><span class="n">n_b</span><span class="p">)</span>
<span class="n">sp_null</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">s_a</span><span class="o">**</span><span class="mi">2</span><span class="o">/</span><span class="n">n_a</span> <span class="o">+</span> <span class="n">s_b_null</span><span class="o">**</span><span class="mi">2</span><span class="o">/</span><span class="n">n_b</span><span class="p">)</span>

<span class="k">if</span> <span class="n">num_tails</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
    <span class="n">t</span> <span class="o">=</span> <span class="nb">abs</span><span class="p">(</span><span class="n">mean_b</span> <span class="o">-</span> <span class="n">mean_a</span><span class="p">)</span> <span class="o">/</span> <span class="n">sp</span> <span class="c1"># two-tailed</span>
    <span class="n">t_null</span> <span class="o">=</span> <span class="nb">abs</span><span class="p">(</span><span class="n">mean_b_null</span> <span class="o">-</span> <span class="n">mean_a</span><span class="p">)</span> <span class="o">/</span> <span class="n">sp_null</span> <span class="c1"># two-tailed</span>
    <span class="n">results</span> <span class="o">=</span> <span class="n">t</span> <span class="o">&gt;</span> <span class="n">Z975</span>  <span class="c1"># two-tailed</span>
    <span class="n">results_null</span> <span class="o">=</span> <span class="n">t_null</span> <span class="o">&gt;</span> <span class="n">Z975</span>  <span class="c1"># two-tailed</span>
<span class="k">else</span><span class="p">:</span>
    <span class="n">t</span> <span class="o">=</span> <span class="p">(</span><span class="n">mean_b</span> <span class="o">-</span> <span class="n">mean_a</span><span class="p">)</span> <span class="o">/</span> <span class="n">sp</span> <span class="c1"># one-tailed</span>
    <span class="n">t_null</span> <span class="o">=</span> <span class="p">(</span><span class="n">mean_b_null</span> <span class="o">-</span> <span class="n">mean_a</span><span class="p">)</span> <span class="o">/</span> <span class="n">sp_null</span> <span class="c1"># one-tailed</span>
    <span class="n">results</span> <span class="o">=</span> <span class="n">t</span> <span class="o">&gt;</span> <span class="n">Z95</span> <span class="c1"># one-tailed</span>
    <span class="n">results_null</span> <span class="o">=</span> <span class="n">t_null</span> <span class="o">&gt;</span> <span class="n">Z95</span> <span class="c1"># one-tailed</span>

<span class="n">false_negative_rate</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">results</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s1">&#39;float&#39;</span><span class="p">)</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">results</span><span class="p">)</span>
<span class="n">false_positive_rate</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">results_null</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s1">&#39;float&#39;</span><span class="p">)</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">results_null</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">false_negative_rate</span><span class="p">,</span> <span class="s2">&quot;false negative rate, we expect it to be close to 20%&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">false_positive_rate</span><span class="p">,</span> <span class="s2">&quot;false positive rate, we expect it to be close to 5%&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.20409999999999995 false negative rate, we expect it to be close to 20%
0.0509 false positive rate, we expect it to be close to 5%
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="mi">111</span><span class="p">)</span>

<span class="n">n</span><span class="p">,</span> <span class="n">bins</span><span class="p">,</span> <span class="n">p</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">mean_b</span> <span class="o">-</span> <span class="n">mean_a</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mf">.04</span><span class="p">,</span> <span class="mf">.06</span><span class="p">,</span> <span class="mi">88</span><span class="p">),</span> <span class="n">color</span><span class="o">=</span><span class="p">[</span><span class="mf">.8</span><span class="p">,</span> <span class="mf">.8</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
<span class="n">n</span><span class="p">,</span> <span class="n">bins</span><span class="p">,</span> <span class="n">p</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">mean_b_null</span> <span class="o">-</span> <span class="n">mean_a</span><span class="p">,</span> <span class="n">bins</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mf">.8</span><span class="p">,</span> <span class="mf">.8</span><span class="p">])</span>

<span class="n">n</span><span class="p">,</span> <span class="n">bins</span><span class="p">,</span> <span class="n">p</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">mean_b</span><span class="p">[</span><span class="n">results</span><span class="o">==</span><span class="kc">False</span><span class="p">]</span> <span class="o">-</span> <span class="n">mean_a</span><span class="p">[</span><span class="n">results</span><span class="o">==</span><span class="kc">False</span><span class="p">],</span> <span class="n">bins</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;b&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">.6</span><span class="p">)</span>
<span class="n">n</span><span class="p">,</span> <span class="n">bins</span><span class="p">,</span> <span class="n">p</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">mean_b_null</span><span class="p">[</span><span class="n">results_null</span><span class="p">]</span> <span class="o">-</span> <span class="n">mean_a</span><span class="p">[</span><span class="n">results_null</span><span class="p">],</span> <span class="n">bins</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;r&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">.6</span><span class="p">)</span>

<span class="n">ax</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="o">-</span><span class="mf">.02</span><span class="p">,</span> <span class="mi">600</span><span class="p">,</span> <span class="s1">&#39;Null true&#39;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;r&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="mf">.03</span><span class="p">,</span> <span class="mi">500</span><span class="p">,</span> <span class="s1">&#39;Minimum true effect size&#39;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;b&#39;</span><span class="p">)</span>

<span class="n">ax</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="mf">.016</span><span class="p">,</span> <span class="mi">300</span><span class="p">,</span> <span class="nb">str</span><span class="p">(</span><span class="nb">round</span><span class="p">(</span><span class="n">false_negative_rate</span><span class="o">*</span><span class="mi">100</span><span class="p">))</span><span class="o">+</span><span class="s2">&quot;</span><span class="si">% f</span><span class="s2">alse negatives&quot;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;b&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="mf">.016</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="nb">str</span><span class="p">(</span><span class="nb">round</span><span class="p">(</span><span class="n">false_positive_rate</span><span class="o">*</span><span class="mi">100</span><span class="p">))</span><span class="o">+</span><span class="s2">&quot;</span><span class="si">% f</span><span class="s2">alse positives&quot;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;r&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Text(0.016, 100, &#39;5.0% false positives&#39;)
</pre></div>
</div>
<img alt="../_images/T990000_causal_inference_158_1.png" src="../_images/T990000_causal_inference_158_1.png" />
</div>
</div>
<p>We can see that we achieve exactly the false positive and false negative rates we set out for in the two different simuluated experiments.</p>
</div>
<div class="section" id="frequentist">
<h2>Frequentist<a class="headerlink" href="#frequentist" title="Permalink to this headline">¶</a></h2>
<p>This project looks at an A/B test run by an e-commerce website. The goal is to see if the company should implement the new page, keep the old page, or perhaps run the experiment longer to make their decision.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># import libraries</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">tqdm</span> <span class="kn">import</span> <span class="o">*</span>

<span class="o">%</span><span class="n">matplotlib</span> <span class="n">inline</span>
<span class="c1">#We are setting the seed to assure you get the same answers on quizzes as we set up</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>

<span class="c1"># import data</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;https://raw.githubusercontent.com/firmai/random-assets/master/ab_data.csv&#39;</span><span class="p">)</span>

<span class="c1"># show top rows</span>
<span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>user_id</th>
      <th>timestamp</th>
      <th>group</th>
      <th>landing_page</th>
      <th>converted</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>851104</td>
      <td>2017-01-21 22:11:48.556739</td>
      <td>control</td>
      <td>old_page</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>804228</td>
      <td>2017-01-12 08:01:45.159739</td>
      <td>control</td>
      <td>old_page</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>661590</td>
      <td>2017-01-11 16:55:06.154213</td>
      <td>treatment</td>
      <td>new_page</td>
      <td>0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>853541</td>
      <td>2017-01-08 18:28:03.143765</td>
      <td>treatment</td>
      <td>new_page</td>
      <td>0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>864975</td>
      <td>2017-01-21 01:52:26.210827</td>
      <td>control</td>
      <td>old_page</td>
      <td>1</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>Mismatch Remove</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Looking for rows where treatment/control doesn&#39;t line up with old/new pages respectively</span>
<span class="n">df_t_not_n</span> <span class="o">=</span> <span class="n">df</span><span class="p">[(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;group&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="s1">&#39;treatment&#39;</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;landing_page&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="s1">&#39;old_page&#39;</span><span class="p">)]</span>
<span class="n">df_not_t_n</span> <span class="o">=</span> <span class="n">df</span><span class="p">[(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;group&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="s1">&#39;control&#39;</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;landing_page&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="s1">&#39;new_page&#39;</span><span class="p">)]</span>

<span class="c1"># Add lengths</span>
<span class="n">mismatch</span><span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">df_t_not_n</span><span class="p">)</span> <span class="o">+</span> <span class="nb">len</span><span class="p">(</span><span class="n">df_not_t_n</span><span class="p">)</span>

<span class="c1"># Create one dataframe from it</span>
<span class="n">mismatch_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">df_t_not_n</span><span class="p">,</span> <span class="n">df_not_t_n</span><span class="p">])</span>

<span class="c1"># Remove incriminating rows</span>
<span class="n">mismatch_index</span> <span class="o">=</span> <span class="n">mismatch_df</span><span class="o">.</span><span class="n">index</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">mismatch_index</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Remove non-unique users</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Calculate number of rows in dataset and display</span>
<span class="n">df_length</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>         
<span class="nb">print</span><span class="p">(</span><span class="n">df_length</span><span class="p">)</span>

<span class="c1"># Find unique users</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Unique users:&quot;</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">user_id</span><span class="o">.</span><span class="n">unique</span><span class="p">()))</span>

<span class="c1"># Check for not unique users</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Non-unique users:&quot;</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">df</span><span class="p">)</span><span class="o">-</span><span class="nb">len</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">user_id</span><span class="o">.</span><span class="n">unique</span><span class="p">()))</span>

<span class="c1"># Drop duplicated user</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">drop_duplicates</span><span class="p">(</span><span class="n">keep</span><span class="o">=</span><span class="s1">&#39;first&#39;</span><span class="p">,</span> <span class="n">subset</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;user_id&quot;</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>290585
Unique users: 290584
Non-unique users: 1
</pre></div>
</div>
</div>
</div>
<p>Probabilities</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># What is the probability of an individual converting regardless of the page they receive</span>
<span class="c1"># Probability of user converting</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Probability of user converting:&quot;</span><span class="p">,</span> <span class="n">df</span><span class="o">.</span><span class="n">converted</span><span class="o">.</span><span class="n">mean</span><span class="p">())</span>

<span class="c1">#Given that an individual was in the control group, what is the probability they converted?</span>
<span class="c1"># Probability of control group converting</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Probability of control group converting:&quot;</span><span class="p">,</span> 
      <span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;group&#39;</span><span class="p">]</span><span class="o">==</span><span class="s1">&#39;control&#39;</span><span class="p">][</span><span class="s1">&#39;converted&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">())</span>

<span class="c1"># Given that an individual was in the treatment group, what is the probability they converted?</span>

<span class="c1"># Probability of treatment group converting</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Probability of treatment group converting:&quot;</span><span class="p">,</span> 
      <span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;group&#39;</span><span class="p">]</span><span class="o">==</span><span class="s1">&#39;treatment&#39;</span><span class="p">][</span><span class="s1">&#39;converted&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">())</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Probability of user converting: 0.11959708724499628
Probability of control group converting: 0.1203863045004612
Probability of treatment group converting: 0.11880806551510564
</pre></div>
</div>
</div>
</div>
<p>For now, consider you need to make the decision just based on all the data provided.  If you want to assume that the old page is better unless the new page proves to be definitely better at a Type I error rate of 5%, what should your null and alternative hypotheses be?  You can state your hypothesis in terms of words or in terms of <strong><span class="math notranslate nohighlight">\(p_{old}\)</span></strong> and <strong><span class="math notranslate nohighlight">\(p_{new}\)</span></strong>, which are the converted rates for the old and new pages.</p>
<ul class="simple">
<li><p>Null-hypothesis</p></li>
</ul>
<p><span class="math notranslate nohighlight">\(H_0:  p_{new} - p_{old} \leq 0\)</span></p>
<p><em>i.e.</em> The null hypothesis is that the difference between the population conversion rate of users given the new page and the old page will be equal to zero (the same) or lower than zero (the old page has a higher population conversion rate).</p>
<ul class="simple">
<li><p>Alternative-hypothesis</p></li>
</ul>
<p><span class="math notranslate nohighlight">\(H_1: p_{new} - p_{old} &gt; 0\)</span></p>
<p><em>i.e.</em> The alternative hypothesis is that the difference between the population conversion rate of users given the new page and the old page will be greater than zero to zero (the new page has a higher population conversion rate).</p>
<p>Assume under the null hypothesis, <span class="math notranslate nohighlight">\(p_{new}\)</span> and <span class="math notranslate nohighlight">\(p_{old}\)</span> both have “true” success rates equal to the converted success rate regardless of page - that is <span class="math notranslate nohighlight">\(p_{new}\)</span> and <span class="math notranslate nohighlight">\(p_{old}\)</span> are equal. Furthermore, assume they are equal to the converted rate in ab_data.csv regardless of the page.</p>
<p>Use a sample size for each page equal to the ones in ab_data.csv.</p>
<p>Perform the sampling distribution for the difference in converted between the two pages over 10,000 iterations of calculating an estimate from the null.</p>
<p><img alt="alt text" src="https://" /><code class="docutils literal notranslate"><span class="pre">a.</span></code> What is the <strong>convert rate</strong> for <span class="math notranslate nohighlight">\(p_{new}\)</span> under the null?</p>
<p>Given the assumption in the question, <span class="math notranslate nohighlight">\(p_{new} = p_{old}\)</span>. Hence, we should calculate the average of the real <span class="math notranslate nohighlight">\(p_{new}\)</span> and <span class="math notranslate nohighlight">\(p_{old}\)</span> (probability of conversion given new page and old page respectively) to calculate <span class="math notranslate nohighlight">\(p_{mean}\)</span>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1">## Same as before</span>


<span class="c1"># Calculate probability of conversion for new page</span>
<span class="n">p_new</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;landing_page&#39;</span><span class="p">]</span><span class="o">==</span><span class="s1">&#39;new_page&#39;</span><span class="p">][</span><span class="s1">&#39;converted&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Probability of conversion for new page (p_new):&quot;</span><span class="p">,</span> <span class="n">p_new</span><span class="p">)</span>

<span class="c1"># Calculate probability of conversion for old page</span>
<span class="n">p_old</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;landing_page&#39;</span><span class="p">]</span><span class="o">==</span><span class="s1">&#39;old_page&#39;</span><span class="p">][</span><span class="s1">&#39;converted&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Probability of conversion for old page (p_old):&quot;</span><span class="p">,</span> <span class="n">p_old</span><span class="p">)</span>

<span class="c1"># Calc. differences in probability of conversion for new and old page (not under H_0)</span>
<span class="n">p_diff</span> <span class="o">=</span> <span class="n">p_new</span><span class="o">-</span><span class="n">p_old</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Difference in probability of conversion for new and old page (not under H_0):&quot;</span><span class="p">,</span> <span class="n">p_diff</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Probability of conversion for new page (p_new): 0.11880806551510564
Probability of conversion for old page (p_old): 0.1203863045004612
Difference in probability of conversion for new and old page (not under H_0): -0.0015782389853555567
</pre></div>
</div>
</div>
</div>
<p>Hence:</p>
<p><span class="math notranslate nohighlight">\(p_{new}: 0.1188\)</span></p>
<p><span class="math notranslate nohighlight">\(p_{old}: 0.1204\)</span></p>
<p>The <strong>convert rate</strong> for <span class="math notranslate nohighlight">\(p_{new}\)</span> under the null</p>
<p><span class="math notranslate nohighlight">\(p_{mean}=p_{old_0}=p_{new_0}: 0.1196\)</span></p>
<p>The <strong>convert rate</strong> for <span class="math notranslate nohighlight">\(p_{old}\)</span> under the null?</p>
<p>As above <span class="math notranslate nohighlight">\(p_{new_0} - p_{old_0}= 0\)</span></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Calculate n_new and n_old</span>
<span class="n">n_new</span><span class="p">,</span> <span class="n">n_old</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;landing_page&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">value_counts</span><span class="p">()</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;new:&quot;</span><span class="p">,</span> <span class="n">n_new</span><span class="p">,</span> <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">old:&quot;</span><span class="p">,</span> <span class="n">n_old</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>new: 145310 
old: 145274
</pre></div>
</div>
</div>
</div>
<p>Hence:</p>
<p>Number of tests with the new page</p>
<p><span class="math notranslate nohighlight">\(n_{new}: 145310\)</span></p>
<p>Number of tests with the old page</p>
<p><span class="math notranslate nohighlight">\(n_{old}: 145274\)</span></p>
<p>Now we will simulate <span class="math notranslate nohighlight">\(n_{new}\)</span> transactions with a convert rate of <span class="math notranslate nohighlight">\(p_{new}\)</span> under the null. Store these <span class="math notranslate nohighlight">\(n_{new}\)</span> 1’s and 0’s in new_page_converted.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">p_mean</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s2">&quot;converted&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>

<span class="p">[</span><span class="n">p_mean</span><span class="p">,</span> <span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">p_mean</span><span class="p">)]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[0.11959708724499628, 0.8804029127550037]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Simulate conversion rates under null hypothesis</span>
<span class="c1"># [0.11959718500778342, 0.8804028149922166] % choose [1, 0]</span>
<span class="n">new_page_converted</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">size</span><span class="o">=</span><span class="n">n_new</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="p">[</span><span class="n">p_mean</span><span class="p">,</span> <span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">p_mean</span><span class="p">)])</span>

<span class="n">new_page_converted</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.1196132406579038
</pre></div>
</div>
</div>
</div>
<p>Simulate <span class="math notranslate nohighlight">\(n_{old}\)</span> transactions with a convert rate of <span class="math notranslate nohighlight">\(p_{old}\)</span> under the null.  Store these <span class="math notranslate nohighlight">\(n_{old}\)</span> 1’s and 0’s in <strong>old_page_converted</strong>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Simulate conversion rates under null hypothesis</span>
<span class="n">old_page_converted</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">size</span><span class="o">=</span><span class="n">n_old</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="p">[</span><span class="n">p_mean</span><span class="p">,</span> <span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">p_mean</span><span class="p">)])</span>

<span class="n">old_page_converted</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.1177843247931495
</pre></div>
</div>
</div>
</div>
<p>Find <span class="math notranslate nohighlight">\(p_{new}\)</span> - <span class="math notranslate nohighlight">\(p_{old}\)</span> for your simulated values</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Calculate difference in p under the null hypothesis</span>
<span class="n">new_page_converted</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="o">-</span><span class="n">old_page_converted</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.0018289158647542963
</pre></div>
</div>
</div>
</div>
<p>Simulate 10,000 <span class="math notranslate nohighlight">\(p_{new}\)</span> - <span class="math notranslate nohighlight">\(p_{old}\)</span> values using this same process</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1">## Good, I like these simulations. </span>
<span class="n">p_diffs</span> <span class="o">=</span> <span class="p">[]</span>

<span class="c1"># Re-run simulation 10,000 times</span>
<span class="c1"># trange creates an estimate for how long this program will take to run</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">trange</span><span class="p">(</span><span class="mi">10000</span><span class="p">):</span>
    <span class="n">new_page_converted</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">size</span><span class="o">=</span><span class="n">n_new</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="p">[</span><span class="n">p_mean</span><span class="p">,</span> <span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">p_mean</span><span class="p">)])</span>
    <span class="n">old_page_converted</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">size</span><span class="o">=</span><span class="n">n_old</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="p">[</span><span class="n">p_mean</span><span class="p">,</span> <span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">p_mean</span><span class="p">)])</span>
    <span class="n">p_diff</span> <span class="o">=</span> <span class="n">new_page_converted</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="o">-</span><span class="n">old_page_converted</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
    <span class="n">p_diffs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">p_diff</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>100%|██████████| 10000/10000 [01:14&lt;00:00, 133.80it/s]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Plot histogram</span>
<span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">p_diffs</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="mi">25</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Simulated Difference of New Page and Old Page Converted Under the Null&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Page difference&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Frequency&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axvline</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="p">(</span><span class="n">p_new</span><span class="o">-</span><span class="n">p_old</span><span class="p">),</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;r&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;dashed&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Real difference&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axvline</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">p_diffs</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()),</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;g&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;dashed&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Simulated difference&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/T990000_causal_inference_182_0.png" src="../_images/T990000_causal_inference_182_0.png" />
</div>
</div>
<p>The simulated data creates a normal distribution (no skew) as expected due to how the data was generated. The mean of this normal distribution is 0, which which is what the data should look like under the null hypothesis.</p>
<p>The proportion of the p_diffs are greater than the actual difference observed</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">p_diff</span> <span class="o">=</span> <span class="n">p_new</span> <span class="o">-</span> <span class="n">p_old</span>

<span class="c1"># Find proportion of p_diffs greater than the actual difference</span>
<span class="n">greater_than_diff</span> <span class="o">=</span> <span class="p">[</span><span class="n">i</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">p_diffs</span> <span class="k">if</span> <span class="n">i</span> <span class="o">&gt;</span> <span class="n">p_diff</span><span class="p">]</span>


<span class="c1"># Calculate values</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Actual difference:&quot;</span> <span class="p">,</span> <span class="n">p_diff</span><span class="p">)</span>

<span class="n">p_greater_than_diff</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">greater_than_diff</span><span class="p">)</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">p_diffs</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Proportion greater than actual difference:&#39;</span><span class="p">,</span> <span class="n">p_greater_than_diff</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;As a percentage: </span><span class="si">{}</span><span class="s1">%&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">p_greater_than_diff</span><span class="o">*</span><span class="mi">100</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Actual difference: -0.0015782389853555567
Proportion greater than actual difference: 0.9065
As a percentage: 90.64999999999999%
</pre></div>
</div>
</div>
</div>
<p>If our sample conformed to the null hypothesis then we’d expect the proportion greater than the actual difference to be 0.5. However, we calculate that almost 90% of the population in our simulated sample lies above the real difference which does not only suggest that the new page does not do significantly better than the old page, it might even be worse!</p>
<p>We could also use a built-in to achieve similar results. Though using the built-in might be easier to code, the above portions are a walkthrough of the ideas that are critical to correctly thinking about statistical significance.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Import statsmodels</span>
<span class="kn">import</span> <span class="nn">statsmodels.api</span> <span class="k">as</span> <span class="nn">sm</span>

<span class="c1"># Calculate number of conversions</span>
<span class="c1"># Some of these values were defined ealier in this notebook: n_old and n_new</span>

<span class="n">convert_old</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">df</span><span class="p">[(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;landing_page&#39;</span><span class="p">]</span><span class="o">==</span><span class="s1">&#39;old_page&#39;</span><span class="p">)</span><span class="o">&amp;</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;converted&#39;</span><span class="p">]</span><span class="o">==</span><span class="mi">1</span><span class="p">)])</span>
<span class="n">convert_new</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">df</span><span class="p">[(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;landing_page&#39;</span><span class="p">]</span><span class="o">==</span><span class="s1">&#39;new_page&#39;</span><span class="p">)</span><span class="o">&amp;</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;converted&#39;</span><span class="p">]</span><span class="o">==</span><span class="mi">1</span><span class="p">)])</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;convert_old:&quot;</span><span class="p">,</span> <span class="n">convert_old</span><span class="p">,</span> 
      <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">convert_new:&quot;</span><span class="p">,</span> <span class="n">convert_new</span><span class="p">,</span>
      <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">n_old:&quot;</span><span class="p">,</span> <span class="n">n_old</span><span class="p">,</span>
      <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">n_new:&quot;</span><span class="p">,</span> <span class="n">n_new</span><span class="p">)</span>


<span class="c1"># Find z-score and p-value</span>
<span class="n">z_score</span><span class="p">,</span> <span class="n">p_value</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">stats</span><span class="o">.</span><span class="n">proportions_ztest</span><span class="p">(</span><span class="n">count</span><span class="o">=</span><span class="p">[</span><span class="n">convert_new</span><span class="p">,</span> <span class="n">convert_old</span><span class="p">],</span> 
                                              <span class="n">nobs</span><span class="o">=</span><span class="p">[</span><span class="n">n_new</span><span class="p">,</span> <span class="n">n_old</span><span class="p">],</span> <span class="n">alternative</span> <span class="o">=</span> <span class="s1">&#39;larger&#39;</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;z-score:&quot;</span><span class="p">,</span> <span class="n">z_score</span><span class="p">,</span>
     <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">p-value:&quot;</span><span class="p">,</span> <span class="n">p_value</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>convert_old: 17489 
convert_new: 17264 
n_old: 145274 
n_new: 145310
z-score: -1.3109241984234394 
p-value: 0.9050583127590245
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1">## Similar to above, but what is happening behind the scenes. </span>

<span class="c1"># null hypothesis: the samples have identical averages</span>
<span class="c1"># if p &lt; 0.05, reject null hypothesis that the two samples are identical</span>
<span class="kn">import</span> <span class="nn">scipy.stats</span> <span class="k">as</span> <span class="nn">stats</span>

<span class="c1"># ztest</span>
<span class="k">def</span> <span class="nf">ztest</span><span class="p">(</span><span class="n">x1</span><span class="p">,</span> <span class="n">n1</span><span class="p">,</span> <span class="n">x2</span><span class="p">,</span> <span class="n">n2</span><span class="p">,</span> <span class="n">one_tailed</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    One- or Two-Tailed Z-test for two samples</span>
<span class="sd">    </span>
<span class="sd">    Args:</span>
<span class="sd">        x1 = # of successes in Sample 1</span>
<span class="sd">        n1 = # of observations in Sample 1</span>
<span class="sd">        x2 = # of successes in Sample 2</span>
<span class="sd">        n2 = # of observations in Sample 2</span>
<span class="sd">        one_tailed = Boolean, whether or not the test should be One-Tailed</span>
<span class="sd">        </span>
<span class="sd">    Return:</span>
<span class="sd">        z = Z-stat</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">p1</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">x1</span><span class="p">)</span> <span class="o">/</span> <span class="n">n1</span>
    <span class="n">p2</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">x2</span><span class="p">)</span> <span class="o">/</span> <span class="n">n2</span>    
 
    <span class="n">p</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">x1</span> <span class="o">+</span> <span class="n">x2</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">n1</span> <span class="o">+</span> <span class="n">n2</span><span class="p">)</span>
    <span class="n">se</span> <span class="o">=</span> <span class="n">p</span> <span class="o">*</span> <span class="p">(</span><span class="mf">1.</span> <span class="o">-</span> <span class="n">p</span><span class="p">)</span> <span class="o">*</span> <span class="p">((</span><span class="mf">1.</span> <span class="o">/</span> <span class="n">n1</span><span class="p">)</span> <span class="o">+</span> <span class="p">(</span><span class="mf">1.</span> <span class="o">/</span> <span class="n">n2</span><span class="p">))</span>
    <span class="n">sse</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">se</span><span class="p">)</span>
    
    <span class="n">z</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">p1</span> <span class="o">-</span> <span class="n">p2</span><span class="p">)</span> <span class="o">/</span> <span class="n">sse</span>
    <span class="n">p</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">stats</span><span class="o">.</span><span class="n">norm</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="nb">abs</span><span class="p">(</span><span class="n">z</span><span class="p">))</span>
    
    <span class="k">if</span> <span class="ow">not</span> <span class="n">one_tailed</span><span class="p">:</span>
        <span class="n">p</span> <span class="o">*=</span> <span class="mf">2.</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">z</span><span class="p">,</span> <span class="n">p</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">z</span><span class="p">,</span> <span class="n">p</span>

<span class="c1"># Do a test with fake data:</span>

<span class="n">control_observations</span> <span class="o">=</span> <span class="n">n_old</span> <span class="c1">#n1</span>
<span class="n">control_successes</span> <span class="o">=</span> <span class="n">convert_old</span> <span class="c1"># x1</span>
<span class="n">test_observations</span> <span class="o">=</span> <span class="n">n_new</span> <span class="c1">#n2</span>
<span class="n">test_successes</span> <span class="o">=</span> <span class="n">convert_new</span> <span class="c1">#x2</span>


<span class="c1">## left is z-stat and right is p-value</span>
<span class="n">z_stat</span><span class="p">,</span> <span class="n">p_value</span> <span class="o">=</span> <span class="n">ztest</span><span class="p">(</span><span class="n">control_successes</span><span class="p">,</span> <span class="n">control_observations</span><span class="p">,</span> <span class="n">test_successes</span><span class="p">,</span> <span class="n">test_observations</span><span class="p">,</span> <span class="n">one_tailed</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">compute_standard_error_prop_two_samples</span><span class="p">(</span><span class="n">x1</span><span class="p">,</span> <span class="n">n1</span><span class="p">,</span> <span class="n">x2</span><span class="p">,</span> <span class="n">n2</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.05</span><span class="p">):</span>
    <span class="n">p1</span> <span class="o">=</span> <span class="n">x1</span><span class="o">/</span><span class="n">n1</span>
    <span class="n">p2</span> <span class="o">=</span> <span class="n">x2</span><span class="o">/</span><span class="n">n2</span>    
    <span class="n">se</span> <span class="o">=</span> <span class="n">p1</span><span class="o">*</span><span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">p1</span><span class="p">)</span><span class="o">/</span><span class="n">n1</span> <span class="o">+</span> <span class="n">p2</span><span class="o">*</span><span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">p2</span><span class="p">)</span><span class="o">/</span><span class="n">n2</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">se</span><span class="p">)</span>
    
<span class="k">def</span> <span class="nf">zconf_interval_two_samples</span><span class="p">(</span><span class="n">x1</span><span class="p">,</span> <span class="n">n1</span><span class="p">,</span> <span class="n">x2</span><span class="p">,</span> <span class="n">n2</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.05</span><span class="p">):</span>
    <span class="n">p1</span> <span class="o">=</span> <span class="n">x1</span><span class="o">/</span><span class="n">n1</span>
    <span class="n">p2</span> <span class="o">=</span> <span class="n">x2</span><span class="o">/</span><span class="n">n2</span>    
    <span class="n">se</span> <span class="o">=</span> <span class="n">compute_standard_error_prop_two_samples</span><span class="p">(</span><span class="n">x1</span><span class="p">,</span> <span class="n">n1</span><span class="p">,</span> <span class="n">x2</span><span class="p">,</span> <span class="n">n2</span><span class="p">)</span>
    <span class="n">z_critical</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">norm</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="mf">0.5</span><span class="o">*</span><span class="n">alpha</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">p2</span><span class="o">-</span><span class="n">p1</span><span class="o">-</span><span class="n">z_critical</span><span class="o">*</span><span class="n">se</span><span class="p">,</span> <span class="n">p2</span><span class="o">-</span><span class="n">p1</span><span class="o">+</span><span class="n">z_critical</span><span class="o">*</span><span class="n">se</span>

<span class="n">ci_low</span><span class="p">,</span><span class="n">ci_upp</span> <span class="o">=</span> <span class="n">zconf_interval_two_samples</span><span class="p">(</span><span class="n">control_successes</span><span class="p">,</span> <span class="n">control_observations</span><span class="p">,</span> <span class="n">test_successes</span><span class="p">,</span> <span class="n">test_observations</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39; 95% Confidence Interval = ( </span><span class="si">{0:.2f}</span><span class="s1">% , </span><span class="si">{1:.2f}</span><span class="s1">% )&#39;</span>
      <span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="mi">100</span><span class="o">*</span><span class="n">ci_low</span><span class="p">,</span> <span class="mi">100</span><span class="o">*</span><span class="n">ci_upp</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>1.3109241984234394 0.09494168724097551
 95% Confidence Interval = ( -0.39% , 0.08% )
</pre></div>
</div>
</div>
</div>
<p>Simply put, a z-score is the number of standard deviations from the mean a data point is. But more technically it’s a measure of how many standard deviations below or above the population mean a raw score is. Given the above definition, it would seem that the differences between the lines shown in the histogram above is -1.31 standard deviations. The p-value is roughly 10.0% which is the probability that this result is due to random chance, this is not enough evidence to reject the null hypothesis and thus we fail to do so. The p-value that we got from ab_page is 0.190 that is significant difference with p-value in A/B Testing, which is around 0.9. The reason is because there are two totally different Null Hypothesis. One inequality direction, is naturally more certain.</p>
</div>
<div class="section" id="regression-approach">
<h2>Regression Approach<a class="headerlink" href="#regression-approach" title="Permalink to this headline">¶</a></h2>
<p>The regression approach allows us to also add an intercept which can account for bias. It is also somewhat easier. We will use a logistic regression.</p>
<p>The goal is to use statsmodels to fit the regression model to see if there is a significant difference in conversion based on which page a customer receives. However, you first need to create a column for the intercept, and create a dummy variable column for which page each user received. Add an intercept column, as well as an ab_page column, which is 1 when an individual receives the treatment and 0 if control.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">df3</span> <span class="o">=</span> <span class="n">df</span> <span class="c1"># Clone dataframe in case of a mistake</span>

<span class="n">df3</span><span class="p">[</span><span class="s1">&#39;intercept&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">df3</span><span class="p">)),</span> <span class="n">index</span><span class="o">=</span><span class="n">df3</span><span class="o">.</span><span class="n">index</span><span class="p">)</span>
<span class="n">df3</span><span class="p">[</span><span class="s1">&#39;ab_page&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">df3</span><span class="p">)),</span> <span class="n">index</span><span class="o">=</span><span class="n">df3</span><span class="o">.</span><span class="n">index</span><span class="p">)</span>

<span class="c1"># Find indexes that need to be changed for treatment group</span>
<span class="n">index_to_change</span> <span class="o">=</span> <span class="n">df3</span><span class="p">[</span><span class="n">df3</span><span class="p">[</span><span class="s1">&#39;group&#39;</span><span class="p">]</span><span class="o">==</span><span class="s1">&#39;treatment&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">index</span>

<span class="c1"># Change values</span>
<span class="n">df3</span><span class="o">.</span><span class="n">set_value</span><span class="p">(</span><span class="n">index</span><span class="o">=</span><span class="n">index_to_change</span><span class="p">,</span> <span class="n">col</span><span class="o">=</span><span class="s1">&#39;ab_page&#39;</span><span class="p">,</span> <span class="n">value</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">df3</span><span class="o">.</span><span class="n">set_value</span><span class="p">(</span><span class="n">index</span><span class="o">=</span><span class="n">df3</span><span class="o">.</span><span class="n">index</span><span class="p">,</span> <span class="n">col</span><span class="o">=</span><span class="s1">&#39;intercept&#39;</span><span class="p">,</span> <span class="n">value</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="c1"># Change datatype</span>
<span class="n">df3</span><span class="p">[[</span><span class="s1">&#39;intercept&#39;</span><span class="p">,</span> <span class="s1">&#39;ab_page&#39;</span><span class="p">]]</span> <span class="o">=</span> <span class="n">df3</span><span class="p">[[</span><span class="s1">&#39;intercept&#39;</span><span class="p">,</span> <span class="s1">&#39;ab_page&#39;</span><span class="p">]]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>

<span class="c1"># Move &quot;converted&quot; to RHS</span>
<span class="n">df3</span> <span class="o">=</span> <span class="n">df3</span><span class="p">[[</span><span class="s1">&#39;user_id&#39;</span><span class="p">,</span> <span class="s1">&#39;timestamp&#39;</span><span class="p">,</span> <span class="s1">&#39;group&#39;</span><span class="p">,</span> <span class="s1">&#39;landing_page&#39;</span><span class="p">,</span> <span class="s1">&#39;ab_page&#39;</span><span class="p">,</span> <span class="s1">&#39;intercept&#39;</span><span class="p">,</span> <span class="s1">&#39;converted&#39;</span><span class="p">]]</span>

<span class="c1"># Set up logistic regression</span>
<span class="n">logit</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">Logit</span><span class="p">(</span><span class="n">df3</span><span class="p">[</span><span class="s1">&#39;converted&#39;</span><span class="p">],</span> <span class="n">df3</span><span class="p">[[</span><span class="s1">&#39;ab_page&#39;</span><span class="p">,</span> <span class="s1">&#39;intercept&#39;</span><span class="p">]])</span>

<span class="c1"># Calculate results</span>
<span class="n">result</span><span class="o">=</span><span class="n">logit</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>

<span class="n">result</span><span class="o">.</span><span class="n">summary2</span><span class="p">()</span> <span class="c1"># result.summary() wasn&#39;t working for some reason, but this one does</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead
  # Remove the CWD from sys.path while we load stuff.
/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:11: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead
  # This is added back by InteractiveShellApp.init_path()
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Optimization terminated successfully.
         Current function value: 0.366118
         Iterations 6
</pre></div>
</div>
<div class="output text_html"><table class="simpletable">
<tr>
        <td>Model:</td>              <td>Logit</td>      <td>Pseudo R-squared:</td>    <td>0.000</td>   
</tr>
<tr>
  <td>Dependent Variable:</td>     <td>converted</td>          <td>AIC:</td>        <td>212780.3502</td>
</tr>
<tr>
         <td>Date:</td>        <td>2019-12-04 00:45</td>       <td>BIC:</td>        <td>212801.5095</td>
</tr>
<tr>
   <td>No. Observations:</td>       <td>290584</td>       <td>Log-Likelihood:</td>  <td>-1.0639e+05</td>
</tr>
<tr>
       <td>Df Model:</td>              <td>1</td>            <td>LL-Null:</td>      <td>-1.0639e+05</td>
</tr>
<tr>
     <td>Df Residuals:</td>         <td>290582</td>        <td>LLR p-value:</td>      <td>0.18988</td>  
</tr>
<tr>
      <td>Converged:</td>           <td>1.0000</td>           <td>Scale:</td>         <td>1.0000</td>   
</tr>
<tr>
    <td>No. Iterations:</td>        <td>6.0000</td>              <td></td>               <td></td>      
</tr>
</table>
<table class="simpletable">
<tr>
      <td></td>       <th>Coef.</th>  <th>Std.Err.</th>     <th>z</th>      <th>P>|z|</th> <th>[0.025</th>  <th>0.975]</th> 
</tr>
<tr>
  <th>ab_page</th>   <td>-0.0150</td>  <td>0.0114</td>   <td>-1.3109</td>  <td>0.1899</td> <td>-0.0374</td> <td>0.0074</td> 
</tr>
<tr>
  <th>intercept</th> <td>-1.9888</td>  <td>0.0081</td>  <td>-246.6690</td> <td>0.0000</td> <td>-2.0046</td> <td>-1.9730</td>
</tr>
</table></div></div>
</div>
<p>Apparently the p-value associated with ab_page is 0.1899, which is slightly lower than the p-value I calculated using the z-test above. The reason why the value is lower is because I added an intercept which is meant to account for bias. This means that this value is more accurate. (As in, it’s probably closer to the true p-value)</p>
<p>Although it would seem from the outset that there is a difference between the conversion rates of new and old pages, there is just not enough evidence to reject the null hypothesis. From the histogram shown in this report, it seems that the new page does worse than the old page.</p>
<p>** There is a benefit to adding additional data and that is the ability to estimate the different effects for people with different associated characteristics. **</p>
<p>We now have an estimate of the effect size, and our uncertainty of it. Often however, we need to make a decision with this information. How exactly we make this choice should depend on the cost/benefits of the decision, but it is sometimes enough just to ask whether or not our estimated value of Δ is “significantly” different from zero. This is usually done by using the language of hypothesis testing.</p>
</div>
<div class="section" id="increasing-the-power">
<h2>Increasing the Power<a class="headerlink" href="#increasing-the-power" title="Permalink to this headline">¶</a></h2>
<p>You can increase the power using correlated covariates. You can use this methodology in the next section.</p>
<p><a class="reference external" href="https://www.firmai.org/documents/variance-reduction/#generate-dataset">https://www.firmai.org/documents/variance-reduction/#generate-dataset</a></p>
</div>
<div class="section" id="bayesian">
<h2>Bayesian<a class="headerlink" href="#bayesian" title="Permalink to this headline">¶</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
<span class="kn">import</span> <span class="nn">scipy.stats</span> <span class="k">as</span> <span class="nn">stats</span>

<span class="n">sns</span><span class="o">.</span><span class="n">set_style</span><span class="p">(</span><span class="s1">&#39;whitegrid&#39;</span><span class="p">)</span>

<span class="o">%</span><span class="n">matplotlib</span> <span class="n">inline</span>
<span class="o">%</span><span class="n">config</span> <span class="n">InlineBackend</span><span class="o">.</span><span class="n">figure_format</span> <span class="o">=</span> <span class="s1">&#39;retina&#39;</span>
</pre></div>
</div>
</div>
</div>
<p>The t-test, z-tests and confidence intervals are classic Frequentist test for a significant difference in means between groups.</p>
<p>One common application of Bayesian analysis in industry is the analysis of split tests. We can use pymc3 to perform split test analysis or do the process manually by sampling from posterior distributions for the arm conversion rates.</p>
<p>The dataset below contains information on user “conversions” on a fitness app on different “arms” of a split test.</p>
<p>A “conversion” is jargon for whether or not a user performed a desired action or not, typically a purchase.</p>
<p>“Arms” are the jargon for the different versions of a product in a currently running split test. Split tests are also commonly referred to as A/B tests, where A and B denote arms in the test.</p>
<p>The data has 6 columns:</p>
<ul class="simple">
<li><p>arm: the version of the app this user was randomly assigned to</p></li>
<li><p>gender: male/female</p></li>
<li><p>age: age bins, one of 20-30, 30-40, 40-50</p></li>
<li><p>day: the day (total of 21 days)</p></li>
<li><p>fitness: the user’s self reported fitness level from -5 to 5</p></li>
<li><p>converted: 1 if the user purchased the product, 0 if not</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1">## Each row is a unique user</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;https://raw.githubusercontent.com/firmai/random-assets/master/split_test_data.csv&#39;</span><span class="p">)</span>
<span class="n">data</span><span class="p">[</span><span class="s1">&#39;male&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">gender</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="mi">1</span> <span class="k">if</span> <span class="n">x</span> <span class="o">==</span> <span class="s1">&#39;male&#39;</span> <span class="k">else</span> <span class="mi">0</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>When a new arm is introduced into a split test, it is generally tested at a low percentage of users initially before assignment becomes balanced between the arms. This ensures that if something is terribly wrong with one of the arms it does not ruin the experience for too many potential customers. So the question is does the new arm lead the user to purchase the product.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">data</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="s1">&#39;arm&#39;</span><span class="p">)[</span><span class="s1">&#39;converted&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">agg</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>arm
A    0.185393
B    0.116667
C    0.255814
Name: converted, dtype: float64
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1">## You can look at overall conversion rate differences along age, gender, and fitness.</span>

<span class="n">data</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="s1">&#39;age&#39;</span><span class="p">)[</span><span class="s1">&#39;converted&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">agg</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>age
20-30    0.253112
30-40    0.155738
40-50    0.116667
Name: converted, dtype: float64
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1">## Interesting relationship, the fitter you are,the more liklely you were</span>
<span class="c1">## to convert.</span>
<span class="n">data</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="s1">&#39;fitness&#39;</span><span class="p">)[</span><span class="s1">&#39;converted&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">agg</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>fitness
-5.0    0.055556
-4.0    0.026316
-3.0    0.073171
-2.0    0.148649
-1.0    0.086957
 0.0    0.179487
 1.0    0.161290
 2.0    0.171053
 3.0    0.276923
 4.0    0.391892
 5.0    0.484848
Name: converted, dtype: float64
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">data</span><span class="o">.</span><span class="n">arm</span><span class="o">.</span><span class="n">value_counts</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>A    356
B    240
C    129
Name: arm, dtype: int64
</pre></div>
</div>
</div>
</div>
<p>Subset the data to the first 5 days. We will start by just modeling the conversion rate distributions for arms A and B through day 5. At day 5, arm C has still not been introduced yet and so there are just 2 arms.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># import pymc3 as pm</span>

<span class="c1"># current = data[data.day &lt; 5]</span>
<span class="c1"># print(current.shape, current.arm.unique())</span>
<span class="c1"># print(current.groupby(&#39;arm&#39;)[&#39;converted&#39;].agg(np.sum))</span>
</pre></div>
</div>
</div>
</div>
<p>Set up a pymc3 model and uniform priors for the probabilities of conversion for arms A and B. Recall that pymc3 uses the with … syntax for defining models. The first step in setting up a new model is to define the model as the “context”. We are going to model the probability distributions for conversion rates for arms A and B. As always with Bayesian statistics, we need to define prior distributions for our belief about these probabilities/rates of conversion per arm.</p>
<p>Let’s say we have no belief whatsoever about rates, and so we will set an uninformative, flat priors over probabilities from 0 to 1 for both arms. This is equivalent to saying that we believe all conversion rates to be equally likely for both arms.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="n">pm</span><span class="o">.</span><span class="n">Model</span><span class="p">()</span> <span class="k">as</span> <span class="n">day5_model</span><span class="p">:</span>
    
    <span class="n">arm_A_prior</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Uniform</span><span class="p">(</span><span class="s1">&#39;A_prior&#39;</span><span class="p">,</span> <span class="n">lower</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">upper</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">A_p</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Uniform</span><span class="p">(</span><span class="s1">&#39;A_prob&#39;</span><span class="p">,</span> <span class="n">lower</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">upper</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">B_p</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Uniform</span><span class="p">(</span><span class="s1">&#39;B_prob&#39;</span><span class="p">,</span> <span class="n">lower</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">upper</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Set up pm.Bernoulli distributions to model conversions for arms A and B. We are now going to set up the “likelihood” portion of the model. This is going to model the <span class="math notranslate nohighlight">\(P(data\; 	\;\theta)\)</span> part of Bayes theorem. Our conversions are represented by a vector of 1s and 0s denoting whether or not the user converted or not. This is known as a “Bernoulli” process and pymc3 has an approprite function to handle it:</p>
<p>p = is set to the prior for the arm that you defined in the last section.</p>
<p>observed = should be set to the converted values for that arm specifically in the data.</p>
<p>By giving it an observed parameter, we are telling pymc3 that we want this to evaluate the likelihood of our data (the conversions) against models represented by the p= probability argument. We assign p= to be our prior belief about conversion rates for that arm because we want to update this belief (convert to posterior) based on the conversion data we have observed for that arm.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">df3</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="n">data</span><span class="p">[</span><span class="s2">&quot;arm&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">isin</span><span class="p">([</span><span class="s2">&quot;B&quot;</span><span class="p">,</span><span class="s2">&quot;A&quot;</span><span class="p">])]</span><span class="o">.</span><span class="n">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>


<span class="k">with</span> <span class="n">day5_model</span><span class="p">:</span>
    
    <span class="n">A</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Bernoulli</span><span class="p">(</span><span class="s1">&#39;A&#39;</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="n">A_p</span><span class="p">,</span> <span class="n">observed</span><span class="o">=</span><span class="n">df3</span><span class="p">[</span><span class="n">df3</span><span class="o">.</span><span class="n">arm</span> <span class="o">==</span> <span class="s2">&quot;A&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">converted</span><span class="o">.</span><span class="n">values</span><span class="p">)</span>
    <span class="n">B</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Bernoulli</span><span class="p">(</span><span class="s1">&#39;B&#39;</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="n">B_p</span><span class="p">,</span> <span class="n">observed</span><span class="o">=</span><span class="n">df3</span><span class="p">[</span><span class="n">df3</span><span class="o">.</span><span class="n">arm</span> <span class="o">==</span> <span class="s2">&quot;B&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">converted</span><span class="o">.</span><span class="n">values</span><span class="p">)</span> 
    
    <span class="n">AvB</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Deterministic</span><span class="p">(</span><span class="s1">&#39;AvB&#39;</span><span class="p">,</span> <span class="n">A_p</span> <span class="o">-</span> <span class="n">B_p</span><span class="p">)</span>  <span class="c1">## this is the uplift</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="fit-the-model">
<h3>Fit the model<a class="headerlink" href="#fit-the-model" title="Permalink to this headline">¶</a></h3>
<p>Now that we’ve set up the prior distributions and likelihoods, we can actually fit the model.</p>
<p>Below is code that will run the sampling procedure to find the posteriors:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="n">day5_model</span><span class="p">:</span>

    <span class="c1"># construct the &quot;trace&quot; variable that holds samples for all of our distributions:</span>
    <span class="n">trace</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="mi">50000</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Auto-assigning NUTS sampler...
Initializing NUTS using jitter+adapt_diag...
Sequential sampling (2 chains in 1 job)
NUTS: [B_prob, A_prob, A_prior]
100%|██████████| 50500/50500 [00:37&lt;00:00, 1338.72it/s]
100%|██████████| 50500/50500 [00:37&lt;00:00, 1339.34it/s]
</pre></div>
</div>
</div>
</div>
<p>Again you use the context with day5_model: to run code for your model.</p>
<p>start = pm.find_MAP() will try to find a good starting point for the sampling process. This means that your model will converge on the “likely” area much faster (though it makes the fitting slower initially).</p>
<p>trace = pm.sample(50000, start=start) uses the sampling method in pymc3 to perform 50,000 sampling iterations. This will automatically assign the NUTS sampler for you. The dataset is small so the speed shouldn’t be too bad.</p>
<p>When this completes, the trace variable now contains the posterior samples for the distributions we specified while constructing the model.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># We defined our arm A prior distribution to be uniform and named it &#39;arm_A_prior&#39;. </span>
<span class="c1"># The pm.sample() procedure converted this into our posterior belief for the rate</span>
<span class="c1"># of conversions in arm A. You can access these posterior samples using the name</span>
<span class="c1"># you gave the variable when you created it:</span>
<span class="c1">#</span>
<span class="c1"># this will be a vector of values that are different potential rates of conversion</span>
<span class="c1"># for arm A. A histogram of these rates defines, roughly, the posterior probability</span>
<span class="c1"># distribution for the arm A rates after we consider the data we have collected.</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>!pip install arviz
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Requirement already satisfied: arviz in /usr/local/lib/python3.6/dist-packages (0.5.1)
Requirement already satisfied: matplotlib&gt;=3.0 in /usr/local/lib/python3.6/dist-packages (from arviz) (3.1.1)
Requirement already satisfied: scipy&gt;=0.19 in /usr/local/lib/python3.6/dist-packages (from arviz) (1.3.2)
Requirement already satisfied: numpy&gt;=1.12 in /usr/local/lib/python3.6/dist-packages (from arviz) (1.17.4)
Requirement already satisfied: xarray&gt;=0.11 in /usr/local/lib/python3.6/dist-packages (from arviz) (0.11.3)
Requirement already satisfied: netcdf4 in /usr/local/lib/python3.6/dist-packages (from arviz) (1.5.3)
Requirement already satisfied: pandas&gt;=0.23 in /usr/local/lib/python3.6/dist-packages (from arviz) (0.25.3)
Requirement already satisfied: cycler&gt;=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib&gt;=3.0-&gt;arviz) (0.10.0)
Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,&gt;=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib&gt;=3.0-&gt;arviz) (2.4.5)
Requirement already satisfied: python-dateutil&gt;=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib&gt;=3.0-&gt;arviz) (2.6.1)
Requirement already satisfied: kiwisolver&gt;=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib&gt;=3.0-&gt;arviz) (1.1.0)
Requirement already satisfied: cftime in /usr/local/lib/python3.6/dist-packages (from netcdf4-&gt;arviz) (1.0.4.2)
Requirement already satisfied: pytz&gt;=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas&gt;=0.23-&gt;arviz) (2018.9)
Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from cycler&gt;=0.10-&gt;matplotlib&gt;=3.0-&gt;arviz) (1.12.0)
Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from kiwisolver&gt;=1.0.1-&gt;matplotlib&gt;=3.0-&gt;arviz) (41.6.0)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">pm</span><span class="o">.</span><span class="n">plot_posterior</span><span class="p">(</span><span class="n">trace</span><span class="p">[</span><span class="mi">5000</span><span class="p">::</span><span class="mi">3</span><span class="p">],</span> <span class="n">varnames</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;A_prob&#39;</span><span class="p">,</span><span class="s1">&#39;B_prob&#39;</span><span class="p">,</span><span class="s1">&#39;AvB&#39;</span><span class="p">],</span>
                  <span class="n">ref_val</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;#87ceeb&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>/usr/local/lib/python3.6/dist-packages/pymc3/plots/__init__.py:40: UserWarning: Keyword argument `varnames` renamed to `var_names`, and will be removed in pymc3 3.8
  warnings.warn(&#39;Keyword argument `{old}` renamed to `{new}`, and will be removed in pymc3 3.8&#39;.format(old=old, new=new))
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([&lt;matplotlib.axes._subplots.AxesSubplot object at 0x7f864d49f048&gt;,
       &lt;matplotlib.axes._subplots.AxesSubplot object at 0x7f864d434630&gt;,
       &lt;matplotlib.axes._subplots.AxesSubplot object at 0x7f864d35f940&gt;],
      dtype=object)
</pre></div>
</div>
<img alt="../_images/T990000_causal_inference_222_2.png" src="../_images/T990000_causal_inference_222_2.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Import statsmodels</span>
<span class="kn">import</span> <span class="nn">statsmodels.api</span> <span class="k">as</span> <span class="nn">sm</span>

<span class="c1"># Calculate number of conversions</span>
<span class="c1"># Some of these values were defined ealier in this notebook: n_old and n_new</span>

<span class="n">df2</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="n">data</span><span class="p">[</span><span class="s2">&quot;arm&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">isin</span><span class="p">([</span><span class="s2">&quot;B&quot;</span><span class="p">,</span><span class="s2">&quot;A&quot;</span><span class="p">])]</span><span class="o">.</span><span class="n">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="n">n_A</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">df2</span><span class="p">[(</span><span class="n">df2</span><span class="p">[</span><span class="s1">&#39;arm&#39;</span><span class="p">]</span><span class="o">==</span><span class="s1">&#39;A&#39;</span><span class="p">)])</span>
<span class="n">n_B</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">df2</span><span class="p">[(</span><span class="n">df2</span><span class="p">[</span><span class="s1">&#39;arm&#39;</span><span class="p">]</span><span class="o">==</span><span class="s1">&#39;B&#39;</span><span class="p">)])</span>

<span class="n">convert_A</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">df2</span><span class="p">[(</span><span class="n">df2</span><span class="p">[</span><span class="s1">&#39;arm&#39;</span><span class="p">]</span><span class="o">==</span><span class="s1">&#39;A&#39;</span><span class="p">)</span><span class="o">&amp;</span><span class="p">(</span><span class="n">df2</span><span class="p">[</span><span class="s1">&#39;converted&#39;</span><span class="p">]</span><span class="o">==</span><span class="mi">1</span><span class="p">)])</span>
<span class="n">convert_B</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">df2</span><span class="p">[(</span><span class="n">df2</span><span class="p">[</span><span class="s1">&#39;arm&#39;</span><span class="p">]</span><span class="o">==</span><span class="s1">&#39;B&#39;</span><span class="p">)</span><span class="o">&amp;</span><span class="p">(</span><span class="n">df2</span><span class="p">[</span><span class="s1">&#39;converted&#39;</span><span class="p">]</span><span class="o">==</span><span class="mi">1</span><span class="p">)])</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;convert_A:&quot;</span><span class="p">,</span> <span class="n">convert_A</span><span class="p">,</span> 
      <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">convert_B:&quot;</span><span class="p">,</span> <span class="n">convert_B</span><span class="p">,</span>
      <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">n_A:&quot;</span><span class="p">,</span><span class="n">n_A</span> <span class="p">,</span>
      <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">n_B:&quot;</span><span class="p">,</span><span class="n">n_B</span>  <span class="p">)</span>

<span class="c1">## According to this analysis new clearly performs worse.</span>
<span class="c1">## There is some other testing techniques we will test.</span>

<span class="c1"># Find z-score and p-value</span>
<span class="n">z_score</span><span class="p">,</span> <span class="n">p_value</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">stats</span><span class="o">.</span><span class="n">proportions_ztest</span><span class="p">(</span><span class="n">count</span><span class="o">=</span><span class="p">[</span><span class="n">convert_B</span><span class="p">,</span> <span class="n">convert_A</span><span class="p">],</span> 
                                              <span class="n">nobs</span><span class="o">=</span><span class="p">[</span><span class="n">n_B</span><span class="p">,</span> <span class="n">n_A</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;z-score:&quot;</span><span class="p">,</span> <span class="n">z_score</span><span class="p">,</span>
     <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">p-value:&quot;</span><span class="p">,</span> <span class="n">p_value</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>convert_A: 66 
convert_B: 28 
n_A: 356 
n_B: 240
z-score: -2.25768200572263 
p-value: 0.023965491876189363
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>!pip install brewer2mpl
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Collecting brewer2mpl
  Downloading https://files.pythonhosted.org/packages/84/57/00c45a199719e617db0875181134fcb3aeef701deae346547ac722eaaf5e/brewer2mpl-1.4.1-py2.py3-none-any.whl
Installing collected packages: brewer2mpl
Successfully installed brewer2mpl-1.4.1
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">brewer2mpl</span>
<span class="n">brewer_set2</span> <span class="o">=</span> <span class="n">brewer2mpl</span><span class="o">.</span><span class="n">get_map</span><span class="p">(</span><span class="s1">&#39;Set2&#39;</span><span class="p">,</span> <span class="s1">&#39;qualitative&#39;</span><span class="p">,</span> <span class="mi">8</span><span class="p">)</span><span class="o">.</span><span class="n">mpl_colors</span>

<span class="n">A</span> <span class="o">=</span> <span class="n">df2</span><span class="p">[</span><span class="n">df2</span><span class="p">[</span><span class="s2">&quot;arm&quot;</span><span class="p">]</span><span class="o">==</span><span class="s2">&quot;A&quot;</span><span class="p">][</span><span class="s2">&quot;converted&quot;</span><span class="p">]</span>
<span class="n">B</span> <span class="o">=</span> <span class="n">df2</span><span class="p">[</span><span class="n">df2</span><span class="p">[</span><span class="s2">&quot;arm&quot;</span><span class="p">]</span><span class="o">==</span><span class="s2">&quot;B&quot;</span><span class="p">][</span><span class="s2">&quot;converted&quot;</span><span class="p">]</span>

<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="n">Bs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">B</span><span class="p">)</span>

<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">shuffle</span><span class="p">(</span><span class="n">Bs</span> <span class="p">)</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span><span class="mi">4</span><span class="p">))</span>

<span class="n">Bs</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">/</span><span class="mi">5</span>


<span class="n">Bs</span> <span class="o">=</span> <span class="n">Bs</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="mi">5</span><span class="p">,</span><span class="mi">48</span><span class="p">))</span>

<span class="n">plt</span><span class="o">.</span><span class="n">bar</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">6</span><span class="p">),</span> <span class="p">[</span><span class="n">Bs</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">5</span><span class="p">)],</span>
    <span class="n">color</span><span class="o">=</span><span class="n">brewer_set2</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">align</span><span class="o">=</span><span class="s1">&#39;center&#39;</span><span class="p">,</span> <span class="n">width</span><span class="o">=</span><span class="mf">.8</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;New Design&#39;</span> <span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="mi">6</span><span class="p">],</span> <span class="p">[</span><span class="n">A</span><span class="o">.</span><span class="n">mean</span><span class="p">(),</span> <span class="n">A</span><span class="o">.</span><span class="n">mean</span><span class="p">()],</span> 
     <span class="n">color</span><span class="o">=</span><span class="n">brewer_set2</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Old Design&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">(</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">5.5</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Split 5 test&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">();</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/T990000_causal_inference_225_0.png" src="../_images/T990000_causal_inference_225_0.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">scipy</span><span class="o">.</span><span class="n">stats</span><span class="o">.</span><span class="n">norm</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">mean</span><span class="p">,</span><span class="n">z_score</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
       nan, nan, nan, nan, nan, nan, nan, nan, nan])
</pre></div>
</div>
</div>
</div>
<p>The Z-score, or standard score, is the number of standard deviations a given data point lies above or below mean.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># implementation from scratch</span>
<span class="k">def</span> <span class="nf">ztest_proportion_two_samples</span><span class="p">(</span><span class="n">x1</span><span class="p">,</span> <span class="n">n1</span><span class="p">,</span> <span class="n">x2</span><span class="p">,</span> <span class="n">n2</span><span class="p">,</span> <span class="n">one_sided</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
    <span class="n">p1</span> <span class="o">=</span> <span class="n">x1</span><span class="o">/</span><span class="n">n1</span>
    <span class="n">p2</span> <span class="o">=</span> <span class="n">x2</span><span class="o">/</span><span class="n">n2</span>    

    <span class="n">p</span> <span class="o">=</span> <span class="p">(</span><span class="n">x1</span><span class="o">+</span><span class="n">x2</span><span class="p">)</span><span class="o">/</span><span class="p">(</span><span class="n">n1</span><span class="o">+</span><span class="n">n2</span><span class="p">)</span>
    <span class="n">se</span> <span class="o">=</span> <span class="n">p</span><span class="o">*</span><span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">p</span><span class="p">)</span><span class="o">*</span><span class="p">(</span><span class="mi">1</span><span class="o">/</span><span class="n">n1</span><span class="o">+</span><span class="mi">1</span><span class="o">/</span><span class="n">n2</span><span class="p">)</span>
    <span class="n">se</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">se</span><span class="p">)</span>
    
    <span class="n">z</span> <span class="o">=</span> <span class="p">(</span><span class="n">p1</span><span class="o">-</span><span class="n">p2</span><span class="p">)</span><span class="o">/</span><span class="n">se</span>
    <span class="n">p</span> <span class="o">=</span> <span class="mi">1</span><span class="o">-</span><span class="n">stats</span><span class="o">.</span><span class="n">norm</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="nb">abs</span><span class="p">(</span><span class="n">z</span><span class="p">))</span>
    <span class="n">p</span> <span class="o">*=</span> <span class="mi">2</span><span class="o">-</span><span class="n">one_sided</span> <span class="c1"># if not one_sided: p *= 2</span>
    <span class="k">return</span> <span class="n">z</span><span class="p">,</span> <span class="n">p</span>

<span class="n">z</span><span class="p">,</span><span class="n">p</span> <span class="o">=</span> <span class="n">ztest_proportion_two_samples</span><span class="p">(</span><span class="n">convert_A</span><span class="p">,</span> <span class="n">n_A</span><span class="p">,</span> <span class="n">convert_B</span><span class="p">,</span> <span class="n">n_B</span><span class="p">,</span> <span class="n">one_sided</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39; z-stat = </span><span class="si">{z}</span><span class="s1"> </span><span class="se">\n</span><span class="s1"> p-value = </span><span class="si">{p}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">z</span><span class="o">=</span><span class="n">z</span><span class="p">,</span><span class="n">p</span><span class="o">=</span><span class="n">p</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> z-stat = 2.25768200572263 
 p-value = 0.02396549187618935
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">compute_standard_error_prop_two_samples</span><span class="p">(</span><span class="n">x1</span><span class="p">,</span> <span class="n">n1</span><span class="p">,</span> <span class="n">x2</span><span class="p">,</span> <span class="n">n2</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.05</span><span class="p">):</span>
    <span class="n">p1</span> <span class="o">=</span> <span class="n">x1</span><span class="o">/</span><span class="n">n1</span>
    <span class="n">p2</span> <span class="o">=</span> <span class="n">x2</span><span class="o">/</span><span class="n">n2</span>    
    <span class="n">se</span> <span class="o">=</span> <span class="n">p1</span><span class="o">*</span><span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">p1</span><span class="p">)</span><span class="o">/</span><span class="n">n1</span> <span class="o">+</span> <span class="n">p2</span><span class="o">*</span><span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">p2</span><span class="p">)</span><span class="o">/</span><span class="n">n2</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">se</span><span class="p">)</span>

<span class="n">compute_standard_error_prop_two_samples</span><span class="p">(</span><span class="n">convert_A</span><span class="p">,</span> <span class="n">n_A</span><span class="p">,</span> <span class="n">convert_B</span><span class="p">,</span> <span class="n">n_B</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.029216757682663377
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">mean</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-0.06872659176029963
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nb">abs</span><span class="p">(</span><span class="n">z_score</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2.25768200572263
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">scipy</span><span class="o">.</span><span class="n">stats</span><span class="o">.</span><span class="n">norm</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">mean</span><span class="p">,</span><span class="nb">abs</span><span class="p">(</span><span class="n">z_score</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([0.17669829, 0.17669684, 0.17669523, 0.17669346, 0.17669154,
       0.17668946, 0.17668722, 0.17668483, 0.17668229, 0.17667958,
       0.17667672, 0.17667371, 0.17667054, 0.17666721, 0.17666373,
       0.17666009, 0.1766563 , 0.17665235, 0.17664824, 0.17664398,
       0.17663957, 0.17663499, 0.17663026, 0.17662538, 0.17662034,
       0.17661514, 0.17660979, 0.17660428, 0.17659862, 0.1765928 ,
       0.17658682, 0.17658069, 0.17657441, 0.17656797, 0.17656137,
       0.17655462, 0.17654771, 0.17654064, 0.17653342, 0.17652605,
       0.17651852, 0.17651083, 0.17650299, 0.17649499, 0.17648684,
       0.17647853, 0.17647007, 0.17646145, 0.17645267, 0.17644374,
       0.17643466, 0.17642542, 0.17641602, 0.17640647, 0.17639677,
       0.17638691, 0.17637689, 0.17636672, 0.17635639, 0.17634591,
       0.17633528, 0.17632448, 0.17631354, 0.17630244, 0.17629118,
       0.17627977, 0.1762682 , 0.17625648, 0.17624461, 0.17623258,
       0.17622039, 0.17620805, 0.17619556, 0.17618291, 0.1761701 ,
       0.17615714, 0.17614403, 0.17613076, 0.17611734, 0.17610377,
       0.17609004, 0.17607615, 0.17606211, 0.17604792, 0.17603357,
       0.17601907, 0.17600441, 0.1759896 , 0.17597464, 0.17595952,
       0.17594424, 0.17592882, 0.17591324, 0.1758975 , 0.17588161,
       0.17586557, 0.17584938, 0.17583303, 0.17581652, 0.17579987])
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">trace</span><span class="p">[</span><span class="s1">&#39;AvB&#39;</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([0.0373995 , 0.09310736, 0.09015652, ..., 0.07253967, 0.04132596,
       0.08840457])
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">std_err</span> <span class="o">=</span> <span class="n">compute_standard_error_prop_two_samples</span><span class="p">(</span><span class="n">convert_A</span><span class="p">,</span> <span class="n">n_A</span><span class="p">,</span> <span class="n">convert_B</span><span class="p">,</span> <span class="n">n_B</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">scipy</span>

<span class="n">mean</span> <span class="o">=</span>  <span class="n">convert_A</span><span class="o">/</span><span class="n">n_A</span> <span class="o">-</span> <span class="n">convert_B</span><span class="o">/</span><span class="n">n_B</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span><span class="mi">5</span><span class="p">))</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mf">0.05</span><span class="p">,</span><span class="mf">0.16</span><span class="p">,</span><span class="mi">100</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">scipy</span><span class="o">.</span><span class="n">stats</span><span class="o">.</span><span class="n">norm</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">mean</span><span class="p">,</span><span class="n">std_err</span><span class="p">),</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Frequentists: $ N(\hat</span><span class="si">{p_1}</span><span class="s1">-\hat</span><span class="si">{p_2}</span><span class="s1">, SE)$&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">trace</span><span class="p">[</span><span class="s1">&#39;AvB&#39;</span><span class="p">],</span> <span class="n">bins</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">normed</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;0.8&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Posterior Distribution&#39;</span><span class="p">);</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">suptitle</span> <span class="p">(</span><span class="s1">&#39;Baesian Posterior Distribution vs. Frequentist Standard Error&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">18</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39; Binomial proportions, uniform priors&#39;</span> <span class="p">)</span>
<span class="k">pass</span>
<span class="c1"># fig.savefig(&#39;03.03 Bayesian CrI vs CI.png&#39;, dpi=200)</span>
<span class="c1"># no prior information, expect similarities</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: MatplotlibDeprecationWarning: 
The &#39;normed&#39; kwarg was deprecated in Matplotlib 2.1 and will be removed in 3.1. Use &#39;density&#39; instead.
  
</pre></div>
</div>
<img alt="../_images/T990000_causal_inference_235_1.png" src="../_images/T990000_causal_inference_235_1.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># What is the probability that we gained less than +5% uplift in conversions?</span>
<span class="p">(</span><span class="n">trace</span><span class="p">[</span><span class="s1">&#39;AvB&#39;</span><span class="p">]</span><span class="o">&lt;</span><span class="mf">0.05</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">trace</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.5515
</pre></div>
</div>
</div>
</div>
<p>Build a model through day 11 for an A/B/C test</p>
<p>Subset the data up through day 11. You will notice now that there are 3 different arms: A, B, and C.</p>
<p>You will need to add in the third arm into the model.</p>
<p>Additionally, calculate 3 “deterministic” variables that look at differences between the three arms:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>A vs. B
A vs. C
B vs. C
</pre></div>
</div>
<p>What action would you take given these results?</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">current</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="n">data</span><span class="p">[</span><span class="s2">&quot;arm&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">isin</span><span class="p">([</span><span class="s2">&quot;B&quot;</span><span class="p">,</span><span class="s2">&quot;A&quot;</span><span class="p">,</span><span class="s2">&quot;C&quot;</span><span class="p">])]</span><span class="o">.</span><span class="n">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="k">with</span> <span class="n">pm</span><span class="o">.</span><span class="n">Model</span><span class="p">()</span> <span class="k">as</span> <span class="n">day11_model</span><span class="p">:</span>
    
    <span class="n">A_p</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Uniform</span><span class="p">(</span><span class="s1">&#39;A_prob&#39;</span><span class="p">,</span> <span class="n">lower</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">upper</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">B_p</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Uniform</span><span class="p">(</span><span class="s1">&#39;B_prob&#39;</span><span class="p">,</span> <span class="n">lower</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">upper</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">C_p</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Uniform</span><span class="p">(</span><span class="s1">&#39;C_prob&#39;</span><span class="p">,</span> <span class="n">lower</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">upper</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    
    <span class="n">A</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Bernoulli</span><span class="p">(</span><span class="s1">&#39;A&#39;</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="n">A_p</span><span class="p">,</span> <span class="n">observed</span><span class="o">=</span><span class="n">current</span><span class="p">[</span><span class="n">current</span><span class="o">.</span><span class="n">arm</span> <span class="o">==</span> <span class="s1">&#39;A&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">converted</span><span class="o">.</span><span class="n">values</span><span class="p">)</span>
    <span class="n">B</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Bernoulli</span><span class="p">(</span><span class="s1">&#39;B&#39;</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="n">B_p</span><span class="p">,</span> <span class="n">observed</span><span class="o">=</span><span class="n">current</span><span class="p">[</span><span class="n">current</span><span class="o">.</span><span class="n">arm</span> <span class="o">==</span> <span class="s1">&#39;B&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">converted</span><span class="o">.</span><span class="n">values</span><span class="p">)</span>
    <span class="n">C</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Bernoulli</span><span class="p">(</span><span class="s1">&#39;C&#39;</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="n">C_p</span><span class="p">,</span> <span class="n">observed</span><span class="o">=</span><span class="n">current</span><span class="p">[</span><span class="n">current</span><span class="o">.</span><span class="n">arm</span> <span class="o">==</span> <span class="s1">&#39;C&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">converted</span><span class="o">.</span><span class="n">values</span><span class="p">)</span>
    
    <span class="n">AvB</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Deterministic</span><span class="p">(</span><span class="s1">&#39;AvB&#39;</span><span class="p">,</span> <span class="n">A_p</span> <span class="o">-</span> <span class="n">B_p</span><span class="p">)</span>
    <span class="n">AvC</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Deterministic</span><span class="p">(</span><span class="s1">&#39;AvC&#39;</span><span class="p">,</span> <span class="n">A_p</span> <span class="o">-</span> <span class="n">C_p</span><span class="p">)</span>
    <span class="n">BvC</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Deterministic</span><span class="p">(</span><span class="s1">&#39;BvC&#39;</span><span class="p">,</span> <span class="n">B_p</span> <span class="o">-</span> <span class="n">C_p</span><span class="p">)</span>
    
    <span class="n">trace</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="mi">50000</span><span class="p">)</span>
    <span class="c1">#trace = pm.sample(50000, step=pm.Metropolis(), start=pm.find_MAP())</span>
    
<span class="n">pm</span><span class="o">.</span><span class="n">plot_posterior</span><span class="p">(</span><span class="n">trace</span><span class="p">[</span><span class="mi">5000</span><span class="p">::</span><span class="mi">3</span><span class="p">],</span> <span class="n">varnames</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;AvB&#39;</span><span class="p">,</span><span class="s1">&#39;BvC&#39;</span><span class="p">,</span><span class="s1">&#39;AvC&#39;</span><span class="p">],</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;#87ceeb&#39;</span><span class="p">,</span> <span class="n">ref_val</span><span class="o">=</span><span class="mf">0.</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>/usr/local/lib/python3.6/dist-packages/pymc3/tuning/starting.py:61: UserWarning: find_MAP should not be used to initialize the NUTS sampler, simply call pymc3.sample() and it will automatically initialize NUTS in a better way.
  warnings.warn(&#39;find_MAP should not be used to initialize the NUTS sampler, simply call pymc3.sample() and it will automatically initialize NUTS in a better way.&#39;)
logp = -502.53, ||grad|| = 148.32: 100%|██████████| 10/10 [00:00&lt;00:00, 839.77it/s]
Auto-assigning NUTS sampler...
Initializing NUTS using jitter+adapt_diag...
Sequential sampling (2 chains in 1 job)
NUTS: [C_prob, B_prob, A_prob]
100%|██████████| 50500/50500 [00:36&lt;00:00, 1367.98it/s]
100%|██████████| 50500/50500 [00:36&lt;00:00, 1386.24it/s]
/usr/local/lib/python3.6/dist-packages/pymc3/plots/__init__.py:40: UserWarning: Keyword argument `varnames` renamed to `var_names`, and will be removed in pymc3 3.8
  warnings.warn(&#39;Keyword argument `{old}` renamed to `{new}`, and will be removed in pymc3 3.8&#39;.format(old=old, new=new))
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([&lt;matplotlib.axes._subplots.AxesSubplot object at 0x7f863e5dc240&gt;,
       &lt;matplotlib.axes._subplots.AxesSubplot object at 0x7f863f1a76a0&gt;,
       &lt;matplotlib.axes._subplots.AxesSubplot object at 0x7f863ea169b0&gt;],
      dtype=object)
</pre></div>
</div>
<img alt="../_images/T990000_causal_inference_238_2.png" src="../_images/T990000_causal_inference_238_2.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">_</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">traceplot</span><span class="p">(</span><span class="n">trace</span><span class="p">)</span> <span class="c1">## and you can change the type plot</span>
<span class="c1"># https://github.com/thibalbo/bayesian-abtests-examples/blob/master/rate.ipynb</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/T990000_causal_inference_239_0.png" src="../_images/T990000_causal_inference_239_0.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">plot_betas</span><span class="p">(</span><span class="n">beta_traces</span><span class="p">,</span> <span class="n">beta_names</span><span class="p">,</span> <span class="n">colors</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;steelblue&#39;</span><span class="p">,</span><span class="s1">&#39;darkred&#39;</span><span class="p">,</span><span class="s1">&#39;goldenrod&#39;</span><span class="p">]):</span>
    <span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">9</span><span class="p">,</span><span class="mi">5</span><span class="p">))</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">bn</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">beta_names</span><span class="p">):</span>
        <span class="n">ax</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">distplot</span><span class="p">(</span><span class="n">beta_traces</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">kde</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="n">colors</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="n">bn</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s1">&#39;upper right&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="n">plot_betas</span><span class="p">([</span><span class="n">trace</span><span class="p">[</span><span class="mi">5000</span><span class="p">::</span><span class="mi">3</span><span class="p">][</span><span class="s1">&#39;A_prob&#39;</span><span class="p">],</span> 
            <span class="n">trace</span><span class="p">[</span><span class="mi">5000</span><span class="p">::</span><span class="mi">3</span><span class="p">][</span><span class="s1">&#39;B_prob&#39;</span><span class="p">],</span>
            <span class="n">trace</span><span class="p">[</span><span class="mi">5000</span><span class="p">::</span><span class="mi">3</span><span class="p">][</span><span class="s1">&#39;C_prob&#39;</span><span class="p">]],</span>
           <span class="p">[</span><span class="s1">&#39;A_prob&#39;</span><span class="p">,</span><span class="s1">&#39;B_prob&#39;</span><span class="p">,</span><span class="s1">&#39;C_prob&#39;</span><span class="p">])</span>

<span class="c1"># We can be fairly certain that arm A has a higher conversion rate than arm B.</span>
<span class="c1"># There is not enough data to make a statement about arm C.</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/T990000_causal_inference_240_0.png" src="../_images/T990000_causal_inference_240_0.png" />
</div>
</div>
</div>
<div class="section" id="another-approach">
<h3>Another Approach<a class="headerlink" href="#another-approach" title="Permalink to this headline">¶</a></h3>
<p>Sample from beta distributions to evaluate the split test</p>
<p>Our arms are represented as Bernoulli distributed random variables (binary outcome conversion vs. failure). Our prior distributions model the probability of different rates for the arms.</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>Note: a uniform distribution between 0 and 1 is equivalent to a Beta(1,1), or in other words a Beta distribution with 0 successes and 0 failures.
</pre></div>
</div>
<p>We know that the Beta distribution is a conjugate prior to the binomial likelihood, and therefore the posterior distributions for our arms are also beta distributions.</p>
<p>Create beta distributions representing the conversions vs. failures for each arm for all days.</p>
<p>The beta distributions will be parameterized with alpha and beta, which are equivalent to successes + 1 and failures + 1 respectively.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">data</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="s1">&#39;arm&#39;</span><span class="p">)[</span><span class="s1">&#39;converted&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">agg</span><span class="p">([</span><span class="nb">sum</span><span class="p">,</span> <span class="nb">len</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>sum</th>
      <th>len</th>
    </tr>
    <tr>
      <th>arm</th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>A</th>
      <td>66</td>
      <td>356</td>
    </tr>
    <tr>
      <th>B</th>
      <td>28</td>
      <td>240</td>
    </tr>
    <tr>
      <th>C</th>
      <td>33</td>
      <td>129</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">a_beta</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">beta</span><span class="p">(</span><span class="mi">67</span><span class="p">,</span> <span class="mi">357</span><span class="p">)</span>
<span class="n">b_beta</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">beta</span><span class="p">(</span><span class="mi">29</span><span class="p">,</span> <span class="mi">241</span><span class="p">)</span>
<span class="n">c_beta</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">beta</span><span class="p">(</span><span class="mi">34</span><span class="p">,</span> <span class="mi">130</span><span class="p">)</span>

<span class="c1">#Plot the beta distributions across the 0-0.4 range of rates.</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">9</span><span class="p">,</span><span class="mi">5</span><span class="p">))</span>
<span class="n">rates</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mf">0.001</span><span class="p">,</span> <span class="mf">0.40</span><span class="p">,</span> <span class="mi">300</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">rates</span><span class="p">,</span> <span class="n">a_beta</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">rates</span><span class="p">),</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;steelblue&#39;</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;A&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">rates</span><span class="p">,</span> <span class="n">b_beta</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">rates</span><span class="p">),</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;darkred&#39;</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;B&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">rates</span><span class="p">,</span> <span class="n">c_beta</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">rates</span><span class="p">),</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;goldenrod&#39;</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;C&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s1">&#39;upper right&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/T990000_causal_inference_244_0.png" src="../_images/T990000_causal_inference_244_0.png" />
</div>
</div>
<p>Calculate AvB, AvC, and BvC using sampling from the beta distribution</p>
<p>The beta distributions for the arm are our posterior distributions for the conversion rate of each arm given the observed data.</p>
<p>We can calculate the distributions of differences in rates between the arms using sampling. The procedure is:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>* Set up a certain number of iterations (1000, for example)
* For each iteration, take a random draw from each beta distribution
* Calculate the difference between the sampled rates between the arms
* Store the differences in lists
</pre></div>
</div>
<p>Then you can plot these distributions of differences.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">a_samples</span> <span class="o">=</span> <span class="n">a_beta</span><span class="o">.</span><span class="n">rvs</span><span class="p">(</span><span class="mi">5000</span><span class="p">)</span>
<span class="n">b_samples</span> <span class="o">=</span> <span class="n">b_beta</span><span class="o">.</span><span class="n">rvs</span><span class="p">(</span><span class="mi">5000</span><span class="p">)</span>
<span class="n">c_samples</span> <span class="o">=</span> <span class="n">c_beta</span><span class="o">.</span><span class="n">rvs</span><span class="p">(</span><span class="mi">5000</span><span class="p">)</span>

<span class="n">AvB</span> <span class="o">=</span> <span class="n">a_samples</span><span class="o">-</span><span class="n">b_samples</span>
<span class="n">AvC</span> <span class="o">=</span> <span class="n">a_samples</span><span class="o">-</span><span class="n">c_samples</span>
<span class="n">BvC</span> <span class="o">=</span> <span class="n">b_samples</span><span class="o">-</span><span class="n">c_samples</span>

<span class="n">ax</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">distplot</span><span class="p">(</span><span class="n">AvB</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">axvline</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">ls</span><span class="o">=</span><span class="s1">&#39;dashed&#39;</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s1">&#39;black&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;matplotlib.lines.Line2D at 0x7f863f1d6f60&gt;
</pre></div>
</div>
<img alt="../_images/T990000_causal_inference_246_1.png" src="../_images/T990000_causal_inference_246_1.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">ax</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">distplot</span><span class="p">(</span><span class="n">AvC</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">axvline</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">ls</span><span class="o">=</span><span class="s1">&#39;dashed&#39;</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s1">&#39;black&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;matplotlib.lines.Line2D at 0x7f863e7b4198&gt;
</pre></div>
</div>
<img alt="../_images/T990000_causal_inference_247_1.png" src="../_images/T990000_causal_inference_247_1.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">ax</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">distplot</span><span class="p">(</span><span class="n">BvC</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">axvline</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">ls</span><span class="o">=</span><span class="s1">&#39;dashed&#39;</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s1">&#39;black&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;matplotlib.lines.Line2D at 0x7f865006b748&gt;
</pre></div>
</div>
<img alt="../_images/T990000_causal_inference_248_1.png" src="../_images/T990000_causal_inference_248_1.png" />
</div>
</div>
</div>
</div>
<div class="section" id="causal-discovery">
<h2>Causal Discovery<a class="headerlink" href="#causal-discovery" title="Permalink to this headline">¶</a></h2>
<div class="section" id="time-series-causal-discovery-tcdf">
<h3>Time Series Causal Discovery - TCDF<a class="headerlink" href="#time-series-causal-discovery-tcdf" title="Permalink to this headline">¶</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1">## Here is a good dataset in which you can test different data</span>
<span class="c1">## I am happy with these, I can apply them tomorrow. </span>

<span class="n">https</span><span class="p">:</span><span class="o">//</span><span class="n">github</span><span class="o">.</span><span class="n">com</span><span class="o">/</span><span class="n">sayakpaul</span><span class="o">/</span><span class="n">A</span><span class="o">-</span><span class="n">B</span><span class="o">-</span><span class="n">testing</span><span class="o">-</span><span class="k">with</span><span class="o">-</span><span class="n">Machine</span><span class="o">-</span><span class="n">Learning</span><span class="o">/</span><span class="n">blob</span><span class="o">/</span><span class="n">master</span><span class="o">/</span><span class="n">A</span><span class="o">%</span><span class="mi">20</span><span class="n">B</span><span class="o">%</span><span class="mi">20</span><span class="n">tests</span><span class="o">%</span><span class="mi">20</span><span class="k">with</span><span class="o">%</span><span class="mi">20</span><span class="n">Machine</span><span class="o">%</span><span class="mi">20</span><span class="n">Learning</span><span class="o">.</span><span class="n">ipynb</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Causal</span> <span class="n">relationship</span><span class="p">,</span> <span class="n">traffic</span> <span class="n">volume</span> <span class="ow">and</span> <span class="n">weather</span><span class="o">.</span>

<span class="n">https</span><span class="p">:</span><span class="o">//</span><span class="n">archive</span><span class="o">.</span><span class="n">ics</span><span class="o">.</span><span class="n">uci</span><span class="o">.</span><span class="n">edu</span><span class="o">/</span><span class="n">ml</span><span class="o">/</span><span class="n">datasets</span><span class="o">/</span><span class="n">Metro</span><span class="o">+</span><span class="n">Interstate</span><span class="o">+</span><span class="n">Traffic</span><span class="o">+</span><span class="n">Volume</span>

<span class="n">Causal</span> <span class="n">relationship</span><span class="p">,</span>  <span class="n">capital</span> <span class="n">markets</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>!git clone https://github.com/M-Nauta/TCDF.git
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Cloning into &#39;TCDF&#39;...
remote: Enumerating objects: 6, done.
remote: Counting objects: 100% (6/6), done.
remote: Compressing objects: 100% (6/6), done.
remote: Total 101 (delta 1), reused 2 (delta 0), pack-reused 95
Receiving objects: 100% (101/101), 4.70 MiB | 21.29 MiB/s, done.
Resolving deltas: 100% (20/20), done.
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">&quot;https://raw.githubusercontent.com/firmai/random-assets/master/Metro_Interstate_Traffic_Volume.csv&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">df</span><span class="o">.</span><span class="n">dtypes</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>holiday                 object
temp                   float64
rain_1h                float64
snow_1h                float64
clouds_all               int64
weather_main            object
weather_description     object
date_time               object
traffic_volume           int64
dtype: object
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>holiday</th>
      <th>temp</th>
      <th>rain_1h</th>
      <th>snow_1h</th>
      <th>clouds_all</th>
      <th>weather_main</th>
      <th>weather_description</th>
      <th>date_time</th>
      <th>traffic_volume</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>None</td>
      <td>288.28</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>40</td>
      <td>Clouds</td>
      <td>scattered clouds</td>
      <td>2012-10-02 09:00:00</td>
      <td>5545</td>
    </tr>
    <tr>
      <th>1</th>
      <td>None</td>
      <td>289.36</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>75</td>
      <td>Clouds</td>
      <td>broken clouds</td>
      <td>2012-10-02 10:00:00</td>
      <td>4516</td>
    </tr>
    <tr>
      <th>2</th>
      <td>None</td>
      <td>289.58</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>90</td>
      <td>Clouds</td>
      <td>overcast clouds</td>
      <td>2012-10-02 11:00:00</td>
      <td>4767</td>
    </tr>
    <tr>
      <th>3</th>
      <td>None</td>
      <td>290.13</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>90</td>
      <td>Clouds</td>
      <td>overcast clouds</td>
      <td>2012-10-02 12:00:00</td>
      <td>5026</td>
    </tr>
    <tr>
      <th>4</th>
      <td>None</td>
      <td>291.14</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>75</td>
      <td>Clouds</td>
      <td>broken clouds</td>
      <td>2012-10-02 13:00:00</td>
      <td>4918</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">df</span><span class="p">[</span><span class="s2">&quot;date_time&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">to_datetime</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s2">&quot;date_time&quot;</span><span class="p">])</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">set_index</span><span class="p">(</span><span class="s2">&quot;date_time&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="p">[[</span><span class="s2">&quot;traffic_volume&quot;</span><span class="p">,</span> <span class="s2">&quot;temp&quot;</span><span class="p">,</span><span class="s2">&quot;clouds_all&quot;</span><span class="p">,</span><span class="s2">&quot;rain_1h&quot;</span><span class="p">,</span><span class="s2">&quot;snow_1h&quot;</span><span class="p">]]</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>traffic_volume</th>
      <th>temp</th>
      <th>clouds_all</th>
      <th>rain_1h</th>
      <th>snow_1h</th>
    </tr>
    <tr>
      <th>date_time</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2012-10-02 09:00:00</th>
      <td>5545</td>
      <td>288.28</td>
      <td>40</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>2012-10-02 10:00:00</th>
      <td>4516</td>
      <td>289.36</td>
      <td>75</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>2012-10-02 11:00:00</th>
      <td>4767</td>
      <td>289.58</td>
      <td>90</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>2012-10-02 12:00:00</th>
      <td>5026</td>
      <td>290.13</td>
      <td>90</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>2012-10-02 13:00:00</th>
      <td>4918</td>
      <td>291.14</td>
      <td>75</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">%</span><span class="n">cd</span> <span class="n">TCDF</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>/content/TCDF
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">df</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="s2">&quot;traffic.csv&quot;</span><span class="p">,</span><span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">%</span><span class="n">run</span> <span class="o">-</span><span class="n">i</span> <span class="s2">&quot;runTCDF.py&quot;</span> <span class="o">--</span><span class="n">help</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>usage: runTCDF.py [-h] [--cuda] [--epochs EPOCHS] [--kernel_size KERNEL_SIZE]
                  [--hidden_layers HIDDEN_LAYERS]
                  [--learning_rate LEARNING_RATE] [--optimizer {Adam,RMSprop}]
                  [--log_interval LOG_INTERVAL] [--seed SEED]
                  [--dilation_coefficient DILATION_COEFFICIENT]
                  [--significance SIGNIFICANCE] [--plot]
                  (--ground_truth GROUND_TRUTH | --data DATA [DATA ...])

TCDF: Temporal Causal Discovery Framework

optional arguments:
  -h, --help            show this help message and exit
  --cuda                Use CUDA (GPU) (default: False)
  --epochs EPOCHS       Number of epochs (default: 1000)
  --kernel_size KERNEL_SIZE
                        Size of kernel, i.e. window size. Maximum delay to be
                        found is kernel size - 1. Recommended to be equal to
                        dilation coeffient (default: 4)
  --hidden_layers HIDDEN_LAYERS
                        Number of hidden layers in the depthwise convolution
                        (default: 0)
  --learning_rate LEARNING_RATE
                        Learning rate (default: 0.01)
  --optimizer {Adam,RMSprop}
                        Optimizer to use (default: Adam)
  --log_interval LOG_INTERVAL
                        Epoch interval to report loss (default: 500)
  --seed SEED           Random seed (default: 1111)
  --dilation_coefficient DILATION_COEFFICIENT
                        Dilation coefficient, recommended to be equal to
                        kernel size (default: 4)
  --significance SIGNIFICANCE
                        Significance number stating when an increase in loss
                        is significant enough to label a potential cause as
                        true (validated) cause. See paper for more details
                        (default: 0.8)
  --plot                Show causal graph (default: False)
  --ground_truth GROUND_TRUTH
                        Provide dataset(s) and the ground truth(s) to evaluate
                        the results of TCDF. Argument format:
                        DataFile1=GroundtruthFile1,Key2=Value2,... with a key
                        for each dataset containing multivariate time series
                        (required file format: csv, a column with header for
                        each time series) and a value for the corresponding
                        ground truth (required file format: csv, no header,
                        index of cause in first column, index of effect in
                        second column, time delay between cause and effect in
                        third column)
  --data DATA [DATA ...]
                        (Path to) one or more datasets to analyse by TCDF
                        containing multiple time series. Required file format:
                        csv with a column (incl. header) for each time series
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="sd">&quot;&quot;&quot;Run TCDF&quot;&quot;&quot;</span>
<span class="o">%</span><span class="n">matplotlib</span> <span class="n">inline</span>
<span class="o">%</span><span class="n">run</span> <span class="o">-</span><span class="n">i</span> <span class="s2">&quot;runTCDF.py&quot;</span> <span class="o">--</span><span class="n">data</span> <span class="n">traffic</span><span class="o">.</span><span class="n">csv</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Arguments: Namespace(cuda=False, data=[&#39;traffic.csv&#39;], dilation_coefficient=4, epochs=1000, ground_truth=None, hidden_layers=0, kernel_size=4, learning_rate=0.01, log_interval=500, optimizer=&#39;Adam&#39;, plot=False, seed=1111, significance=0.8)

 Dataset:  traffic.csv

 Analysis started for target:  traffic_volume
Epoch:  1 [0%] 	Loss: 14659482.000000
Epoch: 500 [50%] 	Loss: 579337.250000
Epoch: 1000 [100%] 	Loss: 509108.156250
Potential causes:  [0]
Validated causes:  [0]

 Analysis started for target:  temp
Epoch:  1 [0%] 	Loss: 85529.460938
Epoch: 500 [50%] 	Loss: 21.284430
Epoch: 1000 [100%] 	Loss: 18.047306
Potential causes:  [1, 4, 3, 2]
Validated causes:  []

 Analysis started for target:  clouds_all
Epoch:  1 [0%] 	Loss: 5221.722168
Epoch: 500 [50%] 	Loss: 455.046783
Epoch: 1000 [100%] 	Loss: 454.659637
Potential causes:  [2]
Validated causes:  [2]

 Analysis started for target:  rain_1h
Epoch:  1 [0%] 	Loss: 2179.200439
Epoch: 500 [50%] 	Loss: 2005.967285
Epoch: 1000 [100%] 	Loss: 2005.880737
Potential causes:  [4, 3, 1, 2]
Validated causes:  []

 Analysis started for target:  snow_1h
Epoch:  1 [0%] 	Loss: 164.129395
Epoch: 500 [50%] 	Loss: 0.015442
Epoch: 1000 [100%] 	Loss: 0.002264
Potential causes:  [4, 3, 2, 1]
Validated causes:  []

===================Results for traffic.csv ==================================
traffic_volume causes traffic_volume with a delay of 1 time steps.
clouds_all causes clouds_all with a delay of 1 time steps.
==================================================================================
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1">## Lets look at FRED</span>
<span class="n">FRED</span>  <span class="o">=</span><span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;https://github.com/firmai/random-assets/raw/master/capital_markets.txt&#39;</span><span class="p">)[</span><span class="mi">1</span><span class="p">:]</span> <span class="c1">## 130 additional series </span>
<span class="n">FRED</span>  <span class="o">=</span><span class="n">FRED</span><span class="o">.</span><span class="n">set_index</span><span class="p">(</span><span class="s1">&#39;sasdate&#39;</span><span class="p">)</span>
<span class="n">FRED</span><span class="o">.</span><span class="n">index</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">to_datetime</span><span class="p">(</span><span class="n">FRED</span><span class="o">.</span><span class="n">index</span><span class="p">)</span>
<span class="n">FRED</span> <span class="o">=</span> <span class="n">FRED</span><span class="o">.</span><span class="n">ffill</span><span class="p">()</span><span class="o">.</span><span class="n">bfill</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">FRED</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="s2">&quot;FRED.csv&quot;</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">FRED</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>RPI</th>
      <th>W875RX1</th>
      <th>DPCERA3M086SBEA</th>
      <th>CMRMTSPLx</th>
      <th>RETAILx</th>
      <th>INDPRO</th>
      <th>IPFPNSS</th>
      <th>IPFINAL</th>
      <th>IPCONGD</th>
      <th>IPDCONGD</th>
      <th>IPNCONGD</th>
      <th>IPBUSEQ</th>
      <th>IPMAT</th>
      <th>IPDMAT</th>
      <th>IPNMAT</th>
      <th>IPMANSICS</th>
      <th>IPB51222S</th>
      <th>IPFUELS</th>
      <th>CUMFNS</th>
      <th>HWI</th>
      <th>HWIURATIO</th>
      <th>CLF16OV</th>
      <th>CE16OV</th>
      <th>UNRATE</th>
      <th>UEMPMEAN</th>
      <th>UEMPLT5</th>
      <th>UEMP5TO14</th>
      <th>UEMP15OV</th>
      <th>UEMP15T26</th>
      <th>UEMP27OV</th>
      <th>CLAIMSx</th>
      <th>PAYEMS</th>
      <th>USGOOD</th>
      <th>CES1021000001</th>
      <th>USCONS</th>
      <th>MANEMP</th>
      <th>DMANEMP</th>
      <th>NDMANEMP</th>
      <th>SRVPRD</th>
      <th>USTPU</th>
      <th>...</th>
      <th>TB6SMFFM</th>
      <th>T1YFFM</th>
      <th>T5YFFM</th>
      <th>T10YFFM</th>
      <th>AAAFFM</th>
      <th>BAAFFM</th>
      <th>TWEXMMTH</th>
      <th>EXSZUSx</th>
      <th>EXJPUSx</th>
      <th>EXUSUKx</th>
      <th>EXCAUSx</th>
      <th>WPSFD49207</th>
      <th>WPSFD49502</th>
      <th>WPSID61</th>
      <th>WPSID62</th>
      <th>OILPRICEx</th>
      <th>PPICMM</th>
      <th>CPIAUCSL</th>
      <th>CPIAPPSL</th>
      <th>CPITRNSL</th>
      <th>CPIMEDSL</th>
      <th>CUSR0000SAC</th>
      <th>CUSR0000SAD</th>
      <th>CUSR0000SAS</th>
      <th>CPIULFSL</th>
      <th>CUSR0000SA0L2</th>
      <th>CUSR0000SA0L5</th>
      <th>PCEPI</th>
      <th>DDURRG3M086SBEA</th>
      <th>DNDGRG3M086SBEA</th>
      <th>DSERRG3M086SBEA</th>
      <th>CES0600000008</th>
      <th>CES2000000008</th>
      <th>CES3000000008</th>
      <th>UMCSENTx</th>
      <th>MZMSL</th>
      <th>DTCOLNVHFNM</th>
      <th>DTCTHFNM</th>
      <th>INVEST</th>
      <th>VXOCLSx</th>
    </tr>
    <tr>
      <th>sasdate</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>1959-01-01</th>
      <td>2437.296</td>
      <td>2288.8</td>
      <td>17.302</td>
      <td>292258.8329</td>
      <td>18235.77392</td>
      <td>22.6250</td>
      <td>23.4581</td>
      <td>22.1904</td>
      <td>32.4078</td>
      <td>21.9882</td>
      <td>37.7280</td>
      <td>7.9955</td>
      <td>21.2146</td>
      <td>12.6047</td>
      <td>30.5372</td>
      <td>21.1492</td>
      <td>20.2590</td>
      <td>38.3482</td>
      <td>80.1973</td>
      <td>1357.0</td>
      <td>0.333579</td>
      <td>67936</td>
      <td>63868</td>
      <td>6.0</td>
      <td>16.3</td>
      <td>1574</td>
      <td>1169</td>
      <td>1396</td>
      <td>594</td>
      <td>802</td>
      <td>291078</td>
      <td>52478</td>
      <td>18796</td>
      <td>713.0</td>
      <td>2993</td>
      <td>14998</td>
      <td>8740</td>
      <td>6258</td>
      <td>33682</td>
      <td>10774</td>
      <td>...</td>
      <td>0.61</td>
      <td>0.88</td>
      <td>1.53</td>
      <td>1.54</td>
      <td>1.64</td>
      <td>2.39</td>
      <td>108.1883</td>
      <td>4.3122</td>
      <td>359.8417</td>
      <td>2.8065</td>
      <td>0.9671</td>
      <td>33.1</td>
      <td>33.4</td>
      <td>30.6</td>
      <td>31.6</td>
      <td>3.00</td>
      <td>32.5</td>
      <td>29.01</td>
      <td>44.8</td>
      <td>29.3</td>
      <td>21.1</td>
      <td>33.3</td>
      <td>38.1</td>
      <td>22.9</td>
      <td>28.9</td>
      <td>30.7</td>
      <td>29.6</td>
      <td>16.074</td>
      <td>56.918</td>
      <td>17.791</td>
      <td>11.358</td>
      <td>2.13</td>
      <td>2.45</td>
      <td>2.04</td>
      <td>95.3</td>
      <td>274.9</td>
      <td>6476.0</td>
      <td>12298.0</td>
      <td>84.2043</td>
      <td>19.5715</td>
    </tr>
    <tr>
      <th>1959-02-01</th>
      <td>2446.902</td>
      <td>2297.0</td>
      <td>17.482</td>
      <td>294429.5453</td>
      <td>18369.56308</td>
      <td>23.0681</td>
      <td>23.7747</td>
      <td>22.3827</td>
      <td>32.6455</td>
      <td>22.1036</td>
      <td>38.0886</td>
      <td>8.1025</td>
      <td>21.8864</td>
      <td>13.1853</td>
      <td>31.0719</td>
      <td>21.5379</td>
      <td>20.2038</td>
      <td>37.8258</td>
      <td>81.4428</td>
      <td>1421.0</td>
      <td>0.358386</td>
      <td>67649</td>
      <td>63684</td>
      <td>5.9</td>
      <td>15.5</td>
      <td>1554</td>
      <td>1164</td>
      <td>1277</td>
      <td>545</td>
      <td>732</td>
      <td>282958</td>
      <td>52688</td>
      <td>18890</td>
      <td>704.2</td>
      <td>2980</td>
      <td>15115</td>
      <td>8839</td>
      <td>6276</td>
      <td>33798</td>
      <td>10816</td>
      <td>...</td>
      <td>0.70</td>
      <td>1.11</td>
      <td>1.53</td>
      <td>1.53</td>
      <td>1.71</td>
      <td>2.46</td>
      <td>108.1883</td>
      <td>4.3133</td>
      <td>359.8417</td>
      <td>2.8093</td>
      <td>0.9748</td>
      <td>33.2</td>
      <td>33.4</td>
      <td>30.7</td>
      <td>31.4</td>
      <td>3.00</td>
      <td>32.5</td>
      <td>29.00</td>
      <td>44.7</td>
      <td>29.4</td>
      <td>21.2</td>
      <td>33.3</td>
      <td>38.1</td>
      <td>23.0</td>
      <td>28.9</td>
      <td>30.7</td>
      <td>29.6</td>
      <td>16.089</td>
      <td>56.951</td>
      <td>17.798</td>
      <td>11.375</td>
      <td>2.14</td>
      <td>2.46</td>
      <td>2.05</td>
      <td>95.3</td>
      <td>276.0</td>
      <td>6476.0</td>
      <td>12298.0</td>
      <td>83.5280</td>
      <td>19.5715</td>
    </tr>
    <tr>
      <th>1959-03-01</th>
      <td>2462.689</td>
      <td>2314.0</td>
      <td>17.647</td>
      <td>293425.3813</td>
      <td>18523.05762</td>
      <td>23.4004</td>
      <td>23.9186</td>
      <td>22.4925</td>
      <td>32.6455</td>
      <td>22.5365</td>
      <td>37.9083</td>
      <td>8.1900</td>
      <td>22.4549</td>
      <td>13.7048</td>
      <td>31.5387</td>
      <td>21.8749</td>
      <td>20.3417</td>
      <td>38.7835</td>
      <td>82.4769</td>
      <td>1524.0</td>
      <td>0.400947</td>
      <td>68068</td>
      <td>64267</td>
      <td>5.6</td>
      <td>15.3</td>
      <td>1459</td>
      <td>1093</td>
      <td>1210</td>
      <td>530</td>
      <td>680</td>
      <td>260346</td>
      <td>53014</td>
      <td>19069</td>
      <td>704.1</td>
      <td>3013</td>
      <td>15259</td>
      <td>8965</td>
      <td>6294</td>
      <td>33945</td>
      <td>10873</td>
      <td>...</td>
      <td>0.33</td>
      <td>0.81</td>
      <td>1.19</td>
      <td>1.19</td>
      <td>1.33</td>
      <td>2.05</td>
      <td>108.1883</td>
      <td>4.3228</td>
      <td>359.8417</td>
      <td>2.8127</td>
      <td>0.9698</td>
      <td>33.2</td>
      <td>33.3</td>
      <td>30.7</td>
      <td>31.5</td>
      <td>2.97</td>
      <td>32.9</td>
      <td>28.97</td>
      <td>44.7</td>
      <td>29.6</td>
      <td>21.3</td>
      <td>33.2</td>
      <td>38.3</td>
      <td>23.0</td>
      <td>28.9</td>
      <td>30.7</td>
      <td>29.6</td>
      <td>16.100</td>
      <td>57.022</td>
      <td>17.785</td>
      <td>11.395</td>
      <td>2.15</td>
      <td>2.45</td>
      <td>2.07</td>
      <td>95.3</td>
      <td>277.4</td>
      <td>6508.0</td>
      <td>12349.0</td>
      <td>81.6405</td>
      <td>19.5715</td>
    </tr>
    <tr>
      <th>1959-04-01</th>
      <td>2478.744</td>
      <td>2330.3</td>
      <td>17.584</td>
      <td>299331.6505</td>
      <td>18534.46600</td>
      <td>23.8989</td>
      <td>24.2641</td>
      <td>22.8221</td>
      <td>33.1606</td>
      <td>22.6807</td>
      <td>38.5393</td>
      <td>8.4040</td>
      <td>23.0751</td>
      <td>14.1173</td>
      <td>32.5154</td>
      <td>22.3414</td>
      <td>20.4243</td>
      <td>38.6093</td>
      <td>83.9922</td>
      <td>1589.0</td>
      <td>0.444973</td>
      <td>68339</td>
      <td>64768</td>
      <td>5.2</td>
      <td>14.9</td>
      <td>1494</td>
      <td>934</td>
      <td>1039</td>
      <td>408</td>
      <td>631</td>
      <td>246413</td>
      <td>53321</td>
      <td>19269</td>
      <td>705.2</td>
      <td>3085</td>
      <td>15385</td>
      <td>9077</td>
      <td>6308</td>
      <td>34052</td>
      <td>10905</td>
      <td>...</td>
      <td>0.31</td>
      <td>0.76</td>
      <td>1.16</td>
      <td>1.16</td>
      <td>1.27</td>
      <td>1.90</td>
      <td>108.1883</td>
      <td>4.3226</td>
      <td>359.8417</td>
      <td>2.8165</td>
      <td>0.9636</td>
      <td>33.2</td>
      <td>33.4</td>
      <td>30.7</td>
      <td>31.7</td>
      <td>2.97</td>
      <td>32.7</td>
      <td>28.98</td>
      <td>44.8</td>
      <td>29.7</td>
      <td>21.3</td>
      <td>33.2</td>
      <td>38.3</td>
      <td>23.1</td>
      <td>29.0</td>
      <td>30.7</td>
      <td>29.6</td>
      <td>16.132</td>
      <td>57.080</td>
      <td>17.796</td>
      <td>11.436</td>
      <td>2.16</td>
      <td>2.47</td>
      <td>2.08</td>
      <td>95.3</td>
      <td>278.1</td>
      <td>6620.0</td>
      <td>12484.0</td>
      <td>81.8099</td>
      <td>19.5715</td>
    </tr>
    <tr>
      <th>1959-05-01</th>
      <td>2493.228</td>
      <td>2345.8</td>
      <td>17.796</td>
      <td>301372.9597</td>
      <td>18679.66354</td>
      <td>24.2589</td>
      <td>24.4655</td>
      <td>23.0418</td>
      <td>33.3190</td>
      <td>23.1424</td>
      <td>38.5393</td>
      <td>8.6764</td>
      <td>23.6694</td>
      <td>14.6062</td>
      <td>32.8075</td>
      <td>22.6524</td>
      <td>20.7275</td>
      <td>37.8694</td>
      <td>84.9159</td>
      <td>1655.0</td>
      <td>0.475711</td>
      <td>68178</td>
      <td>64699</td>
      <td>5.1</td>
      <td>14.7</td>
      <td>1479</td>
      <td>1005</td>
      <td>965</td>
      <td>390</td>
      <td>575</td>
      <td>246952</td>
      <td>53550</td>
      <td>19378</td>
      <td>710.0</td>
      <td>3087</td>
      <td>15487</td>
      <td>9160</td>
      <td>6327</td>
      <td>34172</td>
      <td>10949</td>
      <td>...</td>
      <td>0.43</td>
      <td>1.06</td>
      <td>1.45</td>
      <td>1.41</td>
      <td>1.47</td>
      <td>2.06</td>
      <td>108.1883</td>
      <td>4.3228</td>
      <td>359.8417</td>
      <td>2.8145</td>
      <td>0.9630</td>
      <td>33.3</td>
      <td>33.3</td>
      <td>30.9</td>
      <td>31.5</td>
      <td>2.97</td>
      <td>32.9</td>
      <td>29.04</td>
      <td>44.9</td>
      <td>29.7</td>
      <td>21.4</td>
      <td>33.3</td>
      <td>38.4</td>
      <td>23.2</td>
      <td>29.1</td>
      <td>30.7</td>
      <td>29.6</td>
      <td>16.140</td>
      <td>57.175</td>
      <td>17.777</td>
      <td>11.454</td>
      <td>2.17</td>
      <td>2.48</td>
      <td>2.08</td>
      <td>95.3</td>
      <td>280.1</td>
      <td>6753.0</td>
      <td>12646.0</td>
      <td>80.7315</td>
      <td>19.5715</td>
    </tr>
  </tbody>
</table>
<p>5 rows × 128 columns</p>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="sd">&quot;&quot;&quot;Run TCDF&quot;&quot;&quot;</span>
<span class="o">%</span><span class="n">matplotlib</span> <span class="n">inline</span>
<span class="o">%</span><span class="n">run</span> <span class="o">-</span><span class="n">i</span> <span class="s2">&quot;runTCDF.py&quot;</span> <span class="o">--</span><span class="n">data</span> <span class="n">FRED</span><span class="o">.</span><span class="n">csv</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Arguments: Namespace(cuda=False, data=[&#39;df_capital.csv&#39;], dilation_coefficient=4, epochs=1000, ground_truth=None, hidden_layers=0, kernel_size=4, learning_rate=0.01, log_interval=500, optimizer=&#39;Adam&#39;, plot=False, seed=1111, significance=0.8)

 Dataset:  df_capital.csv

 Analysis started for target:  RPI
Epoch:  1 [0%] 	Loss: 85752896.000000
Epoch: 500 [50%] 	Loss: 52249.558594
Epoch: 1000 [100%] 	Loss: 36934.804688
Potential causes:  [43, 3, 35, 4]
Validated causes:  []

 Analysis started for target:  W875RX1
Epoch:  1 [0%] 	Loss: 62293040.000000
Epoch: 500 [50%] 	Loss: 31606.019531
Epoch: 1000 [100%] 	Loss: 21431.658203
Potential causes:  [43, 35]
Validated causes:  []

 Analysis started for target:  DPCERA3M086SBEA
Epoch:  1 [0%] 	Loss: 18572.773438
Epoch: 500 [50%] 	Loss: 1.781070
Epoch: 1000 [100%] 	Loss: 0.482416
Potential causes:  [70, 26]
Validated causes:  []

 Analysis started for target:  CMRMTSPLx
Epoch:  1 [0%] 	Loss: 793100877824.000000
Epoch: 500 [50%] 	Loss: 1343997056.000000
Epoch: 1000 [100%] 	Loss: 736136064.000000
Potential causes:  [31, 58]
Validated causes:  []

 Analysis started for target:  RETAILx
Epoch:  1 [0%] 	Loss: 57020481536.000000
Epoch: 500 [50%] 	Loss: 143515632.000000
Epoch: 1000 [100%] 	Loss: 36238616.000000
Potential causes:  [4, 58]
Validated causes:  []

 Analysis started for target:  INDPRO
Epoch:  1 [0%] 	Loss: 19889.707031
Epoch: 500 [50%] 	Loss: 3.284763
Epoch: 1000 [100%] 	Loss: 1.045691
Potential causes:  [43, 15]
Validated causes:  []

 Analysis started for target:  IPFPNSS
Epoch:  1 [0%] 	Loss: 20660.240234
Epoch: 500 [50%] 	Loss: 3.481122
Epoch: 1000 [100%] 	Loss: 1.168782
Potential causes:  [43, 123, 42]
Validated causes:  []

 Analysis started for target:  IPFINAL
Epoch:  1 [0%] 	Loss: 20194.000000
Epoch: 500 [50%] 	Loss: 3.533993
Epoch: 1000 [100%] 	Loss: 1.210451
Potential causes:  [43, 123]
Validated causes:  []

 Analysis started for target:  IPCONGD
Epoch:  1 [0%] 	Loss: 22560.273438
Epoch: 500 [50%] 	Loss: 3.961087
Epoch: 1000 [100%] 	Loss: 1.393554
Potential causes:  [43, 52, 26]
Validated causes:  []

 Analysis started for target:  IPDCONGD
Epoch:  1 [0%] 	Loss: 22323.824219
Epoch: 500 [50%] 	Loss: 8.856396
Epoch: 1000 [100%] 	Loss: 3.903853
Potential causes:  [33, 103, 81]
Validated causes:  []

 Analysis started for target:  IPNCONGD
Epoch:  1 [0%] 	Loss: 22969.115234
Epoch: 500 [50%] 	Loss: 3.777876
Epoch: 1000 [100%] 	Loss: 1.458065
Potential causes:  [43, 26, 52, 37]
Validated causes:  []

 Analysis started for target:  IPBUSEQ
Epoch:  1 [0%] 	Loss: 16834.056641
Epoch: 500 [50%] 	Loss: 4.256637
Epoch: 1000 [100%] 	Loss: 2.395701
Potential causes:  [74, 81, 76]
Validated causes:  []

 Analysis started for target:  IPMAT
Epoch:  1 [0%] 	Loss: 19051.064453
Epoch: 500 [50%] 	Loss: 3.820967
Epoch: 1000 [100%] 	Loss: 1.949556
Potential causes:  [43, 52, 48, 116]
Validated causes:  []

 Analysis started for target:  IPDMAT
Epoch:  1 [0%] 	Loss: 17079.640625
Epoch: 500 [50%] 	Loss: 3.773769
Epoch: 1000 [100%] 	Loss: 1.531314
Potential causes:  [74, 116, 73, 81, 15, 29, 52, 104, 25, 48]
Validated causes:  []

 Analysis started for target:  IPNMAT
Epoch:  1 [0%] 	Loss: 23996.507812
Epoch: 500 [50%] 	Loss: 7.336569
Epoch: 1000 [100%] 	Loss: 3.334358
Potential causes:  [43, 52, 37, 15]
Validated causes:  []

 Analysis started for target:  IPMANSICS
Epoch:  1 [0%] 	Loss: 19847.431641
Epoch: 500 [50%] 	Loss: 3.383688
Epoch: 1000 [100%] 	Loss: 1.143387
Potential causes:  [123, 43, 33]
Validated causes:  []

 Analysis started for target:  IPB51222S
Epoch:  1 [0%] 	Loss: 21214.062500
Epoch: 500 [50%] 	Loss: 12.185338
Epoch: 1000 [100%] 	Loss: 7.284137
Potential causes:  [16, 43]
Validated causes:  []

 Analysis started for target:  IPFUELS
Epoch:  1 [0%] 	Loss: 20640.044922
Epoch: 500 [50%] 	Loss: 8.166091
Epoch: 1000 [100%] 	Loss: 4.947646
Potential causes:  [43, 26, 56, 70, 19]
Validated causes:  []

 Analysis started for target:  CUMFNS
Epoch:  1 [0%] 	Loss: 19964.779297
Epoch: 500 [50%] 	Loss: 5.038280
Epoch: 1000 [100%] 	Loss: 2.493563
Potential causes:  [37, 25, 35]
Validated causes:  []

 Analysis started for target:  HWI
Epoch:  1 [0%] 	Loss: 16179254.000000
Epoch: 500 [50%] 	Loss: 34516.941406
Epoch: 1000 [100%] 	Loss: 22385.330078
Potential causes:  [19, 35]
Validated causes:  []

 Analysis started for target:  HWIURATIO
Epoch:  1 [0%] 	Loss: 5095.841797
Epoch: 500 [50%] 	Loss: 0.181282
Epoch: 1000 [100%] 	Loss: 0.042705
Potential causes:  [36, 64]
Validated causes:  []

 Analysis started for target:  CLF16OV
Epoch:  1 [0%] 	Loss: 15051987968.000000
Epoch: 500 [50%] 	Loss: 13085035.000000
Epoch: 1000 [100%] 	Loss: 7745649.000000
Potential causes:  [31, 21]
Validated causes:  []

 Analysis started for target:  CE16OV
Epoch:  1 [0%] 	Loss: 13295001600.000000
Epoch: 500 [50%] 	Loss: 10297508.000000
Epoch: 1000 [100%] 	Loss: 4842798.500000
Potential causes:  [31, 21]
Validated causes:  []

 Analysis started for target:  UNRATE
Epoch:  1 [0%] 	Loss: 5735.038574
Epoch: 500 [50%] 	Loss: 0.283540
Epoch: 1000 [100%] 	Loss: 0.111942
Potential causes:  [36, 26, 64]
Validated causes:  []

 Analysis started for target:  UEMPMEAN
Epoch:  1 [0%] 	Loss: 7767.864258
Epoch: 500 [50%] 	Loss: 1.186470
Epoch: 1000 [100%] 	Loss: 0.677216
Potential causes:  [79, 27]
Validated causes:  []

 Analysis started for target:  UEMPLT5
Epoch:  1 [0%] 	Loss: 7540029.000000
Epoch: 500 [50%] 	Loss: 19358.859375
Epoch: 1000 [100%] 	Loss: 14147.548828
Potential causes:  [25, 43]
Validated causes:  []

 Analysis started for target:  UEMP5TO14
Epoch:  1 [0%] 	Loss: 5095566.000000
Epoch: 500 [50%] 	Loss: 12293.347656
Epoch: 1000 [100%] 	Loss: 8048.029297
Potential causes:  [26, 25]
Validated causes:  []

 Analysis started for target:  UEMP15OV
Epoch:  1 [0%] 	Loss: 9692396.000000
Epoch: 500 [50%] 	Loss: 17205.886719
Epoch: 1000 [100%] 	Loss: 5581.845215
Potential causes:  [28, 29, 27]
Validated causes:  []

 Analysis started for target:  UEMP15T26
Epoch:  1 [0%] 	Loss: 1449010.500000
Epoch: 500 [50%] 	Loss: 5347.143555
Epoch: 1000 [100%] 	Loss: 3989.725830
Potential causes:  [28, 26]
Validated causes:  []

 Analysis started for target:  UEMP27OV
Epoch:  1 [0%] 	Loss: 4111230.250000
Epoch: 500 [50%] 	Loss: 8993.787109
Epoch: 1000 [100%] 	Loss: 5775.723633
Potential causes:  [29, 27]
Validated causes:  []

 Analysis started for target:  CLAIMSx
Epoch:  1 [0%] 	Loss: 125047980032.000000
Epoch: 500 [50%] 	Loss: 825331840.000000
Epoch: 1000 [100%] 	Loss: 588412032.000000
Potential causes:  [30, 35]
Validated causes:  []

 Analysis started for target:  PAYEMS
Epoch:  1 [0%] 	Loss: 11536934912.000000
Epoch: 500 [50%] 	Loss: 10569973.000000
Epoch: 1000 [100%] 	Loss: 4961437.000000
Potential causes:  [31, 38]
Validated causes:  []

 Analysis started for target:  USGOOD
Epoch:  1 [0%] 	Loss: 485848640.000000
Epoch: 500 [50%] 	Loss: 511065.468750
Epoch: 1000 [100%] 	Loss: 186115.562500
Potential causes:  [35, 36]
Validated causes:  []

 Analysis started for target:  CES1021000001
Epoch:  1 [0%] 	Loss: 561996.375000
Epoch: 500 [50%] 	Loss: 539.528992
Epoch: 1000 [100%] 	Loss: 235.866272
Potential causes:  [33, 21, 79, 31, 19]
Validated causes:  []

 Analysis started for target:  USCONS
Epoch:  1 [0%] 	Loss: 28033558.000000
Epoch: 500 [50%] 	Loss: 24047.541016
Epoch: 1000 [100%] 	Loss: 15104.215820
Potential causes:  [35, 43]
Validated causes:  []

 Analysis started for target:  MANEMP
Epoch:  1 [0%] 	Loss: 266112864.000000
Epoch: 500 [50%] 	Loss: 268075.156250
Epoch: 1000 [100%] 	Loss: 31673.900391
Potential causes:  [35, 32, 36, 37]
Validated causes:  []

 Analysis started for target:  DMANEMP
Epoch:  1 [0%] 	Loss: 100166352.000000
Epoch: 500 [50%] 	Loss: 94319.804688
Epoch: 1000 [100%] 	Loss: 17250.869141
Potential causes:  [35, 32]
Validated causes:  []

 Analysis started for target:  NDMANEMP
Epoch:  1 [0%] 	Loss: 40460120.000000
Epoch: 500 [50%] 	Loss: 37514.347656
Epoch: 1000 [100%] 	Loss: 9121.160156
Potential causes:  [35, 32, 37]
Validated causes:  []

 Analysis started for target:  SRVPRD
Epoch:  1 [0%] 	Loss: 7496762368.000000
Epoch: 500 [50%] 	Loss: 6590905.000000
Epoch: 1000 [100%] 	Loss: 2886559.500000
Potential causes:  [31, 38, 59, 21, 58]
Validated causes:  []

 Analysis started for target:  USTPU
Epoch:  1 [0%] 	Loss: 448735424.000000
Epoch: 500 [50%] 	Loss: 480782.125000
Epoch: 1000 [100%] 	Loss: 47553.632812
Potential causes:  [35, 31, 41, 43, 59, 38]
Validated causes:  []

 Analysis started for target:  USWTRADE
Epoch:  1 [0%] 	Loss: 23696104.000000
Epoch: 500 [50%] 	Loss: 15560.618164
Epoch: 1000 [100%] 	Loss: 5476.309082
Potential causes:  [31, 35, 43]
Validated causes:  []

 Analysis started for target:  USTRADE
Epoch:  1 [0%] 	Loss: 149236448.000000
Epoch: 500 [50%] 	Loss: 122544.062500
Epoch: 1000 [100%] 	Loss: 52240.992188
Potential causes:  [35, 31, 43, 38]
Validated causes:  []

 Analysis started for target:  USFIRE
Epoch:  1 [0%] 	Loss: 39761132.000000
Epoch: 500 [50%] 	Loss: 44491.613281
Epoch: 1000 [100%] 	Loss: 13730.485352
Potential causes:  [43, 31, 38, 35]
Validated causes:  []

 Analysis started for target:  USGOVT
Epoch:  1 [0%] 	Loss: 318317440.000000
Epoch: 500 [50%] 	Loss: 522514.312500
Epoch: 1000 [100%] 	Loss: 185503.906250
Potential causes:  [43, 35, 31]
Validated causes:  []

 Analysis started for target:  CES0600000007
Epoch:  1 [0%] 	Loss: 11173.710938
Epoch: 500 [50%] 	Loss: 0.804093
Epoch: 1000 [100%] 	Loss: 0.184646
Potential causes:  [37, 117, 15]
Validated causes:  []

 Analysis started for target:  AWOTMAN
Epoch:  1 [0%] 	Loss: 5502.593750
Epoch: 500 [50%] 	Loss: 0.252715
Epoch: 1000 [100%] 	Loss: 0.090004
Potential causes:  [36, 64]
Validated causes:  []

 Analysis started for target:  AWHMAN
Epoch:  1 [0%] 	Loss: 11276.819336
Epoch: 500 [50%] 	Loss: 0.840916
Epoch: 1000 [100%] 	Loss: 0.195079
Potential causes:  [37, 117, 15]
Validated causes:  []

 Analysis started for target:  HOUST
Epoch:  1 [0%] 	Loss: 2352663.750000
Epoch: 500 [50%] 	Loss: 1939.970947
Epoch: 1000 [100%] 	Loss: 221.153885
Potential causes:  [51, 50, 49, 52, 48]
Validated causes:  []

 Analysis started for target:  HOUSTNE
Epoch:  1 [0%] 	Loss: 55625.156250
Epoch: 500 [50%] 	Loss: 502.576996
Epoch: 1000 [100%] 	Loss: 487.595093
Potential causes:  [53, 47, 48]
Validated causes:  []

 Analysis started for target:  HOUSTMW
Epoch:  1 [0%] 	Loss: 120668.039062
Epoch: 500 [50%] 	Loss: 782.011780
Epoch: 1000 [100%] 	Loss: 678.411987
Potential causes:  [54, 47]
Validated causes:  []

 Analysis started for target:  HOUSTS
Epoch:  1 [0%] 	Loss: 503286.750000
Epoch: 500 [50%] 	Loss: 1363.419922
Epoch: 1000 [100%] 	Loss: 1103.947754
Potential causes:  [47, 55, 50]
Validated causes:  []

 Analysis started for target:  HOUSTW
Epoch:  1 [0%] 	Loss: 172454.000000
Epoch: 500 [50%] 	Loss: 791.927612
Epoch: 1000 [100%] 	Loss: 743.364685
Potential causes:  [56, 51, 47]
Validated causes:  []

 Analysis started for target:  PERMIT
Epoch:  1 [0%] 	Loss: 2124802.000000
Epoch: 500 [50%] 	Loss: 3746.123047
Epoch: 1000 [100%] 	Loss: 1124.483398
Potential causes:  [55, 56]
Validated causes:  []

 Analysis started for target:  PERMITNE
Epoch:  1 [0%] 	Loss: 56126.597656
Epoch: 500 [50%] 	Loss: 394.495300
Epoch: 1000 [100%] 	Loss: 320.571564
Potential causes:  [52, 53, 48]
Validated causes:  []

 Analysis started for target:  PERMITMW
Epoch:  1 [0%] 	Loss: 107220.468750
Epoch: 500 [50%] 	Loss: 402.945526
Epoch: 1000 [100%] 	Loss: 282.134888
Potential causes:  [52, 54, 49]
Validated causes:  []

 Analysis started for target:  PERMITS
Epoch:  1 [0%] 	Loss: 430236.031250
Epoch: 500 [50%] 	Loss: 1229.824951
Epoch: 1000 [100%] 	Loss: 590.719360
Potential causes:  [52, 55]
Validated causes:  []

 Analysis started for target:  PERMITW
Epoch:  1 [0%] 	Loss: 176502.312500
Epoch: 500 [50%] 	Loss: 705.488892
Epoch: 1000 [100%] 	Loss: 534.476868
Potential causes:  [52, 56, 51]
Validated causes:  []

 Analysis started for target:  ACOGNO
Epoch:  1 [0%] 	Loss: 15376446464.000000
Epoch: 500 [50%] 	Loss: 35571552.000000
Epoch: 1000 [100%] 	Loss: 14985654.000000
Potential causes:  [57, 30, 21, 3, 35, 59, 68]
Validated causes:  []

 Analysis started for target:  AMDMNOx
Epoch:  1 [0%] 	Loss: 19829649408.000000
Epoch: 500 [50%] 	Loss: 44073572.000000
Epoch: 1000 [100%] 	Loss: 13107305.000000
Potential causes:  [59, 58]
Validated causes:  [58]

 Analysis started for target:  ANDENOx
Epoch:  1 [0%] 	Loss: 2154161664.000000
Epoch: 500 [50%] 	Loss: 14609113.000000
Epoch: 1000 [100%] 	Loss: 6026002.000000
Potential causes:  [58, 59]
Validated causes:  [58]

 Analysis started for target:  AMDMUOx
Epoch:  1 [0%] 	Loss: 317475880960.000000
Epoch: 500 [50%] 	Loss: 955354496.000000
Epoch: 1000 [100%] 	Loss: 250340096.000000
Potential causes:  [60, 61, 58, 4, 125, 68, 3, 59, 30, 124]
Validated causes:  [60]

 Analysis started for target:  BUSINVx
Epoch:  1 [0%] 	Loss: 967968555008.000000
Epoch: 500 [50%] 	Loss: 1561898624.000000
Epoch: 1000 [100%] 	Loss: 703955008.000000
Potential causes:  [58, 4, 61, 60, 3, 125, 68, 124, 30, 59]
Validated causes:  []

 Analysis started for target:  ISRATIOx
Epoch:  1 [0%] 	Loss: 5188.880859
Epoch: 500 [50%] 	Loss: 0.183036
Epoch: 1000 [100%] 	Loss: 0.036954
Potential causes:  [36, 64]
Validated causes:  []

 Analysis started for target:  M1SL
Epoch:  1 [0%] 	Loss: 2044029.875000
Epoch: 500 [50%] 	Loss: 419.391449
Epoch: 1000 [100%] 	Loss: 206.637985
Potential causes:  [63, 123, 126]
Validated causes:  [63]

 Analysis started for target:  M2SL
Epoch:  1 [0%] 	Loss: 32588924.000000
Epoch: 500 [50%] 	Loss: 14404.286133
Epoch: 1000 [100%] 	Loss: 1570.561768
Potential causes:  [64, 123]
Validated causes:  [64]

 Analysis started for target:  M2REAL
Epoch:  1 [0%] 	Loss: 8652226.000000
Epoch: 500 [50%] 	Loss: 5882.422363
Epoch: 1000 [100%] 	Loss: 2193.595703
Potential causes:  [43, 65, 35]
Validated causes:  []

 Analysis started for target:  AMBSL
Epoch:  1 [0%] 	Loss: 2140549.250000
Epoch: 500 [50%] 	Loss: 1992.140015
Epoch: 1000 [100%] 	Loss: 305.645996
Potential causes:  [67, 123]
Validated causes:  [67]

 Analysis started for target:  TOTRESNS
Epoch:  1 [0%] 	Loss: 797321.437500
Epoch: 500 [50%] 	Loss: 1297.671997
Epoch: 1000 [100%] 	Loss: 170.023102
Potential causes:  [66, 67]
Validated causes:  [67]

 Analysis started for target:  NONBORRES
Epoch:  1 [0%] 	Loss: 688338173952.000000
Epoch: 500 [50%] 	Loss: 3179832064.000000
Epoch: 1000 [100%] 	Loss: 2430268928.000000
Potential causes:  [68, 3, 60, 61, 125, 30, 4]
Validated causes:  [68]

 Analysis started for target:  BUSLOANS
Epoch:  1 [0%] 	Loss: 965808.625000
Epoch: 500 [50%] 	Loss: 900.119873
Epoch: 1000 [100%] 	Loss: 116.091408
Potential causes:  [69, 74]
Validated causes:  [69]

 Analysis started for target:  REALLN
Epoch:  1 [0%] 	Loss: 4067543.500000
Epoch: 500 [50%] 	Loss: 1201.238892
Epoch: 1000 [100%] 	Loss: 454.768707
Potential causes:  [70, 126, 123, 41]
Validated causes:  [70]

 Analysis started for target:  NONREVSL
Epoch:  1 [0%] 	Loss: 1474576.375000
Epoch: 500 [50%] 	Loss: 755.632141
Epoch: 1000 [100%] 	Loss: 115.553329
Potential causes:  [123, 71]
Validated causes:  []

 Analysis started for target:  CONSPI
Epoch:  1 [0%] 	Loss: 5045.701660
Epoch: 500 [50%] 	Loss: 0.172258
Epoch: 1000 [100%] 	Loss: 0.028166
Potential causes:  [36, 64]
Validated causes:  []

 Analysis started for target:  S&amp;P 500
Epoch:  1 [0%] 	Loss: 1082438.375000
Epoch: 500 [50%] 	Loss: 872.265015
Epoch: 1000 [100%] 	Loss: 257.833191
Potential causes:  [74, 73]
Validated causes:  [74]

 Analysis started for target:  S&amp;P: indust
Epoch:  1 [0%] 	Loss: 1723911.750000
Epoch: 500 [50%] 	Loss: 1439.823975
Epoch: 1000 [100%] 	Loss: 347.938202
Potential causes:  [73, 74]
Validated causes:  [73]

 Analysis started for target:  S&amp;P div yield
Epoch:  1 [0%] 	Loss: 5303.688477
Epoch: 500 [50%] 	Loss: 0.291971
Epoch: 1000 [100%] 	Loss: 0.097669
Potential causes:  [36, 64]
Validated causes:  []

 Analysis started for target:  S&amp;P PE ratio
Epoch:  1 [0%] 	Loss: 7856.484863
Epoch: 500 [50%] 	Loss: 5.142366
Epoch: 1000 [100%] 	Loss: 1.379550
Potential causes:  [76, 69]
Validated causes:  []

 Analysis started for target:  FEDFUNDS
Epoch:  1 [0%] 	Loss: 5449.026855
Epoch: 500 [50%] 	Loss: 0.539549
Epoch: 1000 [100%] 	Loss: 0.073419
Potential causes:  [79, 78]
Validated causes:  []

 Analysis started for target:  CP3Mx
Epoch:  1 [0%] 	Loss: 5460.865234
Epoch: 500 [50%] 	Loss: 0.685103
Epoch: 1000 [100%] 	Loss: 0.157584
Potential causes:  [79, 78]
Validated causes:  []

 Analysis started for target:  TB3MS
Epoch:  1 [0%] 	Loss: 5407.179688
Epoch: 500 [50%] 	Loss: 0.627667
Epoch: 1000 [100%] 	Loss: 0.119500
Potential causes:  [79, 78]
Validated causes:  []

 Analysis started for target:  TB6MS
Epoch:  1 [0%] 	Loss: 5420.742676
Epoch: 500 [50%] 	Loss: 0.484453
Epoch: 1000 [100%] 	Loss: 0.103135
Potential causes:  [79, 78, 33, 36]
Validated causes:  []

 Analysis started for target:  GS1
Epoch:  1 [0%] 	Loss: 5456.852539
Epoch: 500 [50%] 	Loss: 0.544521
Epoch: 1000 [100%] 	Loss: 0.160460
Potential causes:  [79, 33, 78]
Validated causes:  []

 Analysis started for target:  GS5
Epoch:  1 [0%] 	Loss: 5555.609863
Epoch: 500 [50%] 	Loss: 0.606913
Epoch: 1000 [100%] 	Loss: 0.350415
Potential causes:  [79, 33]
Validated causes:  []

 Analysis started for target:  GS10
Epoch:  1 [0%] 	Loss: 5615.349121
Epoch: 500 [50%] 	Loss: 0.562860
Epoch: 1000 [100%] 	Loss: 0.339857
Potential causes:  [79, 33]
Validated causes:  []

 Analysis started for target:  AAA
Epoch:  1 [0%] 	Loss: 5774.542480
Epoch: 500 [50%] 	Loss: 0.553156
Epoch: 1000 [100%] 	Loss: 0.293309
Potential causes:  [79, 94, 33, 36, 25]
Validated causes:  []

 Analysis started for target:  BAA
Epoch:  1 [0%] 	Loss: 5905.133789
Epoch: 500 [50%] 	Loss: 0.674713
Epoch: 1000 [100%] 	Loss: 0.370850
Potential causes:  [79, 94]
Validated causes:  []

 Analysis started for target:  COMPAPFFx
Epoch:  1 [0%] 	Loss: 5043.038086
Epoch: 500 [50%] 	Loss: 0.306884
Epoch: 1000 [100%] 	Loss: 0.069237
Potential causes:  [36, 64]
Validated causes:  []

 Analysis started for target:  TB3SMFFM
Epoch:  1 [0%] 	Loss: 4997.265137
Epoch: 500 [50%] 	Loss: 0.297117
Epoch: 1000 [100%] 	Loss: 0.080192
Potential causes:  [89, 64, 36]
Validated causes:  []

 Analysis started for target:  TB6SMFFM
Epoch:  1 [0%] 	Loss: 5009.581543
Epoch: 500 [50%] 	Loss: 0.283286
Epoch: 1000 [100%] 	Loss: 0.046532
Potential causes:  [89, 36, 64]
Validated causes:  []

 Analysis started for target:  T1YFFM
Epoch:  1 [0%] 	Loss: 5040.609863
Epoch: 500 [50%] 	Loss: 0.423215
Epoch: 1000 [100%] 	Loss: 0.155996
Potential causes:  [89, 36, 64]
Validated causes:  []

 Analysis started for target:  T5YFFM
Epoch:  1 [0%] 	Loss: 5135.561035
Epoch: 500 [50%] 	Loss: 0.587340
Epoch: 1000 [100%] 	Loss: 0.088496
Potential causes:  [89, 93]
Validated causes:  []

 Analysis started for target:  T10YFFM
Epoch:  1 [0%] 	Loss: 5194.124023
Epoch: 500 [50%] 	Loss: 0.653412
Epoch: 1000 [100%] 	Loss: 0.080485
Potential causes:  [93, 89]
Validated causes:  []

 Analysis started for target:  AAAFFM
Epoch:  1 [0%] 	Loss: 5345.854980
Epoch: 500 [50%] 	Loss: 0.541934
Epoch: 1000 [100%] 	Loss: 0.054717
Potential causes:  [93, 36, 64]
Validated causes:  []

 Analysis started for target:  BAAFFM
Epoch:  1 [0%] 	Loss: 5465.476562
Epoch: 500 [50%] 	Loss: 0.821742
Epoch: 1000 [100%] 	Loss: 0.096365
Potential causes:  [93, 89, 81]
Validated causes:  []

 Analysis started for target:  TWEXMMTH
Epoch:  1 [0%] 	Loss: 24725.949219
Epoch: 500 [50%] 	Loss: 6.119929
Epoch: 1000 [100%] 	Loss: 3.129452
Potential causes:  [94, 96]
Validated causes:  []

 Analysis started for target:  EXSZUSx
Epoch:  1 [0%] 	Loss: 5194.355469
Epoch: 500 [50%] 	Loss: 0.216036
Epoch: 1000 [100%] 	Loss: 0.050230
Potential causes:  [36, 64]
Validated causes:  []

 Analysis started for target:  EXJPUSx
Epoch:  1 [0%] 	Loss: 70472.226562
Epoch: 500 [50%] 	Loss: 95.434860
Epoch: 1000 [100%] 	Loss: 31.601822
Potential causes:  [96, 94, 21]
Validated causes:  []

 Analysis started for target:  EXUSUKx
Epoch:  1 [0%] 	Loss: 5219.751953
Epoch: 500 [50%] 	Loss: 0.194651
Epoch: 1000 [100%] 	Loss: 0.070847
Potential causes:  [36, 64]
Validated causes:  []

 Analysis started for target:  EXCAUSx
Epoch:  1 [0%] 	Loss: 5168.944824
Epoch: 500 [50%] 	Loss: 0.183844
Epoch: 1000 [100%] 	Loss: 0.034963
Potential causes:  [36, 64]
Validated causes:  []

 Analysis started for target:  WPSFD49207
Epoch:  1 [0%] 	Loss: 36995.636719
Epoch: 500 [50%] 	Loss: 6.851877
Epoch: 1000 [100%] 	Loss: 3.478253
Potential causes:  [102, 116, 126, 26, 28]
Validated causes:  []

 Analysis started for target:  WPSFD49502
Epoch:  1 [0%] 	Loss: 38442.207031
Epoch: 500 [50%] 	Loss: 8.870347
Epoch: 1000 [100%] 	Loss: 3.759807
Potential causes:  [102, 26]
Validated causes:  []

 Analysis started for target:  WPSID61
Epoch:  1 [0%] 	Loss: 36239.550781
Epoch: 500 [50%] 	Loss: 8.874914
Epoch: 1000 [100%] 	Loss: 2.968049
Potential causes:  [102, 26, 126, 70, 116]
Validated causes:  []

 Analysis started for target:  WPSID62
Epoch:  1 [0%] 	Loss: 39040.894531
Epoch: 500 [50%] 	Loss: 27.928562
Epoch: 1000 [100%] 	Loss: 14.207630
Potential causes:  [102, 103]
Validated causes:  []

 Analysis started for target:  OILPRICEx
Epoch:  1 [0%] 	Loss: 12095.535156
Epoch: 500 [50%] 	Loss: 8.930798
Epoch: 1000 [100%] 	Loss: 6.462852
Potential causes:  [103, 102]
Validated causes:  []

 Analysis started for target:  PPICMM
Epoch:  1 [0%] 	Loss: 40951.574219
Epoch: 500 [50%] 	Loss: 40.701157
Epoch: 1000 [100%] 	Loss: 21.836330
Potential causes:  [104, 70, 127]
Validated causes:  []

 Analysis started for target:  CPIAUCSL
Epoch:  1 [0%] 	Loss: 46503.089844
Epoch: 500 [50%] 	Loss: 9.053062
Epoch: 1000 [100%] 	Loss: 3.093753
Potential causes:  [70, 126, 36, 116]
Validated causes:  []

 Analysis started for target:  CPIAPPSL
Epoch:  1 [0%] 	Loss: 29080.285156
Epoch: 500 [50%] 	Loss: 9.756442
Epoch: 1000 [100%] 	Loss: 1.428801
Potential causes:  [106, 37, 42]
Validated causes:  []

 Analysis started for target:  CPITRNSL
Epoch:  1 [0%] 	Loss: 39859.066406
Epoch: 500 [50%] 	Loss: 15.676751
Epoch: 1000 [100%] 	Loss: 6.351853
Potential causes:  [116, 126, 103]
Validated causes:  []

 Analysis started for target:  CPIMEDSL
Epoch:  1 [0%] 	Loss: 96348.976562
Epoch: 500 [50%] 	Loss: 23.935215
Epoch: 1000 [100%] 	Loss: 11.886409
Potential causes:  [70, 126, 19, 63, 33]
Validated causes:  []

 Analysis started for target:  CUSR0000SAC
Epoch:  1 [0%] 	Loss: 36737.410156
Epoch: 500 [50%] 	Loss: 6.819875
Epoch: 1000 [100%] 	Loss: 3.094246
Potential causes:  [116, 28, 126]
Validated causes:  []

 Analysis started for target:  CUSR0000SAD
Epoch:  1 [0%] 	Loss: 26319.310547
Epoch: 500 [50%] 	Loss: 3.690573
Epoch: 1000 [100%] 	Loss: 1.567260
Potential causes:  [116, 42]
Validated causes:  []

 Analysis started for target:  CUSR0000SAS
Epoch:  1 [0%] 	Loss: 57561.742188
Epoch: 500 [50%] 	Loss: 10.828818
Epoch: 1000 [100%] 	Loss: 3.506416
Potential causes:  [70, 116, 126, 36]
Validated causes:  []

 Analysis started for target:  CPIULFSL
Epoch:  1 [0%] 	Loss: 46474.003906
Epoch: 500 [50%] 	Loss: 9.644928
Epoch: 1000 [100%] 	Loss: 3.266514
Potential causes:  [70, 36, 126]
Validated causes:  []

 Analysis started for target:  CUSR0000SA0L2
Epoch:  1 [0%] 	Loss: 43914.550781
Epoch: 500 [50%] 	Loss: 8.117360
Epoch: 1000 [100%] 	Loss: 2.604212
Potential causes:  [70, 126, 116]
Validated causes:  []

 Analysis started for target:  CUSR0000SA0L5
Epoch:  1 [0%] 	Loss: 44520.746094
Epoch: 500 [50%] 	Loss: 8.834036
Epoch: 1000 [100%] 	Loss: 2.770578
Potential causes:  [70, 126]
Validated causes:  []

 Analysis started for target:  PCEPI
Epoch:  1 [0%] 	Loss: 18466.861328
Epoch: 500 [50%] 	Loss: 2.282767
Epoch: 1000 [100%] 	Loss: 0.397427
Potential causes:  [70, 26, 126, 116]
Validated causes:  []

 Analysis started for target:  DDURRG3M086SBEA
Epoch:  1 [0%] 	Loss: 27604.386719
Epoch: 500 [50%] 	Loss: 7.284635
Epoch: 1000 [100%] 	Loss: 1.971427
Potential causes:  [116, 42]
Validated causes:  []

 Analysis started for target:  DNDGRG3M086SBEA
Epoch:  1 [0%] 	Loss: 17793.412109
Epoch: 500 [50%] 	Loss: 1.918104
Epoch: 1000 [100%] 	Loss: 0.983395
Potential causes:  [26, 116]
Validated causes:  []

 Analysis started for target:  DSERRG3M086SBEA
Epoch:  1 [0%] 	Loss: 17893.529297
Epoch: 500 [50%] 	Loss: 2.338729
Epoch: 1000 [100%] 	Loss: 0.439759
Potential causes:  [70, 126, 123]
Validated causes:  []

 Analysis started for target:  CES0600000008
Epoch:  1 [0%] 	Loss: 7057.318848
Epoch: 500 [50%] 	Loss: 0.315515
Epoch: 1000 [100%] 	Loss: 0.058860
Potential causes:  [36, 64]
Validated causes:  []

 Analysis started for target:  CES2000000008
Epoch:  1 [0%] 	Loss: 7383.157227
Epoch: 500 [50%] 	Loss: 0.399455
Epoch: 1000 [100%] 	Loss: 0.071494
Potential causes:  [64, 36, 0, 69]
Validated causes:  []

 Analysis started for target:  CES3000000008
Epoch:  1 [0%] 	Loss: 6887.088867
Epoch: 500 [50%] 	Loss: 0.284886
Epoch: 1000 [100%] 	Loss: 0.057879
Potential causes:  [36, 64]
Validated causes:  []

 Analysis started for target:  UMCSENTx
Epoch:  1 [0%] 	Loss: 22400.789062
Epoch: 500 [50%] 	Loss: 14.642438
Epoch: 1000 [100%] 	Loss: 10.454063
Potential causes:  [122, 94]
Validated causes:  []

 Analysis started for target:  MZMSL
Epoch:  1 [0%] 	Loss: 36910872.000000
Epoch: 500 [50%] 	Loss: 12930.523438
Epoch: 1000 [100%] 	Loss: 2345.329102
Potential causes:  [123, 41, 64]
Validated causes:  [123]

 Analysis started for target:  DTCOLNVHFNM
Epoch:  1 [0%] 	Loss: 25196267520.000000
Epoch: 500 [50%] 	Loss: 43726752.000000
Epoch: 1000 [100%] 	Loss: 20503922.000000
Potential causes:  [124, 125]
Validated causes:  [124]

 Analysis started for target:  DTCTHFNM
Epoch:  1 [0%] 	Loss: 196669554688.000000
Epoch: 500 [50%] 	Loss: 416819072.000000
Epoch: 1000 [100%] 	Loss: 206679136.000000
Potential causes:  [125, 124]
Validated causes:  [125]

 Analysis started for target:  INVEST
Epoch:  1 [0%] 	Loss: 2237290.500000
Epoch: 500 [50%] 	Loss: 1772.640259
Epoch: 1000 [100%] 	Loss: 754.932495
Potential causes:  [70, 123]
Validated causes:  []

 Analysis started for target:  VXOCLSx
Epoch:  1 [0%] 	Loss: 7595.321289
Epoch: 500 [50%] 	Loss: 14.902537
Epoch: 1000 [100%] 	Loss: 8.616574
Potential causes:  [127, 74]
Validated causes:  [74]

===================Results for df_capital.csv ==================================
AMDMNOx causes AMDMNOx with a delay of 1 time steps.
AMDMNOx causes ANDENOx with a delay of 0 time steps.
AMDMUOx causes AMDMUOx with a delay of 4 time steps.
M1SL causes M1SL with a delay of 1 time steps.
M2SL causes M2SL with a delay of 2 time steps.
TOTRESNS causes AMBSL with a delay of 0 time steps.
TOTRESNS causes TOTRESNS with a delay of 1 time steps.
NONBORRES causes NONBORRES with a delay of 1 time steps.
BUSLOANS causes BUSLOANS with a delay of 1 time steps.
REALLN causes REALLN with a delay of 1 time steps.
S&amp;P: indust causes S&amp;P 500 with a delay of 0 time steps.
S&amp;P 500 causes S&amp;P: indust with a delay of 0 time steps.
MZMSL causes MZMSL with a delay of 1 time steps.
DTCOLNVHFNM causes DTCOLNVHFNM with a delay of 1 time steps.
DTCTHFNM causes DTCTHFNM with a delay of 1 time steps.
S&amp;P: indust causes VXOCLSx with a delay of 0 time steps.
==================================================================================
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>AMDMNOx - Real Manufacturers’ New Orders: Durable Goods</p></li>
<li><p>ANDENOx - Real Value of Manufacturers’ New Orders for Capital Goods:</p></li>
<li><p>TOTRESNS - Total Reserves of Depository Institutions</p></li>
<li><p>AMBSLREALx - Adjusted Monetary Base</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1">## Now lets have a look at capital markets</span>
<span class="c1">## ... only going to look at the last 500 records, features of which have 70% filled records</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">capital</span>  <span class="o">=</span><span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;https://github.com/firmai/random-assets/raw/master/CMD.csv&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="o">-</span><span class="mi">1000</span><span class="p">:,</span><span class="mi">1</span><span class="p">:]</span> <span class="c1">## 130 additional series </span>

<span class="c1">## Lets look at FRED</span>
<span class="n">capital</span>  <span class="o">=</span><span class="n">capital</span><span class="o">.</span><span class="n">set_index</span><span class="p">(</span><span class="s1">&#39;Date&#39;</span><span class="p">)</span>
<span class="n">capital</span><span class="o">.</span><span class="n">index</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">to_datetime</span><span class="p">(</span><span class="n">capital</span><span class="o">.</span><span class="n">index</span><span class="p">)</span>
<span class="n">capital</span> <span class="o">=</span> <span class="n">capital</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,</span> <span class="n">capital</span><span class="o">.</span><span class="n">isnull</span><span class="p">()</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span> <span class="o">&lt;</span> <span class="mf">.3</span><span class="p">]</span>
<span class="n">capital</span> <span class="o">=</span> <span class="n">capital</span><span class="o">.</span><span class="n">ffill</span><span class="p">()</span><span class="o">.</span><span class="n">bfill</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">capital</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Date</th>
      <th>corpbond_iss</th>
      <th>mbs_iss</th>
      <th>muni_iss</th>
      <th>muni_newcapital_iss</th>
      <th>muni_refunding_iss</th>
      <th>corpstock_iss</th>
      <th>pdtranagencyandmbs</th>
      <th>ustotal_iss_sa</th>
      <th>usbondandnotes_iss</th>
      <th>nfc_seo</th>
      <th>nfc_ipo</th>
      <th>usbill_iss</th>
      <th>usnote_iss</th>
      <th>usbond_iss</th>
      <th>ust_total_iss</th>
      <th>uscorpbonds_out</th>
      <th>usbills_out</th>
      <th>usbillsandcertif_out</th>
      <th>usnotes_out</th>
      <th>usbonds_out</th>
      <th>usnotesandbonds_out</th>
      <th>usttotala_out</th>
      <th>usgross_out</th>
      <th>usgf_to_gdp</th>
      <th>usttotala_to_gdp</th>
      <th>usnotesandbonds_to_gdp</th>
      <th>st_liabs_to_for</th>
      <th>total_net_frn</th>
      <th>total_net_bond</th>
      <th>total_net_stock</th>
      <th>dom_ltsecs_pur</th>
      <th>dom_ltsecs_sales</th>
      <th>corp_agency_bond_pur</th>
      <th>corp_agency_bond_sales</th>
      <th>dom_ltsecs_net</th>
      <th>frn_ltsecs_net</th>
      <th>tbill_for_total</th>
      <th>tbill_foi_total</th>
      <th>tbill_priv_total</th>
      <th>...</th>
      <th>repo_tsynom_on</th>
      <th>revrepo_tsynom_on</th>
      <th>repo_tsynom_term</th>
      <th>revrepo_tsynom_term</th>
      <th>repoandreversetotal</th>
      <th>net_repo_on</th>
      <th>net_repo_term</th>
      <th>net_repo</th>
      <th>fedl15d</th>
      <th>fedl15to90d</th>
      <th>fedl90to1y</th>
      <th>fedl1to5y</th>
      <th>fedl5to10y</th>
      <th>fedgreater10y</th>
      <th>fed_net_tsy_dur</th>
      <th>fedhold_bills</th>
      <th>fedhold_notes</th>
      <th>fedhold_bonds</th>
      <th>fedhold_certifandbills</th>
      <th>fedhold_notesandbonds</th>
      <th>ngdpm</th>
      <th>wpi</th>
      <th>avgmatprivheld</th>
      <th>taungdppercapita</th>
      <th>taucorecpi</th>
      <th>infexpst</th>
      <th>infexplt</th>
      <th>oilexportertsyhold</th>
      <th>ismprices</th>
      <th>ismnoinv</th>
      <th>ismempl</th>
      <th>ism</th>
      <th>coreinffactor</th>
      <th>gz_spread</th>
      <th>ebp</th>
      <th>onset_sad</th>
      <th>aaasurvrp</th>
      <th>epu</th>
      <th>fedhold_total</th>
      <th>copper</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>434</th>
      <td>1936-03-01</td>
      <td>488.0</td>
      <td>NaN</td>
      <td>131.0</td>
      <td>60.0</td>
      <td>71.0</td>
      <td>23.65</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>26412.3</td>
      <td>1.953</td>
      <td>1.953</td>
      <td>11.924</td>
      <td>15.541</td>
      <td>27.465</td>
      <td>29.418</td>
      <td>30.792326</td>
      <td>0.357104</td>
      <td>0.341166</td>
      <td>0.318517</td>
      <td>1177.2</td>
      <td>24.530</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>201.840</td>
      <td>177.910</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>23.930</td>
      <td>0.6</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>...</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>610.0</td>
      <td>1555.0</td>
      <td>266.0</td>
      <td>610.0</td>
      <td>1821.0</td>
      <td>86.227869</td>
      <td>13.7</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>-0.417632</td>
      <td>NaN</td>
      <td>1.021237</td>
      <td>2430.0</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>435</th>
      <td>1936-04-01</td>
      <td>644.0</td>
      <td>NaN</td>
      <td>102.0</td>
      <td>49.0</td>
      <td>53.0</td>
      <td>64.25</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>26687.6</td>
      <td>1.953</td>
      <td>1.953</td>
      <td>11.910</td>
      <td>15.541</td>
      <td>27.451</td>
      <td>29.404</td>
      <td>30.776462</td>
      <td>0.354103</td>
      <td>0.338312</td>
      <td>0.315841</td>
      <td>1231.2</td>
      <td>34.732</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>215.938</td>
      <td>163.406</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>52.532</td>
      <td>-17.8</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>...</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>610.0</td>
      <td>1555.0</td>
      <td>266.0</td>
      <td>610.0</td>
      <td>1821.0</td>
      <td>86.913934</td>
      <td>13.7</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>-0.207399</td>
      <td>NaN</td>
      <td>1.001635</td>
      <td>2430.0</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>436</th>
      <td>1936-05-01</td>
      <td>223.0</td>
      <td>NaN</td>
      <td>99.0</td>
      <td>68.0</td>
      <td>31.0</td>
      <td>40.25</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>26947.9</td>
      <td>2.153</td>
      <td>2.153</td>
      <td>11.910</td>
      <td>15.541</td>
      <td>27.451</td>
      <td>29.604</td>
      <td>31.003613</td>
      <td>0.354012</td>
      <td>0.338031</td>
      <td>0.313447</td>
      <td>1299.8</td>
      <td>24.805</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>119.410</td>
      <td>121.305</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>-1.895</td>
      <td>26.7</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>...</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>619.0</td>
      <td>1546.0</td>
      <td>266.0</td>
      <td>619.0</td>
      <td>1812.0</td>
      <td>87.577869</td>
      <td>13.5</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>-0.047618</td>
      <td>NaN</td>
      <td>1.880942</td>
      <td>2430.0</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>437</th>
      <td>1936-06-01</td>
      <td>545.0</td>
      <td>NaN</td>
      <td>109.0</td>
      <td>64.0</td>
      <td>45.0</td>
      <td>78.95</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>26753.4</td>
      <td>2.354</td>
      <td>2.354</td>
      <td>11.381</td>
      <td>17.168</td>
      <td>28.549</td>
      <td>30.903</td>
      <td>32.976312</td>
      <td>0.373610</td>
      <td>0.350120</td>
      <td>0.323450</td>
      <td>1426.2</td>
      <td>80.502</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>150.443</td>
      <td>109.741</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>40.702</td>
      <td>39.8</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>...</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>620.0</td>
      <td>1494.0</td>
      <td>316.0</td>
      <td>620.0</td>
      <td>1810.0</td>
      <td>88.263934</td>
      <td>13.7</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>-0.003456</td>
      <td>NaN</td>
      <td>1.895939</td>
      <td>2430.0</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>438</th>
      <td>1936-07-01</td>
      <td>268.0</td>
      <td>NaN</td>
      <td>42.0</td>
      <td>33.0</td>
      <td>9.0</td>
      <td>33.65</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>26912.7</td>
      <td>2.353</td>
      <td>2.353</td>
      <td>11.381</td>
      <td>17.168</td>
      <td>28.549</td>
      <td>30.902</td>
      <td>32.882444</td>
      <td>0.369765</td>
      <td>0.347495</td>
      <td>0.321035</td>
      <td>1358.3</td>
      <td>131.658</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>211.544</td>
      <td>134.886</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>76.658</td>
      <td>55.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>...</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>609.0</td>
      <td>1497.0</td>
      <td>325.0</td>
      <td>609.0</td>
      <td>1822.0</td>
      <td>88.927869</td>
      <td>13.9</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>0.028172</td>
      <td>NaN</td>
      <td>0.248790</td>
      <td>2430.0</td>
      <td>NaN</td>
    </tr>
  </tbody>
</table>
<p>5 rows × 179 columns</p>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">capital</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(1000, 129)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">capital</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="s2">&quot;capital_markets.csv&quot;</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="sd">&quot;&quot;&quot;Run TCDF&quot;&quot;&quot;</span>
<span class="o">%</span><span class="n">matplotlib</span> <span class="n">inline</span>
<span class="o">%</span><span class="n">run</span> <span class="o">-</span><span class="n">i</span> <span class="s2">&quot;runTCDF.py&quot;</span> <span class="o">--</span><span class="n">data</span> <span class="n">capital_markets</span><span class="o">.</span><span class="n">csv</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Arguments: Namespace(cuda=False, data=[&#39;capital_markets.csv&#39;], dilation_coefficient=4, epochs=1000, ground_truth=None, hidden_layers=0, kernel_size=4, learning_rate=0.01, log_interval=500, optimizer=&#39;Adam&#39;, plot=False, seed=1111, significance=0.8)

 Dataset:  capital_markets.csv

 Analysis started for target:  corpbond_iss
Epoch:  1 [0%] 	Loss: 4681369600.000000
Epoch: 500 [50%] 	Loss: 201031280.000000
Epoch: 1000 [100%] 	Loss: 102773024.000000
Potential causes:  [30, 23, 25, 33, 0, 26]
Validated causes:  [30, 0]

 Analysis started for target:  muni_iss
Epoch:  1 [0%] 	Loss: 283737984.000000
Epoch: 500 [50%] 	Loss: 351164.500000
Epoch: 1000 [100%] 	Loss: 280665.593750
Potential causes:  [2, 3]
Validated causes:  [2, 3]

 Analysis started for target:  muni_newcapital_iss
Epoch:  1 [0%] 	Loss: 101863512.000000
Epoch: 500 [50%] 	Loss: 2275843.250000
Epoch: 1000 [100%] 	Loss: 145202.546875
Potential causes:  [1, 2, 3]
Validated causes:  [1, 3]

 Analysis started for target:  muni_refunding_iss
Epoch:  1 [0%] 	Loss: 59333820.000000
Epoch: 500 [50%] 	Loss: 571136.562500
Epoch: 1000 [100%] 	Loss: 475917.062500
Potential causes:  [1, 3, 2]
Validated causes:  [1, 3, 2]

 Analysis started for target:  corpstock_iss
Epoch:  1 [0%] 	Loss: 54180292.000000
Epoch: 500 [50%] 	Loss: 3915705.250000
Epoch: 1000 [100%] 	Loss: 3424878.500000
Potential causes:  [98, 31]
Validated causes:  [31]

 Analysis started for target:  usbondandnotes_iss
Epoch:  1 [0%] 	Loss: 6041412608.000000
Epoch: 500 [50%] 	Loss: 413894848.000000
Epoch: 1000 [100%] 	Loss: 306631840.000000
Potential causes:  [19, 43, 5, 27]
Validated causes:  [5, 27]

 Analysis started for target:  uscorpbonds_out
Epoch:  1 [0%] 	Loss: 4678223396864.000000
Epoch: 500 [50%] 	Loss: 9015471104.000000
Epoch: 1000 [100%] 	Loss: 2320420608.000000
Potential causes:  [27, 6]
Validated causes:  [6]

 Analysis started for target:  usbills_out
Epoch:  1 [0%] 	Loss: 905671.125000
Epoch: 500 [50%] 	Loss: 244.961914
Epoch: 1000 [100%] 	Loss: 56.413559
Potential causes:  [8, 2, 102]
Validated causes:  [8]

 Analysis started for target:  usbillsandcertif_out
Epoch:  1 [0%] 	Loss: 906085.750000
Epoch: 500 [50%] 	Loss: 428.920776
Epoch: 1000 [100%] 	Loss: 72.681816
Potential causes:  [7, 8]
Validated causes:  [7]

 Analysis started for target:  usnotes_out
Epoch:  1 [0%] 	Loss: 9288908.000000
Epoch: 500 [50%] 	Loss: 3422.900635
Epoch: 1000 [100%] 	Loss: 984.484558
Potential causes:  [29, 11, 9]
Validated causes:  [11]

 Analysis started for target:  usbonds_out
Epoch:  1 [0%] 	Loss: 660883.437500
Epoch: 500 [50%] 	Loss: 405.974762
Epoch: 1000 [100%] 	Loss: 38.442757
Potential causes:  [10, 118]
Validated causes:  [10]

 Analysis started for target:  usnotesandbonds_out
Epoch:  1 [0%] 	Loss: 13242911.000000
Epoch: 500 [50%] 	Loss: 3899.955078
Epoch: 1000 [100%] 	Loss: 863.362427
Potential causes:  [29, 11]
Validated causes:  [11]

 Analysis started for target:  usttotala_out
Epoch:  1 [0%] 	Loss: 18939272.000000
Epoch: 500 [50%] 	Loss: 7347.901855
Epoch: 1000 [100%] 	Loss: 2388.178467
Potential causes:  [29, 11]
Validated causes:  [11]

 Analysis started for target:  usgross_out
Epoch:  1 [0%] 	Loss: 50429596.000000
Epoch: 500 [50%] 	Loss: 36245.851562
Epoch: 1000 [100%] 	Loss: 10535.823242
Potential causes:  [29, 109, 27, 11, 102]
Validated causes:  []

 Analysis started for target:  usgf_to_gdp
Epoch:  1 [0%] 	Loss: 48163.363281
Epoch: 500 [50%] 	Loss: 3.326878
Epoch: 1000 [100%] 	Loss: 0.980433
Potential causes:  [106, 116, 18, 5, 104]
Validated causes:  []

 Analysis started for target:  usttotala_to_gdp
Epoch:  1 [0%] 	Loss: 48090.023438
Epoch: 500 [50%] 	Loss: 3.315362
Epoch: 1000 [100%] 	Loss: 0.963154
Potential causes:  [106, 116, 18, 104, 5]
Validated causes:  []

 Analysis started for target:  usnotesandbonds_to_gdp
Epoch:  1 [0%] 	Loss: 48071.019531
Epoch: 500 [50%] 	Loss: 3.305394
Epoch: 1000 [100%] 	Loss: 0.947363
Potential causes:  [106, 116, 18, 104, 5]
Validated causes:  []

 Analysis started for target:  st_liabs_to_for
Epoch:  1 [0%] 	Loss: 3972727570432.000000
Epoch: 500 [50%] 	Loss: 8516237824.000000
Epoch: 1000 [100%] 	Loss: 4013020928.000000
Potential causes:  [27, 17]
Validated causes:  [17]

 Analysis started for target:  total_net_frn
Epoch:  1 [0%] 	Loss: 874998080.000000
Epoch: 500 [50%] 	Loss: 375018.750000
Epoch: 1000 [100%] 	Loss: 63336.230469
Potential causes:  [19, 25, 20, 26, 41, 42, 43]
Validated causes:  [19]

 Analysis started for target:  total_net_bond
Epoch:  1 [0%] 	Loss: 831089856.000000
Epoch: 500 [50%] 	Loss: 647369.687500
Epoch: 1000 [100%] 	Loss: 136453.609375
Potential causes:  [18, 20, 25, 26, 41]
Validated causes:  [18]

 Analysis started for target:  total_net_stock
Epoch:  1 [0%] 	Loss: 63184956.000000
Epoch: 500 [50%] 	Loss: 911808.562500
Epoch: 1000 [100%] 	Loss: 263149.156250
Potential causes:  [18, 25, 26, 19, 42]
Validated causes:  [18, 25, 26, 19]

 Analysis started for target:  dom_ltsecs_pur
Epoch:  1 [0%] 	Loss: 1047574806528.000000
Epoch: 500 [50%] 	Loss: 2004355456.000000
Epoch: 1000 [100%] 	Loss: 64455376.000000
Potential causes:  [39, 33]
Validated causes:  [39]

 Analysis started for target:  dom_ltsecs_sales
Epoch:  1 [0%] 	Loss: 1007538995200.000000
Epoch: 500 [50%] 	Loss: 3170776576.000000
Epoch: 1000 [100%] 	Loss: 454652320.000000
Potential causes:  [39, 33]
Validated causes:  [39]

 Analysis started for target:  corp_agency_bond_pur
Epoch:  1 [0%] 	Loss: 12786182144.000000
Epoch: 500 [50%] 	Loss: 45117164.000000
Epoch: 1000 [100%] 	Loss: 29284882.000000
Potential causes:  [24, 23]
Validated causes:  [24, 23]

 Analysis started for target:  corp_agency_bond_sales
Epoch:  1 [0%] 	Loss: 10127206400.000000
Epoch: 500 [50%] 	Loss: 55037864.000000
Epoch: 1000 [100%] 	Loss: 31776270.000000
Potential causes:  [23, 24]
Validated causes:  [23, 24]

 Analysis started for target:  dom_ltsecs_net
Epoch:  1 [0%] 	Loss: 993965184.000000
Epoch: 500 [50%] 	Loss: 440616.906250
Epoch: 1000 [100%] 	Loss: 87782.929688
Potential causes:  [41, 26, 42, 18, 19]
Validated causes:  [41]

 Analysis started for target:  frn_ltsecs_net
Epoch:  1 [0%] 	Loss: 105110992.000000
Epoch: 500 [50%] 	Loss: 51347.800781
Epoch: 1000 [100%] 	Loss: 19456.697266
Potential causes:  [25, 18]
Validated causes:  [25, 18]

 Analysis started for target:  tbill_for_total
Epoch:  1 [0%] 	Loss: 74820296704.000000
Epoch: 500 [50%] 	Loss: 28455450.000000
Epoch: 1000 [100%] 	Loss: 10334148.000000
Potential causes:  [27, 28]
Validated causes:  [27]

 Analysis started for target:  tbill_net
Epoch:  1 [0%] 	Loss: 118684312.000000
Epoch: 500 [50%] 	Loss: 1519401.375000
Epoch: 1000 [100%] 	Loss: 374640.687500
Potential causes:  [27, 102, 28, 98, 34, 5]
Validated causes:  [27]

 Analysis started for target:  frn_bonds_pur
Epoch:  1 [0%] 	Loss: 39238451200.000000
Epoch: 500 [50%] 	Loss: 29316938.000000
Epoch: 1000 [100%] 	Loss: 12433799.000000
Potential causes:  [30, 29]
Validated causes:  [30]

 Analysis started for target:  frn_bonds_sales
Epoch:  1 [0%] 	Loss: 37949833216.000000
Epoch: 500 [50%] 	Loss: 52524256.000000
Epoch: 1000 [100%] 	Loss: 13341458.000000
Potential causes:  [29, 30, 109, 26, 38, 39, 34, 37, 107, 97, 21, 17, 127, 6, 27, 36, 35, 40, 115, 101, 22]
Validated causes:  [29]

 Analysis started for target:  frn_stocks_pur
Epoch:  1 [0%] 	Loss: 24443131904.000000
Epoch: 500 [50%] 	Loss: 28372234.000000
Epoch: 1000 [100%] 	Loss: 11081559.000000
Potential causes:  [32, 33, 34]
Validated causes:  [32]

 Analysis started for target:  frn_stocks_sales
Epoch:  1 [0%] 	Loss: 25205243904.000000
Epoch: 500 [50%] 	Loss: 30476458.000000
Epoch: 1000 [100%] 	Loss: 16252728.000000
Potential causes:  [31, 33]
Validated causes:  [31]

 Analysis started for target:  dom_stocks_pur
Epoch:  1 [0%] 	Loss: 137566273536.000000
Epoch: 500 [50%] 	Loss: 172732816.000000
Epoch: 1000 [100%] 	Loss: 17372728.000000
Potential causes:  [34, 29, 33, 38, 37]
Validated causes:  [34]

 Analysis started for target:  dom_stocks_sales
Epoch:  1 [0%] 	Loss: 136879636480.000000
Epoch: 500 [50%] 	Loss: 41278680.000000
Epoch: 1000 [100%] 	Loss: 18232994.000000
Potential causes:  [33, 29, 34]
Validated causes:  [33]

 Analysis started for target:  ust_sales
Epoch:  1 [0%] 	Loss: 304362815488.000000
Epoch: 500 [50%] 	Loss: 668293312.000000
Epoch: 1000 [100%] 	Loss: 220571248.000000
Potential causes:  [39, 36]
Validated causes:  [39, 36]

 Analysis started for target:  ust_pur
Epoch:  1 [0%] 	Loss: 313676005376.000000
Epoch: 500 [50%] 	Loss: 621372736.000000
Epoch: 1000 [100%] 	Loss: 158984640.000000
Potential causes:  [39, 35]
Validated causes:  [39, 35]

 Analysis started for target:  frn_ltsecs_pur
Epoch:  1 [0%] 	Loss: 118907002880.000000
Epoch: 500 [50%] 	Loss: 222092992.000000
Epoch: 1000 [100%] 	Loss: 73998576.000000
Potential causes:  [29, 38, 33]
Validated causes:  [29, 38]

 Analysis started for target:  frn_ltsecs_sales
Epoch:  1 [0%] 	Loss: 118445391872.000000
Epoch: 500 [50%] 	Loss: 280552544.000000
Epoch: 1000 [100%] 	Loss: 80150280.000000
Potential causes:  [37, 29, 33]
Validated causes:  [37]

 Analysis started for target:  dom_bonds_pur
Epoch:  1 [0%] 	Loss: 444840312832.000000
Epoch: 500 [50%] 	Loss: 2828025088.000000
Epoch: 1000 [100%] 	Loss: 127420400.000000
Potential causes:  [40, 36, 35]
Validated causes:  [40]

 Analysis started for target:  dom_bonds_sales
Epoch:  1 [0%] 	Loss: 419334520832.000000
Epoch: 500 [50%] 	Loss: 546021888.000000
Epoch: 1000 [100%] 	Loss: 266484032.000000
Potential causes:  [39, 35, 36]
Validated causes:  [39]

 Analysis started for target:  dom_bonds_net
Epoch:  1 [0%] 	Loss: 807029632.000000
Epoch: 500 [50%] 	Loss: 5062283.500000
Epoch: 1000 [100%] 	Loss: 306742.750000
Potential causes:  [25, 42, 19, 26, 18]
Validated causes:  [25]

 Analysis started for target:  dom_stocks_net
Epoch:  1 [0%] 	Loss: 49709152.000000
Epoch: 500 [50%] 	Loss: 205917.421875
Epoch: 1000 [100%] 	Loss: 25404.568359
Potential causes:  [25, 41]
Validated causes:  [25, 41]

 Analysis started for target:  ust_net
Epoch:  1 [0%] 	Loss: 316961472.000000
Epoch: 500 [50%] 	Loss: 21539070.000000
Epoch: 1000 [100%] 	Loss: 390491.281250
Potential causes:  [41, 24]
Validated causes:  [41, 24]

 Analysis started for target:  rx2
Epoch:  1 [0%] 	Loss: 48068.546875
Epoch: 500 [50%] 	Loss: 3.522934
Epoch: 1000 [100%] 	Loss: 1.070873
Potential causes:  [106, 116, 104, 18, 70, 5]
Validated causes:  []

 Analysis started for target:  rx3
Epoch:  1 [0%] 	Loss: 48179.558594
Epoch: 500 [50%] 	Loss: 3.600485
Epoch: 1000 [100%] 	Loss: 1.081423
Potential causes:  [106, 57, 70, 116, 104, 48, 18]
Validated causes:  []

 Analysis started for target:  rx4
Epoch:  1 [0%] 	Loss: 48290.371094
Epoch: 500 [50%] 	Loss: 3.606118
Epoch: 1000 [100%] 	Loss: 1.043389
Potential causes:  [106, 48]
Validated causes:  []

 Analysis started for target:  rx5
Epoch:  1 [0%] 	Loss: 48393.824219
Epoch: 500 [50%] 	Loss: 3.722472
Epoch: 1000 [100%] 	Loss: 1.130242
Potential causes:  [106, 48]
Validated causes:  []

 Analysis started for target:  rx6
Epoch:  1 [0%] 	Loss: 48486.218750
Epoch: 500 [50%] 	Loss: 3.610085
Epoch: 1000 [100%] 	Loss: 1.138560
Potential causes:  [49, 52]
Validated causes:  []

 Analysis started for target:  rx7
Epoch:  1 [0%] 	Loss: 48571.468750
Epoch: 500 [50%] 	Loss: 3.701339
Epoch: 1000 [100%] 	Loss: 1.206656
Potential causes:  [52, 48]
Validated causes:  []

 Analysis started for target:  rx8
Epoch:  1 [0%] 	Loss: 48649.515625
Epoch: 500 [50%] 	Loss: 3.726647
Epoch: 1000 [100%] 	Loss: 1.129188
Potential causes:  [52, 49, 48]
Validated causes:  []

 Analysis started for target:  rx9
Epoch:  1 [0%] 	Loss: 48719.351562
Epoch: 500 [50%] 	Loss: 3.674852
Epoch: 1000 [100%] 	Loss: 1.105500
Potential causes:  [52, 49, 48]
Validated causes:  []

 Analysis started for target:  rx10
Epoch:  1 [0%] 	Loss: 48783.949219
Epoch: 500 [50%] 	Loss: 4.085249
Epoch: 1000 [100%] 	Loss: 1.329019
Potential causes:  [49, 64, 48]
Validated causes:  []

 Analysis started for target:  rx15
Epoch:  1 [0%] 	Loss: 49050.605469
Epoch: 500 [50%] 	Loss: 5.491628
Epoch: 1000 [100%] 	Loss: 1.406105
Potential causes:  [64, 52]
Validated causes:  []

 Analysis started for target:  rx20
Epoch:  1 [0%] 	Loss: 49276.136719
Epoch: 500 [50%] 	Loss: 6.440078
Epoch: 1000 [100%] 	Loss: 1.694027
Potential causes:  [65, 54]
Validated causes:  []

 Analysis started for target:  ret2
Epoch:  1 [0%] 	Loss: 48506.937500
Epoch: 500 [50%] 	Loss: 4.215701
Epoch: 1000 [100%] 	Loss: 1.267539
Potential causes:  [66, 70, 106, 74]
Validated causes:  []

 Analysis started for target:  ret3
Epoch:  1 [0%] 	Loss: 48620.257812
Epoch: 500 [50%] 	Loss: 4.296632
Epoch: 1000 [100%] 	Loss: 1.235440
Potential causes:  [66, 106, 70, 45, 74, 48]
Validated causes:  []

 Analysis started for target:  ret4
Epoch:  1 [0%] 	Loss: 48732.496094
Epoch: 500 [50%] 	Loss: 4.516153
Epoch: 1000 [100%] 	Loss: 1.227894
Potential causes:  [48, 66, 45]
Validated causes:  []

 Analysis started for target:  ret5
Epoch:  1 [0%] 	Loss: 48836.875000
Epoch: 500 [50%] 	Loss: 4.590962
Epoch: 1000 [100%] 	Loss: 1.226420
Potential causes:  [66, 48, 106, 45, 70]
Validated causes:  []

 Analysis started for target:  ret6
Epoch:  1 [0%] 	Loss: 48929.296875
Epoch: 500 [50%] 	Loss: 4.114995
Epoch: 1000 [100%] 	Loss: 1.071530
Potential causes:  [48, 106, 66, 52]
Validated causes:  []

 Analysis started for target:  ret7
Epoch:  1 [0%] 	Loss: 49014.757812
Epoch: 500 [50%] 	Loss: 4.020707
Epoch: 1000 [100%] 	Loss: 1.037271
Potential causes:  [48, 52]
Validated causes:  []

 Analysis started for target:  ret8
Epoch:  1 [0%] 	Loss: 49093.664062
Epoch: 500 [50%] 	Loss: 4.236659
Epoch: 1000 [100%] 	Loss: 1.101334
Potential causes:  [52, 48]
Validated causes:  []

 Analysis started for target:  ret9
Epoch:  1 [0%] 	Loss: 49162.816406
Epoch: 500 [50%] 	Loss: 4.191928
Epoch: 1000 [100%] 	Loss: 1.086714
Potential causes:  [52, 61, 48, 57, 106]
Validated causes:  []

 Analysis started for target:  ret10
Epoch:  1 [0%] 	Loss: 49227.339844
Epoch: 500 [50%] 	Loss: 4.319827
Epoch: 1000 [100%] 	Loss: 1.140199
Potential causes:  [52, 61, 64, 48, 57, 106]
Validated causes:  []

 Analysis started for target:  ret15
Epoch:  1 [0%] 	Loss: 49492.949219
Epoch: 500 [50%] 	Loss: 7.575989
Epoch: 1000 [100%] 	Loss: 1.699906
Potential causes:  [53, 52, 65]
Validated causes:  []

 Analysis started for target:  ret20
Epoch:  1 [0%] 	Loss: 49725.132812
Epoch: 500 [50%] 	Loss: 6.901110
Epoch: 1000 [100%] 	Loss: 1.444465
Potential causes:  [54, 65]
Validated causes:  []

 Analysis started for target:  threem
Epoch:  1 [0%] 	Loss: 48359.554688
Epoch: 500 [50%] 	Loss: 3.614526
Epoch: 1000 [100%] 	Loss: 1.115153
Potential causes:  [66, 106]
Validated causes:  []

 Analysis started for target:  one
Epoch:  1 [0%] 	Loss: 48422.867188
Epoch: 500 [50%] 	Loss: 3.426707
Epoch: 1000 [100%] 	Loss: 1.000520
Potential causes:  [66, 106, 70]
Validated causes:  []

 Analysis started for target:  two
Epoch:  1 [0%] 	Loss: 48465.386719
Epoch: 500 [50%] 	Loss: 3.353078
Epoch: 1000 [100%] 	Loss: 0.950962
Potential causes:  [66, 70, 106]
Validated causes:  []

 Analysis started for target:  three
Epoch:  1 [0%] 	Loss: 48512.511719
Epoch: 500 [50%] 	Loss: 3.330628
Epoch: 1000 [100%] 	Loss: 0.931044
Potential causes:  [66, 70, 106, 74]
Validated causes:  []

 Analysis started for target:  four
Epoch:  1 [0%] 	Loss: 48558.515625
Epoch: 500 [50%] 	Loss: 3.351994
Epoch: 1000 [100%] 	Loss: 0.942356
Potential causes:  [66, 70, 106, 74]
Validated causes:  []

 Analysis started for target:  five
Epoch:  1 [0%] 	Loss: 48601.222656
Epoch: 500 [50%] 	Loss: 3.338374
Epoch: 1000 [100%] 	Loss: 0.913033
Potential causes:  [70, 66, 106, 74]
Validated causes:  []

 Analysis started for target:  six
Epoch:  1 [0%] 	Loss: 48640.156250
Epoch: 500 [50%] 	Loss: 3.304523
Epoch: 1000 [100%] 	Loss: 0.904887
Potential causes:  [70, 106, 74, 66]
Validated causes:  []

 Analysis started for target:  seven
Epoch:  1 [0%] 	Loss: 48674.652344
Epoch: 500 [50%] 	Loss: 3.314607
Epoch: 1000 [100%] 	Loss: 0.908876
Potential causes:  [70, 74, 106, 66]
Validated causes:  []

 Analysis started for target:  eight
Epoch:  1 [0%] 	Loss: 48705.382812
Epoch: 500 [50%] 	Loss: 3.330935
Epoch: 1000 [100%] 	Loss: 0.914265
Potential causes:  [70, 106, 74, 66]
Validated causes:  []

 Analysis started for target:  nine
Epoch:  1 [0%] 	Loss: 48732.191406
Epoch: 500 [50%] 	Loss: 3.338117
Epoch: 1000 [100%] 	Loss: 0.904459
Potential causes:  [70, 106, 74, 66]
Validated causes:  []

 Analysis started for target:  ten
Epoch:  1 [0%] 	Loss: 48755.355469
Epoch: 500 [50%] 	Loss: 3.369753
Epoch: 1000 [100%] 	Loss: 0.919855
Potential causes:  [70, 74, 106, 66]
Validated causes:  []

 Analysis started for target:  eleven
Epoch:  1 [0%] 	Loss: 48776.085938
Epoch: 500 [50%] 	Loss: 3.354059
Epoch: 1000 [100%] 	Loss: 0.911432
Potential causes:  [70, 74, 106, 66]
Validated causes:  []

 Analysis started for target:  twelve
Epoch:  1 [0%] 	Loss: 48793.839844
Epoch: 500 [50%] 	Loss: 3.362992
Epoch: 1000 [100%] 	Loss: 0.915518
Potential causes:  [70, 74, 106, 66]
Validated causes:  []

 Analysis started for target:  thirteen
Epoch:  1 [0%] 	Loss: 48809.207031
Epoch: 500 [50%] 	Loss: 3.368565
Epoch: 1000 [100%] 	Loss: 0.920280
Potential causes:  [74, 70, 106, 66]
Validated causes:  []

 Analysis started for target:  fourteen
Epoch:  1 [0%] 	Loss: 48822.414062
Epoch: 500 [50%] 	Loss: 3.377612
Epoch: 1000 [100%] 	Loss: 0.928572
Potential causes:  [74, 106, 70]
Validated causes:  []

 Analysis started for target:  fifteen
Epoch:  1 [0%] 	Loss: 48833.582031
Epoch: 500 [50%] 	Loss: 3.397366
Epoch: 1000 [100%] 	Loss: 0.940706
Potential causes:  [74, 106, 70]
Validated causes:  []

 Analysis started for target:  twenty
Epoch:  1 [0%] 	Loss: 48870.613281
Epoch: 500 [50%] 	Loss: 3.448774
Epoch: 1000 [100%] 	Loss: 0.949987
Potential causes:  [74, 106, 70]
Validated causes:  []

 Analysis started for target:  mort_rate
Epoch:  1 [0%] 	Loss: 49116.449219
Epoch: 500 [50%] 	Loss: 3.414256
Epoch: 1000 [100%] 	Loss: 0.873507
Potential causes:  [74, 66, 106]
Validated causes:  []

 Analysis started for target:  muni_yield
Epoch:  1 [0%] 	Loss: 48923.804688
Epoch: 500 [50%] 	Loss: 3.544070
Epoch: 1000 [100%] 	Loss: 1.018095
Potential causes:  [106, 70, 74]
Validated causes:  []

 Analysis started for target:  aaa
Epoch:  1 [0%] 	Loss: 49055.117188
Epoch: 500 [50%] 	Loss: 3.466618
Epoch: 1000 [100%] 	Loss: 0.901485
Potential causes:  [74, 106, 66]
Validated causes:  []

 Analysis started for target:  baa
Epoch:  1 [0%] 	Loss: 49275.199219
Epoch: 500 [50%] 	Loss: 3.560392
Epoch: 1000 [100%] 	Loss: 1.012664
Potential causes:  [74, 106, 66]
Validated causes:  []

 Analysis started for target:  yield_avg
Epoch:  1 [0%] 	Loss: 48775.160156
Epoch: 500 [50%] 	Loss: 3.352194
Epoch: 1000 [100%] 	Loss: 0.921618
Potential causes:  [106, 70, 74, 66]
Validated causes:  []

 Analysis started for target:  rx_avg
Epoch:  1 [0%] 	Loss: 48670.339844
Epoch: 500 [50%] 	Loss: 4.058087
Epoch: 1000 [100%] 	Loss: 1.119429
Potential causes:  [89, 88]
Validated causes:  []

 Analysis started for target:  ret_avg
Epoch:  1 [0%] 	Loss: 49113.421875
Epoch: 500 [50%] 	Loss: 5.818861
Epoch: 1000 [100%] 	Loss: 1.102845
Potential causes:  [88, 106]
Validated causes:  []

 Analysis started for target:  exp_ret_ngdpcapita
Epoch:  1 [0%] 	Loss: 48940.894531
Epoch: 500 [50%] 	Loss: 8.063824
Epoch: 1000 [100%] 	Loss: 2.813799
Potential causes:  [90, 88, 104, 106]
Validated causes:  []

 Analysis started for target:  tsypi
Epoch:  1 [0%] 	Loss: 47990.062500
Epoch: 500 [50%] 	Loss: 3.287379
Epoch: 1000 [100%] 	Loss: 0.915772
Potential causes:  [106, 116]
Validated causes:  []

 Analysis started for target:  total_npos
Epoch:  1 [0%] 	Loss: 1957531648.000000
Epoch: 500 [50%] 	Loss: 1644423.375000
Epoch: 1000 [100%] 	Loss: 459874.125000
Potential causes:  [101, 99, 98, 100]
Validated causes:  [99]

 Analysis started for target:  total_npos_to_gdp
Epoch:  1 [0%] 	Loss: 48164.195312
Epoch: 500 [50%] 	Loss: 3.714212
Epoch: 1000 [100%] 	Loss: 0.845459
Potential causes:  [106, 93]
Validated causes:  []

 Analysis started for target:  total_npos_to_parpriv
Epoch:  1 [0%] 	Loss: 47785.976562
Epoch: 500 [50%] 	Loss: 7.881034
Epoch: 1000 [100%] 	Loss: 2.842298
Potential causes:  [93, 94]
Validated causes:  []

 Analysis started for target:  netdur_npos
Epoch:  1 [0%] 	Loss: 48119.242188
Epoch: 500 [50%] 	Loss: 6.129825
Epoch: 1000 [100%] 	Loss: 1.715222
Potential causes:  [106, 95]
Validated causes:  []

 Analysis started for target:  abs_npos
Epoch:  1 [0%] 	Loss: 3026781696.000000
Epoch: 500 [50%] 	Loss: 8279365.500000
Epoch: 1000 [100%] 	Loss: 5687700.000000
Potential causes:  [98, 100, 97]
Validated causes:  [97]

 Analysis started for target:  absdurrisk_npos
Epoch:  1 [0%] 	Loss: 75510808576.000000
Epoch: 500 [50%] 	Loss: 1075106560.000000
Epoch: 1000 [100%] 	Loss: 622983552.000000
Potential causes:  [101, 96, 99, 97]
Validated causes:  [97]

 Analysis started for target:  pd_npos_l1
Epoch:  1 [0%] 	Loss: 139468864.000000
Epoch: 500 [50%] 	Loss: 83585.484375
Epoch: 1000 [100%] 	Loss: 13059.812500
Potential causes:  [92, 99]
Validated causes:  [92, 99]

 Analysis started for target:  pd_npos_g1
Epoch:  1 [0%] 	Loss: 1686948608.000000
Epoch: 500 [50%] 	Loss: 2881844.000000
Epoch: 1000 [100%] 	Loss: 1658409.625000
Potential causes:  [101, 100]
Validated causes:  [100]

 Analysis started for target:  pd_npos_g1l7
Epoch:  1 [0%] 	Loss: 845193792.000000
Epoch: 500 [50%] 	Loss: 10211889.000000
Epoch: 1000 [100%] 	Loss: 8163404.000000
Potential causes:  [99, 100]
Validated causes:  [99, 100]

 Analysis started for target:  pd_npos_g7
Epoch:  1 [0%] 	Loss: 234873360.000000
Epoch: 500 [50%] 	Loss: 7422288.500000
Epoch: 1000 [100%] 	Loss: 6219999.500000
Potential causes:  [101, 99]
Validated causes:  [101, 99]

 Analysis started for target:  pd_npos_gse_and_mbs
Epoch:  1 [0%] 	Loss: 3833199360.000000
Epoch: 500 [50%] 	Loss: 43694376.000000
Epoch: 1000 [100%] 	Loss: 21168594.000000
Potential causes:  [103, 102]
Validated causes:  [103, 102]

 Analysis started for target:  pd_npos_gse
Epoch:  1 [0%] 	Loss: 1386877696.000000
Epoch: 500 [50%] 	Loss: 21359552.000000
Epoch: 1000 [100%] 	Loss: 9525585.000000
Potential causes:  [102, 103]
Validated causes:  [102, 103]

 Analysis started for target:  fedl15d
Epoch:  1 [0%] 	Loss: 270274112.000000
Epoch: 500 [50%] 	Loss: 20001574.000000
Epoch: 1000 [100%] 	Loss: 16536906.000000
Potential causes:  [104, 106, 96, 4]
Validated causes:  [104, 106]

 Analysis started for target:  fedl15to90d
Epoch:  1 [0%] 	Loss: 3326907648.000000
Epoch: 500 [50%] 	Loss: 24756792.000000
Epoch: 1000 [100%] 	Loss: 21879328.000000
Potential causes:  [105, 106]
Validated causes:  [105]

 Analysis started for target:  fedl90to1y
Epoch:  1 [0%] 	Loss: 7613012992.000000
Epoch: 500 [50%] 	Loss: 48150708.000000
Epoch: 1000 [100%] 	Loss: 25845266.000000
Potential causes:  [106, 29]
Validated causes:  [106]

 Analysis started for target:  fedl1to5y
Epoch:  1 [0%] 	Loss: 97201905664.000000
Epoch: 500 [50%] 	Loss: 266555312.000000
Epoch: 1000 [100%] 	Loss: 85593208.000000
Potential causes:  [107, 109]
Validated causes:  [107]

 Analysis started for target:  fedl5to10y
Epoch:  1 [0%] 	Loss: 38588907520.000000
Epoch: 500 [50%] 	Loss: 125696328.000000
Epoch: 1000 [100%] 	Loss: 69181352.000000
Potential causes:  [108, 109, 26]
Validated causes:  [108]

 Analysis started for target:  fedgreater10y
Epoch:  1 [0%] 	Loss: 32677959680.000000
Epoch: 500 [50%] 	Loss: 18706256.000000
Epoch: 1000 [100%] 	Loss: 9303146.000000
Potential causes:  [109, 108]
Validated causes:  [109]

 Analysis started for target:  fed_net_tsy_dur
Epoch:  1 [0%] 	Loss: 49400.179688
Epoch: 500 [50%] 	Loss: 4.167851
Epoch: 1000 [100%] 	Loss: 1.063708
Potential causes:  [110, 106]
Validated causes:  []

 Analysis started for target:  fedhold_bills
Epoch:  1 [0%] 	Loss: 9816653824.000000
Epoch: 500 [50%] 	Loss: 30689918.000000
Epoch: 1000 [100%] 	Loss: 19427084.000000
Potential causes:  [114, 111]
Validated causes:  []

 Analysis started for target:  fedhold_notes
Epoch:  1 [0%] 	Loss: 23341225984.000000
Epoch: 500 [50%] 	Loss: 20852352.000000
Epoch: 1000 [100%] 	Loss: 5693112.000000
Potential causes:  [112, 27, 113, 97, 6]
Validated causes:  [112]

 Analysis started for target:  fedhold_bonds
Epoch:  1 [0%] 	Loss: 2892752384.000000
Epoch: 500 [50%] 	Loss: 2237276.000000
Epoch: 1000 [100%] 	Loss: 495599.812500
Potential causes:  [113, 112]
Validated causes:  [113]

 Analysis started for target:  fedhold_certifandbills
Epoch:  1 [0%] 	Loss: 9856002048.000000
Epoch: 500 [50%] 	Loss: 28580548.000000
Epoch: 1000 [100%] 	Loss: 17029664.000000
Potential causes:  [105, 114, 111]
Validated causes:  []

 Analysis started for target:  fedhold_notesandbonds
Epoch:  1 [0%] 	Loss: 474785185792.000000
Epoch: 500 [50%] 	Loss: 513307232.000000
Epoch: 1000 [100%] 	Loss: 339826240.000000
Potential causes:  [107, 109, 108]
Validated causes:  []

 Analysis started for target:  ngdpm
Epoch:  1 [0%] 	Loss: 68171808.000000
Epoch: 500 [50%] 	Loss: 23775.138672
Epoch: 1000 [100%] 	Loss: 10488.849609
Potential causes:  [117, 112]
Validated causes:  []

 Analysis started for target:  wpi
Epoch:  1 [0%] 	Loss: 96136.789062
Epoch: 500 [50%] 	Loss: 38.155560
Epoch: 1000 [100%] 	Loss: 14.999487
Potential causes:  [76, 120, 102, 116, 12]
Validated causes:  []

 Analysis started for target:  avgmatprivheld
Epoch:  1 [0%] 	Loss: 63816.847656
Epoch: 500 [50%] 	Loss: 20.180128
Epoch: 1000 [100%] 	Loss: 5.881293
Potential causes:  [118, 10, 120]
Validated causes:  []

 Analysis started for target:  taungdppercapita
Epoch:  1 [0%] 	Loss: 48709.839844
Epoch: 500 [50%] 	Loss: 3.632292
Epoch: 1000 [100%] 	Loss: 1.003319
Potential causes:  [106, 116]
Validated causes:  []

 Analysis started for target:  infexplt
Epoch:  1 [0%] 	Loss: 48488.300781
Epoch: 500 [50%] 	Loss: 5.407022
Epoch: 1000 [100%] 	Loss: 1.107224
Potential causes:  [120, 106]
Validated causes:  []

 Analysis started for target:  ismprices
Epoch:  1 [0%] 	Loss: 64578.285156
Epoch: 500 [50%] 	Loss: 42.893082
Epoch: 1000 [100%] 	Loss: 23.520727
Potential causes:  [121, 124]
Validated causes:  []

 Analysis started for target:  ismnoinv
Epoch:  1 [0%] 	Loss: 48229.906250
Epoch: 500 [50%] 	Loss: 3.312619
Epoch: 1000 [100%] 	Loss: 0.962656
Potential causes:  [106, 116, 18, 5, 104, 13, 42]
Validated causes:  []

 Analysis started for target:  ismempl
Epoch:  1 [0%] 	Loss: 61531.187500
Epoch: 500 [50%] 	Loss: 14.657625
Epoch: 1000 [100%] 	Loss: 6.501225
Potential causes:  [124, 121, 123]
Validated causes:  []

 Analysis started for target:  ism
Epoch:  1 [0%] 	Loss: 62032.464844
Epoch: 500 [50%] 	Loss: 19.588104
Epoch: 1000 [100%] 	Loss: 7.165090
Potential causes:  [124, 121, 123]
Validated causes:  []

 Analysis started for target:  onset_sad
Epoch:  1 [0%] 	Loss: 47982.328125
Epoch: 500 [50%] 	Loss: 3.317006
Epoch: 1000 [100%] 	Loss: 0.950093
Potential causes:  [106, 116, 7, 104, 18, 5, 13, 42]
Validated causes:  []

 Analysis started for target:  epu
Epoch:  1 [0%] 	Loss: 48157.355469
Epoch: 500 [50%] 	Loss: 4.102136
Epoch: 1000 [100%] 	Loss: 1.366636
Potential causes:  [106, 104, 116, 8, 18, 120]
Validated causes:  []

 Analysis started for target:  fedhold_total
Epoch:  1 [0%] 	Loss: 568159436800.000000
Epoch: 500 [50%] 	Loss: 1054575232.000000
Epoch: 1000 [100%] 	Loss: 414971456.000000
Potential causes:  [107, 127, 108, 109]
Validated causes:  [127]

 Analysis started for target:  copper
Epoch:  1 [0%] 	Loss: 48517.230469
Epoch: 500 [50%] 	Loss: 3.472349
Epoch: 1000 [100%] 	Loss: 1.054004
Potential causes:  [106, 116, 18]
Validated causes:  []

===================Results for capital_markets.csv ==================================
frn_bonds_sales causes corpbond_iss with a delay of 0 time steps.
corpbond_iss causes corpbond_iss with a delay of 3 time steps.
muni_newcapital_iss causes muni_iss with a delay of 0 time steps.
muni_refunding_iss causes muni_iss with a delay of 0 time steps.
muni_iss causes muni_newcapital_iss with a delay of 0 time steps.
muni_refunding_iss causes muni_newcapital_iss with a delay of 0 time steps.
muni_iss causes muni_refunding_iss with a delay of 0 time steps.
muni_refunding_iss causes muni_refunding_iss with a delay of 1 time steps.
muni_newcapital_iss causes muni_refunding_iss with a delay of 0 time steps.
frn_stocks_pur causes corpstock_iss with a delay of 0 time steps.
usbondandnotes_iss causes usbondandnotes_iss with a delay of 3 time steps.
tbill_for_total causes usbondandnotes_iss with a delay of 0 time steps.
uscorpbonds_out causes uscorpbonds_out with a delay of 1 time steps.
usbillsandcertif_out causes usbills_out with a delay of 0 time steps.
usbills_out causes usbillsandcertif_out with a delay of 0 time steps.
usnotesandbonds_out causes usnotes_out with a delay of 0 time steps.
usbonds_out causes usbonds_out with a delay of 2 time steps.
usnotesandbonds_out causes usnotesandbonds_out with a delay of 4 time steps.
usnotesandbonds_out causes usttotala_out with a delay of 0 time steps.
st_liabs_to_for causes st_liabs_to_for with a delay of 3 time steps.
total_net_bond causes total_net_frn with a delay of 0 time steps.
total_net_frn causes total_net_bond with a delay of 0 time steps.
total_net_frn causes total_net_stock with a delay of 0 time steps.
dom_ltsecs_net causes total_net_stock with a delay of 0 time steps.
frn_ltsecs_net causes total_net_stock with a delay of 0 time steps.
total_net_bond causes total_net_stock with a delay of 0 time steps.
dom_bonds_pur causes dom_ltsecs_pur with a delay of 0 time steps.
dom_bonds_pur causes dom_ltsecs_sales with a delay of 0 time steps.
corp_agency_bond_sales causes corp_agency_bond_pur with a delay of 0 time steps.
corp_agency_bond_pur causes corp_agency_bond_pur with a delay of 1 time steps.
corp_agency_bond_pur causes corp_agency_bond_sales with a delay of 0 time steps.
corp_agency_bond_sales causes corp_agency_bond_sales with a delay of 1 time steps.
dom_bonds_net causes dom_ltsecs_net with a delay of 0 time steps.
dom_ltsecs_net causes frn_ltsecs_net with a delay of 0 time steps.
total_net_frn causes frn_ltsecs_net with a delay of 0 time steps.
tbill_for_total causes tbill_for_total with a delay of 1 time steps.
tbill_for_total causes tbill_net with a delay of 0 time steps.
frn_bonds_sales causes frn_bonds_pur with a delay of 0 time steps.
frn_bonds_pur causes frn_bonds_sales with a delay of 0 time steps.
frn_stocks_sales causes frn_stocks_pur with a delay of 0 time steps.
frn_stocks_pur causes frn_stocks_sales with a delay of 0 time steps.
dom_stocks_sales causes dom_stocks_pur with a delay of 0 time steps.
dom_stocks_pur causes dom_stocks_sales with a delay of 0 time steps.
dom_bonds_pur causes ust_sales with a delay of 0 time steps.
ust_pur causes ust_sales with a delay of 0 time steps.
dom_bonds_pur causes ust_pur with a delay of 0 time steps.
ust_sales causes ust_pur with a delay of 0 time steps.
frn_bonds_pur causes frn_ltsecs_pur with a delay of 0 time steps.
frn_ltsecs_sales causes frn_ltsecs_pur with a delay of 0 time steps.
frn_ltsecs_pur causes frn_ltsecs_sales with a delay of 0 time steps.
dom_bonds_sales causes dom_bonds_pur with a delay of 0 time steps.
dom_bonds_pur causes dom_bonds_sales with a delay of 0 time steps.
dom_ltsecs_net causes dom_bonds_net with a delay of 0 time steps.
dom_ltsecs_net causes dom_stocks_net with a delay of 0 time steps.
dom_bonds_net causes dom_stocks_net with a delay of 0 time steps.
dom_bonds_net causes ust_net with a delay of 0 time steps.
corp_agency_bond_sales causes ust_net with a delay of 0 time steps.
pd_npos_g1 causes total_npos with a delay of 0 time steps.
absdurrisk_npos causes abs_npos with a delay of 0 time steps.
absdurrisk_npos causes absdurrisk_npos with a delay of 1 time steps.
total_npos causes pd_npos_l1 with a delay of 0 time steps.
pd_npos_g1 causes pd_npos_l1 with a delay of 0 time steps.
pd_npos_g1l7 causes pd_npos_g1 with a delay of 0 time steps.
pd_npos_g1 causes pd_npos_g1l7 with a delay of 0 time steps.
pd_npos_g1l7 causes pd_npos_g1l7 with a delay of 1 time steps.
pd_npos_g7 causes pd_npos_g7 with a delay of 1 time steps.
pd_npos_g1 causes pd_npos_g7 with a delay of 0 time steps.
pd_npos_gse causes pd_npos_gse_and_mbs with a delay of 0 time steps.
pd_npos_gse_and_mbs causes pd_npos_gse_and_mbs with a delay of 1 time steps.
pd_npos_gse_and_mbs causes pd_npos_gse with a delay of 0 time steps.
pd_npos_gse causes pd_npos_gse with a delay of 1 time steps.
fedl15d causes fedl15d with a delay of 3 time steps.
fedl90to1y causes fedl15d with a delay of 0 time steps.
fedl15to90d causes fedl15to90d with a delay of 1 time steps.
fedl90to1y causes fedl90to1y with a delay of 1 time steps.
fedl1to5y causes fedl1to5y with a delay of 1 time steps.
fedl5to10y causes fedl5to10y with a delay of 1 time steps.
fedgreater10y causes fedgreater10y with a delay of 1 time steps.
fedhold_notes causes fedhold_notes with a delay of 2 time steps.
fedhold_bonds causes fedhold_bonds with a delay of 1 time steps.
fedhold_total causes fedhold_total with a delay of 1 time steps.
==================================================================================
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="time-series-causal-discovery-trig">
<h3>Time Series Causal Discovery - Trig<a class="headerlink" href="#time-series-causal-discovery-trig" title="Permalink to this headline">¶</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>!git clone https://github.com/jakobrunge/tigramite.git
%cd tigramite
!python setup.py install
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Cloning into &#39;tigramite&#39;...
remote: Enumerating objects: 190, done.
remote: Counting objects: 100% (190/190), done.
remote: Compressing objects: 100% (128/128), done.
remote: Total 2883 (delta 104), reused 133 (delta 61), pack-reused 2693
Receiving objects: 100% (2883/2883), 10.53 MiB | 15.04 MiB/s, done.
Resolving deltas: 100% (1844/1844), done.
/content/tigramite
Compiling tigramite/tigramite_cython_code.pyx because it changed.
[1/1] Cythonizing tigramite/tigramite_cython_code.pyx
/usr/local/lib/python3.6/dist-packages/Cython/Compiler/Main.py:369: FutureWarning: Cython directive &#39;language_level&#39; not set, using 2 for now (Py2). This will change in a later release! File: /content/tigramite/tigramite/tigramite_cython_code.pyx
  tree = Parsing.p_module(s, pxd, full_module_name)
running install
running bdist_egg
running egg_info
creating tigramite.egg-info
writing tigramite.egg-info/PKG-INFO
writing dependency_links to tigramite.egg-info/dependency_links.txt
writing requirements to tigramite.egg-info/requires.txt
writing top-level names to tigramite.egg-info/top_level.txt
writing manifest file &#39;tigramite.egg-info/SOURCES.txt&#39;
writing manifest file &#39;tigramite.egg-info/SOURCES.txt&#39;
installing library code to build/bdist.linux-x86_64/egg
running install_lib
running build_py
creating build
creating build/lib.linux-x86_64-3.6
creating build/lib.linux-x86_64-3.6/tigramite
copying tigramite/data_processing.py -&gt; build/lib.linux-x86_64-3.6/tigramite
copying tigramite/models.py -&gt; build/lib.linux-x86_64-3.6/tigramite
copying tigramite/independence_tests.py -&gt; build/lib.linux-x86_64-3.6/tigramite
copying tigramite/__init__.py -&gt; build/lib.linux-x86_64-3.6/tigramite
copying tigramite/plotting.py -&gt; build/lib.linux-x86_64-3.6/tigramite
copying tigramite/pcmci.py -&gt; build/lib.linux-x86_64-3.6/tigramite
running build_ext
building &#39;tigramite.tigramite_cython_code&#39; extension
creating build/temp.linux-x86_64-3.6
creating build/temp.linux-x86_64-3.6/tigramite
x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/include/python3.6m -I/usr/local/lib/python3.6/dist-packages/numpy/core/include -c tigramite/tigramite_cython_code.c -o build/temp.linux-x86_64-3.6/tigramite/tigramite_cython_code.o
In file included from <span class=" -Color -Color-Bold">/usr/local/lib/python3.6/dist-packages/numpy/core/include/numpy/ndarraytypes.h:1830:0</span>,
                 from <span class=" -Color -Color-Bold">/usr/local/lib/python3.6/dist-packages/numpy/core/include/numpy/ndarrayobject.h:12</span>,
                 from <span class=" -Color -Color-Bold">/usr/local/lib/python3.6/dist-packages/numpy/core/include/numpy/arrayobject.h:4</span>,
                 from <span class=" -Color -Color-Bold">tigramite/tigramite_cython_code.c:611</span>:
<span class=" -Color -Color-Bold">/usr/local/lib/python3.6/dist-packages/numpy/core/include/numpy/npy_1_7_deprecated_api.h:17:2:</span> <span class=" -Color -Color-Bold -Color-Bold-Magenta">warning: </span>#warning &quot;Using deprecated NumPy API, disable it with &quot; &quot;#define NPY_NO_DEPRECATED_API NPY_1_7_API_VERSION&quot; [<span class=" -Color -Color-Bold -Color-Bold-Magenta">-Wcpp</span>]
 #<span class=" -Color -Color-Bold -Color-Bold-Magenta">warning</span> &quot;Using deprecated NumPy API, disable it with &quot; \
  <span class=" -Color -Color-Bold -Color-Bold-Magenta">^~~~~~~</span>
x86_64-linux-gnu-gcc -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.6/tigramite/tigramite_cython_code.o -o build/lib.linux-x86_64-3.6/tigramite/tigramite_cython_code.cpython-36m-x86_64-linux-gnu.so
creating build/bdist.linux-x86_64
creating build/bdist.linux-x86_64/egg
creating build/bdist.linux-x86_64/egg/tigramite
copying build/lib.linux-x86_64-3.6/tigramite/data_processing.py -&gt; build/bdist.linux-x86_64/egg/tigramite
copying build/lib.linux-x86_64-3.6/tigramite/models.py -&gt; build/bdist.linux-x86_64/egg/tigramite
copying build/lib.linux-x86_64-3.6/tigramite/independence_tests.py -&gt; build/bdist.linux-x86_64/egg/tigramite
copying build/lib.linux-x86_64-3.6/tigramite/__init__.py -&gt; build/bdist.linux-x86_64/egg/tigramite
copying build/lib.linux-x86_64-3.6/tigramite/plotting.py -&gt; build/bdist.linux-x86_64/egg/tigramite
copying build/lib.linux-x86_64-3.6/tigramite/pcmci.py -&gt; build/bdist.linux-x86_64/egg/tigramite
copying build/lib.linux-x86_64-3.6/tigramite/tigramite_cython_code.cpython-36m-x86_64-linux-gnu.so -&gt; build/bdist.linux-x86_64/egg/tigramite
byte-compiling build/bdist.linux-x86_64/egg/tigramite/data_processing.py to data_processing.cpython-36.pyc
byte-compiling build/bdist.linux-x86_64/egg/tigramite/models.py to models.cpython-36.pyc
byte-compiling build/bdist.linux-x86_64/egg/tigramite/independence_tests.py to independence_tests.cpython-36.pyc
byte-compiling build/bdist.linux-x86_64/egg/tigramite/__init__.py to __init__.cpython-36.pyc
byte-compiling build/bdist.linux-x86_64/egg/tigramite/plotting.py to plotting.cpython-36.pyc
byte-compiling build/bdist.linux-x86_64/egg/tigramite/pcmci.py to pcmci.cpython-36.pyc
creating stub loader for tigramite/tigramite_cython_code.cpython-36m-x86_64-linux-gnu.so
byte-compiling build/bdist.linux-x86_64/egg/tigramite/tigramite_cython_code.py to tigramite_cython_code.cpython-36.pyc
creating build/bdist.linux-x86_64/egg/EGG-INFO
copying tigramite.egg-info/PKG-INFO -&gt; build/bdist.linux-x86_64/egg/EGG-INFO
copying tigramite.egg-info/SOURCES.txt -&gt; build/bdist.linux-x86_64/egg/EGG-INFO
copying tigramite.egg-info/dependency_links.txt -&gt; build/bdist.linux-x86_64/egg/EGG-INFO
copying tigramite.egg-info/requires.txt -&gt; build/bdist.linux-x86_64/egg/EGG-INFO
copying tigramite.egg-info/top_level.txt -&gt; build/bdist.linux-x86_64/egg/EGG-INFO
writing build/bdist.linux-x86_64/egg/EGG-INFO/native_libs.txt
zip_safe flag not set; analyzing archive contents...
tigramite.__pycache__.tigramite_cython_code.cpython-36: module references __file__
creating dist
creating &#39;dist/tigramite-4.1.0-py3.6-linux-x86_64.egg&#39; and adding &#39;build/bdist.linux-x86_64/egg&#39; to it
removing &#39;build/bdist.linux-x86_64/egg&#39; (and everything under it)
Processing tigramite-4.1.0-py3.6-linux-x86_64.egg
creating /usr/local/lib/python3.6/dist-packages/tigramite-4.1.0-py3.6-linux-x86_64.egg
Extracting tigramite-4.1.0-py3.6-linux-x86_64.egg to /usr/local/lib/python3.6/dist-packages
Adding tigramite 4.1.0 to easy-install.pth file

Installed /usr/local/lib/python3.6/dist-packages/tigramite-4.1.0-py3.6-linux-x86_64.egg
Processing dependencies for tigramite==4.1.0
Searching for six==1.12.0
Best match: six 1.12.0
Adding six 1.12.0 to easy-install.pth file

Using /usr/local/lib/python3.6/dist-packages
Searching for scipy==1.3.3
Best match: scipy 1.3.3
Adding scipy 1.3.3 to easy-install.pth file

Using /usr/local/lib/python3.6/dist-packages
Searching for numpy==1.17.4
Best match: numpy 1.17.4
Adding numpy 1.17.4 to easy-install.pth file
Installing f2py script to /usr/local/bin
Installing f2py3 script to /usr/local/bin
Installing f2py3.6 script to /usr/local/bin

Using /usr/local/lib/python3.6/dist-packages
Finished processing dependencies for tigramite==4.1.0
</pre></div>
</div>
</div>
</div>
<p>TIGRAMITE is a time series analysis python module. It allows to reconstruct graphical models (conditional independence graphs) from discrete or continuously-valued time series based on the PCMCI method and create high-quality plots of the results. PMCI is used to Detecting and quantifying causal associations in large nonlinear time series datasets. This tutorial explains how to use PCMCI to obtain optimal predictors.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span>
<span class="kn">from</span> <span class="nn">tigramite.pcmci</span> <span class="kn">import</span> <span class="n">PCMCI</span>
<span class="kn">from</span> <span class="nn">tigramite.independence_tests</span> <span class="kn">import</span> <span class="n">ParCorr</span>
<span class="kn">import</span> <span class="nn">tigramite.data_processing</span> <span class="k">as</span> <span class="nn">pp</span>
<span class="n">numpy</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">values</span>

<span class="c1"># Data must be array of shape (time, variables)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

<span class="n">dataframe</span> <span class="o">=</span> <span class="n">pp</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
<span class="n">cond_ind_test</span> <span class="o">=</span> <span class="n">ParCorr</span><span class="p">()</span>
<span class="n">pcmci</span> <span class="o">=</span> <span class="n">PCMCI</span><span class="p">(</span><span class="n">dataframe</span><span class="o">=</span><span class="n">dataframe</span><span class="p">,</span> <span class="n">cond_ind_test</span><span class="o">=</span><span class="n">cond_ind_test</span><span class="p">)</span>
<span class="n">results</span> <span class="o">=</span> <span class="n">pcmci</span><span class="o">.</span><span class="n">run_pcmci</span><span class="p">(</span><span class="n">tau_max</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">pc_alpha</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
<span class="n">pcmci</span><span class="o">.</span><span class="n">print_significant_links</span><span class="p">(</span><span class="n">p_matrix</span><span class="o">=</span><span class="n">results</span><span class="p">[</span><span class="s1">&#39;p_matrix&#39;</span><span class="p">],</span>
                                     <span class="n">val_matrix</span><span class="o">=</span><span class="n">results</span><span class="p">[</span><span class="s1">&#39;val_matrix&#39;</span><span class="p">],</span>
                                     <span class="n">alpha_level</span><span class="o">=</span><span class="mf">0.05</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(48204, 5)

## Significant links at alpha = 0.05:

    Variable 0 has 7 link(s):
        (0 -1): pval = 0.00000 | val = 0.796
        (0 -2): pval = 0.00000 | val = -0.249
        (1 0): pval = 0.00000 | val = 0.062
        (1 -1): pval = 0.00000 | val = 0.051
        (0 -3): pval = 0.00000 | val = -0.034
        (2 -1): pval = 0.00030 | val = 0.016
        (2 0): pval = 0.03805 | val = 0.009

    Variable 1 has 5 link(s):
        (1 -1): pval = 0.00000 | val = 0.724
        (0 0): pval = 0.00000 | val = 0.062
        (0 -1): pval = 0.00000 | val = 0.048
        (2 0): pval = 0.00017 | val = 0.017
        (1 -2): pval = 0.00176 | val = -0.014

    Variable 2 has 6 link(s):
        (2 -1): pval = 0.00000 | val = 0.538
        (2 -2): pval = 0.00000 | val = 0.111
        (2 -3): pval = 0.00000 | val = 0.045
        (0 -1): pval = 0.00000 | val = 0.024
        (1 0): pval = 0.00017 | val = 0.017
        (0 0): pval = 0.03805 | val = 0.009

    Variable 3 has 0 link(s):

    Variable 4 has 3 link(s):
        (4 -1): pval = 0.00000 | val = 0.677
        (4 -2): pval = 0.00000 | val = -0.038
        (4 -3): pval = 0.00000 | val = 0.021
</pre></div>
</div>
</div>
</div>
<p>What causes traffic</p>
<ul class="simple">
<li><p>Traffic and hour ago more now</p></li>
<li><p>Traffic two hours ago less now</p></li>
<li><p>Clouds one hour ago more traffic now</p></li>
<li><p>Rain one hour ago more traffic now</p></li>
</ul>
<p>What causes temperature</p>
<ul class="simple">
<li><p>Traffic one hour ago higher temperature now</p></li>
</ul>
<p>What causes rain</p>
<ul class="simple">
<li><p>Traffic one hour ago more rain now</p></li>
<li><p>Temperature two hours ago more rain now</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Imports</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib</span>
<span class="kn">from</span> <span class="nn">matplotlib</span> <span class="kn">import</span> <span class="n">pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="o">%</span><span class="n">matplotlib</span> <span class="n">inline</span>     
<span class="c1">## use `%matplotlib notebook` for interactive figures</span>
<span class="c1"># plt.style.use(&#39;ggplot&#39;)</span>
<span class="kn">import</span> <span class="nn">sklearn</span>

<span class="kn">import</span> <span class="nn">tigramite</span>
<span class="kn">from</span> <span class="nn">tigramite</span> <span class="kn">import</span> <span class="n">data_processing</span> <span class="k">as</span> <span class="n">pp</span>
<span class="kn">from</span> <span class="nn">tigramite</span> <span class="kn">import</span> <span class="n">plotting</span> <span class="k">as</span> <span class="n">tp</span>
<span class="kn">from</span> <span class="nn">tigramite.pcmci</span> <span class="kn">import</span> <span class="n">PCMCI</span>
<span class="kn">from</span> <span class="nn">tigramite.independence_tests</span> <span class="kn">import</span> <span class="n">ParCorr</span><span class="p">,</span> <span class="n">GPDC</span><span class="p">,</span> <span class="n">CMIknn</span><span class="p">,</span> <span class="n">CMIsymb</span>
<span class="kn">from</span> <span class="nn">tigramite.models</span> <span class="kn">import</span> <span class="n">LinearMediation</span><span class="p">,</span> <span class="n">Prediction</span>

<span class="c1">## Ignoring this for now</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>
<span class="n">T</span> <span class="o">=</span> <span class="mi">150</span>
<span class="n">links_coeffs</span> <span class="o">=</span> <span class="p">{</span><span class="mi">0</span><span class="p">:</span> <span class="p">[((</span><span class="mi">0</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span> <span class="mf">0.6</span><span class="p">)],</span>
                <span class="mi">1</span><span class="p">:</span> <span class="p">[((</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span> <span class="mf">0.6</span><span class="p">),</span> <span class="p">((</span><span class="mi">0</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span> <span class="mf">0.8</span><span class="p">)],</span>
                <span class="mi">2</span><span class="p">:</span> <span class="p">[((</span><span class="mi">2</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span> <span class="mf">0.5</span><span class="p">),</span> <span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span> <span class="mf">0.7</span><span class="p">)],</span>  <span class="c1"># ((0, -1), c)],</span>
                <span class="p">}</span>
<span class="n">N</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">links_coeffs</span><span class="p">)</span>
<span class="n">data</span><span class="p">,</span> <span class="n">true_parents</span> <span class="o">=</span> <span class="n">pp</span><span class="o">.</span><span class="n">var_process</span><span class="p">(</span><span class="n">links_coeffs</span><span class="p">,</span> <span class="n">T</span><span class="o">=</span><span class="n">T</span><span class="p">)</span>


<span class="n">dataframe</span> <span class="o">=</span> <span class="n">pp</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">values</span><span class="p">,</span> <span class="n">var_names</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">columns</span><span class="p">)</span>
<span class="n">N</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>

<span class="n">pred</span> <span class="o">=</span> <span class="n">Prediction</span><span class="p">(</span><span class="n">dataframe</span><span class="o">=</span><span class="n">dataframe</span><span class="p">,</span>
        <span class="n">cond_ind_test</span><span class="o">=</span><span class="n">ParCorr</span><span class="p">(),</span>   <span class="c1">#CMIknn ParCorr</span>
        <span class="n">prediction_model</span> <span class="o">=</span> <span class="n">sklearn</span><span class="o">.</span><span class="n">linear_model</span><span class="o">.</span><span class="n">LinearRegression</span><span class="p">(),</span>
<span class="c1">#         prediction_model = sklearn.gaussian_process.GaussianProcessRegressor(),</span>
        <span class="c1"># prediction_model = sklearn.neighbors.KNeighborsRegressor(),</span>
    <span class="n">data_transform</span><span class="o">=</span><span class="n">sklearn</span><span class="o">.</span><span class="n">preprocessing</span><span class="o">.</span><span class="n">StandardScaler</span><span class="p">(),</span>
    <span class="n">train_indices</span><span class="o">=</span> <span class="nb">range</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="mf">0.8</span><span class="o">*</span><span class="nb">len</span><span class="p">(</span><span class="n">df</span><span class="p">))),</span>
    <span class="n">test_indices</span><span class="o">=</span> <span class="nb">range</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="mf">0.8</span><span class="o">*</span><span class="nb">len</span><span class="p">(</span><span class="n">df</span><span class="p">)),</span> <span class="nb">len</span><span class="p">(</span><span class="n">df</span><span class="p">)),</span>
    <span class="n">verbosity</span><span class="o">=</span><span class="mi">1</span>
    <span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">target</span> <span class="o">=</span> <span class="mi">0</span> <span class="c1"># I want to test what causes more traffic</span>
<span class="n">tau_max</span> <span class="o">=</span> <span class="mi">10</span>
<span class="n">steps_ahead_count</span> <span class="o">=</span> <span class="mi">2</span> 
<span class="n">predictors</span> <span class="o">=</span> <span class="n">pred</span><span class="o">.</span><span class="n">get_predictors</span><span class="p">(</span>
                  <span class="n">selected_targets</span><span class="o">=</span><span class="p">[</span><span class="n">target</span><span class="p">],</span>
                  <span class="n">steps_ahead</span><span class="o">=</span><span class="n">steps_ahead_count</span><span class="p">,</span>
                  <span class="n">tau_max</span><span class="o">=</span><span class="n">tau_max</span><span class="p">,</span>
                  <span class="n">pc_alpha</span><span class="o">=</span><span class="kc">None</span>
                  <span class="p">)</span>
<span class="n">link_matrix</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">N</span><span class="p">,</span> <span class="n">N</span><span class="p">,</span> <span class="n">tau_max</span><span class="o">+</span><span class="mi">1</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="s1">&#39;bool&#39;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="p">[</span><span class="n">target</span><span class="p">]:</span>
    <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">predictors</span><span class="p">[</span><span class="n">j</span><span class="p">]:</span>
        <span class="n">link_matrix</span><span class="p">[</span><span class="n">p</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">j</span><span class="p">,</span> <span class="nb">abs</span><span class="p">(</span><span class="n">p</span><span class="p">[</span><span class="mi">1</span><span class="p">])]</span> <span class="o">=</span> <span class="mi">1</span>

<span class="c1"># Plot time series graph</span>
<span class="n">tp</span><span class="o">.</span><span class="n">plot_time_series_graph</span><span class="p">(</span>
    <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span>
    <span class="n">val_matrix</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">link_matrix</span><span class="o">.</span><span class="n">shape</span><span class="p">),</span>
    <span class="n">link_matrix</span><span class="o">=</span><span class="n">link_matrix</span><span class="p">,</span>
    <span class="n">var_names</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">link_colorbar_label</span><span class="o">=</span><span class="s1">&#39;&#39;</span><span class="p">,</span>
    <span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>##
## Running Tigramite PC algorithm
##

Parameters:
selected_variables = [0]
independence test = par_corr
tau_min = 2
tau_max = 10
pc_alpha = None
max_conds_dim = None
max_combinations = 1



## Variable 0

## Resulting condition sets:

    Variable 0 has 20 parent(s):
    [pc_alpha = 0.5]
        (0 -2): max_pval = 0.00000, min_val = 0.611
        (0 -3): max_pval = 0.00000, min_val = 0.197
        (0 -10): max_pval = 0.00000, min_val = 0.124
        (0 -7): max_pval = 0.00000, min_val = 0.032
        (0 -9): max_pval = 0.00000, min_val = 0.029
        (1 -9): max_pval = 0.01441, min_val = 0.012
        (0 -5): max_pval = 0.03245, min_val = 0.011
        (1 -6): max_pval = 0.04817, min_val = 0.010
        (1 -5): max_pval = 0.08431, min_val = 0.009
        (2 -10): max_pval = 0.13232, min_val = 0.008
        (1 -7): max_pval = 0.13450, min_val = 0.008
        (1 -3): max_pval = 0.14321, min_val = 0.007
        (2 -3): max_pval = 0.14919, min_val = 0.007
        (2 -6): max_pval = 0.15496, min_val = 0.007
        (0 -4): max_pval = 0.16754, min_val = 0.007
        (4 -9): max_pval = 0.26270, min_val = 0.006
        (2 -7): max_pval = 0.35278, min_val = 0.005
        (0 -6): max_pval = 0.42142, min_val = 0.004
        (1 -8): max_pval = 0.42705, min_val = 0.004
        (4 -6): max_pval = 0.48738, min_val = 0.004
</pre></div>
</div>
<img alt="../_images/T990000_causal_inference_282_1.png" src="../_images/T990000_causal_inference_282_1.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">pred</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">target_predictors</span><span class="o">=</span><span class="n">predictors</span><span class="p">,</span> 
                <span class="n">selected_targets</span><span class="o">=</span><span class="p">[</span><span class="n">target</span><span class="p">],</span>
                    <span class="n">tau_max</span><span class="o">=</span><span class="n">tau_max</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;tigramite.models.Prediction at 0x7f3b9883f860&gt;
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">predicted</span> <span class="o">=</span> <span class="n">pred</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">target</span><span class="p">)</span>
<span class="n">true_data</span> <span class="o">=</span> <span class="n">pred</span><span class="o">.</span><span class="n">get_test_array</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span>

<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">true_data</span><span class="p">,</span> <span class="n">predicted</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="sa">r</span><span class="s2">&quot;NRMSE = </span><span class="si">%.2f</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">true_data</span> <span class="o">-</span> <span class="n">predicted</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="o">/</span><span class="n">true_data</span><span class="o">.</span><span class="n">std</span><span class="p">()))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">true_data</span><span class="p">,</span> <span class="n">true_data</span><span class="p">,</span> <span class="s1">&#39;k-&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;True test data&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Predicted test data&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>##
## Predicting target 0
##
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Text(0, 0.5, &#39;Predicted test data&#39;)
</pre></div>
</div>
<img alt="../_images/T990000_causal_inference_284_2.png" src="../_images/T990000_causal_inference_284_2.png" />
</div>
</div>
<p>It still underfits, if I use all the predictors it still works better:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">all_predictors</span> <span class="o">=</span> <span class="p">{</span><span class="n">target</span><span class="p">:[(</span><span class="n">i</span><span class="p">,</span> <span class="o">-</span><span class="n">tau</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">N</span><span class="p">)</span> <span class="k">for</span> <span class="n">tau</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">tau_max</span><span class="o">+</span><span class="mi">1</span><span class="p">)]}</span>
<span class="n">pred</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">target_predictors</span><span class="o">=</span><span class="n">all_predictors</span><span class="p">,</span> 
                <span class="n">selected_targets</span><span class="o">=</span><span class="p">[</span><span class="n">target</span><span class="p">],</span>
                    <span class="n">tau_max</span><span class="o">=</span><span class="n">tau_max</span><span class="p">)</span>

<span class="c1"># new_data = pp.DataFrame(pp.var_process(links_coeffs, T=100)[0])</span>
<span class="n">predicted</span> <span class="o">=</span> <span class="n">pred</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">target</span><span class="p">)</span>
<span class="c1"># predicted = pred.predict(target)</span>
<span class="n">true_data</span> <span class="o">=</span> <span class="n">pred</span><span class="o">.</span><span class="n">get_test_array</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span>

<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">true_data</span><span class="p">,</span> <span class="n">predicted</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">true_data</span><span class="p">,</span> <span class="n">true_data</span><span class="p">,</span> <span class="s1">&#39;k-&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="sa">r</span><span class="s2">&quot;NRMSE = </span><span class="si">%.2f</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">true_data</span> <span class="o">-</span> <span class="n">predicted</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="o">/</span><span class="n">true_data</span><span class="o">.</span><span class="n">std</span><span class="p">()))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;True test data&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Predicted test data&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>##
## Predicting target 0
##
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Text(0, 0.5, &#39;Predicted test data&#39;)
</pre></div>
</div>
<img alt="../_images/T990000_causal_inference_286_2.png" src="../_images/T990000_causal_inference_286_2.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">tp</span><span class="o">.</span><span class="n">plot_timeseries</span><span class="p">(</span><span class="n">dataframe</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(&lt;Figure size 432x288 with 5 Axes&gt;,
 array([&lt;matplotlib.axes._subplots.AxesSubplot object at 0x7f3b9ba307b8&gt;,
        &lt;matplotlib.axes._subplots.AxesSubplot object at 0x7f3b9b29f5c0&gt;,
        &lt;matplotlib.axes._subplots.AxesSubplot object at 0x7f3b9b281208&gt;,
        &lt;matplotlib.axes._subplots.AxesSubplot object at 0x7f3b9b9594e0&gt;,
        &lt;matplotlib.axes._subplots.AxesSubplot object at 0x7f3b986f5908&gt;],
       dtype=object))
</pre></div>
</div>
<img alt="../_images/T990000_causal_inference_287_1.png" src="../_images/T990000_causal_inference_287_1.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">parcorr</span> <span class="o">=</span> <span class="n">ParCorr</span><span class="p">(</span><span class="n">significance</span><span class="o">=</span><span class="s1">&#39;analytic&#39;</span><span class="p">)</span>
<span class="n">pcmci</span> <span class="o">=</span> <span class="n">PCMCI</span><span class="p">(</span>
    <span class="n">dataframe</span><span class="o">=</span><span class="n">dataframe</span><span class="p">,</span> 
    <span class="n">cond_ind_test</span><span class="o">=</span><span class="n">parcorr</span><span class="p">,</span>
    <span class="n">verbosity</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">correlations</span> <span class="o">=</span> <span class="n">pcmci</span><span class="o">.</span><span class="n">get_lagged_dependencies</span><span class="p">(</span><span class="n">tau_max</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
<span class="n">lag_func_matrix</span> <span class="o">=</span> <span class="n">tp</span><span class="o">.</span><span class="n">plot_lagfuncs</span><span class="p">(</span><span class="n">val_matrix</span><span class="o">=</span><span class="n">correlations</span><span class="p">,</span> <span class="n">setup_args</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;var_names&#39;</span><span class="p">:</span><span class="n">df</span><span class="o">.</span><span class="n">columns</span><span class="p">,</span> 
                                    <span class="s1">&#39;x_base&#39;</span><span class="p">:</span><span class="mi">5</span><span class="p">,</span> <span class="s1">&#39;y_base&#39;</span><span class="p">:</span><span class="mf">.5</span><span class="p">})</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>## Estimating lagged dependencies
</pre></div>
</div>
<img alt="../_images/T990000_causal_inference_289_1.png" src="../_images/T990000_causal_inference_289_1.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">pcmci</span><span class="o">.</span><span class="n">verbosity</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">results</span> <span class="o">=</span> <span class="n">pcmci</span><span class="o">.</span><span class="n">run_pcmci</span><span class="p">(</span><span class="n">tau_max</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">pc_alpha</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>##
## Running Tigramite PC algorithm
##

Parameters:
independence test = par_corr
tau_min = 1
tau_max = 10
pc_alpha = None
max_conds_dim = None
max_combinations = 1



## Variable traffic_volume

## Variable temp

## Variable clouds_all

## Variable rain_1h

## Variable snow_1h

## Resulting condition sets:

    Variable traffic_volume has 16 parent(s):
    [pc_alpha = 0.5]
        (traffic_volume -1): max_pval = 0.00000, min_val = 0.799
        (traffic_volume -2): max_pval = 0.00000, min_val = 0.250
        (traffic_volume -10): max_pval = 0.00000, min_val = 0.118
        (traffic_volume -6): max_pval = 0.00000, min_val = 0.045
        (traffic_volume -9): max_pval = 0.00000, min_val = 0.041
        (traffic_volume -5): max_pval = 0.00000, min_val = 0.027
        (clouds_all -6): max_pval = 0.00008, min_val = 0.018
        (snow_1h -8): max_pval = 0.15344, min_val = 0.007
        (traffic_volume -7): max_pval = 0.16798, min_val = 0.006
        (temp -5): max_pval = 0.23241, min_val = 0.005
        (traffic_volume -8): max_pval = 0.40167, min_val = 0.004
        (clouds_all -9): max_pval = 0.43980, min_val = 0.004
        (clouds_all -2): max_pval = 0.44582, min_val = 0.003
        (temp -1): max_pval = 0.45517, min_val = 0.003
        (snow_1h -7): max_pval = 0.47342, min_val = 0.003
        (rain_1h -8): max_pval = 0.48775, min_val = 0.003

    Variable temp has 16 parent(s):
    [pc_alpha = 0.4]
        (temp -1): max_pval = 0.00000, min_val = 0.727
        (traffic_volume -1): max_pval = 0.00000, min_val = 0.094
        (temp -4): max_pval = 0.00000, min_val = 0.084
        (temp -7): max_pval = 0.00000, min_val = 0.053
        (temp -6): max_pval = 0.00000, min_val = 0.030
        (traffic_volume -10): max_pval = 0.00000, min_val = 0.027
        (temp -5): max_pval = 0.00000, min_val = 0.026
        (clouds_all -10): max_pval = 0.00929, min_val = 0.012
        (temp -9): max_pval = 0.01652, min_val = 0.011
        (temp -8): max_pval = 0.08932, min_val = 0.008
        (traffic_volume -7): max_pval = 0.09220, min_val = 0.008
        (clouds_all -9): max_pval = 0.22069, min_val = 0.006
        (temp -2): max_pval = 0.29612, min_val = 0.005
        (clouds_all -7): max_pval = 0.30841, min_val = 0.005
        (temp -3): max_pval = 0.34922, min_val = 0.004
        (clouds_all -5): max_pval = 0.35645, min_val = 0.004

    Variable clouds_all has 17 parent(s):
    [pc_alpha = 0.3]
        (clouds_all -1): max_pval = 0.00000, min_val = 0.535
        (clouds_all -2): max_pval = 0.00000, min_val = 0.110
        (clouds_all -3): max_pval = 0.00000, min_val = 0.044
        (traffic_volume -1): max_pval = 0.00000, min_val = 0.026
        (clouds_all -10): max_pval = 0.00000, min_val = 0.021
        (clouds_all -4): max_pval = 0.00004, min_val = 0.019
        (traffic_volume -7): max_pval = 0.00022, min_val = 0.017
        (clouds_all -5): max_pval = 0.00082, min_val = 0.015
        (clouds_all -8): max_pval = 0.00593, min_val = 0.013
        (traffic_volume -4): max_pval = 0.09125, min_val = 0.008
        (temp -1): max_pval = 0.09640, min_val = 0.008
        (traffic_volume -2): max_pval = 0.13159, min_val = 0.007
        (temp -3): max_pval = 0.14259, min_val = 0.007
        (snow_1h -10): max_pval = 0.18988, min_val = 0.006
        (snow_1h -1): max_pval = 0.19329, min_val = 0.006
        (clouds_all -6): max_pval = 0.21431, min_val = 0.006
        (temp -9): max_pval = 0.26970, min_val = 0.005

    Variable rain_1h has 0 parent(s):
    [pc_alpha = 0.05]

    Variable snow_1h has 10 parent(s):
    [pc_alpha = 0.3]
        (snow_1h -1): max_pval = 0.00000, min_val = 0.677
        (snow_1h -4): max_pval = 0.00000, min_val = 0.069
        (snow_1h -9): max_pval = 0.00000, min_val = 0.035
        (snow_1h -2): max_pval = 0.00000, min_val = 0.033
        (snow_1h -5): max_pval = 0.00000, min_val = 0.024
        (snow_1h -10): max_pval = 0.00910, min_val = 0.012
        (snow_1h -7): max_pval = 0.05957, min_val = 0.009
        (snow_1h -3): max_pval = 0.23009, min_val = 0.005
        (snow_1h -6): max_pval = 0.24136, min_val = 0.005
        (traffic_volume -5): max_pval = 0.29544, min_val = 0.005

##
## Running Tigramite MCI algorithm
##

Parameters:

independence test = par_corr
tau_min = 0
tau_max = 10
max_conds_py = None
max_conds_px = None

## Significant links at alpha = 0.05:

    Variable traffic_volume has 20 link(s):
        (traffic_volume -1): pval = 0.00000 | val = 0.789 | conf = (0.000, 0.000)
        (traffic_volume -2): pval = 0.00000 | val = -0.237 | conf = (0.000, 0.000)
        (temp 0): pval = 0.00000 | val = 0.050 | conf = (0.000, 0.000)
        (traffic_volume -3): pval = 0.00000 | val = -0.039 | conf = (0.000, 0.000)
        (traffic_volume -6): pval = 0.00000 | val = -0.035 | conf = (0.000, 0.000)
        (traffic_volume -10): pval = 0.00000 | val = -0.032 | conf = (0.000, 0.000)
        (temp -1): pval = 0.00000 | val = 0.030 | conf = (0.000, 0.000)
        (traffic_volume -9): pval = 0.00000 | val = 0.028 | conf = (0.000, 0.000)
        (temp -9): pval = 0.00000 | val = -0.028 | conf = (0.000, 0.000)
        (traffic_volume -5): pval = 0.00000 | val = 0.025 | conf = (0.000, 0.000)
        (traffic_volume -8): pval = 0.00000 | val = 0.025 | conf = (0.000, 0.000)
        (temp -8): pval = 0.00000 | val = -0.024 | conf = (0.000, 0.000)
        (temp -7): pval = 0.00013 | val = -0.017 | conf = (0.000, 0.000)
        (temp -5): pval = 0.00043 | val = -0.016 | conf = (0.000, 0.000)
        (traffic_volume -7): pval = 0.00055 | val = -0.016 | conf = (0.000, 0.000)
        (clouds_all -6): pval = 0.00087 | val = -0.015 | conf = (0.000, 0.000)
        (clouds_all -1): pval = 0.00167 | val = 0.014 | conf = (0.000, 0.000)
        (clouds_all -2): pval = 0.00320 | val = 0.013 | conf = (0.000, 0.000)
        (temp -4): pval = 0.00375 | val = -0.013 | conf = (0.000, 0.000)
        (temp -10): pval = 0.00794 | val = -0.012 | conf = (0.000, 0.000)

    Variable temp has 17 link(s):
        (temp -1): pval = 0.00000 | val = 0.726 | conf = (0.000, 0.000)
        (temp -6): pval = 0.00000 | val = -0.206 | conf = (0.000, 0.000)
        (temp -4): pval = 0.00000 | val = -0.197 | conf = (0.000, 0.000)
        (temp -7): pval = 0.00000 | val = 0.195 | conf = (0.000, 0.000)
        (temp -5): pval = 0.00000 | val = 0.188 | conf = (0.000, 0.000)
        (temp -10): pval = 0.00000 | val = -0.113 | conf = (0.000, 0.000)
        (temp -8): pval = 0.00000 | val = -0.092 | conf = (0.000, 0.000)
        (temp -9): pval = 0.00000 | val = 0.081 | conf = (0.000, 0.000)
        (temp -2): pval = 0.00000 | val = -0.069 | conf = (0.000, 0.000)
        (temp -3): pval = 0.00000 | val = 0.052 | conf = (0.000, 0.000)
        (traffic_volume 0): pval = 0.00000 | val = 0.050 | conf = (0.000, 0.000)
        (traffic_volume -1): pval = 0.00000 | val = 0.043 | conf = (0.000, 0.000)
        (clouds_all 0): pval = 0.00001 | val = 0.020 | conf = (0.000, 0.000)
        (traffic_volume -10): pval = 0.00046 | val = -0.016 | conf = (0.000, 0.000)
        (traffic_volume -4): pval = 0.00726 | val = 0.012 | conf = (0.000, 0.000)
        (traffic_volume -9): pval = 0.03761 | val = -0.009 | conf = (0.000, 0.000)
        (clouds_all -4): pval = 0.04880 | val = 0.009 | conf = (0.000, 0.000)

    Variable clouds_all has 10 link(s):
        (clouds_all -1): pval = 0.00000 | val = 0.534 | conf = (0.000, 0.000)
        (clouds_all -2): pval = 0.00000 | val = 0.109 | conf = (0.000, 0.000)
        (clouds_all -3): pval = 0.00000 | val = 0.043 | conf = (0.000, 0.000)
        (traffic_volume -1): pval = 0.00001 | val = 0.020 | conf = (0.000, 0.000)
        (temp 0): pval = 0.00001 | val = 0.020 | conf = (0.000, 0.000)
        (clouds_all -4): pval = 0.00005 | val = 0.018 | conf = (0.000, 0.000)
        (clouds_all -5): pval = 0.00123 | val = 0.015 | conf = (0.000, 0.000)
        (traffic_volume -7): pval = 0.00547 | val = -0.013 | conf = (0.000, 0.000)
        (clouds_all -8): pval = 0.02452 | val = 0.010 | conf = (0.000, 0.000)
        (traffic_volume -4): pval = 0.04286 | val = -0.009 | conf = (0.000, 0.000)

    Variable rain_1h has 0 link(s):

    Variable snow_1h has 13 link(s):
        (snow_1h -1): pval = 0.00000 | val = 0.689 | conf = (0.000, 0.000)
        (snow_1h -5): pval = 0.00000 | val = 0.166 | conf = (0.000, 0.000)
        (snow_1h -4): pval = 0.00000 | val = -0.140 | conf = (0.000, 0.000)
        (snow_1h -9): pval = 0.00000 | val = -0.113 | conf = (0.000, 0.000)
        (snow_1h -6): pval = 0.00000 | val = -0.112 | conf = (0.000, 0.000)
        (snow_1h -10): pval = 0.00000 | val = 0.080 | conf = (0.000, 0.000)
        (snow_1h -7): pval = 0.00000 | val = 0.076 | conf = (0.000, 0.000)
        (snow_1h -2): pval = 0.00000 | val = -0.066 | conf = (0.000, 0.000)
        (snow_1h -8): pval = 0.00000 | val = -0.048 | conf = (0.000, 0.000)
        (snow_1h -3): pval = 0.00000 | val = 0.032 | conf = (0.000, 0.000)
        (traffic_volume -8): pval = 0.00003 | val = 0.019 | conf = (0.000, 0.000)
        (clouds_all -9): pval = 0.02553 | val = -0.010 | conf = (0.000, 0.000)
        (traffic_volume -3): pval = 0.03675 | val = -0.010 | conf = (0.000, 0.000)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">q_matrix</span> <span class="o">=</span> <span class="n">pcmci</span><span class="o">.</span><span class="n">get_corrected_pvalues</span><span class="p">(</span><span class="n">p_matrix</span><span class="o">=</span><span class="n">results</span><span class="p">[</span><span class="s1">&#39;p_matrix&#39;</span><span class="p">],</span> <span class="n">fdr_method</span><span class="o">=</span><span class="s1">&#39;fdr_bh&#39;</span><span class="p">)</span>
<span class="n">pcmci</span><span class="o">.</span><span class="n">print_significant_links</span><span class="p">(</span>
        <span class="n">p_matrix</span> <span class="o">=</span> <span class="n">results</span><span class="p">[</span><span class="s1">&#39;p_matrix&#39;</span><span class="p">],</span> 
        <span class="n">q_matrix</span> <span class="o">=</span> <span class="n">q_matrix</span><span class="p">,</span>
        <span class="n">val_matrix</span> <span class="o">=</span> <span class="n">results</span><span class="p">[</span><span class="s1">&#39;val_matrix&#39;</span><span class="p">],</span>
        <span class="n">alpha_level</span> <span class="o">=</span> <span class="mf">0.01</span><span class="p">)</span>

<span class="n">link_matrix</span> <span class="o">=</span> <span class="n">pcmci</span><span class="o">.</span><span class="n">return_significant_parents</span><span class="p">(</span><span class="n">pq_matrix</span><span class="o">=</span><span class="n">q_matrix</span><span class="p">,</span>
                        <span class="n">val_matrix</span><span class="o">=</span><span class="n">results</span><span class="p">[</span><span class="s1">&#39;val_matrix&#39;</span><span class="p">],</span> <span class="n">alpha_level</span><span class="o">=</span><span class="mf">0.01</span><span class="p">)[</span><span class="s1">&#39;link_matrix&#39;</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>## Significant links at alpha = 0.01:

    Variable traffic_volume has 17 link(s):
        (traffic_volume -1): pval = 0.00000 | qval = 0.00000 | val = 0.789
        (traffic_volume -2): pval = 0.00000 | qval = 0.00000 | val = -0.237
        (temp 0): pval = 0.00000 | qval = 0.00000 | val = 0.050
        (traffic_volume -3): pval = 0.00000 | qval = 0.00000 | val = -0.039
        (traffic_volume -6): pval = 0.00000 | qval = 0.00000 | val = -0.035
        (traffic_volume -10): pval = 0.00000 | qval = 0.00000 | val = -0.032
        (temp -1): pval = 0.00000 | qval = 0.00000 | val = 0.030
        (traffic_volume -9): pval = 0.00000 | qval = 0.00000 | val = 0.028
        (temp -9): pval = 0.00000 | qval = 0.00000 | val = -0.028
        (traffic_volume -5): pval = 0.00000 | qval = 0.00000 | val = 0.025
        (traffic_volume -8): pval = 0.00000 | qval = 0.00000 | val = 0.025
        (temp -8): pval = 0.00000 | qval = 0.00000 | val = -0.024
        (temp -7): pval = 0.00013 | qval = 0.00080 | val = -0.017
        (temp -5): pval = 0.00043 | qval = 0.00268 | val = -0.016
        (traffic_volume -7): pval = 0.00055 | qval = 0.00326 | val = -0.016
        (clouds_all -6): pval = 0.00087 | qval = 0.00504 | val = -0.015
        (clouds_all -1): pval = 0.00167 | qval = 0.00927 | val = 0.014

    Variable temp has 14 link(s):
        (temp -1): pval = 0.00000 | qval = 0.00000 | val = 0.726
        (temp -6): pval = 0.00000 | qval = 0.00000 | val = -0.206
        (temp -4): pval = 0.00000 | qval = 0.00000 | val = -0.197
        (temp -7): pval = 0.00000 | qval = 0.00000 | val = 0.195
        (temp -5): pval = 0.00000 | qval = 0.00000 | val = 0.188
        (temp -10): pval = 0.00000 | qval = 0.00000 | val = -0.113
        (temp -8): pval = 0.00000 | qval = 0.00000 | val = -0.092
        (temp -9): pval = 0.00000 | qval = 0.00000 | val = 0.081
        (temp -2): pval = 0.00000 | qval = 0.00000 | val = -0.069
        (temp -3): pval = 0.00000 | qval = 0.00000 | val = 0.052
        (traffic_volume 0): pval = 0.00000 | qval = 0.00000 | val = 0.050
        (traffic_volume -1): pval = 0.00000 | qval = 0.00000 | val = 0.043
        (clouds_all 0): pval = 0.00001 | qval = 0.00001 | val = 0.020
        (traffic_volume -10): pval = 0.00046 | qval = 0.00280 | val = -0.016

    Variable clouds_all has 7 link(s):
        (clouds_all -1): pval = 0.00000 | qval = 0.00000 | val = 0.534
        (clouds_all -2): pval = 0.00000 | qval = 0.00000 | val = 0.109
        (clouds_all -3): pval = 0.00000 | qval = 0.00000 | val = 0.043
        (traffic_volume -1): pval = 0.00001 | qval = 0.00006 | val = 0.020
        (temp 0): pval = 0.00001 | qval = 0.00001 | val = 0.020
        (clouds_all -4): pval = 0.00005 | qval = 0.00036 | val = 0.018
        (clouds_all -5): pval = 0.00123 | qval = 0.00701 | val = 0.015

    Variable rain_1h has 0 link(s):

    Variable snow_1h has 11 link(s):
        (snow_1h -1): pval = 0.00000 | qval = 0.00000 | val = 0.689
        (snow_1h -5): pval = 0.00000 | qval = 0.00000 | val = 0.166
        (snow_1h -4): pval = 0.00000 | qval = 0.00000 | val = -0.140
        (snow_1h -9): pval = 0.00000 | qval = 0.00000 | val = -0.113
        (snow_1h -6): pval = 0.00000 | qval = 0.00000 | val = -0.112
        (snow_1h -10): pval = 0.00000 | qval = 0.00000 | val = 0.080
        (snow_1h -7): pval = 0.00000 | qval = 0.00000 | val = 0.076
        (snow_1h -2): pval = 0.00000 | qval = 0.00000 | val = -0.066
        (snow_1h -8): pval = 0.00000 | qval = 0.00000 | val = -0.048
        (snow_1h -3): pval = 0.00000 | qval = 0.00000 | val = 0.032
        (traffic_volume -8): pval = 0.00003 | qval = 0.00023 | val = 0.019
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">tp</span><span class="o">.</span><span class="n">plot_graph</span><span class="p">(</span>
    <span class="n">val_matrix</span><span class="o">=</span><span class="n">results</span><span class="p">[</span><span class="s1">&#39;val_matrix&#39;</span><span class="p">],</span>
    <span class="n">link_matrix</span><span class="o">=</span><span class="n">link_matrix</span><span class="p">,</span>
    <span class="n">var_names</span><span class="o">=</span><span class="n">df</span><span class="o">.</span><span class="n">columns</span><span class="p">,</span>
    <span class="n">link_colorbar_label</span><span class="o">=</span><span class="s1">&#39;cross-MCI&#39;</span><span class="p">,</span>
    <span class="n">node_colorbar_label</span><span class="o">=</span><span class="s1">&#39;auto-MCI&#39;</span><span class="p">,</span>
    <span class="p">)</span>
<span class="c1">## left is node colour, right is edge colout</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(&lt;Figure size 432x288 with 3 Axes&gt;,
 &lt;matplotlib.axes._subplots.AxesSubplot at 0x7f3b97fc2668&gt;)
</pre></div>
</div>
<img alt="../_images/T990000_causal_inference_292_1.png" src="../_images/T990000_causal_inference_292_1.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Plot time series graph</span>
<span class="n">tp</span><span class="o">.</span><span class="n">plot_time_series_graph</span><span class="p">(</span>
    <span class="n">val_matrix</span><span class="o">=</span><span class="n">results</span><span class="p">[</span><span class="s1">&#39;val_matrix&#39;</span><span class="p">],</span>
    <span class="n">link_matrix</span><span class="o">=</span><span class="n">link_matrix</span><span class="p">,</span>
    <span class="n">var_names</span><span class="o">=</span><span class="n">df</span><span class="o">.</span><span class="n">columns</span><span class="p">,</span>
    <span class="n">link_colorbar_label</span><span class="o">=</span><span class="s1">&#39;MCI&#39;</span><span class="p">,</span>
    <span class="p">)</span>


<span class="c1"># A wider range of activities can be found here:</span>
<span class="c1"># https://github.com/jakobrunge/tigramite/blob/master/tutorials/tigramite_tutorial_basics.ipynb</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/T990000_causal_inference_293_0.png" src="../_images/T990000_causal_inference_293_0.png" />
</div>
</div>
</div>
<div class="section" id="cross-sectional-causal-discovery">
<h3>Cross-sectional Causal Discovery<a class="headerlink" href="#cross-sectional-causal-discovery" title="Permalink to this headline">¶</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>!pip install cdt
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Collecting cdt
?25l  Downloading https://files.pythonhosted.org/packages/ab/9a/00c6ed8a5e029271d92387cd3ae1130455f29cb4a1638231f4b7106690d7/cdt-0.5.14-py3-none-any.whl (917kB)

     |▍                               | 10kB 30.9MB/s eta 0:00:01
     |▊                               | 20kB 6.2MB/s eta 0:00:01
     |█                               | 30kB 8.8MB/s eta 0:00:01
     |█▍                              | 40kB 5.8MB/s eta 0:00:01
     |█▉                              | 51kB 7.1MB/s eta 0:00:01
     |██▏                             | 61kB 8.4MB/s eta 0:00:01
     |██▌                             | 71kB 9.6MB/s eta 0:00:01
     |██▉                             | 81kB 10.7MB/s eta 0:00:01
     |███▏                            | 92kB 11.9MB/s eta 0:00:01
     |███▋                            | 102kB 9.4MB/s eta 0:00:01
     |████                            | 112kB 9.4MB/s eta 0:00:01
     |████▎                           | 122kB 9.4MB/s eta 0:00:01
     |████▋                           | 133kB 9.4MB/s eta 0:00:01
     |█████                           | 143kB 9.4MB/s eta 0:00:01
     |█████▍                          | 153kB 9.4MB/s eta 0:00:01
     |█████▊                          | 163kB 9.4MB/s eta 0:00:01
     |██████                          | 174kB 9.4MB/s eta 0:00:01
     |██████▍                         | 184kB 9.4MB/s eta 0:00:01
     |██████▉                         | 194kB 9.4MB/s eta 0:00:01
     |███████▏                        | 204kB 9.4MB/s eta 0:00:01
     |███████▌                        | 215kB 9.4MB/s eta 0:00:01
     |███████▉                        | 225kB 9.4MB/s eta 0:00:01
     |████████▏                       | 235kB 9.4MB/s eta 0:00:01
     |████████▋                       | 245kB 9.4MB/s eta 0:00:01
     |█████████                       | 256kB 9.4MB/s eta 0:00:01
     |█████████▎                      | 266kB 9.4MB/s eta 0:00:01
     |█████████▋                      | 276kB 9.4MB/s eta 0:00:01
     |██████████                      | 286kB 9.4MB/s eta 0:00:01
     |██████████▍                     | 296kB 9.4MB/s eta 0:00:01
     |██████████▊                     | 307kB 9.4MB/s eta 0:00:01
     |███████████                     | 317kB 9.4MB/s eta 0:00:01
     |███████████▍                    | 327kB 9.4MB/s eta 0:00:01
     |███████████▉                    | 337kB 9.4MB/s eta 0:00:01
     |████████████▏                   | 348kB 9.4MB/s eta 0:00:01
     |████████████▌                   | 358kB 9.4MB/s eta 0:00:01
     |████████████▉                   | 368kB 9.4MB/s eta 0:00:01
     |█████████████▏                  | 378kB 9.4MB/s eta 0:00:01
     |█████████████▋                  | 389kB 9.4MB/s eta 0:00:01
     |██████████████                  | 399kB 9.4MB/s eta 0:00:01
     |██████████████▎                 | 409kB 9.4MB/s eta 0:00:01
     |██████████████▋                 | 419kB 9.4MB/s eta 0:00:01
     |███████████████                 | 430kB 9.4MB/s eta 0:00:01
     |███████████████▍                | 440kB 9.4MB/s eta 0:00:01
     |███████████████▊                | 450kB 9.4MB/s eta 0:00:01
     |████████████████                | 460kB 9.4MB/s eta 0:00:01
     |████████████████▍               | 471kB 9.4MB/s eta 0:00:01
     |████████████████▉               | 481kB 9.4MB/s eta 0:00:01
     |█████████████████▏              | 491kB 9.4MB/s eta 0:00:01
     |█████████████████▌              | 501kB 9.4MB/s eta 0:00:01
     |█████████████████▉              | 512kB 9.4MB/s eta 0:00:01
     |██████████████████▏             | 522kB 9.4MB/s eta 0:00:01
     |██████████████████▋             | 532kB 9.4MB/s eta 0:00:01
     |███████████████████             | 542kB 9.4MB/s eta 0:00:01
     |███████████████████▎            | 552kB 9.4MB/s eta 0:00:01
     |███████████████████▋            | 563kB 9.4MB/s eta 0:00:01
     |████████████████████            | 573kB 9.4MB/s eta 0:00:01
     |████████████████████▍           | 583kB 9.4MB/s eta 0:00:01
     |████████████████████▊           | 593kB 9.4MB/s eta 0:00:01
     |█████████████████████           | 604kB 9.4MB/s eta 0:00:01
     |█████████████████████▍          | 614kB 9.4MB/s eta 0:00:01
     |█████████████████████▊          | 624kB 9.4MB/s eta 0:00:01
     |██████████████████████▏         | 634kB 9.4MB/s eta 0:00:01
     |██████████████████████▌         | 645kB 9.4MB/s eta 0:00:01
     |██████████████████████▉         | 655kB 9.4MB/s eta 0:00:01
     |███████████████████████▏        | 665kB 9.4MB/s eta 0:00:01
     |███████████████████████▋        | 675kB 9.4MB/s eta 0:00:01
     |████████████████████████        | 686kB 9.4MB/s eta 0:00:01
     |████████████████████████▎       | 696kB 9.4MB/s eta 0:00:01
     |████████████████████████▋       | 706kB 9.4MB/s eta 0:00:01
     |█████████████████████████       | 716kB 9.4MB/s eta 0:00:01
     |█████████████████████████▍      | 727kB 9.4MB/s eta 0:00:01
     |█████████████████████████▊      | 737kB 9.4MB/s eta 0:00:01
     |██████████████████████████      | 747kB 9.4MB/s eta 0:00:01
     |██████████████████████████▍     | 757kB 9.4MB/s eta 0:00:01
     |██████████████████████████▊     | 768kB 9.4MB/s eta 0:00:01
     |███████████████████████████▏    | 778kB 9.4MB/s eta 0:00:01
     |███████████████████████████▌    | 788kB 9.4MB/s eta 0:00:01
     |███████████████████████████▉    | 798kB 9.4MB/s eta 0:00:01
     |████████████████████████████▏   | 808kB 9.4MB/s eta 0:00:01
     |████████████████████████████▋   | 819kB 9.4MB/s eta 0:00:01
     |█████████████████████████████   | 829kB 9.4MB/s eta 0:00:01
     |█████████████████████████████▎  | 839kB 9.4MB/s eta 0:00:01
     |█████████████████████████████▋  | 849kB 9.4MB/s eta 0:00:01
     |██████████████████████████████  | 860kB 9.4MB/s eta 0:00:01
     |██████████████████████████████▍ | 870kB 9.4MB/s eta 0:00:01
     |██████████████████████████████▊ | 880kB 9.4MB/s eta 0:00:01
     |███████████████████████████████ | 890kB 9.4MB/s eta 0:00:01
     |███████████████████████████████▍| 901kB 9.4MB/s eta 0:00:01
     |███████████████████████████████▊| 911kB 9.4MB/s eta 0:00:01
     |████████████████████████████████| 921kB 9.4MB/s 
?25hRequirement already satisfied: statsmodels in /usr/local/lib/python3.6/dist-packages (from cdt) (0.10.2)
Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from cdt) (0.14.0)
Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from cdt) (2.21.0)
Requirement already satisfied: networkx in /usr/local/lib/python3.6/dist-packages (from cdt) (2.4)
Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from cdt) (1.17.4)
Collecting GPUtil
  Downloading https://files.pythonhosted.org/packages/ed/0e/5c61eedde9f6c87713e89d794f01e378cfd9565847d4576fa627d758c554/GPUtil-1.4.0.tar.gz
Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from cdt) (0.25.3)
Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from cdt) (1.3.3)
Collecting skrebate
  Downloading https://files.pythonhosted.org/packages/7d/01/764fdd40b0e9f01624725c3cf1ffa00071fabb66b62d39fc2c28b34f3edb/skrebate-0.6.tar.gz
Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from cdt) (4.28.1)
Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from cdt) (0.21.3)
Requirement already satisfied: patsy&gt;=0.4.0 in /usr/local/lib/python3.6/dist-packages (from statsmodels-&gt;cdt) (0.5.1)
Requirement already satisfied: chardet&lt;3.1.0,&gt;=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests-&gt;cdt) (3.0.4)
Requirement already satisfied: urllib3&lt;1.25,&gt;=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests-&gt;cdt) (1.24.3)
Requirement already satisfied: certifi&gt;=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests-&gt;cdt) (2019.9.11)
Requirement already satisfied: idna&lt;2.9,&gt;=2.5 in /usr/local/lib/python3.6/dist-packages (from requests-&gt;cdt) (2.8)
Requirement already satisfied: decorator&gt;=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx-&gt;cdt) (4.4.1)
Requirement already satisfied: pytz&gt;=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas-&gt;cdt) (2018.9)
Requirement already satisfied: python-dateutil&gt;=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas-&gt;cdt) (2.6.1)
Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from patsy&gt;=0.4.0-&gt;statsmodels-&gt;cdt) (1.12.0)
Building wheels for collected packages: GPUtil, skrebate
  Building wheel for GPUtil (setup.py) ... ?25l?25hdone
  Created wheel for GPUtil: filename=GPUtil-1.4.0-cp36-none-any.whl size=7410 sha256=71391d031da52c0459ea26aac96f8941b6b23884fd285e1977899d28cb82093c
  Stored in directory: /root/.cache/pip/wheels/3d/77/07/80562de4bb0786e5ea186911a2c831fdd0018bda69beab71fd
  Building wheel for skrebate (setup.py) ... ?25l?25hdone
  Created wheel for skrebate: filename=skrebate-0.6-cp36-none-any.whl size=29329 sha256=a30226de478af52c60241e33889041d7153e0d65118d0acab404d6b6684b9cca
  Stored in directory: /root/.cache/pip/wheels/f5/99/36/c827bcfa6852c6d068895b2723c57cea84f93642270c6dc05c
Successfully built GPUtil skrebate
Installing collected packages: GPUtil, skrebate, cdt
Successfully installed GPUtil-1.4.0 cdt-0.5.14 skrebate-0.6
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1">#Import libraries</span>
<span class="kn">import</span> <span class="nn">cdt</span>
<span class="kn">from</span> <span class="nn">cdt</span> <span class="kn">import</span> <span class="n">SETTINGS</span>
<span class="n">SETTINGS</span><span class="o">.</span><span class="n">verbose</span><span class="o">=</span><span class="kc">False</span>
<span class="n">SETTINGS</span><span class="o">.</span><span class="n">NJOBS</span><span class="o">=</span><span class="mi">16</span>
<span class="kn">import</span> <span class="nn">networkx</span> <span class="k">as</span> <span class="nn">nx</span>
<span class="kn">import</span> <span class="nn">time</span>
<span class="c1"># A warning on R libraries might occur. It is for the use of the r libraries that could be imported into the framework</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">from</span> <span class="nn">matplotlib</span> <span class="kn">import</span> <span class="n">pyplot</span> <span class="k">as</span> <span class="n">plt</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Load data and graph solution</span>
<span class="n">data</span><span class="p">,</span> <span class="n">solution</span> <span class="o">=</span> <span class="n">cdt</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">load_dataset</span><span class="p">(</span><span class="s1">&#39;sachs&#39;</span><span class="p">)</span>
<span class="n">nx</span><span class="o">.</span><span class="n">draw_networkx</span><span class="p">(</span><span class="n">solution</span><span class="p">,</span> <span class="n">font_size</span><span class="o">=</span><span class="mi">8</span><span class="p">)</span> <span class="c1"># The plot function allows for quick visualization of the graph. </span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="n">data</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/T990000_causal_inference_297_0.png" src="../_images/T990000_causal_inference_297_0.png" />
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(7466, 11)
</pre></div>
</div>
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>praf</th>
      <th>pmek</th>
      <th>plcg</th>
      <th>PIP2</th>
      <th>PIP3</th>
      <th>p44/42</th>
      <th>pakts473</th>
      <th>PKA</th>
      <th>PKC</th>
      <th>P38</th>
      <th>pjnk</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>26.4</td>
      <td>13.2</td>
      <td>8.82</td>
      <td>18.30</td>
      <td>58.80</td>
      <td>6.61</td>
      <td>17.0</td>
      <td>414.0</td>
      <td>17.00</td>
      <td>44.9</td>
      <td>40.0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>35.9</td>
      <td>16.5</td>
      <td>12.30</td>
      <td>16.80</td>
      <td>8.13</td>
      <td>18.60</td>
      <td>32.5</td>
      <td>352.0</td>
      <td>3.37</td>
      <td>16.5</td>
      <td>61.5</td>
    </tr>
    <tr>
      <th>2</th>
      <td>59.4</td>
      <td>44.1</td>
      <td>14.60</td>
      <td>10.20</td>
      <td>13.00</td>
      <td>14.90</td>
      <td>32.5</td>
      <td>403.0</td>
      <td>11.40</td>
      <td>31.9</td>
      <td>19.5</td>
    </tr>
    <tr>
      <th>3</th>
      <td>73.0</td>
      <td>82.8</td>
      <td>23.10</td>
      <td>13.50</td>
      <td>1.29</td>
      <td>5.83</td>
      <td>11.8</td>
      <td>528.0</td>
      <td>13.70</td>
      <td>28.6</td>
      <td>23.1</td>
    </tr>
    <tr>
      <th>4</th>
      <td>33.7</td>
      <td>19.8</td>
      <td>5.19</td>
      <td>9.73</td>
      <td>24.80</td>
      <td>21.10</td>
      <td>46.1</td>
      <td>305.0</td>
      <td>4.66</td>
      <td>25.7</td>
      <td>81.3</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Finding the structure of the graph</span>
<span class="kn">from</span> <span class="nn">cdt.independence.graph</span> <span class="kn">import</span> <span class="n">FSGNN</span>

<span class="c1"># own data</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">&quot;https://raw.githubusercontent.com/firmai/random-assets/master/Metro_Interstate_Traffic_Volume.csv&quot;</span><span class="p">)</span>
<span class="n">df</span><span class="p">[</span><span class="s2">&quot;date_time&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">to_datetime</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s2">&quot;date_time&quot;</span><span class="p">])</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">set_index</span><span class="p">(</span><span class="s2">&quot;date_time&quot;</span><span class="p">)</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="p">[[</span><span class="s2">&quot;traffic_volume&quot;</span><span class="p">,</span> <span class="s2">&quot;temp&quot;</span><span class="p">,</span><span class="s2">&quot;clouds_all&quot;</span><span class="p">,</span><span class="s2">&quot;rain_1h&quot;</span><span class="p">,</span><span class="s2">&quot;snow_1h&quot;</span><span class="p">]]</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">2000</span><span class="p">)</span>

<span class="n">Fsgnn</span> <span class="o">=</span> <span class="n">FSGNN</span><span class="p">(</span><span class="n">train_epochs</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">test_epochs</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span> <span class="n">l1</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">1000</span><span class="p">)</span>

<span class="n">start_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">ugraph</span> <span class="o">=</span> <span class="n">Fsgnn</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">threshold</span><span class="o">=</span><span class="mf">1e-7</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;--- Execution time : </span><span class="si">%4.4s</span><span class="s2"> seconds ---&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">start_time</span><span class="p">))</span>
<span class="n">nx</span><span class="o">.</span><span class="n">draw_networkx</span><span class="p">(</span><span class="n">ugraph</span><span class="p">,</span> <span class="n">font_size</span><span class="o">=</span><span class="mi">8</span><span class="p">)</span> <span class="c1"># The plot function allows for quick visualization of the graph.</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
<span class="c1"># List results</span>
<span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">ugraph</span><span class="o">.</span><span class="n">edges</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="s1">&#39;weight&#39;</span><span class="p">)),</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;Cause&#39;</span><span class="p">,</span> <span class="s1">&#39;Effect&#39;</span><span class="p">,</span> <span class="s1">&#39;Score&#39;</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>--- Execution time : 563. seconds ---
</pre></div>
</div>
<img alt="../_images/T990000_causal_inference_299_1.png" src="../_images/T990000_causal_inference_299_1.png" />
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Cause</th>
      <th>Effect</th>
      <th>Score</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>clouds_all</td>
      <td>rain_1h</td>
      <td>3.594876e-07</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
</div>
</div>
<div class="section" id="id3">
<h2>Causal Inference<a class="headerlink" href="#id3" title="Permalink to this headline">¶</a></h2>
<p>One day a team lead notices that some members of their team wear cool hats, and that these members of the team tend to be less productive. Being data drive, the Team Lead starts to record whether or not a team member wears a cool hat (<span class="math notranslate nohighlight">\(X=1\)</span> for a cool hat, <span class="math notranslate nohighlight">\(X=0\)</span> for no cool hat) and whether or not they are productive (<span class="math notranslate nohighlight">\(Y=1\)</span> for productive, <span class="math notranslate nohighlight">\(Y=0\)</span> for unproductive).</p>
<p>After making observations for a week, they end up with a dataset like the following:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>!git clone https://github.com/ijmbarr/notes-on-causal-inference.git
# % to switch directory 
%cd notes-on-causal-inference
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Cloning into &#39;notes-on-causal-inference&#39;...
remote: Enumerating objects: 46, done.
remote: Total 46 (delta 0), reused 0 (delta 0), pack-reused 46
Unpacking objects: 100% (46/46), done.
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">__future__</span> <span class="kn">import</span> <span class="n">division</span>
<span class="kn">import</span> <span class="nn">datagenerators</span> <span class="k">as</span> <span class="nn">dg</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>

<span class="n">sns</span><span class="o">.</span><span class="n">set_style</span><span class="p">(</span><span class="s2">&quot;whitegrid&quot;</span><span class="p">)</span>
<span class="n">sns</span><span class="o">.</span><span class="n">set_palette</span><span class="p">(</span><span class="s2">&quot;colorblind&quot;</span><span class="p">)</span>

<span class="o">%</span><span class="n">matplotlib</span> <span class="n">inline</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">observed_data_0</span> <span class="o">=</span> <span class="n">dg</span><span class="o">.</span><span class="n">generate_dataset_0</span><span class="p">()</span>
<span class="n">observed_data_0</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>x</th>
      <th>y</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>1</td>
      <td>1</td>
    </tr>
    <tr>
      <th>3</th>
      <td>1</td>
      <td>1</td>
    </tr>
    <tr>
      <th>4</th>
      <td>1</td>
      <td>1</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>The first question the team lead asks is: are people wearing cool hats more likely to be productive that those who don’t? This means estimating the quantity</p>
<p>𝑃(𝑌=1|𝑋=1)−(𝑌=1|𝑋=0)</p>
<p>which we can do directly from the data:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">estimate_uplift</span><span class="p">(</span><span class="n">ds</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Estimate the difference in means between two groups.</span>
<span class="sd">    This is closer related to the z and t tests </span>
<span class="sd">    </span>
<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    ds: pandas.DataFrame</span>
<span class="sd">        a dataframe of samples.</span>
<span class="sd">        </span>
<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    estimated_uplift: dict[Str: float] containing two items:</span>
<span class="sd">        &quot;estimated_effect&quot; - the difference in mean values of $y$ for treated and untreated samples.</span>
<span class="sd">        &quot;standard_error&quot; - 90% confidence intervals arround &quot;estimated_effect&quot;</span>
<span class="sd">        </span>
<span class="sd">        </span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">base</span> <span class="o">=</span> <span class="n">ds</span><span class="p">[</span><span class="n">ds</span><span class="o">.</span><span class="n">x</span> <span class="o">==</span> <span class="mi">0</span><span class="p">]</span>
    <span class="n">variant</span> <span class="o">=</span> <span class="n">ds</span><span class="p">[</span><span class="n">ds</span><span class="o">.</span><span class="n">x</span> <span class="o">==</span> <span class="mi">1</span><span class="p">]</span>
    
    <span class="n">delta</span> <span class="o">=</span> <span class="n">variant</span><span class="o">.</span><span class="n">y</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span> <span class="o">-</span> <span class="n">base</span><span class="o">.</span><span class="n">y</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
    <span class="n">delta_err</span> <span class="o">=</span> <span class="mf">1.96</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span>
        <span class="n">variant</span><span class="o">.</span><span class="n">y</span><span class="o">.</span><span class="n">var</span><span class="p">()</span> <span class="o">/</span> <span class="n">variant</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> 
        <span class="n">base</span><span class="o">.</span><span class="n">y</span><span class="o">.</span><span class="n">var</span><span class="p">()</span> <span class="o">/</span> <span class="n">base</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
    
    <span class="k">return</span> <span class="p">{</span><span class="s2">&quot;estimated_effect&quot;</span><span class="p">:</span> <span class="n">delta</span><span class="p">,</span> <span class="s2">&quot;standard_error&quot;</span><span class="p">:</span> <span class="n">delta_err</span><span class="p">}</span>

<span class="n">estimate_uplift</span><span class="p">(</span><span class="n">observed_data_0</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>{&#39;estimated_effect&#39;: -0.10276997189883585,
 &#39;standard_error&#39;: 0.08740397960545142}
</pre></div>
</div>
</div>
</div>
<p>It looks like people with cool hats are less <a class="reference external" href="http://productive.To">productive.To</a> be sure, we can run a statistical test:</p>
<p>A chi-square test tests a null hypothesis about the relationship between two variables. For example, you could test the hypothesis that men and women are equally likely to vote “Democratic,” “Republican,” “Other” or “not at all.” A chi-square test requires categorical variables, usually only two, but each may have any number of levels, whereas A t-test requires two variables; one must be categorical and have exactly two levels, and the other must be quantitative and be estimable by a mean.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">scipy.stats</span> <span class="kn">import</span> <span class="n">chi2_contingency</span>

<span class="n">contingency_table</span> <span class="o">=</span> <span class="p">(</span>
    <span class="n">observed_data_0</span>
    <span class="o">.</span><span class="n">assign</span><span class="p">(</span><span class="n">placeholder</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="o">.</span><span class="n">pivot_table</span><span class="p">(</span><span class="n">index</span><span class="o">=</span><span class="s2">&quot;x&quot;</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="s2">&quot;y&quot;</span><span class="p">,</span> <span class="n">values</span><span class="o">=</span><span class="s2">&quot;placeholder&quot;</span><span class="p">,</span> <span class="n">aggfunc</span><span class="o">=</span><span class="s2">&quot;sum&quot;</span><span class="p">)</span>
    <span class="o">.</span><span class="n">values</span>
<span class="p">)</span>

<span class="n">_</span><span class="p">,</span> <span class="n">p</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">chi2_contingency</span><span class="p">(</span><span class="n">contingency_table</span><span class="p">,</span> <span class="n">lambda_</span><span class="o">=</span><span class="s2">&quot;log-likelihood&quot;</span><span class="p">)</span>

<span class="c1"># p-value</span>
<span class="n">p</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.027229350677741307
</pre></div>
</div>
</div>
</div>
<p>The p-value is low enough to accept the null hyothesis. The problem is that it has not been randomly assigned as a controlled experiment, and instead uses observational data, we can create a fake experiment to assign a hat randomly and it could be possibly show the opposite effect.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1">## Dont take this too seriously, created to show how random allocation showed opposite effect</span>
<span class="c1">## .. the idea being that confounders have now been removed.</span>
<span class="c1">## This is simply running the experiment, generating the data and</span>
<span class="c1">## identifying the results</span>
<span class="k">def</span> <span class="nf">run_ab_test</span><span class="p">(</span><span class="n">datagenerator</span><span class="p">,</span> <span class="n">n_samples</span><span class="o">=</span><span class="mi">10000</span><span class="p">,</span> <span class="n">filter_</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Generates n_samples from datagenerator with the value of X randomized</span>
<span class="sd">    so that 50% of the samples recieve treatment X=1 and 50% receive X=0,</span>
<span class="sd">    and feeds the results into `estimate_uplift` to get an unbiased </span>
<span class="sd">    estimate of the average treatment effect.</span>
<span class="sd">    </span>
<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    effect: dict</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">n_samples_a</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">n_samples</span> <span class="o">/</span> <span class="mi">2</span><span class="p">)</span>
    <span class="n">n_samples_b</span> <span class="o">=</span> <span class="n">n_samples</span> <span class="o">-</span> <span class="n">n_samples_a</span>
    <span class="n">set_X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">n_samples_a</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n_samples_b</span><span class="p">)])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">int64</span><span class="p">)</span>
    <span class="n">ds</span> <span class="o">=</span> <span class="n">datagenerator</span><span class="p">(</span><span class="n">n_samples</span><span class="o">=</span><span class="n">n_samples</span><span class="p">,</span> <span class="n">set_X</span><span class="o">=</span><span class="n">set_X</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">filter_</span> <span class="o">!=</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">ds</span> <span class="o">=</span> <span class="n">ds</span><span class="p">[</span><span class="n">filter_</span><span class="p">(</span><span class="n">ds</span><span class="p">)]</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">estimate_uplift</span><span class="p">(</span><span class="n">ds</span><span class="p">)</span>

<span class="n">run_ab_test</span><span class="p">(</span><span class="n">dg</span><span class="o">.</span><span class="n">generate_dataset_0</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>{&#39;estimated_effect&#39;: 0.19519999999999998,
 &#39;standard_error&#39;: 0.019224808009126987}
</pre></div>
</div>
</div>
</div>
<p>So the opposite seems to be true. Note: In the above example, and in all following examples, I’m assuming that our samples are i.i.d., and obey the Stable unit treatment value assumption (SUTVA). Basically this means that when one person chooses, or is forced to wear a really cool hat they have no influence on the choice or effect of another person wearing a really cool hat.</p>
<p>In the previous example, when we make no intervention on the system, we have an observational distribution of <span class="math notranslate nohighlight">\(Y\)</span>, conditioned on the fact we observe <span class="math notranslate nohighlight">\(X\)</span>:</p>
<p><span class="math notranslate nohighlight">\(P(Y|X)\)</span></p>
<p>When we force people to wear cool hats, we are making an intervention. The distribution of <span class="math notranslate nohighlight">\(Y\)</span> is then given by the <em>interventional</em> distribution</p>
<p><span class="math notranslate nohighlight">\(P(Y|\hbox{do}(X))\)</span></p>
<p>In general these two are not the same.</p>
<p>The question these notes will try and answer is how we can reason about the interventional distribution, when we only have access to observational data.</p>
<p>This is a useful question because there are lots of situations where running an A/B test to directly measure the effects of an intervention is impractical, unfeasable or unethical. In these situations we still want to be able to say something about what the effect of an intervention is - to do this we need to make some assumptions about the data generating process we are investigating.</p>
</div>
<div class="section" id="potential-outcomes">
<h2>Potential Outcomes<a class="headerlink" href="#potential-outcomes" title="Permalink to this headline">¶</a></h2>
<p>One way to approach this problem is to introduce two new random variables to our system: <span class="math notranslate nohighlight">\(Y_{0}\)</span> and <span class="math notranslate nohighlight">\(Y_{1}\)</span>, known as the Potential Outcomes. We imagine that these variables exist, and can be treated as any other random variable - the only difference is that they are never directly observed. <span class="math notranslate nohighlight">\(Y\)</span> is defined in terms of</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(Y = Y_{1}\)</span> when <span class="math notranslate nohighlight">\(X=1\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(Y = Y_{0}\)</span> when <span class="math notranslate nohighlight">\(X=0\)</span></p></li>
</ul>
<p>This shifts the problem from one about how distributions change under the intervention, to one about data drawn i.i.d. from some underlying distribution with missing values. Under certain assumptions about why values are missing, there is well developed theory about how to estimate the missing values.</p>
</div>
<div class="section" id="goals">
<h2>Goals<a class="headerlink" href="#goals" title="Permalink to this headline">¶</a></h2>
<p>Often we do not care about the full interventional distribution, <span class="math notranslate nohighlight">\(P(Y|\hbox{do}(X))\)</span>, and it is enough to have an estimate of the difference in means between the two groups. This is a quantity known as the Average Treatment Effect:</p>
<p><span class="math notranslate nohighlight">\(\Delta = E[Y_{1} - Y_{0}]\)</span></p>
<p>When we run and A/B test and compare the means of each group, this is directly the quantity we are measuring</p>
<p>Two related quantities are</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(ATT = E[Y_{1} - Y_{0}|X=1]\)</span>, the “Average Treatment effect of the Treated”</p></li>
<li><p><span class="math notranslate nohighlight">\(ATC = E[Y_{1} - Y_{0}|X=0]\)</span>, the “Average Treatment effect of the Control”</p></li>
</ul>
<p>One way to interpret ATC is as a measure of the effect of treating only samples which wouldn’t naturally be treated, and vice versa for ATT. Depending on your use case, they may be more natural measures of what you care about. The following techniques will allow us to estimate them all.</p>
<p><span class="math notranslate nohighlight">\(\def\ci{\perp\!\!\!\perp}\)</span></p>
</div>
<div class="section" id="making-assumptions">
<h2>Making Assumptions<a class="headerlink" href="#making-assumptions" title="Permalink to this headline">¶</a></h2>
<p>When we A/B test, we randomize the assignment of <span class="math notranslate nohighlight">\(X\)</span>. This has the effect of allowing us to choose which variable of <span class="math notranslate nohighlight">\(Y_{1}\)</span> or <span class="math notranslate nohighlight">\(Y_{0}\)</span> is revealed to us. This makes the outcome independent of the value of <span class="math notranslate nohighlight">\(X\)</span>. We write this as</p>
<p><span class="math notranslate nohighlight">\(Y_{1}, Y_{0} \ci X\)</span></p>
<p>Which means that the distribution of <span class="math notranslate nohighlight">\(X, Y_{0}, Y_{1}\)</span> factorizes as</p>
<p><span class="math notranslate nohighlight">\(P(X, Y_{0}, Y_{1}) = P(X)P(Y_{0}, Y_{1})\)</span></p>
<p>If this independence holds then</p>
<p><span class="math notranslate nohighlight">\(E[Y_{1}|X=1] = E[Y_{1}]\)</span></p>
<p>If we want to estimate the ATE using observational data, we need to use other information we have about the samples - specifically we need to <strong>assume</strong> that we have enough additional information to completely explain the choice of treatment each subject.</p>
<p>If we call the additional information the random variable <span class="math notranslate nohighlight">\(Z\)</span>, we can write this assumption as</p>
<p><span class="math notranslate nohighlight">\(Y_{1}, Y_{0} \ci X \, | \, Z\)</span></p>
<p>or</p>
<p><span class="math notranslate nohighlight">\(P(X, Y_{0}, Y_{1}| Z) = P(X|Z)P(Y_{0}, Y_{1}|Z)\)</span></p>
<p>This means that the observed treatment a sample receives, <span class="math notranslate nohighlight">\(X\)</span>, is completely explained by <span class="math notranslate nohighlight">\(Z\)</span>. This is sometimes called the “ignorability” assumption.</p>
<p>In our motivating example about cool hats this would mean that there is some other factor - let’s call it “skill” - which impacts both the productivity of the person and whether or not they wear a cool hat. In our example above, skilled people are more likely to be productive and also less likely to were cool hats. These facts together <em>could</em> explain why the effect of cool hats seemed to reverse when ran an A/B test.</p>
<p>If we split our data on whether or not the person is skilled, we find that for each subgroup there is a positive relationship between wearing cool hats and productivity:</p>
<p>Unfortuntly, because we never observe <span class="math notranslate nohighlight">\(Y_{0}\)</span> and <span class="math notranslate nohighlight">\(Y_{1}\)</span> for the same sample, we cannot test the assumption that</p>
<p><span class="math notranslate nohighlight">\(Y_{1}, Y_{0} \ci X \, | \, Z\)</span></p>
<p>It is something we have to use our knownledge of the system we are investigating to evaluate.</p>
<p>The quality of any prediction you make depends on exactly how well this assumption holds. Simpson’s Paradox is an extreme example of the fact that if <span class="math notranslate nohighlight">\(Z\)</span> does not give contain all confounding variables, then any inference we make could be wrong. <a class="reference external" href="https://www.kellogg.northwestern.edu/faculty/gordon_b/files/kellogg_fb_whitepaper.pdf">Facebook have a good paper comparing different causal inference approaches with direct A/B test that show how effects can be overestimated when conditional independence doesn’t hold</a>.</p>
<p>Once we have made this assumption there are a number of techniques for approaching this. I will outline a few of simpler approaches in the rest of the post, but keep in mind that this is a area of ongoing research. In human speak you can investigate the counterfactual with an additional variable, but you should trust this apprach less than interventionist studies.</p>
</div>
<div class="section" id="modeling-the-counterfactual">
<h2>Modeling the Counterfactual<a class="headerlink" href="#modeling-the-counterfactual" title="Permalink to this headline">¶</a></h2>
<p>From the above, it should be clear that if know <span class="math notranslate nohighlight">\(Y_{0}\)</span> and <span class="math notranslate nohighlight">\(Y_{1}\)</span>, we can estimate the ATE. So why not just try and model them directly? Specifically we can build estimators:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\hat{Y}_{0}(Z) = E[Y|Z, X=0]\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(\hat{Y}_{1}(Z) = E[Y|Z, X=1]\)</span>.</p></li>
</ul>
<p>If we can model these two quantities, we can estimate the ATE as:</p>
<p><span class="math notranslate nohighlight">\(\Delta = \frac{1}{N}\sum_{i}(\hat{Y}_{1}(z_{i}) - \hat{Y}_{0}(z_{i}))\)</span></p>
<p>The success of this approach depends on how well we can model the potential outcomes. To see it in action, let’s use the following data generating process:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">observed_data_1</span> <span class="o">=</span> <span class="n">dg</span><span class="o">.</span><span class="n">generate_dataset_1</span><span class="p">()</span>

<span class="n">observed_data_1</span><span class="o">.</span><span class="n">plot</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="s2">&quot;z&quot;</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s2">&quot;y&quot;</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s2">&quot;x&quot;</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s2">&quot;rainbow&quot;</span><span class="p">,</span> <span class="n">colorbar</span><span class="o">=</span><span class="kc">False</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/T990000_causal_inference_316_0.png" src="../_images/T990000_causal_inference_316_0.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">sns</span><span class="o">.</span><span class="n">kdeplot</span><span class="p">(</span><span class="n">observed_data_1</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="k">lambda</span> <span class="n">df</span><span class="p">:</span> <span class="n">df</span><span class="o">.</span><span class="n">x</span> <span class="o">==</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">y</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;untreated&quot;</span><span class="p">)</span>
<span class="n">sns</span><span class="o">.</span><span class="n">kdeplot</span><span class="p">(</span><span class="n">observed_data_1</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="k">lambda</span> <span class="n">df</span><span class="p">:</span> <span class="n">df</span><span class="o">.</span><span class="n">x</span> <span class="o">==</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">y</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;treated&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;matplotlib.axes._subplots.AxesSubplot at 0x7f64f3a0dac8&gt;
</pre></div>
</div>
<img alt="../_images/T990000_causal_inference_317_1.png" src="../_images/T990000_causal_inference_317_1.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># We can confirm this by looking at the difference in means between the two groups</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Observed ATE: </span><span class="si">{estimated_effect:.3f}</span><span class="s2"> (</span><span class="si">{standard_error:.3f}</span><span class="s2">)&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="o">**</span><span class="n">estimate_uplift</span><span class="p">(</span><span class="n">observed_data_1</span><span class="p">)))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Observed ATE: 0.207 (0.101)
</pre></div>
</div>
</div>
</div>
<p>However, if we look at the distribution of the covariance, 𝑍, it is clear that there is a difference between the groups.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">sns</span><span class="o">.</span><span class="n">kdeplot</span><span class="p">(</span><span class="n">observed_data_1</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="k">lambda</span> <span class="n">df</span><span class="p">:</span> <span class="n">df</span><span class="o">.</span><span class="n">x</span> <span class="o">==</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">z</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;untreated&quot;</span><span class="p">)</span>
<span class="n">sns</span><span class="o">.</span><span class="n">kdeplot</span><span class="p">(</span><span class="n">observed_data_1</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="k">lambda</span> <span class="n">df</span><span class="p">:</span> <span class="n">df</span><span class="o">.</span><span class="n">x</span> <span class="o">==</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">z</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;treated&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;matplotlib.axes._subplots.AxesSubplot at 0x7f64f3519208&gt;
</pre></div>
</div>
<img alt="../_images/T990000_causal_inference_320_1.png" src="../_images/T990000_causal_inference_320_1.png" />
</div>
</div>
<p>If we believe that <span class="math notranslate nohighlight">\(Z\)</span> has some influence on the metric <span class="math notranslate nohighlight">\(Y\)</span>, this should concern us. We need some way to disentangle the effect of <span class="math notranslate nohighlight">\(X\)</span> on <span class="math notranslate nohighlight">\(Y\)</span> and the effect of <span class="math notranslate nohighlight">\(Z\)</span> on <span class="math notranslate nohighlight">\(Y\)</span>.</p>
<p>We can check the actually ATE using our simulated A/B test and confirm that it is difference of the observed value:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Real ATE:  </span><span class="si">{estimated_effect:.3f}</span><span class="s2"> (</span><span class="si">{standard_error:.3f}</span><span class="s2">)&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="o">**</span><span class="n">run_ab_test</span><span class="p">(</span><span class="n">dg</span><span class="o">.</span><span class="n">generate_dataset_1</span><span class="p">)))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Real ATE:  -0.497 (0.026)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1">## Interesting - https://colab.research.google.com/drive/1juY2A4SVR1-nZzLX__zwOjHy_SvLBcaD#scrollTo=vR-1V8w5rN3m</span>
<span class="c1">## Expansion with similar framewokr - http://www.degeneratestate.org/posts/2018/Jul/10/causal-inference-with-python-part-2-causal-graphical-models/</span>
<span class="c1">## https://github.com/microsoft/EconML</span>
<span class="c1">## You can follow through with this if you do the naming convention</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./nbs"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        
            



<div class='prev-next-bottom'>
    
    <div id="prev">
        <a class="left-prev" href="T990000_build_a_kubeflow_pipeline.html" title="previous page">
            <i class="prevnext-label fas fa-angle-left"></i>
            <div class="prevnext-info">
                <p class="prevnext-label">previous</p>
                <p class="prevnext-title">Build a Kubeflow Pipeline</p>
            </div>
        </a>
    </div>
     <div id="next">
        <a class="right-next" href="T990000_concept_embedding_nlp.html" title="next page">
            <div class="prevnext-info">
                <p class="prevnext-label">next</p>
                <p class="prevnext-title">Exploring Word Embeddings</p>
            </div>
            <i class="prevnext-label fas fa-angle-right"></i>
        </a>
     </div>

</div>
        
        </div>
    </div>
    <footer class="footer">
    <div class="container">
      <p>
        
          By Sparsh A.<br/>
        
            &copy; Copyright 2021.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>
  
  <script src="../_static/js/index.1c5a1a01449ed65a7b51.js"></script>

  
  </body>
</html>